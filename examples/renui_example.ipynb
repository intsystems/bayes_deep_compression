{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sasha/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Optional\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../src', '/home/sasha/BMM/bayes_deep_compression/examples', '/home/sasha/anaconda3/lib/python311.zip', '/home/sasha/anaconda3/lib/python3.11', '/home/sasha/anaconda3/lib/python3.11/lib-dynload', '', '/home/sasha/anaconda3/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, \"../src\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier(nn.Module): \n",
    "    def __init__(self, classes: int = 10): \n",
    "        super().__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) \n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        #self.dropout1 = nn.Dropout2d(0.25) \n",
    "        #self.dropout2 = nn.Dropout2d(0.5) \n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128) \n",
    "        self.fc2 = nn.Linear(128, classes) \n",
    "  \n",
    "    def forward(self, x): \n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        #x = self.dropout1(x) \n",
    "        x = self.pool(F.relu(self.conv2(x))) \n",
    "        #x = self.dropout2(x) \n",
    "        x = x.view(-1, 64 * 7 * 7) \n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.fc2(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayescomp.bayes.variational.net import VarBayesModuleNet\n",
    "from bayescomp.bayes.variational.net import NormalVarBayesModule\n",
    "from bayescomp.bayes.variational.optimization_renui import VarRenuiLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayescomp.bayes.variational.trainer import VarBayesTrainer, VarTrainerParams, Beta_Scheduler_Plato, CallbackLossAccuracy\n",
    "from bayescomp.bayes.variational.trainer import Beta_Scheduler\n",
    "from bayescomp.report.base import ReportChain\n",
    "from bayescomp.report.variational import VarBaseReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5de1c29817d4b609e18fb40168a43e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000],Loss:4241.04736328125, KL Loss: 186135.578125. FitLoss: 2535.42529296875,Accuracy:0.10341249999999999,Validation Loss:4131.306640625,Validation Accuracy:0.097, Prune parameters: 621.0/421642,Beta: 0.01\n",
      "Epoch [2/1000],Loss:4171.94482421875, KL Loss: 186274.6875. FitLoss: 2443.8427734375,Accuracy:0.11176250000000001,Validation Loss:4109.03564453125,Validation Accuracy:0.129, Prune parameters: 623.0/421642,Beta: 0.01\n",
      "Epoch [3/1000],Loss:4096.3388671875, KL Loss: 186383.625. FitLoss: 2342.326904296875,Accuracy:0.14002500000000004,Validation Loss:4069.18994140625,Validation Accuracy:0.339, Prune parameters: 635.0/421642,Beta: 0.01\n",
      "Epoch [4/1000],Loss:4032.044189453125, KL Loss: 186549.625. FitLoss: 2277.48095703125,Accuracy:0.15331250000000005,Validation Loss:3972.56298828125,Validation Accuracy:0.446, Prune parameters: 642.0/421642,Beta: 0.01\n",
      "Epoch [5/1000],Loss:3943.364501953125, KL Loss: 186803.6875. FitLoss: 2192.447265625,Accuracy:0.20112499999999991,Validation Loss:3815.319580078125,Validation Accuracy:0.512, Prune parameters: 659.0/421642,Beta: 0.01\n",
      "Epoch [6/1000],Loss:3792.97802734375, KL Loss: 186860.015625. FitLoss: 2067.364990234375,Accuracy:0.2665624999999999,Validation Loss:3608.87744140625,Validation Accuracy:0.538, Prune parameters: 641.0/421642,Beta: 0.01\n",
      "Epoch [7/1000],Loss:3604.24267578125, KL Loss: 187105.9375. FitLoss: 1993.514404296875,Accuracy:0.2975875,Validation Loss:3342.140869140625,Validation Accuracy:0.52, Prune parameters: 621.0/421642,Beta: 0.01\n",
      "Epoch [8/1000],Loss:3451.096435546875, KL Loss: 187417.640625. FitLoss: 1891.8646240234375,Accuracy:0.3519125000000001,Validation Loss:3116.740478515625,Validation Accuracy:0.563, Prune parameters: 627.0/421642,Beta: 0.01\n",
      "Epoch [9/1000],Loss:3341.56005859375, KL Loss: 187664.28125. FitLoss: 1884.2861328125,Accuracy:0.3990625,Validation Loss:2938.752685546875,Validation Accuracy:0.643, Prune parameters: 605.0/421642,Beta: 0.01\n",
      "Epoch [10/1000],Loss:3237.941162109375, KL Loss: 188059.328125. FitLoss: 1747.7186279296875,Accuracy:0.4436750000000001,Validation Loss:2838.106201171875,Validation Accuracy:0.697, Prune parameters: 595.0/421642,Beta: 0.01\n",
      "Epoch [11/1000],Loss:3182.3984375, KL Loss: 188177.546875. FitLoss: 1727.9449462890625,Accuracy:0.45781250000000007,Validation Loss:2802.737060546875,Validation Accuracy:0.704, Prune parameters: 594.0/421642,Beta: 0.01\n",
      "Epoch [12/1000],Loss:3074.638671875, KL Loss: 188435.546875. FitLoss: 1547.1405029296875,Accuracy:0.4970375000000001,Validation Loss:2707.118896484375,Validation Accuracy:0.749, Prune parameters: 556.0/421642,Beta: 0.01\n",
      "Epoch [13/1000],Loss:2926.839599609375, KL Loss: 188694.625. FitLoss: 1415.994873046875,Accuracy:0.5271125000000001,Validation Loss:2687.325927734375,Validation Accuracy:0.73, Prune parameters: 549.0/421642,Beta: 0.01\n",
      "Epoch [14/1000],Loss:2853.246337890625, KL Loss: 188894.796875. FitLoss: 1321.1220703125,Accuracy:0.5554500000000003,Validation Loss:2600.0029296875,Validation Accuracy:0.766, Prune parameters: 563.0/421642,Beta: 0.01\n",
      "Epoch [15/1000],Loss:2863.374267578125, KL Loss: 189092.046875. FitLoss: 1393.558349609375,Accuracy:0.5562625,Validation Loss:2527.1240234375,Validation Accuracy:0.777, Prune parameters: 534.0/421642,Beta: 0.01\n",
      "Epoch [16/1000],Loss:2811.73583984375, KL Loss: 189310.46875. FitLoss: 1221.154541015625,Accuracy:0.6056500000000001,Validation Loss:2577.65576171875,Validation Accuracy:0.741, Prune parameters: 551.0/421642,Beta: 0.01\n",
      "Epoch [17/1000],Loss:2751.4541015625, KL Loss: 189565.3125. FitLoss: 1141.272216796875,Accuracy:0.6291625,Validation Loss:2461.278076171875,Validation Accuracy:0.832, Prune parameters: 555.0/421642,Beta: 0.01\n",
      "Epoch [18/1000],Loss:2672.0869140625, KL Loss: 189706.515625. FitLoss: 1125.86181640625,Accuracy:0.6310625000000001,Validation Loss:2458.654541015625,Validation Accuracy:0.809, Prune parameters: 560.0/421642,Beta: 0.01\n",
      "Epoch [19/1000],Loss:2685.209228515625, KL Loss: 189896.03125. FitLoss: 1122.2371826171875,Accuracy:0.6193125000000002,Validation Loss:2451.890380859375,Validation Accuracy:0.805, Prune parameters: 532.0/421642,Beta: 0.01\n",
      "Epoch [20/1000],Loss:2631.8291015625, KL Loss: 190058.46875. FitLoss: 970.3045654296875,Accuracy:0.6773750000000002,Validation Loss:2379.357666015625,Validation Accuracy:0.846, Prune parameters: 559.0/421642,Beta: 0.01\n",
      "Epoch [21/1000],Loss:2630.5703125, KL Loss: 190238.875. FitLoss: 985.3114624023438,Accuracy:0.6786874999999997,Validation Loss:2375.86376953125,Validation Accuracy:0.828, Prune parameters: 510.0/421642,Beta: 0.01\n",
      "Epoch [22/1000],Loss:2552.42822265625, KL Loss: 190368.71875. FitLoss: 847.657958984375,Accuracy:0.7152375,Validation Loss:2321.36181640625,Validation Accuracy:0.869, Prune parameters: 557.0/421642,Beta: 0.01\n",
      "Epoch [23/1000],Loss:2512.448974609375, KL Loss: 190511.03125. FitLoss: 846.16796875,Accuracy:0.7136,Validation Loss:2315.451904296875,Validation Accuracy:0.888, Prune parameters: 533.0/421642,Beta: 0.01\n",
      "Epoch [24/1000],Loss:2491.41796875, KL Loss: 190785.625. FitLoss: 850.0806274414062,Accuracy:0.7180249999999999,Validation Loss:2297.024169921875,Validation Accuracy:0.892, Prune parameters: 551.0/421642,Beta: 0.01\n",
      "Epoch [25/1000],Loss:2457.84814453125, KL Loss: 190890.28125. FitLoss: 733.9934692382812,Accuracy:0.7542000000000001,Validation Loss:2267.843994140625,Validation Accuracy:0.903, Prune parameters: 510.0/421642,Beta: 0.01\n",
      "Epoch [26/1000],Loss:2445.22705078125, KL Loss: 191063.171875. FitLoss: 721.0421142578125,Accuracy:0.76075,Validation Loss:2269.08837890625,Validation Accuracy:0.886, Prune parameters: 549.0/421642,Beta: 0.01\n",
      "Epoch [27/1000],Loss:2444.6689453125, KL Loss: 191211.5. FitLoss: 721.97705078125,Accuracy:0.7578125000000002,Validation Loss:2245.358154296875,Validation Accuracy:0.901, Prune parameters: 539.0/421642,Beta: 0.01\n",
      "Epoch [28/1000],Loss:2396.90625, KL Loss: 191373.109375. FitLoss: 669.1310424804688,Accuracy:0.7785374999999998,Validation Loss:2230.473388671875,Validation Accuracy:0.904, Prune parameters: 533.0/421642,Beta: 0.01\n",
      "Epoch [29/1000],Loss:2386.78271484375, KL Loss: 191490.890625. FitLoss: 647.9384155273438,Accuracy:0.7891875,Validation Loss:2207.608154296875,Validation Accuracy:0.919, Prune parameters: 495.0/421642,Beta: 0.01\n",
      "Epoch [30/1000],Loss:2382.09765625, KL Loss: 191647.46875. FitLoss: 609.3800048828125,Accuracy:0.8000875000000003,Validation Loss:2189.466796875,Validation Accuracy:0.917, Prune parameters: 488.0/421642,Beta: 0.01\n",
      "Epoch [31/1000],Loss:2371.105712890625, KL Loss: 191728.03125. FitLoss: 601.3953857421875,Accuracy:0.7983250000000001,Validation Loss:2228.3935546875,Validation Accuracy:0.89, Prune parameters: 470.0/421642,Beta: 0.01\n",
      "Epoch [32/1000],Loss:2352.86083984375, KL Loss: 191894.15625. FitLoss: 588.8280639648438,Accuracy:0.8056125000000003,Validation Loss:2174.627685546875,Validation Accuracy:0.927, Prune parameters: 484.0/421642,Beta: 0.01\n",
      "Epoch [33/1000],Loss:2302.775634765625, KL Loss: 192062.171875. FitLoss: 519.8632202148438,Accuracy:0.8278375000000002,Validation Loss:2159.33447265625,Validation Accuracy:0.926, Prune parameters: 488.0/421642,Beta: 0.01\n",
      "Epoch [34/1000],Loss:2318.27685546875, KL Loss: 192153.46875. FitLoss: 526.9185791015625,Accuracy:0.8262249999999998,Validation Loss:2170.471923828125,Validation Accuracy:0.924, Prune parameters: 489.0/421642,Beta: 0.01\n",
      "Epoch [35/1000],Loss:2294.69091796875, KL Loss: 192308.28125. FitLoss: 520.1787109375,Accuracy:0.8273125,Validation Loss:2145.688232421875,Validation Accuracy:0.936, Prune parameters: 495.0/421642,Beta: 0.01\n",
      "Epoch [36/1000],Loss:2270.71240234375, KL Loss: 192344.546875. FitLoss: 497.43267822265625,Accuracy:0.8355874999999999,Validation Loss:2163.279541015625,Validation Accuracy:0.924, Prune parameters: 480.0/421642,Beta: 0.01\n",
      "Epoch [37/1000],Loss:2263.622314453125, KL Loss: 192574.609375. FitLoss: 494.17254638671875,Accuracy:0.8389750000000002,Validation Loss:2129.762451171875,Validation Accuracy:0.943, Prune parameters: 502.0/421642,Beta: 0.01\n",
      "Epoch [38/1000],Loss:2257.58056640625, KL Loss: 192742.765625. FitLoss: 435.1174621582031,Accuracy:0.8566874999999998,Validation Loss:2121.84912109375,Validation Accuracy:0.943, Prune parameters: 472.0/421642,Beta: 0.01\n",
      "Epoch [39/1000],Loss:2263.7373046875, KL Loss: 192886.859375. FitLoss: 460.05780029296875,Accuracy:0.8502125000000001,Validation Loss:2133.3017578125,Validation Accuracy:0.934, Prune parameters: 481.0/421642,Beta: 0.01\n",
      "Epoch [40/1000],Loss:2236.133056640625, KL Loss: 192981.140625. FitLoss: 415.6376037597656,Accuracy:0.8646749999999999,Validation Loss:2105.29248046875,Validation Accuracy:0.944, Prune parameters: 480.0/421642,Beta: 0.01\n",
      "Epoch [41/1000],Loss:2216.59326171875, KL Loss: 193123.90625. FitLoss: 400.2095947265625,Accuracy:0.8702500000000002,Validation Loss:2105.3623046875,Validation Accuracy:0.95, Prune parameters: 481.0/421642,Beta: 0.01\n",
      "Epoch [42/1000],Loss:2220.703125, KL Loss: 193199.359375. FitLoss: 382.273681640625,Accuracy:0.8730875000000001,Validation Loss:2112.6650390625,Validation Accuracy:0.945, Prune parameters: 508.0/421642,Beta: 0.01\n",
      "Epoch [43/1000],Loss:2191.09228515625, KL Loss: 193284.03125. FitLoss: 364.7400207519531,Accuracy:0.8817000000000002,Validation Loss:2098.65673828125,Validation Accuracy:0.948, Prune parameters: 505.0/421642,Beta: 0.01\n",
      "Epoch [44/1000],Loss:2192.976318359375, KL Loss: 193532.421875. FitLoss: 361.6380615234375,Accuracy:0.8829750000000001,Validation Loss:2101.7158203125,Validation Accuracy:0.943, Prune parameters: 454.0/421642,Beta: 0.01\n",
      "Epoch [45/1000],Loss:2177.93310546875, KL Loss: 193671.640625. FitLoss: 353.3393249511719,Accuracy:0.8838250000000004,Validation Loss:2086.10888671875,Validation Accuracy:0.948, Prune parameters: 451.0/421642,Beta: 0.01\n",
      "Epoch [46/1000],Loss:2177.13232421875, KL Loss: 193731.078125. FitLoss: 325.7899169921875,Accuracy:0.8948625000000001,Validation Loss:2087.062255859375,Validation Accuracy:0.953, Prune parameters: 439.0/421642,Beta: 0.01\n",
      "Epoch [47/1000],Loss:2188.620361328125, KL Loss: 193918.53125. FitLoss: 363.8778076171875,Accuracy:0.8796999999999999,Validation Loss:2088.88134765625,Validation Accuracy:0.956, Prune parameters: 458.0/421642,Beta: 0.01\n",
      "Epoch [48/1000],Loss:2186.974609375, KL Loss: 194039.90625. FitLoss: 366.44696044921875,Accuracy:0.8795250000000001,Validation Loss:2079.436279296875,Validation Accuracy:0.958, Prune parameters: 457.0/421642,Beta: 0.01\n",
      "Epoch [49/1000],Loss:2180.1953125, KL Loss: 194161.21875. FitLoss: 355.6492919921875,Accuracy:0.8836375000000001,Validation Loss:2102.249755859375,Validation Accuracy:0.947, Prune parameters: 488.0/421642,Beta: 0.01\n",
      "Epoch [50/1000],Loss:2177.126708984375, KL Loss: 194280.34375. FitLoss: 338.4111328125,Accuracy:0.8897124999999999,Validation Loss:2081.244873046875,Validation Accuracy:0.951, Prune parameters: 455.0/421642,Beta: 0.01\n",
      "Epoch [51/1000],Loss:2147.8896484375, KL Loss: 194466.0. FitLoss: 296.7597351074219,Accuracy:0.9027874999999999,Validation Loss:2070.26611328125,Validation Accuracy:0.954, Prune parameters: 436.0/421642,Beta: 0.01\n",
      "Epoch [52/1000],Loss:2149.86669921875, KL Loss: 194590.453125. FitLoss: 280.0732116699219,Accuracy:0.9079749999999999,Validation Loss:2067.206787109375,Validation Accuracy:0.961, Prune parameters: 501.0/421642,Beta: 0.01\n",
      "Epoch [53/1000],Loss:2139.9140625, KL Loss: 194616.46875. FitLoss: 270.3711242675781,Accuracy:0.9107875000000002,Validation Loss:2064.14013671875,Validation Accuracy:0.963, Prune parameters: 458.0/421642,Beta: 0.01\n",
      "Epoch [54/1000],Loss:2139.97998046875, KL Loss: 194764.65625. FitLoss: 275.1563415527344,Accuracy:0.9097249999999997,Validation Loss:2064.737060546875,Validation Accuracy:0.958, Prune parameters: 407.0/421642,Beta: 0.01\n",
      "Epoch [55/1000],Loss:2148.61572265625, KL Loss: 194932.9375. FitLoss: 277.2902526855469,Accuracy:0.9097000000000002,Validation Loss:2068.03759765625,Validation Accuracy:0.958, Prune parameters: 429.0/421642,Beta: 0.01\n",
      "Epoch [56/1000],Loss:2129.06396484375, KL Loss: 195050.765625. FitLoss: 259.1335144042969,Accuracy:0.9152874999999998,Validation Loss:2055.701904296875,Validation Accuracy:0.966, Prune parameters: 442.0/421642,Beta: 0.01\n",
      "Epoch [57/1000],Loss:2130.136962890625, KL Loss: 195059.59375. FitLoss: 251.9368896484375,Accuracy:0.9169625,Validation Loss:2063.141357421875,Validation Accuracy:0.96, Prune parameters: 415.0/421642,Beta: 0.01\n",
      "Epoch [58/1000],Loss:2117.532958984375, KL Loss: 195250.125. FitLoss: 254.34693908691406,Accuracy:0.9152750000000001,Validation Loss:2052.18505859375,Validation Accuracy:0.973, Prune parameters: 461.0/421642,Beta: 0.01\n",
      "Epoch [59/1000],Loss:2117.940673828125, KL Loss: 195409.328125. FitLoss: 222.12779235839844,Accuracy:0.9268499999999997,Validation Loss:2047.63671875,Validation Accuracy:0.967, Prune parameters: 482.0/421642,Beta: 0.01\n",
      "Epoch [60/1000],Loss:2120.01904296875, KL Loss: 195430.09375. FitLoss: 227.33135986328125,Accuracy:0.9254875000000007,Validation Loss:2046.7027587890625,Validation Accuracy:0.967, Prune parameters: 462.0/421642,Beta: 0.01\n",
      "Epoch [61/1000],Loss:2111.319091796875, KL Loss: 195599.046875. FitLoss: 227.24903869628906,Accuracy:0.9249999999999998,Validation Loss:2050.328857421875,Validation Accuracy:0.969, Prune parameters: 453.0/421642,Beta: 0.01\n",
      "Epoch [62/1000],Loss:2111.52001953125, KL Loss: 195786.421875. FitLoss: 233.4744110107422,Accuracy:0.9244625,Validation Loss:2050.283447265625,Validation Accuracy:0.968, Prune parameters: 467.0/421642,Beta: 0.01\n",
      "Epoch [63/1000],Loss:2115.669189453125, KL Loss: 195879.1875. FitLoss: 232.91790771484375,Accuracy:0.9242750000000001,Validation Loss:2055.592041015625,Validation Accuracy:0.967, Prune parameters: 448.0/421642,Beta: 0.01\n",
      "Epoch [64/1000],Loss:2102.797119140625, KL Loss: 195944.71875. FitLoss: 208.68898010253906,Accuracy:0.9312750000000001,Validation Loss:2051.775146484375,Validation Accuracy:0.969, Prune parameters: 438.0/421642,Beta: 0.01\n",
      "Epoch [65/1000],Loss:2097.987060546875, KL Loss: 196102.78125. FitLoss: 207.39395141601562,Accuracy:0.9319624999999998,Validation Loss:2044.7821044921875,Validation Accuracy:0.966, Prune parameters: 448.0/421642,Beta: 0.01\n",
      "Epoch [66/1000],Loss:2098.587646484375, KL Loss: 196177.078125. FitLoss: 198.31163024902344,Accuracy:0.9344750000000002,Validation Loss:2045.8604736328125,Validation Accuracy:0.971, Prune parameters: 456.0/421642,Beta: 0.01\n",
      "Epoch [67/1000],Loss:2095.281005859375, KL Loss: 196313.390625. FitLoss: 191.58441162109375,Accuracy:0.9355249999999999,Validation Loss:2043.857421875,Validation Accuracy:0.974, Prune parameters: 413.0/421642,Beta: 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#trainer = VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader, [post_train_step])\u001b[39;00m\n\u001b[1;32m     51\u001b[0m trainer \u001b[38;5;241m=\u001b[39m VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader)\n\u001b[0;32m---> 52\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(model)\n",
      "File \u001b[0;32m~/BMM/bayes_deep_compression/examples/../src/bayescomp/bayes/variational/trainer.py:151\u001b[0m, in \u001b[0;36mVarBayesTrainer.train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    149\u001b[0m train_fit_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (objects, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset):\n\u001b[0;32m--> 151\u001b[0m     train_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(model, objects, labels)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__post_train_step(train_output)\n\u001b[1;32m    153\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(train_output\u001b[38;5;241m.\u001b[39mtotal_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/BMM/bayes_deep_compression/examples/../src/bayescomp/bayes/variational/trainer.py:232\u001b[0m, in \u001b[0;36mVarBayesTrainer.train_step\u001b[0;34m(self, model, objects, labels)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 232\u001b[0m total_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m#print(dict(model.named_parameters()))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=1000\n",
    "EPOCHS=1000\n",
    "LR = 1e-3 #5e-4\n",
    "# Split the training set into training and validation sets \n",
    "VAL_PERCENT = 0.2 # percentage of the data used for validation \n",
    "SAMPLES = 10\n",
    "BETA = 1e-2 #5e-5 #len(train_dataset) *1. / BATCH_SIZE\n",
    "BETA_FAC = 5e-1\n",
    "PRUNE = -5#1.99, 2.1\n",
    "PLATO_TOL = 20\n",
    "\n",
    "base_module = Classifier()\n",
    "var_module = NormalVarBayesModule(base_module)\n",
    "model = VarBayesModuleNet(base_module, nn.ModuleList([var_module]))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "fit_loss = nn.CrossEntropyLoss(reduction=\"sum\") \n",
    "kl_loss = VarRenuiLoss()\n",
    "beta = BETA#len(train_dataset) *1. / BATCH_SIZE\n",
    "print(beta)\n",
    "#beta = Beta_Scheduler(beta=(len(train_dataset) *1. / BATCH_SIZE))\n",
    "\n",
    "# beta_KL = Beta_Scheduler_Plato(beta.beta, 1 / BETA_FAC, PLATO_TOL, ref = beta, threshold=1e-4)\n",
    "\n",
    "#Данная функция будет выполнятся после каждого шага тренера, соответсвенно нам требуется сделать шаг планировщика и изменить соотвествующий коэффициент\n",
    "    \n",
    "#print(model.base_module.state_dict().keys())\n",
    "val_size    = int(VAL_PERCENT * len(train_dataset)) \n",
    "train_size  = len(train_dataset) - val_size \n",
    "\n",
    "t_dataset, v_dataset = torch.utils.data.random_split(train_dataset,  \n",
    "                                                        [train_size,  \n",
    "                                                            val_size]) \n",
    "\n",
    "# Create DataLoaders for the training and validation sets \n",
    "train_loader = torch.utils.data.DataLoader(t_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=True, \n",
    "                                        pin_memory=True) \n",
    "\n",
    "eval_loader = torch.utils.data.DataLoader(v_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=False, \n",
    "                                        pin_memory=True)\n",
    "\n",
    "model.to(device) \n",
    "train_params = VarTrainerParams(EPOCHS, optimizer,fit_loss, kl_loss, SAMPLES, PRUNE, beta, {'accuracy': CallbackLossAccuracy()})\n",
    "#trainer = VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader, [post_train_step])\n",
    "trainer = VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader)\n",
    "trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2027556001.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    for param in\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for param in "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
