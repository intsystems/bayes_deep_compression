{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayessian NN with gaussian variational learning on MNIST\n",
    "\n",
    "In the example we will learn ordinary and bayessian NNs on MNIST dataset, compare their performances, evaluate pruning effectiveness and model's uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from classification_nn import ClassificationNet\n",
    "from metrics import log_metrics\n",
    "from variational_gaussian.bayes_nn import MakeModuleBayessian\n",
    "from variational_gaussian.bayessian_loss import MakeLossBayessian\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms.functional import pil_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# load experiment's config\n",
    "with open(\"params.yaml\") as f:\n",
    "    exp_params = yaml.full_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "def img_transform(img):\n",
    "    return pil_to_tensor(img).float()\n",
    "\n",
    "train_dataset = MNIST(\"./data\", train=True, download=True, transform=img_transform)\n",
    "test_dataset = MNIST(\"./data\", train=False, download=True, transform=img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=exp_params[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=exp_params[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = train_dataset[0][0].shape\n",
    "print(IMG_SIZE)\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Basic NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_nn = ClassificationNet(IMG_SIZE, NUM_CLASSES, exp_params[\"num_layers\"], exp_params[\"hidden_size\"])\n",
    "basic_nn = basic_nn.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define yours optimization\n",
    "\n",
    "N_EPOCHS = 10\n",
    "LR = 1e-3\n",
    "# add L_2 regularization\n",
    "WEIGHT_DECAY = 1e-3\n",
    "\n",
    "optimizer = optim.Adam(basic_nn.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(N_EPOCHS), desc=\"Epochs\"):\n",
    "    # training\n",
    "    basic_nn.train()\n",
    "\n",
    "    losses = []\n",
    "    for imgs, targets in tqdm(train_loader, desc=\"Train batchs\", leave=True):\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits = basic_nn(imgs)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    writer.add_scalar(\"Train/Cross_entropy\", torch.Tensor(losses).mean(), epoch)\n",
    "\n",
    "    # testing\n",
    "    basic_nn.eval()\n",
    "    with torch.no_grad():\n",
    "        log_metrics(epoch, basic_nn, test_loader, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "non-package-mode-MnliztJp-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
