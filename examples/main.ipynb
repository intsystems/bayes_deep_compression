{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sasha/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем путь к нашей библиотеке в переменную окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../src', '/home/sasha/BMM/bayes_deep_compression/examples', '/home/sasha/anaconda3/lib/python311.zip', '/home/sasha/anaconda3/lib/python3.11', '/home/sasha/anaconda3/lib/python3.11/lib-dynload', '', '/home/sasha/anaconda3/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем простой классификтор, который будет нашей базовой моделью, кторую мы хотим обучить и запрунить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier(nn.Module): \n",
    "    def __init__(self, classes: int = 10): \n",
    "        super().__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) \n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        #self.dropout1 = nn.Dropout2d(0.25) \n",
    "        #self.dropout2 = nn.Dropout2d(0.5) \n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128) \n",
    "        self.fc2 = nn.Linear(128, classes) \n",
    "  \n",
    "    def forward(self, x): \n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        #x = self.dropout1(x) \n",
    "        x = self.pool(F.relu(self.conv2(x))) \n",
    "        #x = self.dropout2(x) \n",
    "        x = x.view(-1, 64 * 7 * 7) \n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.fc2(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как работают распределения в нашей библиотеке(Их не обязательно импортировать для работы и обучения байесовской модели)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый вид это привычные нам распределения на числа. Импортируем тот, который используется у нас в модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayescomp.bayes.variational.distribution import LogUniformVarDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый вид это привычные нам распределения на числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayescomp.bayes.variational.net_distribution import VarBayesModuleNetDistribution #Необязательно импортировать для обучения, оно встроено в нашу байесовскую модель\n",
    "from bayescomp.bayes.base.net_distribution import BaseNetDistributionPruner #Также не обязательно для обучения, но нужен, если вы хотите запрунить модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем инициализировать веса распределения просто из параметров модели. При этом используется рекомендуемая начальная инициализация параметров распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogUniformVarDist(param_mus: torch.Size([2]), param_std_log: torch.Size([2]), scale_mus: torch.Size([2]), scale_alphas_log: torch.Size([2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = nn.Parameter(torch.tensor([0.0, 1.0])) \n",
    "LogUniformVarDist.from_parameter(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это три модуля являются основными для байесовского обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayescomp.bayes.variational.net import LogUniformVarBayesModule, VarBayesModuleNet #Первым модулоем мы оборачиваем те слои модели, которые мы хотим сделать байесовыми, второй модуль это сама байесовская сеть\n",
    "from bayescomp.bayes.variational.optimization import LogUniformVarKLLoss #Это лосс байесовской модели, который отвечает за тип обучения. Всегда рекомендуется использовать специализированный лосс, но для большинства распределений его нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет MNIST, на котором мы хотим обучить наш классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посомтрим внимательнее как нужно создавать байесовскую сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом создадим нашу базовую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы часть слоев превратим в байесовски с помощью LogUniformVarBayesModule. И создадим список всех слоев nn.ModuleList([layer1, layer2, ...]), которые мы хотим обучить (в том чилсе слои, которые не являются байесовыми). Заметим, что можно обернуть и всю сеть целиком и передать список состоящий только из нее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayes_model = BayesModule(module)\n",
    "var_module = LogUniformVarBayesModule(module)\n",
    "bayes_model = VarBayesModuleNet(module, nn.ModuleList([var_module])) #Первый аргумент базовая сеть, второй список всех слоев (где нужные из них являются байесовыми)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посомтрим на струкутру получившейся сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VarBayesModuleNet(\n",
      "  (module_list): ModuleList(\n",
      "    (0): LogUniformVarBayesModule(\n",
      "      (posterior_params): ParameterList(\n",
      "          (0): Object of type: ParameterDict\n",
      "          (1): Object of type: ParameterDict\n",
      "          (2): Object of type: ParameterDict\n",
      "          (3): Object of type: ParameterDict\n",
      "          (4): Object of type: ParameterDict\n",
      "          (5): Object of type: ParameterDict\n",
      "          (6): Object of type: ParameterDict\n",
      "          (7): Object of type: ParameterDict\n",
      "        (0): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "        )\n",
      "        (1): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        )\n",
      "        (2): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "        )\n",
      "        (3): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        )\n",
      "        (4): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "        )\n",
      "        (5): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 128]\n",
      "        )\n",
      "        (6): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "        )\n",
      "        (7): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 10]\n",
      "        )\n",
      "      )\n",
      "      (prior_params): ParameterList()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(bayes_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У выбранной сети отсутвует prior на параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1.weight': None,\n",
       " 'conv1.bias': None,\n",
       " 'conv2.weight': None,\n",
       " 'conv2.bias': None,\n",
       " 'fc1.weight': None,\n",
       " 'fc1.bias': None,\n",
       " 'fc2.weight': None,\n",
       " 'fc2.bias': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_model.prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посомотрим как выглядит шаг обучения для сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(bayes_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом он ничем не отличается от обычного шага, нам только нужно парвильно агрегировать лоссы от нескольких семплов на одном шаге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = test_dataset[10]\n",
    "y = bayes_model(torch.ones_like(image))\n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "bayes_model.prior\n",
    "out = y.sum() + kl_loss(bayes_model.weights, bayes_model.posterior, bayes_model.prior)\n",
    "optimizer.zero_grad() \n",
    "out.backward() \n",
    "optimizer.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создать распределение сетей можно просто из распределения на параметры и базовой сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_distributon = VarBayesModuleNetDistribution(bayes_model.base_module, bayes_model.posterior)\n",
    "#Это прунер, которые зануляет веса в зависимости от плотности распределения при 0\n",
    "net_distributon_pruner = BaseNetDistributionPruner(net_distributon)\n",
    "#Здесь мы устанавливаем средние веса модели  \n",
    "net_distributon.set_map_params()\n",
    "#Пруним на основе определенного порога\n",
    "net_distributon_pruner.prune(1.9)\n",
    "#get basic model for evaluation\n",
    "eval_model = net_distributon.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили модель с той же архитектурой что и изначальная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 4.4351e-02, -1.2533e-01,  3.0028e-01],\n",
      "          [ 1.1433e-01,  1.3923e-01,  2.6681e-01],\n",
      "          [ 2.5070e-01, -2.8697e-01,  3.3039e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4337e-01, -1.2639e-01, -1.1402e-01],\n",
      "          [-8.3545e-02, -3.2522e-01,  5.2171e-02],\n",
      "          [ 1.2482e-01,  9.4748e-02,  2.7281e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0706e-01, -1.8491e-01,  2.9258e-01],\n",
      "          [ 9.9194e-02, -2.6916e-01, -1.7594e-01],\n",
      "          [-2.0441e-01,  1.0864e-01, -1.9634e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1243e-01,  5.6338e-02, -2.2699e-02],\n",
      "          [ 1.2042e-02, -3.1548e-01,  2.5183e-01],\n",
      "          [ 1.7549e-01,  2.0988e-01, -6.7290e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0186e-01, -2.2581e-01, -1.3754e-01],\n",
      "          [-2.3887e-01,  1.2280e-01, -2.6371e-01],\n",
      "          [-2.7575e-01,  3.0222e-02, -1.3726e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1438e-01, -6.9328e-02, -1.5306e-01],\n",
      "          [ 2.2248e-01,  3.2117e-01, -2.1904e-01],\n",
      "          [-3.0336e-01, -2.9675e-01, -2.5299e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0033e-01, -1.6992e-02, -3.2443e-01],\n",
      "          [-2.1820e-01,  1.5997e-01,  1.6474e-01],\n",
      "          [ 7.8728e-02, -3.2854e-01, -1.1264e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4430e-03, -2.9649e-01, -1.8626e-01],\n",
      "          [-2.5688e-01, -3.0337e-01, -2.1620e-01],\n",
      "          [ 1.8763e-01,  3.2564e-01,  9.5624e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5302e-01,  2.3252e-02, -1.9148e-01],\n",
      "          [-2.3964e-01, -2.1365e-01,  1.3000e-01],\n",
      "          [-1.1083e-01,  2.5711e-01,  2.2803e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2555e-01,  6.9153e-04, -2.9723e-01],\n",
      "          [ 1.3256e-01, -3.2174e-01, -2.9262e-02],\n",
      "          [-6.5537e-02,  1.2179e-01, -2.6878e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9411e-01, -3.2938e-01,  2.9353e-01],\n",
      "          [ 1.2410e-01, -1.2376e-01, -2.4766e-01],\n",
      "          [ 2.6988e-01,  1.9949e-01, -2.7927e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2315e-01,  6.8162e-02, -2.2946e-01],\n",
      "          [-1.0682e-02,  3.0742e-01,  2.6686e-01],\n",
      "          [ 1.0624e-01, -4.4230e-02, -1.3511e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7318e-01,  1.3154e-02,  2.6699e-01],\n",
      "          [-2.8405e-01, -5.6858e-02,  1.5368e-01],\n",
      "          [ 1.2671e-01,  2.1102e-01,  2.1320e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2442e-01,  1.8347e-01,  2.7447e-01],\n",
      "          [ 2.8637e-01,  9.8882e-02,  9.0126e-02],\n",
      "          [ 4.0207e-02, -2.0291e-01, -2.6603e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.9528e-02, -1.3628e-01,  1.9918e-04],\n",
      "          [-1.0888e-02,  1.4844e-01,  2.7004e-01],\n",
      "          [ 2.5383e-01, -1.7193e-01, -2.1503e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.9867e-02, -7.2068e-02,  2.7529e-01],\n",
      "          [ 2.0354e-01, -6.4494e-04,  2.4694e-01],\n",
      "          [-8.9728e-02, -2.5840e-01, -1.4453e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6677e-02, -1.8832e-01,  2.6012e-01],\n",
      "          [-1.0005e-01, -2.0143e-01,  1.4423e-01],\n",
      "          [ 1.8289e-01,  2.3544e-01,  2.0531e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4796e-01, -5.8032e-02, -3.1442e-01],\n",
      "          [-1.8082e-01, -3.2450e-01,  1.0787e-01],\n",
      "          [-7.9383e-02,  3.2185e-01, -5.6993e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1120e-02, -3.1012e-01,  2.2689e-02],\n",
      "          [-2.0921e-01, -2.0552e-01,  3.2498e-01],\n",
      "          [ 1.3881e-01, -1.3056e-01, -2.9577e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5614e-01, -9.5900e-02,  3.0539e-01],\n",
      "          [ 1.1183e-01, -1.4444e-01,  2.4152e-01],\n",
      "          [ 2.3767e-01,  1.9289e-02,  7.2932e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8383e-02,  3.9277e-02,  5.5080e-02],\n",
      "          [-1.0972e-01, -1.3138e-01, -9.3705e-02],\n",
      "          [ 7.8422e-02, -4.5930e-02,  3.2991e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0252e-01, -2.1850e-01,  2.5301e-01],\n",
      "          [-1.2400e-01,  6.0446e-02,  6.6564e-02],\n",
      "          [ 3.0696e-01, -1.0633e-01, -1.3199e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8288e-02, -3.5980e-02,  1.9968e-01],\n",
      "          [ 5.7394e-02,  1.3886e-01,  2.5160e-01],\n",
      "          [ 1.5901e-01,  1.3863e-01,  1.4691e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5982e-01,  1.3266e-01,  2.4035e-02],\n",
      "          [ 1.0778e-01,  1.9849e-01,  5.3228e-02],\n",
      "          [ 1.4493e-02,  2.9097e-01, -9.7465e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4353e-01, -3.2310e-01, -3.1189e-01],\n",
      "          [-2.0168e-01, -2.2387e-01,  2.6240e-01],\n",
      "          [ 3.1833e-01,  2.4768e-01,  1.6398e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3015e-02,  1.7974e-01, -1.2704e-01],\n",
      "          [-1.9436e-01, -2.8527e-01,  2.2083e-01],\n",
      "          [-8.5008e-03,  2.0382e-01, -1.9280e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5929e-01,  8.1191e-02,  3.0550e-01],\n",
      "          [ 2.8525e-01,  3.0852e-01, -1.1175e-01],\n",
      "          [ 3.2264e-01, -2.7809e-01,  2.6533e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5129e-02,  3.2030e-01,  1.4619e-01],\n",
      "          [ 3.0478e-01, -2.4359e-01, -1.4781e-01],\n",
      "          [-2.8162e-02, -1.7869e-01, -4.9206e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1530e-01,  3.1945e-01, -3.0106e-01],\n",
      "          [-2.1734e-01, -2.3283e-01, -4.7721e-02],\n",
      "          [-2.8233e-02, -3.1953e-01,  5.0736e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8479e-01,  4.5911e-02, -2.7851e-01],\n",
      "          [-2.6070e-01, -2.9180e-01,  3.1790e-01],\n",
      "          [-1.8605e-01, -2.4985e-01,  3.2733e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6904e-01, -2.6852e-01,  1.9924e-01],\n",
      "          [-2.2885e-02, -1.3350e-01,  2.7415e-01],\n",
      "          [-5.1354e-02, -2.3834e-01, -2.6335e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2086e-01,  2.4292e-01, -7.1730e-03],\n",
      "          [-9.7100e-03, -2.3622e-01, -2.6843e-01],\n",
      "          [ 2.4919e-01, -3.2632e-01, -2.2132e-01]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(eval_model.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('module_list.0.posterior_params.0.param_mus',\n",
       "              tensor([[[[ 4.4351e-02, -1.2533e-01,  3.0028e-01],\n",
       "                        [ 1.1433e-01,  1.3923e-01,  2.6681e-01],\n",
       "                        [ 2.5070e-01, -2.8697e-01,  3.3039e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4337e-01, -1.2639e-01, -1.1402e-01],\n",
       "                        [-8.3545e-02, -3.2522e-01,  5.2171e-02],\n",
       "                        [ 1.2482e-01,  9.4748e-02,  2.7281e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0706e-01, -1.8491e-01,  2.9258e-01],\n",
       "                        [ 9.9194e-02, -2.6916e-01, -1.7594e-01],\n",
       "                        [-2.0441e-01,  1.0864e-01, -1.9634e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.1243e-01,  5.6338e-02, -2.2699e-02],\n",
       "                        [ 1.2042e-02, -3.1548e-01,  2.5183e-01],\n",
       "                        [ 1.7549e-01,  2.0988e-01, -6.7290e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0186e-01, -2.2581e-01, -1.3754e-01],\n",
       "                        [-2.3887e-01,  1.2280e-01, -2.6371e-01],\n",
       "                        [-2.7575e-01,  3.0222e-02, -1.3726e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1438e-01, -6.9328e-02, -1.5306e-01],\n",
       "                        [ 2.2248e-01,  3.2117e-01, -2.1904e-01],\n",
       "                        [-3.0336e-01, -2.9675e-01, -2.5299e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0033e-01, -1.6992e-02, -3.2443e-01],\n",
       "                        [-2.1820e-01,  1.5997e-01,  1.6474e-01],\n",
       "                        [ 7.8728e-02, -3.2854e-01, -1.1264e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4430e-03, -2.9649e-01, -1.8626e-01],\n",
       "                        [-2.5688e-01, -3.0337e-01, -2.1620e-01],\n",
       "                        [ 1.8763e-01,  3.2564e-01,  9.5624e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5302e-01,  2.3252e-02, -1.9148e-01],\n",
       "                        [-2.3964e-01, -2.1365e-01,  1.3000e-01],\n",
       "                        [-1.1083e-01,  2.5711e-01,  2.2803e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2555e-01,  6.9153e-04, -2.9723e-01],\n",
       "                        [ 1.3256e-01, -3.2174e-01, -2.9262e-02],\n",
       "                        [-6.5537e-02,  1.2179e-01, -2.6878e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9411e-01, -3.2938e-01,  2.9353e-01],\n",
       "                        [ 1.2410e-01, -1.2376e-01, -2.4766e-01],\n",
       "                        [ 2.6988e-01,  1.9949e-01, -2.7927e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2315e-01,  6.8162e-02, -2.2946e-01],\n",
       "                        [-1.0682e-02,  3.0742e-01,  2.6686e-01],\n",
       "                        [ 1.0624e-01, -4.4230e-02, -1.3511e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7318e-01,  1.3154e-02,  2.6699e-01],\n",
       "                        [-2.8405e-01, -5.6858e-02,  1.5368e-01],\n",
       "                        [ 1.2671e-01,  2.1102e-01,  2.1320e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2442e-01,  1.8347e-01,  2.7447e-01],\n",
       "                        [ 2.8637e-01,  9.8882e-02,  9.0126e-02],\n",
       "                        [ 4.0207e-02, -2.0291e-01, -2.6603e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.9528e-02, -1.3628e-01,  1.9918e-04],\n",
       "                        [-1.0888e-02,  1.4844e-01,  2.7004e-01],\n",
       "                        [ 2.5383e-01, -1.7193e-01, -2.1503e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9867e-02, -7.2068e-02,  2.7529e-01],\n",
       "                        [ 2.0354e-01, -6.4494e-04,  2.4694e-01],\n",
       "                        [-8.9728e-02, -2.5840e-01, -1.4453e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.6677e-02, -1.8832e-01,  2.6012e-01],\n",
       "                        [-1.0005e-01, -2.0143e-01,  1.4423e-01],\n",
       "                        [ 1.8289e-01,  2.3544e-01,  2.0531e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4796e-01, -5.8032e-02, -3.1442e-01],\n",
       "                        [-1.8082e-01, -3.2450e-01,  1.0787e-01],\n",
       "                        [-7.9383e-02,  3.2185e-01, -5.6993e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1120e-02, -3.1012e-01,  2.2689e-02],\n",
       "                        [-2.0921e-01, -2.0552e-01,  3.2498e-01],\n",
       "                        [ 1.3881e-01, -1.3056e-01, -2.9577e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5614e-01, -9.5900e-02,  3.0539e-01],\n",
       "                        [ 1.1183e-01, -1.4444e-01,  2.4152e-01],\n",
       "                        [ 2.3767e-01,  1.9289e-02,  7.2932e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8383e-02,  3.9277e-02,  5.5080e-02],\n",
       "                        [-1.0972e-01, -1.3138e-01, -9.3705e-02],\n",
       "                        [ 7.8422e-02, -4.5930e-02,  3.2991e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0252e-01, -2.1850e-01,  2.5301e-01],\n",
       "                        [-1.2400e-01,  6.0446e-02,  6.6564e-02],\n",
       "                        [ 3.0696e-01, -1.0633e-01, -1.3199e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8288e-02, -3.5980e-02,  1.9968e-01],\n",
       "                        [ 5.7394e-02,  1.3886e-01,  2.5160e-01],\n",
       "                        [ 1.5901e-01,  1.3863e-01,  1.4691e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5982e-01,  1.3266e-01,  2.4035e-02],\n",
       "                        [ 1.0778e-01,  1.9849e-01,  5.3228e-02],\n",
       "                        [ 1.4493e-02,  2.9097e-01, -9.7465e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4353e-01, -3.2310e-01, -3.1189e-01],\n",
       "                        [-2.0168e-01, -2.2387e-01,  2.6240e-01],\n",
       "                        [ 3.1833e-01,  2.4768e-01,  1.6398e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3015e-02,  1.7974e-01, -1.2704e-01],\n",
       "                        [-1.9436e-01, -2.8527e-01,  2.2083e-01],\n",
       "                        [-8.5008e-03,  2.0382e-01, -1.9280e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5929e-01,  8.1191e-02,  3.0550e-01],\n",
       "                        [ 2.8525e-01,  3.0852e-01, -1.1175e-01],\n",
       "                        [ 3.2264e-01, -2.7809e-01,  2.6533e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5129e-02,  3.2030e-01,  1.4619e-01],\n",
       "                        [ 3.0478e-01, -2.4359e-01, -1.4781e-01],\n",
       "                        [-2.8162e-02, -1.7869e-01, -4.9206e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1530e-01,  3.1945e-01, -3.0106e-01],\n",
       "                        [-2.1734e-01, -2.3283e-01, -4.7721e-02],\n",
       "                        [-2.8233e-02, -3.1953e-01,  5.0736e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.8479e-01,  4.5911e-02, -2.7851e-01],\n",
       "                        [-2.6070e-01, -2.9180e-01,  3.1790e-01],\n",
       "                        [-1.8605e-01, -2.4985e-01,  3.2733e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6904e-01, -2.6852e-01,  1.9924e-01],\n",
       "                        [-2.2885e-02, -1.3350e-01,  2.7415e-01],\n",
       "                        [-5.1354e-02, -2.3834e-01, -2.6335e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2086e-01,  2.4292e-01, -7.1730e-03],\n",
       "                        [-9.7100e-03, -2.3622e-01, -2.6843e-01],\n",
       "                        [ 2.4919e-01, -3.2632e-01, -2.2132e-01]]]])),\n",
       "             ('module_list.0.posterior_params.0.param_std_log',\n",
       "              tensor([[[[ -6.1309,  -4.8572,  -5.7741],\n",
       "                        [ -7.8108,  -7.3821,  -4.7182],\n",
       "                        [ -4.8377, -11.5245,  -6.9355]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.1162,  -4.9522,  -6.7209],\n",
       "                        [ -4.7690,  -4.6808,  -4.8827],\n",
       "                        [ -4.6564,  -6.2008,  -4.9633]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.7678,  -5.2178,  -8.9590],\n",
       "                        [ -5.0341,  -4.7696,  -6.1974],\n",
       "                        [ -4.6494,  -4.7115,  -5.2549]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -8.8684,  -5.1600,  -5.2670],\n",
       "                        [ -5.3217,  -5.0801,  -4.7305],\n",
       "                        [ -7.0623,  -5.6469,  -5.1094]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.2182,  -5.9416,  -5.0690],\n",
       "                        [ -5.1327,  -8.3204,  -5.9542],\n",
       "                        [ -7.3783,  -4.6890,  -5.0220]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.8065,  -5.2885,  -7.4891],\n",
       "                        [ -5.0511,  -4.8168,  -4.8554],\n",
       "                        [ -5.7424,  -5.4220,  -5.8636]]],\n",
       "              \n",
       "              \n",
       "                      [[[-10.9409,  -5.4390,  -6.0425],\n",
       "                        [ -6.2912,  -5.4249,  -6.7238],\n",
       "                        [ -5.2268,  -6.7539,  -8.6926]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.2240,  -4.6261,  -6.5449],\n",
       "                        [ -5.7210,  -5.7704,  -5.4285],\n",
       "                        [ -5.5706,  -5.1259,  -4.8102]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.9963,  -5.4324,  -6.2309],\n",
       "                        [ -5.2498,  -7.4679,  -4.8426],\n",
       "                        [ -5.5689,  -4.8656,  -5.3836]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.0990,  -6.1563,  -5.5630],\n",
       "                        [ -7.6143,  -5.0293,  -8.2187],\n",
       "                        [ -5.3834,  -4.7096,  -5.3968]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7724,  -5.0000,  -5.3379],\n",
       "                        [ -5.3924,  -4.6505,  -4.6052],\n",
       "                        [ -6.9498,  -4.9935,  -6.0027]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7477,  -6.3273,  -4.6267],\n",
       "                        [ -6.5316,  -4.8446,  -5.2155],\n",
       "                        [ -5.5960,  -6.2125,  -5.9624]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.0853,  -4.8839,  -5.7258],\n",
       "                        [ -5.6719,  -5.1327,  -6.1288],\n",
       "                        [ -6.1505,  -4.9213,  -6.5002]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.4689,  -4.9607,  -4.9863],\n",
       "                        [ -4.7476,  -4.6665,  -5.0151],\n",
       "                        [ -7.4794,  -4.7979,  -4.7412]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.8614,  -4.7362,  -4.9491],\n",
       "                        [ -4.6128,  -7.0325,  -5.5629],\n",
       "                        [ -5.4410,  -5.2080,  -5.2347]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7531,  -4.9848,  -4.7727],\n",
       "                        [ -5.9623,  -6.1608,  -4.7297],\n",
       "                        [ -6.1624,  -4.8169,  -5.3699]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.3501,  -5.1525,  -4.7838],\n",
       "                        [ -5.3031,  -4.6672,  -7.0799],\n",
       "                        [ -4.9561,  -4.9870,  -5.1239]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.8563,  -4.8396,  -6.1376],\n",
       "                        [ -6.3670,  -4.8130,  -4.9670],\n",
       "                        [ -6.6328,  -4.6891,  -5.0316]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6550,  -7.7283,  -5.5596],\n",
       "                        [ -6.3994,  -5.7042,  -5.8374],\n",
       "                        [ -6.5818,  -4.8193,  -5.6819]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.0586,  -5.7277,  -5.2177],\n",
       "                        [ -4.7766,  -6.2085,  -4.9314],\n",
       "                        [ -6.6436,  -6.0348,  -4.6430]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.2750,  -5.1816,  -5.0704],\n",
       "                        [ -5.3479,  -5.0818,  -5.5470],\n",
       "                        [ -5.2737,  -6.5050,  -6.8802]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -7.6597,  -5.0512,  -5.8497],\n",
       "                        [ -5.3294,  -5.2398,  -5.3255],\n",
       "                        [ -5.1086,  -5.2414,  -5.4018]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.1309,  -6.4318,  -6.7967],\n",
       "                        [ -5.0203,  -4.6795,  -7.9989],\n",
       "                        [ -5.2840,  -6.0963,  -5.4949]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6510,  -5.7440,  -5.1827],\n",
       "                        [ -4.8913,  -6.8896,  -5.4201],\n",
       "                        [ -5.6163,  -6.2105,  -6.0735]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.8481,  -5.0110,  -4.6682],\n",
       "                        [ -4.7378,  -4.6155,  -6.3075],\n",
       "                        [ -5.2284,  -5.0801,  -5.1032]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.7684,  -4.8276,  -4.6802],\n",
       "                        [ -5.0317,  -7.0510,  -5.9650],\n",
       "                        [ -7.2367,  -4.6497,  -6.5418]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6830,  -4.7320,  -5.7102],\n",
       "                        [ -4.9406,  -5.4414,  -5.9833],\n",
       "                        [ -7.3995,  -5.3172,  -5.5229]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.9003,  -5.9076,  -7.5420],\n",
       "                        [ -4.9516,  -5.4444,  -4.7426],\n",
       "                        [ -5.5882,  -5.4065,  -4.6319]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.3676,  -5.0947,  -4.6468],\n",
       "                        [ -4.7063,  -6.2347,  -6.2446],\n",
       "                        [ -5.1170,  -5.0869,  -5.3647]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.8913,  -4.9993,  -4.8980],\n",
       "                        [ -6.4054,  -5.3362,  -4.8138],\n",
       "                        [ -5.3769,  -5.3857,  -4.7141]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3765,  -6.4029,  -5.1556],\n",
       "                        [ -5.6705,  -4.9418,  -5.3873],\n",
       "                        [ -4.9139,  -6.5927,  -5.7899]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3979,  -4.7046,  -5.7229],\n",
       "                        [ -6.2840,  -5.7730,  -5.4950],\n",
       "                        [ -4.6594,  -4.9675,  -5.5806]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_alphas_log',\n",
       "              tensor([[[[-2.4871, -3.1250, -3.7059],\n",
       "                        [-2.5777, -3.6549, -3.8614],\n",
       "                        [-3.3727, -2.4074, -2.1088]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1725, -2.0301, -2.0620],\n",
       "                        [-2.0747, -2.7266, -2.1008],\n",
       "                        [-3.2120, -3.2470, -2.2684]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2131, -2.4525, -3.5067],\n",
       "                        [-2.6292, -2.1063, -2.0624],\n",
       "                        [-2.6286, -2.4160, -2.8037]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1040, -2.4119, -2.3670],\n",
       "                        [-2.7131, -2.5885, -2.2263],\n",
       "                        [-3.6665, -2.1110, -3.9462]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6408, -2.3819, -3.3418],\n",
       "                        [-2.6681, -3.6322, -2.7575],\n",
       "                        [-3.1474, -2.8592, -3.7689]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0849, -2.8589, -2.4025],\n",
       "                        [-3.1749, -2.8377, -2.0901],\n",
       "                        [-2.2571, -3.1026, -2.3579]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8014, -3.9953, -3.7415],\n",
       "                        [-2.2891, -2.6536, -3.1352],\n",
       "                        [-3.9610, -3.1224, -3.1753]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3758, -2.0249, -2.9964],\n",
       "                        [-3.9839, -2.3918, -3.1351],\n",
       "                        [-3.6814, -3.7079, -3.3098]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3955, -3.1606, -3.1247],\n",
       "                        [-3.5737, -3.3460, -2.8501],\n",
       "                        [-2.2557, -2.5679, -3.9761]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1841, -3.2176, -3.1736],\n",
       "                        [-3.8193, -2.9220, -2.9710],\n",
       "                        [-2.1852, -3.9111, -3.0227]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4306, -3.7200, -3.6078],\n",
       "                        [-3.6642, -3.0280, -3.7172],\n",
       "                        [-2.7543, -3.2131, -2.8144]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5090, -2.2943, -3.5644],\n",
       "                        [-3.0150, -2.1338, -3.6936],\n",
       "                        [-2.1472, -2.2934, -2.0290]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6682, -2.3807, -2.9042],\n",
       "                        [-2.7177, -2.1783, -3.1439],\n",
       "                        [-2.7401, -2.8087, -3.9302]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6531, -2.1318, -2.3814],\n",
       "                        [-2.5925, -3.8633, -2.5666],\n",
       "                        [-3.1687, -3.8304, -3.9981]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4917, -3.4084, -2.0845],\n",
       "                        [-3.8301, -3.4964, -2.8178],\n",
       "                        [-2.1240, -3.9695, -3.5436]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1871, -2.0885, -2.3616],\n",
       "                        [-3.9179, -2.3202, -2.9815],\n",
       "                        [-2.3313, -3.9492, -2.6635]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5130, -2.4642, -3.5569],\n",
       "                        [-3.5597, -2.4479, -3.4485],\n",
       "                        [-3.9613, -2.8370, -3.9023]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4471, -2.9049, -2.5081],\n",
       "                        [-3.0561, -2.3261, -3.0233],\n",
       "                        [-3.3036, -3.4472, -2.0442]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2602, -3.3004, -3.1909],\n",
       "                        [-3.0194, -2.4154, -3.2602],\n",
       "                        [-3.0166, -3.8577, -3.2132]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2759, -2.2377, -3.1680],\n",
       "                        [-2.0822, -3.0409, -3.0467],\n",
       "                        [-2.2509, -2.3527, -3.4056]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9987, -3.0252, -3.3888],\n",
       "                        [-3.2693, -2.9531, -2.5457],\n",
       "                        [-3.5743, -2.9816, -2.9569]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1276, -3.1132, -3.0406],\n",
       "                        [-2.1132, -3.8694, -2.9173],\n",
       "                        [-3.7204, -2.2608, -3.7383]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0366, -2.3247, -3.2860],\n",
       "                        [-3.7049, -3.3126, -2.7220],\n",
       "                        [-3.4596, -2.8985, -2.3939]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1705, -2.1989, -2.9071],\n",
       "                        [-2.4815, -2.7882, -3.3933],\n",
       "                        [-2.2882, -2.7888, -3.4737]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0765, -3.1807, -2.6163],\n",
       "                        [-3.8066, -3.5777, -3.2311],\n",
       "                        [-2.5530, -3.6029, -3.9844]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3726, -3.6286, -2.1994],\n",
       "                        [-2.9440, -2.5214, -2.5569],\n",
       "                        [-2.3368, -3.5068, -3.4601]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0863, -2.4355, -3.2090],\n",
       "                        [-3.3335, -2.2014, -2.9983],\n",
       "                        [-2.6257, -3.6411, -3.4257]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4926, -3.3155, -3.3445],\n",
       "                        [-2.0753, -3.7368, -2.6104],\n",
       "                        [-3.1560, -3.8130, -3.2542]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5317, -2.6659, -2.8675],\n",
       "                        [-3.3470, -3.4241, -2.6851],\n",
       "                        [-2.5471, -3.9265, -2.6108]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1700, -2.2743, -2.9562],\n",
       "                        [-2.1973, -3.9539, -3.9973],\n",
       "                        [-2.2685, -3.8024, -2.1443]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5089, -3.3068, -2.2780],\n",
       "                        [-2.0397, -2.4360, -3.8475],\n",
       "                        [-3.1803, -2.2300, -2.6589]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0791, -3.7793, -3.9269],\n",
       "                        [-3.4775, -2.5356, -3.2252],\n",
       "                        [-3.3420, -3.7172, -2.3035]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.1.param_mus',\n",
       "              tensor([ 0.2809,  0.0459,  0.1258, -0.1995,  0.1660,  0.0167, -0.2853, -0.0366,\n",
       "                       0.1365,  0.0775,  0.2575, -0.2328,  0.2005,  0.0950,  0.3182, -0.0661,\n",
       "                       0.0401,  0.1156, -0.2846, -0.0984,  0.1283, -0.2915,  0.2013, -0.2550,\n",
       "                       0.1724,  0.1169,  0.3061, -0.0747,  0.2329,  0.2218, -0.2851,  0.0146])),\n",
       "             ('module_list.0.posterior_params.1.param_std_log',\n",
       "              tensor([-5.8423, -5.5990, -6.1144, -4.7638, -5.0489, -4.7593, -4.6843, -8.9877,\n",
       "                      -4.9280, -5.0391, -7.9117, -4.8865, -5.4963, -7.5179, -7.3670, -6.3617,\n",
       "                      -5.6142, -5.0196, -5.2684, -4.8763, -5.8794, -5.2748, -4.7897, -5.4139,\n",
       "                      -4.6548, -4.8520, -5.7752, -5.4039, -5.0330, -4.9193, -5.4622, -5.3173])),\n",
       "             ('module_list.0.posterior_params.1.scale_alphas_log',\n",
       "              tensor([-3.7699, -2.2629, -3.5090, -2.4368, -3.8877, -3.1643, -3.2643, -3.8376,\n",
       "                      -2.9198, -2.6652, -2.2396, -3.5372, -3.2222, -2.8150, -3.9762, -3.3303,\n",
       "                      -2.2459, -3.4070, -3.2128, -2.9412, -3.4340, -2.1017, -2.1783, -2.5142,\n",
       "                      -3.6847, -2.4663, -2.5701, -3.3436, -3.3203, -3.5416, -2.1945, -2.5401])),\n",
       "             ('module_list.0.posterior_params.1.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.2.param_mus',\n",
       "              tensor([[[[ 0.0316,  0.0157, -0.0203],\n",
       "                        [-0.0577,  0.0054,  0.0501],\n",
       "                        [ 0.0342, -0.0245,  0.0203]],\n",
       "              \n",
       "                       [[ 0.0546, -0.0232, -0.0176],\n",
       "                        [ 0.0429,  0.0443, -0.0128],\n",
       "                        [ 0.0175, -0.0229, -0.0087]],\n",
       "              \n",
       "                       [[ 0.0225, -0.0405, -0.0031],\n",
       "                        [ 0.0266,  0.0236, -0.0153],\n",
       "                        [ 0.0376,  0.0232, -0.0136]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0522, -0.0044, -0.0113],\n",
       "                        [ 0.0334, -0.0206,  0.0559],\n",
       "                        [-0.0314, -0.0332, -0.0366]],\n",
       "              \n",
       "                       [[-0.0155, -0.0313, -0.0225],\n",
       "                        [ 0.0492, -0.0348, -0.0057],\n",
       "                        [-0.0392,  0.0328,  0.0563]],\n",
       "              \n",
       "                       [[ 0.0450, -0.0359,  0.0231],\n",
       "                        [ 0.0420, -0.0214, -0.0426],\n",
       "                        [ 0.0195,  0.0099, -0.0363]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0033,  0.0562,  0.0056],\n",
       "                        [ 0.0327, -0.0148,  0.0141],\n",
       "                        [-0.0510, -0.0161, -0.0385]],\n",
       "              \n",
       "                       [[-0.0102, -0.0244, -0.0055],\n",
       "                        [-0.0272, -0.0345,  0.0082],\n",
       "                        [-0.0578,  0.0072,  0.0248]],\n",
       "              \n",
       "                       [[-0.0243, -0.0541,  0.0444],\n",
       "                        [-0.0358, -0.0143,  0.0197],\n",
       "                        [ 0.0066, -0.0329,  0.0054]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0514,  0.0035,  0.0246],\n",
       "                        [ 0.0226, -0.0434,  0.0063],\n",
       "                        [-0.0450,  0.0492, -0.0176]],\n",
       "              \n",
       "                       [[ 0.0242, -0.0576, -0.0571],\n",
       "                        [ 0.0204, -0.0003,  0.0173],\n",
       "                        [-0.0226, -0.0182,  0.0052]],\n",
       "              \n",
       "                       [[ 0.0145, -0.0573, -0.0361],\n",
       "                        [-0.0232,  0.0455, -0.0579],\n",
       "                        [ 0.0093, -0.0079, -0.0194]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0193, -0.0197, -0.0504],\n",
       "                        [-0.0021,  0.0437, -0.0264],\n",
       "                        [ 0.0289,  0.0509, -0.0013]],\n",
       "              \n",
       "                       [[-0.0442, -0.0494,  0.0021],\n",
       "                        [ 0.0044, -0.0535,  0.0109],\n",
       "                        [ 0.0030, -0.0532, -0.0253]],\n",
       "              \n",
       "                       [[-0.0314, -0.0247,  0.0158],\n",
       "                        [ 0.0202, -0.0500, -0.0396],\n",
       "                        [-0.0072, -0.0355,  0.0335]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0336, -0.0279,  0.0572],\n",
       "                        [ 0.0318,  0.0181, -0.0030],\n",
       "                        [ 0.0204,  0.0043,  0.0462]],\n",
       "              \n",
       "                       [[ 0.0231,  0.0123, -0.0459],\n",
       "                        [-0.0489,  0.0272,  0.0173],\n",
       "                        [ 0.0365, -0.0228, -0.0494]],\n",
       "              \n",
       "                       [[ 0.0573,  0.0110, -0.0469],\n",
       "                        [-0.0028,  0.0440,  0.0321],\n",
       "                        [ 0.0161, -0.0063, -0.0184]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0118,  0.0042, -0.0542],\n",
       "                        [-0.0407,  0.0431,  0.0265],\n",
       "                        [ 0.0421, -0.0147,  0.0289]],\n",
       "              \n",
       "                       [[ 0.0083, -0.0067, -0.0576],\n",
       "                        [ 0.0447, -0.0311, -0.0234],\n",
       "                        [-0.0187,  0.0544,  0.0322]],\n",
       "              \n",
       "                       [[-0.0030,  0.0235,  0.0283],\n",
       "                        [ 0.0300,  0.0446,  0.0302],\n",
       "                        [ 0.0439,  0.0039,  0.0353]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0390, -0.0008, -0.0440],\n",
       "                        [-0.0395, -0.0135, -0.0497],\n",
       "                        [-0.0097, -0.0274,  0.0471]],\n",
       "              \n",
       "                       [[-0.0574, -0.0263,  0.0417],\n",
       "                        [-0.0002,  0.0437, -0.0007],\n",
       "                        [-0.0466,  0.0238,  0.0138]],\n",
       "              \n",
       "                       [[ 0.0029, -0.0251,  0.0008],\n",
       "                        [-0.0345,  0.0197,  0.0253],\n",
       "                        [-0.0069,  0.0119, -0.0237]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0127, -0.0531, -0.0410],\n",
       "                        [-0.0268,  0.0085, -0.0100],\n",
       "                        [ 0.0056, -0.0434, -0.0446]],\n",
       "              \n",
       "                       [[ 0.0147, -0.0077,  0.0230],\n",
       "                        [-0.0539, -0.0351, -0.0170],\n",
       "                        [-0.0242,  0.0284, -0.0522]],\n",
       "              \n",
       "                       [[-0.0381,  0.0490,  0.0528],\n",
       "                        [-0.0177, -0.0271,  0.0348],\n",
       "                        [ 0.0005, -0.0107, -0.0070]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0224, -0.0486, -0.0207],\n",
       "                        [ 0.0474,  0.0022,  0.0517],\n",
       "                        [-0.0358, -0.0142,  0.0037]],\n",
       "              \n",
       "                       [[-0.0360,  0.0533,  0.0412],\n",
       "                        [ 0.0071, -0.0054,  0.0563],\n",
       "                        [ 0.0268,  0.0487, -0.0337]],\n",
       "              \n",
       "                       [[-0.0023, -0.0144,  0.0147],\n",
       "                        [ 0.0424, -0.0461, -0.0004],\n",
       "                        [-0.0059,  0.0462, -0.0059]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0078,  0.0525,  0.0486],\n",
       "                        [ 0.0555,  0.0144, -0.0426],\n",
       "                        [-0.0313,  0.0099, -0.0332]],\n",
       "              \n",
       "                       [[ 0.0509,  0.0306, -0.0096],\n",
       "                        [-0.0194,  0.0470, -0.0297],\n",
       "                        [ 0.0118, -0.0529,  0.0010]],\n",
       "              \n",
       "                       [[ 0.0476,  0.0285,  0.0376],\n",
       "                        [ 0.0136, -0.0042,  0.0369],\n",
       "                        [ 0.0357, -0.0159,  0.0272]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0262,  0.0260,  0.0522],\n",
       "                        [-0.0215,  0.0448, -0.0101],\n",
       "                        [ 0.0485,  0.0570,  0.0354]],\n",
       "              \n",
       "                       [[-0.0356, -0.0173,  0.0091],\n",
       "                        [ 0.0368, -0.0297,  0.0491],\n",
       "                        [ 0.0286, -0.0098, -0.0393]],\n",
       "              \n",
       "                       [[ 0.0540, -0.0537, -0.0321],\n",
       "                        [-0.0250,  0.0127, -0.0142],\n",
       "                        [ 0.0291, -0.0500, -0.0165]]]])),\n",
       "             ('module_list.0.posterior_params.2.param_std_log',\n",
       "              tensor([[[[ -9.8160,  -8.2878,  -9.0872],\n",
       "                        [ -5.4397,  -5.6462,  -5.7565],\n",
       "                        [ -5.2870,  -5.2141,  -4.7615]],\n",
       "              \n",
       "                       [[ -4.7025,  -5.2309,  -5.4760],\n",
       "                        [ -4.6421,  -5.6561,  -6.1246],\n",
       "                        [ -4.9228,  -5.4121,  -5.1588]],\n",
       "              \n",
       "                       [[ -7.1780,  -7.1960,  -6.7923],\n",
       "                        [ -5.4248,  -5.1166,  -6.8615],\n",
       "                        [ -4.7873,  -4.8766,  -4.7434]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.8691,  -8.1647,  -4.9927],\n",
       "                        [ -8.0910,  -4.7028,  -4.8536],\n",
       "                        [ -4.9025,  -4.8885,  -7.8909]],\n",
       "              \n",
       "                       [[ -5.1599,  -5.0218,  -4.7514],\n",
       "                        [ -5.7379,  -5.0703,  -7.6476],\n",
       "                        [ -4.9491,  -4.8722,  -5.1946]],\n",
       "              \n",
       "                       [[ -4.9785,  -5.8707,  -5.5641],\n",
       "                        [ -5.0246,  -4.7492,  -4.9898],\n",
       "                        [ -5.7512,  -5.2407,  -5.1503]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9477,  -9.2638,  -6.1910],\n",
       "                        [ -5.2779,  -5.6292,  -4.6801],\n",
       "                        [ -5.3064,  -4.6078,  -5.5724]],\n",
       "              \n",
       "                       [[ -6.3550,  -5.9306,  -4.7697],\n",
       "                        [ -5.4013,  -5.9634,  -5.2230],\n",
       "                        [ -5.3543,  -4.8651,  -8.0622]],\n",
       "              \n",
       "                       [[ -4.7251,  -8.3836,  -5.1631],\n",
       "                        [-10.1605,  -5.7589,  -8.7752],\n",
       "                        [ -7.7111,  -5.8897,  -5.1032]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.2510,  -4.7562,  -7.1329],\n",
       "                        [ -4.6069,  -4.6932,  -4.9170],\n",
       "                        [ -5.2044,  -4.8047,  -4.6908]],\n",
       "              \n",
       "                       [[ -6.5016,  -5.0068,  -4.9847],\n",
       "                        [ -4.6460,  -4.9465,  -4.8268],\n",
       "                        [ -4.6241,  -8.1769,  -5.0839]],\n",
       "              \n",
       "                       [[ -5.3999,  -4.6043,  -4.8351],\n",
       "                        [ -5.8048,  -4.9700,  -7.0310],\n",
       "                        [ -4.8651,  -5.6233,  -5.0057]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.0941,  -4.6921,  -4.8880],\n",
       "                        [ -6.2416,  -5.2891,  -6.5550],\n",
       "                        [ -5.2259,  -5.1810,  -5.6172]],\n",
       "              \n",
       "                       [[ -7.0652,  -7.4046,  -5.3346],\n",
       "                        [ -4.8738,  -5.2593,  -5.4168],\n",
       "                        [ -4.9336,  -7.5453,  -4.9111]],\n",
       "              \n",
       "                       [[ -5.6563,  -5.0307,  -4.7169],\n",
       "                        [ -5.2157,  -5.0157,  -7.0427],\n",
       "                        [ -5.0872,  -4.6451,  -9.4825]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.9930,  -7.0743,  -5.4742],\n",
       "                        [ -5.2183,  -5.4632,  -4.9555],\n",
       "                        [ -6.5984,  -5.2257,  -5.1601]],\n",
       "              \n",
       "                       [[ -6.3447,  -4.7239,  -4.9029],\n",
       "                        [ -4.6379,  -5.8729,  -4.7153],\n",
       "                        [ -5.1821,  -5.5978,  -4.8325]],\n",
       "              \n",
       "                       [[ -6.7889,  -4.9651,  -5.2931],\n",
       "                        [ -5.5394,  -6.7781,  -5.1973],\n",
       "                        [ -4.8068,  -7.0349,  -4.6368]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ -6.9915,  -5.6419,  -4.6257],\n",
       "                        [ -5.6515,  -4.7430,  -5.4308],\n",
       "                        [ -4.6798,  -6.9028,  -5.3530]],\n",
       "              \n",
       "                       [[ -5.3206,  -5.4343,  -5.0117],\n",
       "                        [ -5.2829,  -5.3243,  -5.6549],\n",
       "                        [ -5.5766,  -4.8307,  -4.8617]],\n",
       "              \n",
       "                       [[ -4.6159,  -6.2552,  -6.9179],\n",
       "                        [ -5.7141,  -5.6426,  -6.0328],\n",
       "                        [ -5.4778,  -4.7403,  -5.5728]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -8.5254,  -5.0386,  -5.0464],\n",
       "                        [ -4.7536,  -5.7276,  -5.1615],\n",
       "                        [ -5.5853,  -5.4955,  -6.2394]],\n",
       "              \n",
       "                       [[ -5.0479,  -6.3655,  -5.1769],\n",
       "                        [ -4.8733,  -6.2668,  -5.8473],\n",
       "                        [ -7.7186,  -6.0421,  -8.7987]],\n",
       "              \n",
       "                       [[ -4.6488,  -5.3406,  -4.6545],\n",
       "                        [ -6.3212,  -4.9119,  -5.2095],\n",
       "                        [ -4.6151,  -7.3869,  -4.6851]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.8688,  -4.9913,  -6.3743],\n",
       "                        [ -5.6083,  -4.6803,  -5.3046],\n",
       "                        [ -6.4616,  -5.0908,  -4.6750]],\n",
       "              \n",
       "                       [[ -4.8880,  -4.6234,  -6.5282],\n",
       "                        [ -8.4829,  -4.7247,  -5.8744],\n",
       "                        [ -5.5975,  -7.5122,  -5.7736]],\n",
       "              \n",
       "                       [[ -6.6118,  -4.6895,  -6.2846],\n",
       "                        [ -4.8687,  -4.9342,  -4.8633],\n",
       "                        [ -4.6178,  -5.1776,  -6.7466]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.9686,  -5.2524,  -5.4588],\n",
       "                        [ -6.2967,  -5.3435,  -5.2934],\n",
       "                        [ -5.2137,  -7.2625,  -5.0120]],\n",
       "              \n",
       "                       [[ -5.1240,  -5.0241,  -4.6214],\n",
       "                        [ -6.1016,  -6.5488,  -4.9567],\n",
       "                        [ -4.6304,  -4.9003,  -6.1200]],\n",
       "              \n",
       "                       [[ -6.5544,  -5.4232,  -6.2495],\n",
       "                        [ -5.1870,  -4.8474,  -4.9601],\n",
       "                        [ -5.0372,  -5.9677,  -4.6056]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3892,  -6.7739,  -4.7658],\n",
       "                        [ -4.9211,  -5.0567,  -7.5088],\n",
       "                        [ -6.4514,  -6.3463,  -6.3136]],\n",
       "              \n",
       "                       [[ -6.6182,  -4.7512,  -4.9776],\n",
       "                        [ -6.8122,  -4.6144,  -4.6187],\n",
       "                        [ -7.0007,  -5.3790,  -5.5945]],\n",
       "              \n",
       "                       [[ -5.2762,  -4.7876,  -4.7124],\n",
       "                        [ -4.6391,  -5.0517,  -5.4007],\n",
       "                        [ -7.8810,  -7.1520,  -4.6797]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.9805,  -4.6148,  -5.1969],\n",
       "                        [ -5.6914,  -4.8208,  -4.6341],\n",
       "                        [ -4.7811,  -4.7402,  -4.7416]],\n",
       "              \n",
       "                       [[ -5.3055,  -6.2130,  -5.4512],\n",
       "                        [ -4.9706,  -5.4768,  -5.2818],\n",
       "                        [ -4.9966,  -5.0446,  -5.1518]],\n",
       "              \n",
       "                       [[ -4.8851,  -4.6916,  -5.1195],\n",
       "                        [ -5.5267,  -5.3815,  -5.3967],\n",
       "                        [ -5.1913,  -4.8602,  -4.6831]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_alphas_log',\n",
       "              tensor([[[[-2.6708, -3.7551, -3.1189],\n",
       "                        [-3.8326, -2.4728, -2.5904],\n",
       "                        [-3.3719, -2.3253, -3.2637]],\n",
       "              \n",
       "                       [[-2.6648, -2.5342, -2.7739],\n",
       "                        [-2.7934, -3.9618, -2.1445],\n",
       "                        [-2.9612, -2.3004, -3.0350]],\n",
       "              \n",
       "                       [[-2.8471, -3.1955, -2.3854],\n",
       "                        [-3.6564, -3.4344, -3.7782],\n",
       "                        [-3.5369, -3.8519, -2.6325]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5991, -2.0199, -2.1233],\n",
       "                        [-2.1016, -2.2106, -3.9748],\n",
       "                        [-3.7909, -2.1369, -2.4780]],\n",
       "              \n",
       "                       [[-3.4479, -3.7296, -2.8969],\n",
       "                        [-2.2975, -2.5162, -2.4447],\n",
       "                        [-2.8348, -2.0720, -3.0581]],\n",
       "              \n",
       "                       [[-3.7307, -3.1034, -3.2887],\n",
       "                        [-3.1465, -2.5216, -2.4771],\n",
       "                        [-2.8391, -3.6378, -2.4676]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8475, -2.8147, -2.8092],\n",
       "                        [-3.7948, -3.1370, -2.2852],\n",
       "                        [-2.6503, -2.5590, -2.0351]],\n",
       "              \n",
       "                       [[-2.5615, -3.9959, -2.4078],\n",
       "                        [-3.2859, -3.7989, -3.1635],\n",
       "                        [-3.5403, -2.3675, -2.7670]],\n",
       "              \n",
       "                       [[-3.1526, -2.2708, -3.2939],\n",
       "                        [-2.8639, -3.2114, -2.4769],\n",
       "                        [-2.2941, -2.8516, -2.6155]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.1011, -2.8229, -3.4500],\n",
       "                        [-3.8107, -2.8843, -3.6491],\n",
       "                        [-2.1847, -3.4471, -3.3394]],\n",
       "              \n",
       "                       [[-2.2714, -3.4715, -3.0056],\n",
       "                        [-3.3074, -2.2614, -2.6675],\n",
       "                        [-3.5570, -2.8104, -3.0236]],\n",
       "              \n",
       "                       [[-2.5283, -3.5225, -3.2782],\n",
       "                        [-2.6086, -3.8404, -2.0397],\n",
       "                        [-3.6361, -2.7740, -3.1817]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9397, -2.1887, -3.9978],\n",
       "                        [-2.0272, -2.2477, -2.5769],\n",
       "                        [-2.3136, -3.0527, -3.4411]],\n",
       "              \n",
       "                       [[-2.6459, -3.5431, -3.9385],\n",
       "                        [-3.5950, -2.3299, -2.2561],\n",
       "                        [-3.2015, -2.6298, -2.9787]],\n",
       "              \n",
       "                       [[-3.1159, -2.4469, -2.0356],\n",
       "                        [-3.4005, -3.1047, -3.1597],\n",
       "                        [-3.9587, -2.7050, -2.9658]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5106, -2.7883, -3.1245],\n",
       "                        [-2.4516, -2.2267, -2.5949],\n",
       "                        [-2.5968, -3.6347, -2.0170]],\n",
       "              \n",
       "                       [[-2.8326, -3.7165, -2.0488],\n",
       "                        [-2.0636, -3.1634, -3.1988],\n",
       "                        [-3.9365, -2.4189, -3.7980]],\n",
       "              \n",
       "                       [[-2.0888, -2.9007, -3.3267],\n",
       "                        [-2.5138, -2.5858, -2.8375],\n",
       "                        [-3.1915, -2.3994, -2.3591]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.1274, -3.6271, -2.1576],\n",
       "                        [-2.9771, -3.6624, -3.9825],\n",
       "                        [-3.7351, -2.9187, -3.9739]],\n",
       "              \n",
       "                       [[-2.5195, -2.6703, -2.9357],\n",
       "                        [-2.7282, -2.9299, -3.1480],\n",
       "                        [-2.5105, -3.6901, -2.4087]],\n",
       "              \n",
       "                       [[-3.3308, -2.9273, -2.3080],\n",
       "                        [-3.3339, -2.8513, -2.7537],\n",
       "                        [-3.4311, -3.3386, -3.6150]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4682, -2.2300, -3.5046],\n",
       "                        [-2.1635, -3.5545, -2.5593],\n",
       "                        [-3.7978, -3.1113, -3.5799]],\n",
       "              \n",
       "                       [[-2.9903, -3.4998, -3.5468],\n",
       "                        [-2.3833, -3.8778, -2.5556],\n",
       "                        [-3.1480, -2.7781, -2.3946]],\n",
       "              \n",
       "                       [[-2.7622, -3.8699, -3.3894],\n",
       "                        [-3.0383, -2.0985, -3.3252],\n",
       "                        [-3.8566, -2.1773, -2.1942]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9417, -2.1430, -2.4474],\n",
       "                        [-3.3327, -3.4004, -2.1575],\n",
       "                        [-3.6564, -3.9154, -3.0489]],\n",
       "              \n",
       "                       [[-3.2183, -3.0222, -3.4177],\n",
       "                        [-3.4403, -3.8521, -2.2094],\n",
       "                        [-3.0951, -2.2278, -2.9596]],\n",
       "              \n",
       "                       [[-2.5221, -3.3716, -2.6504],\n",
       "                        [-2.0578, -3.2558, -3.6113],\n",
       "                        [-2.2082, -3.2919, -2.7404]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.5466, -3.8607, -3.9542],\n",
       "                        [-2.1979, -2.4029, -3.9868],\n",
       "                        [-2.9700, -3.9234, -2.2832]],\n",
       "              \n",
       "                       [[-2.6979, -2.4574, -2.8219],\n",
       "                        [-2.8278, -3.6978, -2.5641],\n",
       "                        [-3.6614, -2.7231, -2.7259]],\n",
       "              \n",
       "                       [[-3.0610, -2.4355, -3.6477],\n",
       "                        [-3.2526, -3.0627, -3.5074],\n",
       "                        [-3.0113, -3.1055, -3.3588]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1990, -3.3439, -2.7901],\n",
       "                        [-3.0792, -3.3070, -3.4699],\n",
       "                        [-3.1442, -2.0215, -3.1312]],\n",
       "              \n",
       "                       [[-2.8588, -3.1403, -3.6591],\n",
       "                        [-2.8823, -2.5807, -2.9023],\n",
       "                        [-3.0156, -2.6237, -2.0226]],\n",
       "              \n",
       "                       [[-3.8294, -2.6921, -2.1612],\n",
       "                        [-2.3686, -3.2377, -3.5910],\n",
       "                        [-3.7999, -2.5346, -2.9541]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.0855, -3.8150, -2.3139],\n",
       "                        [-3.8859, -2.8339, -2.4873],\n",
       "                        [-3.9359, -3.4058, -3.7406]],\n",
       "              \n",
       "                       [[-3.7487, -3.8834, -2.2428],\n",
       "                        [-3.1249, -3.3806, -3.9321],\n",
       "                        [-2.3478, -2.4059, -3.6055]],\n",
       "              \n",
       "                       [[-2.9292, -3.1609, -2.5993],\n",
       "                        [-2.7661, -3.6543, -3.2429],\n",
       "                        [-3.3789, -2.8616, -3.1544]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.3.param_mus',\n",
       "              tensor([ 4.1539e-02,  5.7190e-02,  5.7607e-02, -5.7313e-03,  4.5703e-02,\n",
       "                      -3.9403e-02,  3.3062e-02,  3.0239e-02,  3.9690e-02, -4.1816e-02,\n",
       "                      -1.7884e-02,  4.9022e-03, -4.8174e-02, -1.9403e-02,  1.0979e-02,\n",
       "                       1.1211e-02,  3.7324e-02,  4.4533e-02,  2.5723e-02,  1.4041e-03,\n",
       "                      -2.3933e-02,  1.3083e-02,  1.4502e-02, -1.6059e-02,  2.5677e-02,\n",
       "                      -5.6865e-02, -3.1650e-02,  4.5923e-02,  2.7903e-02, -1.1275e-02,\n",
       "                      -2.8342e-02,  3.5090e-02,  1.9823e-05,  3.3122e-02, -2.7005e-02,\n",
       "                      -5.3014e-02, -1.8398e-02,  1.2195e-02,  4.1372e-02, -4.8659e-02,\n",
       "                      -2.6498e-02, -3.3190e-02,  1.7129e-02, -1.2126e-02, -6.6982e-03,\n",
       "                       2.6318e-02,  5.6053e-02,  3.2684e-02,  8.0737e-03,  4.1922e-02,\n",
       "                      -3.3682e-03, -2.3151e-02, -3.7331e-02, -4.2175e-02,  4.5858e-02,\n",
       "                       5.4774e-02,  4.0846e-02,  4.9387e-02, -4.2630e-02,  3.4076e-02,\n",
       "                       7.4895e-03,  2.8771e-02,  4.7267e-02,  2.1797e-02])),\n",
       "             ('module_list.0.posterior_params.3.param_std_log',\n",
       "              tensor([ -4.7356,  -5.3830,  -7.4981,  -5.9037,  -5.0968,  -5.0780,  -4.7452,\n",
       "                       -4.7958,  -6.1969,  -5.5558,  -7.0556,  -5.3374,  -4.9485,  -5.7415,\n",
       "                       -4.7360,  -4.9982,  -4.7122,  -5.3383,  -4.8023,  -6.3568,  -4.8183,\n",
       "                       -5.1908,  -4.8322,  -5.0773,  -5.3403,  -5.4196, -10.5347,  -4.8538,\n",
       "                       -7.6096,  -5.3380,  -6.8794,  -6.8063,  -5.2716,  -6.5816,  -5.1337,\n",
       "                       -4.9194,  -5.8577,  -4.9891,  -5.0248,  -4.6722,  -6.1502,  -4.9200,\n",
       "                       -5.4138,  -4.8896,  -7.3196,  -6.1379,  -5.2092,  -5.1115,  -5.7318,\n",
       "                       -5.1227,  -5.1307,  -5.3368,  -7.1596,  -5.7785,  -4.7988,  -5.1099,\n",
       "                       -4.8352,  -4.9528,  -4.6095,  -5.1014,  -4.6176,  -4.7222,  -5.2042,\n",
       "                       -4.7724])),\n",
       "             ('module_list.0.posterior_params.3.scale_alphas_log',\n",
       "              tensor([-3.7860, -2.1592, -2.5224, -3.1835, -2.3221, -3.5613, -3.5781, -2.8131,\n",
       "                      -2.4862, -2.6616, -2.1922, -3.6470, -3.1211, -3.1925, -3.9131, -2.8834,\n",
       "                      -2.6850, -2.2319, -3.8319, -2.2702, -3.6130, -2.2009, -3.1335, -2.8103,\n",
       "                      -3.1897, -3.0770, -2.4984, -2.0462, -2.0594, -2.9192, -3.8937, -3.8722,\n",
       "                      -2.7047, -2.3228, -2.7585, -3.7140, -2.4401, -2.1603, -3.6450, -2.7215,\n",
       "                      -2.8982, -2.3918, -2.1194, -2.2393, -2.8007, -2.9086, -3.2894, -2.9929,\n",
       "                      -3.4601, -2.1792, -2.2189, -3.0124, -2.9562, -3.2878, -2.5506, -1.9997,\n",
       "                      -2.0690, -2.6355, -3.7702, -3.9408, -2.9941, -2.7001, -2.3605, -2.3755])),\n",
       "             ('module_list.0.posterior_params.3.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.4.param_mus',\n",
       "              tensor([[-1.5337e-02,  1.4584e-02,  1.2526e-02,  ...,  5.8489e-04,\n",
       "                       -2.7068e-04,  3.6999e-04],\n",
       "                      [ 2.1179e-04, -1.4780e-02,  2.2576e-03,  ...,  1.0240e-02,\n",
       "                       -7.0898e-04,  9.5543e-03],\n",
       "                      [-1.1712e-02,  1.3465e-02,  3.9852e-03,  ..., -1.8455e-05,\n",
       "                       -1.6303e-02,  1.8577e-03],\n",
       "                      ...,\n",
       "                      [-4.4104e-03, -6.0635e-03,  6.3180e-03,  ..., -9.3344e-04,\n",
       "                        2.1544e-03, -2.0929e-03],\n",
       "                      [-2.9550e-03,  5.9907e-03, -2.4263e-03,  ...,  1.3448e-02,\n",
       "                       -1.1717e-03,  2.8749e-04],\n",
       "                      [ 1.1669e-02, -1.6290e-02, -1.2708e-03,  ..., -9.2287e-04,\n",
       "                        1.3480e-02, -8.5691e-04]])),\n",
       "             ('module_list.0.posterior_params.4.param_std_log',\n",
       "              tensor([[-4.9005, -4.9358, -5.2207,  ..., -4.6553, -4.9249, -5.0482],\n",
       "                      [-5.3381, -4.7070, -4.8170,  ..., -5.9609, -6.6296, -5.3654],\n",
       "                      [-5.7353, -4.7324, -4.9074,  ..., -4.6462, -7.0206, -5.0046],\n",
       "                      ...,\n",
       "                      [-4.9025, -5.0534, -5.8751,  ..., -5.1953, -4.7055, -5.5008],\n",
       "                      [-5.1505, -4.7450, -6.5138,  ..., -4.8876, -4.6799, -5.6588],\n",
       "                      [-4.7323, -4.9922, -4.7932,  ..., -6.8722, -4.8829, -5.1280]])),\n",
       "             ('module_list.0.posterior_params.4.scale_alphas_log',\n",
       "              tensor([[-3.6055, -2.0734, -3.6081,  ..., -2.9918, -2.2910, -2.5256],\n",
       "                      [-2.4526, -3.7418, -2.8126,  ..., -2.3148, -2.0245, -2.0954],\n",
       "                      [-2.6678, -3.1369, -3.1742,  ..., -2.5796, -3.9361, -3.7291],\n",
       "                      ...,\n",
       "                      [-3.7518, -2.8004, -2.8894,  ..., -3.3936, -3.0414, -2.2999],\n",
       "                      [-3.1791, -3.3750, -2.7291,  ..., -3.9335, -2.6925, -2.6924],\n",
       "                      [-3.3847, -3.1915, -3.8963,  ..., -3.7753, -2.9934, -2.1145]])),\n",
       "             ('module_list.0.posterior_params.4.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.5.param_mus',\n",
       "              tensor([ 1.6533e-02,  1.0326e-02,  1.1081e-02,  1.6404e-02,  1.4232e-02,\n",
       "                      -1.4051e-02,  1.6417e-02, -1.6611e-02,  1.4738e-02, -8.1589e-03,\n",
       "                       1.1211e-02,  1.3180e-02, -2.5274e-03, -7.2020e-04, -1.4420e-02,\n",
       "                       1.6024e-02, -1.4482e-02, -9.6689e-03, -1.0948e-02,  1.3951e-02,\n",
       "                       3.2561e-03, -1.4332e-04, -9.9656e-03, -1.0719e-02,  4.6882e-03,\n",
       "                      -1.1900e-02,  1.4266e-02,  5.3570e-04, -1.2251e-02,  1.9511e-04,\n",
       "                      -1.1367e-02, -3.4232e-03, -3.8105e-03, -1.0850e-02,  4.3341e-03,\n",
       "                      -8.9158e-03, -8.5685e-03, -2.9176e-05,  2.7076e-04,  1.2191e-02,\n",
       "                       1.5734e-02, -4.3270e-03,  5.8746e-03, -6.2046e-03, -1.2295e-02,\n",
       "                      -2.3688e-03, -5.4514e-03,  2.6108e-03, -1.5049e-02, -1.5133e-02,\n",
       "                      -2.8079e-03, -1.4082e-03,  3.6390e-03, -9.8725e-03, -1.6857e-02,\n",
       "                      -9.3517e-03,  6.4753e-04,  7.0959e-04, -1.3368e-03,  7.6177e-03,\n",
       "                      -7.0566e-03,  5.4972e-03,  8.8718e-03, -8.5762e-03,  1.4082e-02,\n",
       "                      -8.6748e-03, -1.2254e-02, -1.6229e-02,  3.1135e-04, -1.2190e-02,\n",
       "                       1.5744e-02,  8.1070e-04, -2.9439e-03, -7.1331e-03,  3.1813e-03,\n",
       "                      -9.0519e-03, -1.0026e-02, -1.1023e-02,  4.8062e-03,  4.3610e-03,\n",
       "                      -5.2083e-04, -1.4528e-02, -6.2744e-03,  9.9057e-03, -4.0322e-03,\n",
       "                      -4.5653e-03,  1.8964e-03,  1.6640e-02,  1.4505e-03, -1.5328e-02,\n",
       "                       1.3922e-02, -6.9058e-05, -1.4823e-02,  5.1072e-03,  1.1861e-02,\n",
       "                       3.5855e-04,  9.0185e-03,  3.7934e-03, -3.3967e-03, -5.6805e-03,\n",
       "                      -3.6370e-03, -6.5381e-04,  1.2001e-02, -8.0242e-03, -3.3800e-03,\n",
       "                      -3.3562e-04,  1.0406e-02,  2.6299e-04,  1.0645e-02,  7.6685e-03,\n",
       "                      -8.4984e-04,  8.6902e-03,  2.8986e-03,  1.2156e-02,  1.9200e-03,\n",
       "                      -7.9660e-03, -5.3466e-03, -6.4142e-03,  1.5696e-02, -1.4381e-03,\n",
       "                       2.3950e-03, -8.9440e-03,  1.0656e-03,  8.6319e-03,  1.3785e-02,\n",
       "                       1.2189e-02,  3.4768e-04, -1.4362e-02])),\n",
       "             ('module_list.0.posterior_params.5.param_std_log',\n",
       "              tensor([ -8.2366,  -5.0983,  -4.8645,  -4.7711,  -5.8253,  -6.5226,  -5.0606,\n",
       "                       -5.2259,  -5.3590,  -5.7836,  -6.3341,  -4.7679,  -7.3174,  -5.7766,\n",
       "                       -5.2299,  -5.2708,  -4.8598,  -5.0658,  -6.0717,  -5.1017,  -4.6929,\n",
       "                       -5.0890,  -5.5675, -11.0617,  -5.1685,  -5.7089,  -4.9668,  -7.0701,\n",
       "                       -4.9822,  -5.4202,  -5.5536,  -6.1450,  -6.0286,  -6.9987,  -4.9326,\n",
       "                       -5.7021,  -5.5378,  -7.3642,  -6.2143,  -6.2973,  -6.2897,  -5.7166,\n",
       "                       -5.2637,  -4.8364,  -4.8708,  -5.8620,  -4.9510,  -4.6683,  -5.0747,\n",
       "                       -4.9368,  -4.7995,  -6.7841,  -4.9920,  -5.4213,  -5.4100,  -6.4717,\n",
       "                       -4.8690,  -9.3201,  -4.6867,  -7.2298,  -5.2512,  -4.9947,  -5.5228,\n",
       "                       -8.3407,  -5.1401,  -5.0715,  -4.6927,  -4.7562,  -5.1099,  -4.6669,\n",
       "                       -5.5449,  -4.8149,  -5.5546,  -4.9569,  -6.6028,  -7.7490,  -5.2452,\n",
       "                       -4.6876,  -5.2146,  -5.6392,  -5.4124,  -4.8836,  -4.8222, -13.1231,\n",
       "                       -4.9991,  -4.7325,  -5.5522,  -6.5608,  -5.2739,  -4.7258,  -5.4663,\n",
       "                       -6.0616,  -5.4965,  -5.5333,  -4.6610,  -6.5839,  -4.7758,  -7.0320,\n",
       "                       -4.9922,  -4.6821,  -4.6373,  -4.6326,  -6.8627,  -7.0440,  -5.4813,\n",
       "                       -6.8849,  -4.7765,  -8.6893,  -5.0077,  -5.4790,  -5.7800,  -4.6140,\n",
       "                       -4.6633,  -7.6646,  -7.0012,  -4.6438, -11.0707,  -5.4507,  -5.1577,\n",
       "                       -5.9563,  -4.9487,  -4.7646,  -5.0705,  -4.7930,  -5.4795,  -6.8562,\n",
       "                       -6.7237,  -4.7267])),\n",
       "             ('module_list.0.posterior_params.5.scale_alphas_log',\n",
       "              tensor([-3.2496, -3.2840, -3.1654, -2.2186, -2.0312, -2.5825, -2.6224, -3.9943,\n",
       "                      -3.4058, -3.9576, -2.0401, -2.2688, -2.1599, -3.6682, -2.7629, -3.6288,\n",
       "                      -3.6923, -2.6895, -2.2660, -3.2739, -3.6964, -2.4578, -3.4816, -3.7200,\n",
       "                      -2.7976, -2.6356, -3.5015, -2.3652, -2.7260, -2.2867, -3.7757, -3.8314,\n",
       "                      -3.0580, -2.5417, -3.6043, -3.2573, -3.1635, -3.5354, -3.5456, -2.1891,\n",
       "                      -2.6875, -3.4492, -3.1763, -2.0508, -3.6563, -2.8375, -2.6308, -3.6222,\n",
       "                      -3.4091, -2.8387, -2.3182, -2.2666, -3.9335, -3.3633, -2.6456, -2.9322,\n",
       "                      -2.8072, -2.4549, -2.4280, -3.1373, -2.7335, -2.4130, -3.5521, -2.8976,\n",
       "                      -3.7468, -2.1407, -2.2353, -3.9124, -3.8386, -2.4035, -2.2970, -3.2796,\n",
       "                      -3.0813, -2.0088, -3.0807, -2.7075, -2.2094, -2.3646, -2.4947, -2.4224,\n",
       "                      -3.5232, -2.2759, -2.8622, -3.9448, -2.9196, -2.8846, -3.5863, -2.9635,\n",
       "                      -3.3143, -3.4068, -2.8788, -3.0387, -3.2242, -3.6309, -2.0579, -3.6323,\n",
       "                      -3.2490, -3.0411, -3.9639, -2.6344, -3.2649, -3.7415, -3.7286, -2.8895,\n",
       "                      -3.9094, -2.2639, -2.7380, -2.6198, -2.8647, -3.3665, -3.1935, -3.7499,\n",
       "                      -3.1402, -2.2498, -2.1294, -3.9743, -3.9144, -2.8427, -2.4026, -3.5866,\n",
       "                      -3.2123, -2.8546, -3.1692, -2.5461, -2.6219, -3.2579, -3.9485, -2.9517])),\n",
       "             ('module_list.0.posterior_params.5.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('module_list.0.posterior_params.6.param_mus',\n",
       "              tensor([[ 0.0816, -0.0732,  0.0030,  ...,  0.0158, -0.0733, -0.0591],\n",
       "                      [ 0.0551,  0.0470,  0.0798,  ...,  0.0646,  0.0181, -0.0333],\n",
       "                      [ 0.0066, -0.0310, -0.0576,  ..., -0.0464, -0.0810,  0.0346],\n",
       "                      ...,\n",
       "                      [ 0.0073, -0.0141, -0.0869,  ..., -0.0049, -0.0028, -0.0234],\n",
       "                      [ 0.0364,  0.0172,  0.0732,  ...,  0.0834,  0.0327,  0.0757],\n",
       "                      [ 0.0430,  0.0687,  0.0129,  ...,  0.0027,  0.0649,  0.0127]])),\n",
       "             ('module_list.0.posterior_params.6.param_std_log',\n",
       "              tensor([[-5.9510, -6.6026, -5.2028,  ..., -5.2436, -5.9582, -5.3737],\n",
       "                      [-4.9577, -5.0050, -5.0326,  ..., -4.8070, -4.8850, -5.1634],\n",
       "                      [-6.5324, -5.0440, -4.8236,  ..., -5.8018, -5.0043, -4.7082],\n",
       "                      ...,\n",
       "                      [-5.1059, -5.8829, -5.2848,  ..., -4.7389, -5.9443, -4.6654],\n",
       "                      [-5.1779, -5.0363, -5.0763,  ..., -4.7351, -5.1824, -5.3695],\n",
       "                      [-4.6850, -4.7959, -5.2654,  ..., -5.7445, -4.6746, -5.9050]])),\n",
       "             ('module_list.0.posterior_params.6.scale_alphas_log',\n",
       "              tensor([[-3.6981, -3.5990, -2.4124,  ..., -3.5876, -2.3265, -3.2337],\n",
       "                      [-3.5059, -3.3682, -3.4724,  ..., -3.1253, -3.3925, -2.4833],\n",
       "                      [-3.0434, -3.1776, -3.4474,  ..., -3.1774, -2.8964, -2.7794],\n",
       "                      ...,\n",
       "                      [-2.9587, -3.9703, -2.8524,  ..., -3.1719, -2.5423, -2.8329],\n",
       "                      [-2.3247, -3.2416, -2.1618,  ..., -3.5066, -3.7951, -3.1546],\n",
       "                      [-3.8693, -2.7667, -3.7745,  ..., -2.2323, -2.0669, -3.4408]])),\n",
       "             ('module_list.0.posterior_params.6.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.7.param_mus',\n",
       "              tensor([ 0.0821,  0.0132, -0.0330,  0.0742, -0.0628,  0.0026,  0.0620, -0.0232,\n",
       "                      -0.0819, -0.0460])),\n",
       "             ('module_list.0.posterior_params.7.param_std_log',\n",
       "              tensor([-6.6942, -5.0067, -4.9992, -5.7169, -4.8333, -5.5636, -6.1745, -7.2947,\n",
       "                      -4.6531, -5.1420])),\n",
       "             ('module_list.0.posterior_params.7.scale_alphas_log',\n",
       "              tensor([-2.8062, -2.7360, -3.5748, -2.8217, -3.6504, -3.6697, -3.7784, -2.9999,\n",
       "                      -2.6156, -2.3703])),\n",
       "             ('module_list.0.posterior_params.7.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward делается по последнему сохраненному сэмплу. Заметим, что мы нигде не копируем данные, и модели не инкапсулируется. Поэтому, чтобы отвязать, их неободимо скопировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0778,  0.0181, -0.0610,  0.0948, -0.0597, -0.0267,  0.0706, -0.0306,\n",
      "         -0.0909, -0.0415]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0778,  0.0181, -0.0610,  0.0948, -0.0597, -0.0267,  0.0706, -0.0306,\n",
      "         -0.0909, -0.0415]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(bayes_model(torch.zeros_like(image)))\n",
    "#print(bayes_model(torch.zeros_like(image), sample = False))\n",
    "print(module(torch.zeros_like(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы импортируем несколько модулей для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayescomp.bayes.variational.trainer import VarBayesTrainer, VarTrainerParams, Beta_Scheduler_Plato, CallbackLossAccuracy #Сам тренер, Параметры тренера, Планировщик beta(коэффициент сооьношения между обычным лоссом и байесовским), и callback для метрики точности\n",
    "from bayescomp.report.base import ReportChain #Это просто список callback\n",
    "from bayescomp.report.variational import VarBaseReport #Этот модуль callback просто выводит каждый шаг данные от тренера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = Beta_Scheduler_Plato()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207e90a9ac6c4a8c8eb30ca114563c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4000],Loss:30396.640625, KL Loss: 3039456.75. FitLoss: 2.070071220397949,Accuracy:0.42060000000000003,Validation Loss:30366.765625,Validation Accuracy:0.687, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [2/4000],Loss:30343.501953125, KL Loss: 3034233.75. FitLoss: 1.1637693643569946,Accuracy:0.7126374999999999,Validation Loss:30313.7265625,Validation Accuracy:0.793, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [3/4000],Loss:30290.798828125, KL Loss: 3029015.5. FitLoss: 0.6407099962234497,Accuracy:0.7932125000000003,Validation Loss:30261.302734375,Validation Accuracy:0.864, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [4/4000],Loss:30238.435546875, KL Loss: 3023794.75. FitLoss: 0.4896555244922638,Accuracy:0.8437499999999998,Validation Loss:30208.990234375,Validation Accuracy:0.865, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [5/4000],Loss:30186.09375, KL Loss: 3018569.25. FitLoss: 0.3991885483264923,Accuracy:0.8764874999999999,Validation Loss:30156.63671875,Validation Accuracy:0.897, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [6/4000],Loss:30133.73828125, KL Loss: 3013341.75. FitLoss: 0.32433369755744934,Accuracy:0.8995750000000001,Validation Loss:30104.30859375,Validation Accuracy:0.906, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [7/4000],Loss:30081.396484375, KL Loss: 3008111.0. FitLoss: 0.28646376729011536,Accuracy:0.9127000000000004,Validation Loss:30051.955078125,Validation Accuracy:0.923, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [8/4000],Loss:30029.041015625, KL Loss: 3002878.5. FitLoss: 0.25745922327041626,Accuracy:0.9214249999999998,Validation Loss:29999.595703125,Validation Accuracy:0.928, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [9/4000],Loss:29976.669921875, KL Loss: 2997644.0. FitLoss: 0.23235970735549927,Accuracy:0.9305375000000001,Validation Loss:29947.203125,Validation Accuracy:0.935, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [10/4000],Loss:29924.28125, KL Loss: 2992407.25. FitLoss: 0.21015922725200653,Accuracy:0.9373249999999997,Validation Loss:29894.806640625,Validation Accuracy:0.949, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [11/4000],Loss:29871.8828125, KL Loss: 2987168.25. FitLoss: 0.20234555006027222,Accuracy:0.9392125,Validation Loss:29842.40234375,Validation Accuracy:0.939, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [12/4000],Loss:29819.453125, KL Loss: 2981927.25. FitLoss: 0.18510937690734863,Accuracy:0.94505,Validation Loss:29789.96875,Validation Accuracy:0.944, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [13/4000],Loss:29767.01171875, KL Loss: 2976683.5. FitLoss: 0.1743815839290619,Accuracy:0.9483250000000003,Validation Loss:29737.5078125,Validation Accuracy:0.955, Prune parameters: 851.0/421642,Beta: 0.01\n",
      "Epoch [14/4000],Loss:29714.5390625, KL Loss: 2971437.75. FitLoss: 0.15976682305335999,Accuracy:0.95175,Validation Loss:29685.01953125,Validation Accuracy:0.958, Prune parameters: 2447.0/421642,Beta: 0.01\n",
      "Epoch [15/4000],Loss:29662.046875, KL Loss: 2966190.0. FitLoss: 0.15116219222545624,Accuracy:0.9555624999999999,Validation Loss:29632.521484375,Validation Accuracy:0.953, Prune parameters: 4155.0/421642,Beta: 0.01\n",
      "Epoch [16/4000],Loss:29609.533203125, KL Loss: 2960939.25. FitLoss: 0.14130724966526031,Accuracy:0.9584250000000003,Validation Loss:29579.990234375,Validation Accuracy:0.964, Prune parameters: 5791.0/421642,Beta: 0.01\n",
      "Epoch [17/4000],Loss:29556.99609375, KL Loss: 2955686.5. FitLoss: 0.1310819387435913,Accuracy:0.9620875000000002,Validation Loss:29527.447265625,Validation Accuracy:0.964, Prune parameters: 7468.0/421642,Beta: 0.01\n",
      "Epoch [18/4000],Loss:29504.4375, KL Loss: 2950431.25. FitLoss: 0.12665601074695587,Accuracy:0.9638625,Validation Loss:29474.880859375,Validation Accuracy:0.964, Prune parameters: 9143.0/421642,Beta: 0.01\n",
      "Epoch [19/4000],Loss:29451.859375, KL Loss: 2945173.5. FitLoss: 0.12358663976192474,Accuracy:0.9644874999999997,Validation Loss:29422.283203125,Validation Accuracy:0.962, Prune parameters: 10839.0/421642,Beta: 0.01\n",
      "Epoch [20/4000],Loss:29399.25, KL Loss: 2939913.75. FitLoss: 0.11348174512386322,Accuracy:0.9678124999999996,Validation Loss:29369.673828125,Validation Accuracy:0.961, Prune parameters: 12515.0/421642,Beta: 0.01\n",
      "Epoch [21/4000],Loss:29346.62109375, KL Loss: 2934651.0. FitLoss: 0.11055859178304672,Accuracy:0.9689624999999996,Validation Loss:29317.029296875,Validation Accuracy:0.962, Prune parameters: 14208.0/421642,Beta: 0.01\n",
      "Epoch [22/4000],Loss:29293.9765625, KL Loss: 2929386.25. FitLoss: 0.112520232796669,Accuracy:0.9680999999999995,Validation Loss:29264.359375,Validation Accuracy:0.967, Prune parameters: 15938.0/421642,Beta: 0.01\n",
      "Epoch [23/4000],Loss:29241.298828125, KL Loss: 2924119.25. FitLoss: 0.10590242594480515,Accuracy:0.9712874999999993,Validation Loss:29211.669921875,Validation Accuracy:0.971, Prune parameters: 17590.0/421642,Beta: 0.01\n",
      "Epoch [24/4000],Loss:29188.6015625, KL Loss: 2918849.5. FitLoss: 0.10293411463499069,Accuracy:0.9700374999999996,Validation Loss:29158.955078125,Validation Accuracy:0.969, Prune parameters: 19319.0/421642,Beta: 0.01\n",
      "Epoch [25/4000],Loss:29135.869140625, KL Loss: 2913577.5. FitLoss: 0.0942094624042511,Accuracy:0.9745000000000005,Validation Loss:29106.2265625,Validation Accuracy:0.969, Prune parameters: 21002.0/421642,Beta: 0.01\n",
      "Epoch [26/4000],Loss:29083.12890625, KL Loss: 2908303.0. FitLoss: 0.10007931292057037,Accuracy:0.9717999999999997,Validation Loss:29053.462890625,Validation Accuracy:0.968, Prune parameters: 22680.0/421642,Beta: 0.01\n",
      "Epoch [27/4000],Loss:29030.357421875, KL Loss: 2903025.75. FitLoss: 0.09747827053070068,Accuracy:0.9725999999999996,Validation Loss:29000.6796875,Validation Accuracy:0.971, Prune parameters: 24373.0/421642,Beta: 0.01\n",
      "Epoch [28/4000],Loss:14381.611328125, KL Loss: 2897844.5. FitLoss: 0.09115884453058243,Accuracy:0.9743749999999997,Validation Loss:452.52142333984375,Validation Accuracy:0.964, Prune parameters: 25979.0/421642,Beta: 0.00015625\n",
      "Epoch [29/4000],Loss:113.18266296386719, KL Loss: 2894247.25. FitLoss: 0.09514135867357254,Accuracy:0.9716374999999996,Validation Loss:7.175153732299805,Validation Accuracy:0.965, Prune parameters: 26689.0/421642,Beta: 2.44140625e-06\n",
      "Epoch [30/4000],Loss:7.141725063323975, KL Loss: 2892601.75. FitLoss: 0.07970839738845825,Accuracy:0.9760124999999997,Validation Loss:7.1542253494262695,Validation Accuracy:0.971, Prune parameters: 27018.0/421642,Beta: 2.44140625e-06\n",
      "Epoch [31/4000],Loss:7.12877893447876, KL Loss: 2891879.75. FitLoss: 0.06852568686008453,Accuracy:0.9802250000000001,Validation Loss:7.152412414550781,Validation Accuracy:0.969, Prune parameters: 27154.0/421642,Beta: 2.44140625e-06\n",
      "Epoch [32/4000],Loss:225.07568359375, KL Loss: 2891562.5. FitLoss: 0.05960654094815254,Accuracy:0.9820249999999998,Validation Loss:1807.2462158203125,Validation Accuracy:0.972, Prune parameters: 27224.0/421642,Beta: 0.000625\n",
      "Epoch [33/4000],Loss:57588.3359375, KL Loss: 2891166.0. FitLoss: 0.050944238901138306,Accuracy:0.9839999999999993,Validation Loss:231157.71875,Validation Accuracy:0.98, Prune parameters: 27894.0/421642,Beta: 0.08\n",
      "Epoch [34/4000],Loss:230747.328125, KL Loss: 2884341.0. FitLoss: 0.06787601113319397,Accuracy:0.9824249999999998,Validation Loss:230123.296875,Validation Accuracy:0.973, Prune parameters: 31917.0/421642,Beta: 0.08\n",
      "Epoch [35/4000],Loss:193783.265625, KL Loss: 2869744.0. FitLoss: 0.18771161139011383,Accuracy:0.9624249999999999,Validation Loss:28612.38671875,Validation Accuracy:0.934, Prune parameters: 36818.0/421642,Beta: 0.01\n",
      "Epoch [36/4000],Loss:7121.78759765625, KL Loss: 2856506.75. FitLoss: 0.2895183265209198,Accuracy:0.9246375000000002,Validation Loss:111.62872314453125,Validation Accuracy:0.94, Prune parameters: 39819.0/421642,Beta: 3.90625e-05\n",
      "Epoch [37/4000],Loss:27.962265014648438, KL Loss: 2849768.25. FitLoss: 0.22719410061836243,Accuracy:0.9302750000000003,Validation Loss:0.6318793892860413,Validation Accuracy:0.939, Prune parameters: 41123.0/421642,Beta: 1.52587890625e-07\n",
      "Epoch [38/4000],Loss:0.2886938452720642, KL Loss: 2846814.0. FitLoss: 0.15971432626247406,Accuracy:0.9514875,Validation Loss:0.2007780820131302,Validation Accuracy:0.96, Prune parameters: 41732.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [39/4000],Loss:0.18465368449687958, KL Loss: 2845523.75. FitLoss: 0.13037963211536407,Accuracy:0.9581375,Validation Loss:0.17418617010116577,Validation Accuracy:0.97, Prune parameters: 41983.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [40/4000],Loss:0.17464159429073334, KL Loss: 2844960.5. FitLoss: 0.10681305080652237,Accuracy:0.9658249999999999,Validation Loss:0.2164544314146042,Validation Accuracy:0.968, Prune parameters: 42102.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [41/4000],Loss:0.19713075459003448, KL Loss: 2844715.25. FitLoss: 0.08861348032951355,Accuracy:0.9716999999999999,Validation Loss:0.21939592063426971,Validation Accuracy:0.969, Prune parameters: 42150.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [42/4000],Loss:0.18627001345157623, KL Loss: 2844608.5. FitLoss: 0.07775680720806122,Accuracy:0.9741499999999996,Validation Loss:0.215187668800354,Validation Accuracy:0.968, Prune parameters: 42168.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [43/4000],Loss:0.17949090898036957, KL Loss: 2844562.0. FitLoss: 0.07097947597503662,Accuracy:0.9775624999999992,Validation Loss:0.20915544033050537,Validation Accuracy:0.97, Prune parameters: 42177.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [44/4000],Loss:0.17149673402309418, KL Loss: 2844542.0. FitLoss: 0.06298607587814331,Accuracy:0.9806249999999996,Validation Loss:0.20104169845581055,Validation Accuracy:0.974, Prune parameters: 42182.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [45/4000],Loss:0.16290411353111267, KL Loss: 2844534.0. FitLoss: 0.05439375713467598,Accuracy:0.9834249999999993,Validation Loss:0.30039215087890625,Validation Accuracy:0.977, Prune parameters: 42182.0/421642,Beta: 7.62939453125e-08\n",
      "Epoch [46/4000],Loss:6.969056129455566, KL Loss: 2844530.75. FitLoss: 0.05152898654341698,Accuracy:0.9839499999999998,Validation Loss:55.64391326904297,Validation Accuracy:0.976, Prune parameters: 42183.0/421642,Beta: 1.953125e-05\n",
      "Epoch [47/4000],Loss:1770.928466796875, KL Loss: 2844526.0. FitLoss: 0.0488300547003746,Accuracy:0.9846124999999996,Validation Loss:14222.5703125,Validation Accuracy:0.978, Prune parameters: 42198.0/421642,Beta: 0.005\n",
      "Epoch [48/4000],Loss:225654.90625, KL Loss: 2843636.25. FitLoss: 0.04762625694274902,Accuracy:0.9853499999999998,Validation Loss:454385.09375,Validation Accuracy:0.975, Prune parameters: 43565.0/421642,Beta: 0.16\n",
      "Epoch [49/4000],Loss:453343.6875, KL Loss: 2833397.5. FitLoss: 0.13652515411376953,Accuracy:0.9732499999999995,Validation Loss:451863.34375,Validation Accuracy:0.962, Prune parameters: 48581.0/421642,Beta: 0.16\n",
      "Epoch [50/4000],Loss:223874.328125, KL Loss: 2816734.0. FitLoss: 0.44508418440818787,Accuracy:0.91275,Validation Loss:7021.603515625,Validation Accuracy:0.905, Prune parameters: 53684.0/421642,Beta: 0.0025\n",
      "Epoch [51/4000],Loss:1748.0789794921875, KL Loss: 2804559.0. FitLoss: 0.386613667011261,Accuracy:0.8852249999999999,Validation Loss:27.645910263061523,Validation Accuracy:0.92, Prune parameters: 56243.0/421642,Beta: 9.765625e-06\n",
      "Epoch [52/4000],Loss:7.08295202255249, KL Loss: 2798995.75. FitLoss: 0.27327969670295715,Accuracy:0.9138374999999999,Validation Loss:0.3269331753253937,Validation Accuracy:0.93, Prune parameters: 57347.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [53/4000],Loss:0.2705928087234497, KL Loss: 2796571.75. FitLoss: 0.21058307588100433,Accuracy:0.9318499999999995,Validation Loss:0.24000850319862366,Validation Accuracy:0.949, Prune parameters: 57817.0/421642,Beta: 1.9073486328125e-08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m train_params \u001b[38;5;241m=\u001b[39m VarTrainerParams(EPOCHS, optimizer,fit_loss, kl_loss, SAMPLES, PRUNE, BETA, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: CallbackLossAccuracy()})\n\u001b[1;32m     51\u001b[0m trainer \u001b[38;5;241m=\u001b[39m VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader, [post_train_step])\n\u001b[0;32m---> 52\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(model)\n",
      "File \u001b[0;32m~/BMM/bayes_deep_compression/examples/../src/bayescomp/bayes/variational/trainer.py:151\u001b[0m, in \u001b[0;36mVarBayesTrainer.train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    149\u001b[0m train_fit_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (objects, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset):\n\u001b[0;32m--> 151\u001b[0m     train_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(model, objects, labels)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__post_train_step(train_output)\n\u001b[1;32m    153\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(train_output\u001b[38;5;241m.\u001b[39mtotal_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/BMM/bayes_deep_compression/examples/../src/bayescomp/bayes/variational/trainer.py:217\u001b[0m, in \u001b[0;36mVarBayesTrainer.train_step\u001b[0;34m(self, model, objects, labels)\u001b[0m\n\u001b[1;32m    214\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(objects)\n\u001b[1;32m    215\u001b[0m fit_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mfit_loss(outputs, labels))\n\u001b[1;32m    216\u001b[0m dist_losses\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mdist_loss(param_sample_list, model\u001b[38;5;241m.\u001b[39mposterior, model\u001b[38;5;241m.\u001b[39mprior)\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mcallback_losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m custom_loss \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mcallback_losses\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/BMM/bayes_deep_compression/examples/../src/bayescomp/bayes/variational/optimization.py:59\u001b[0m, in \u001b[0;36mLogUniformVarKLLoss.forward\u001b[0;34m(self, param_sample_list, posterior, prior)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m posterior\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     53\u001b[0m     KL_w_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\n\u001b[1;32m     54\u001b[0m         torch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(dist\u001b[38;5;241m.\u001b[39mparam_std_log) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(dist\u001b[38;5;241m.\u001b[39mparam_std_log) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;241m+\u001b[39m dist\u001b[38;5;241m.\u001b[39mparam_mus\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     58\u001b[0m     )\n\u001b[0;32m---> 59\u001b[0m     KL_w \u001b[38;5;241m=\u001b[39m KL_w \u001b[38;5;241m+\u001b[39m KL_w_element\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mKL_z \u001b[38;5;241m+\u001b[39m KL_w\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=1000\n",
    "EPOCHS=4000\n",
    "LR = 1e-3 #5e-4\n",
    "# Split the training set into training and validation sets \n",
    "VAL_PERCENT = 0.2 # percentage of the data used for validation \n",
    "SAMPLES = 10\n",
    "BETA = 0.01 #5e-5\n",
    "BETA_FAC = 5e-1\n",
    "PRUNE = 1.9#1.99, 2.1\n",
    "PLATO_TOL = 20\n",
    "\n",
    "base_module = Classifier()\n",
    "var_module = LogUniformVarBayesModule(base_module)\n",
    "model = VarBayesModuleNet(base_module, nn.ModuleList([var_module]))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "fit_loss = nn.CrossEntropyLoss() \n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "\n",
    "beta = Beta_Scheduler_Plato(BETA, BETA_FAC, PLATO_TOL)\n",
    "beta_KL = Beta_Scheduler_Plato(beta.beta, 1 / BETA_FAC, PLATO_TOL, ref = beta, threshold=1e-4)\n",
    "\n",
    "#Данная функция будет выполнятся после каждого шага тренера, соответсвенно нам требуется сделать шаг планировщика и изменить соотвествующий коэффициент\n",
    "def post_train_step(trainer: VarTrainerParams, train_result: VarBayesTrainer.TrainResult):\n",
    "    beta.step(train_result.fit_loss)\n",
    "    beta_KL.step(train_result.dist_loss)\n",
    "    trainer.params.beta = float(beta)\n",
    "    \n",
    "#print(model.base_module.state_dict().keys())\n",
    "val_size    = int(VAL_PERCENT * len(train_dataset)) \n",
    "train_size  = len(train_dataset) - val_size \n",
    "\n",
    "t_dataset, v_dataset = torch.utils.data.random_split(train_dataset,  \n",
    "                                                        [train_size,  \n",
    "                                                            val_size]) \n",
    "\n",
    "# Create DataLoaders for the training and validation sets \n",
    "train_loader = torch.utils.data.DataLoader(t_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=True, \n",
    "                                        pin_memory=True) \n",
    "eval_loader = torch.utils.data.DataLoader(v_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=False, \n",
    "                                        pin_memory=True) \n",
    "\n",
    "model.to(device) \n",
    "train_params = VarTrainerParams(EPOCHS, optimizer,fit_loss, kl_loss, SAMPLES, PRUNE, BETA, {'accuracy': CallbackLossAccuracy()})\n",
    "trainer = VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader, [post_train_step])\n",
    "trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_module.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_bayes.pt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(409356., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.prune({'threshold': 1.9})\n",
    "print(model.prune_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47343., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.prune([{'threshold': -2.2}])\n",
    "print(model.prune_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = Classifier()\n",
    "var_module = LogUniformVarBayesModule(module)\n",
    "model = VarBayesModuleNet(module, nn.ModuleList([var_module]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('module_list.0.posterior_params.0.param_mus',\n",
       "              tensor([[[[-0.2737, -0.0213, -0.1784],\n",
       "                        [-0.0449,  0.1339,  0.2884],\n",
       "                        [ 0.1757,  0.2454,  0.0318]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2829,  0.1125,  0.2672],\n",
       "                        [-0.0329,  0.1954,  0.2326],\n",
       "                        [-0.0857, -0.2534,  0.0893]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1525,  0.0669, -0.2533],\n",
       "                        [-0.1758,  0.1672,  0.1206],\n",
       "                        [ 0.0153,  0.1936, -0.3305]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0107,  0.3182,  0.2102],\n",
       "                        [-0.1029,  0.3132, -0.2125],\n",
       "                        [-0.2650,  0.0061,  0.2422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1922,  0.1445, -0.1445],\n",
       "                        [-0.1862, -0.1703,  0.1814],\n",
       "                        [-0.3061, -0.1629,  0.1818]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2469, -0.2962, -0.1922],\n",
       "                        [-0.1502, -0.0190, -0.1009],\n",
       "                        [ 0.1418,  0.0435, -0.2017]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2999,  0.2396,  0.0861],\n",
       "                        [-0.1399,  0.0275, -0.3024],\n",
       "                        [-0.1098, -0.1394, -0.2101]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0273,  0.2970, -0.2747],\n",
       "                        [ 0.1127,  0.2224,  0.0496],\n",
       "                        [-0.2127,  0.1349, -0.2917]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0222,  0.2411,  0.0425],\n",
       "                        [ 0.0817,  0.1037,  0.2716],\n",
       "                        [ 0.0878, -0.2382, -0.0517]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0719,  0.1895,  0.1076],\n",
       "                        [-0.1426, -0.1827,  0.3090],\n",
       "                        [-0.1734,  0.0608, -0.1394]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2088,  0.1865,  0.1586],\n",
       "                        [-0.1817, -0.1410, -0.1049],\n",
       "                        [-0.1832, -0.3061, -0.3109]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2269,  0.1814, -0.3188],\n",
       "                        [ 0.2725, -0.0902, -0.2374],\n",
       "                        [-0.1628, -0.2985, -0.0739]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2382, -0.0886,  0.2284],\n",
       "                        [ 0.0932, -0.0300,  0.1199],\n",
       "                        [-0.3036,  0.0679,  0.3242]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2995, -0.0269,  0.2335],\n",
       "                        [-0.2868,  0.1297,  0.2263],\n",
       "                        [-0.1365,  0.0827, -0.1368]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2408, -0.1476,  0.1649],\n",
       "                        [ 0.1636, -0.0114, -0.1543],\n",
       "                        [ 0.1516,  0.2401, -0.3093]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0533,  0.1382,  0.0024],\n",
       "                        [-0.1546,  0.2536, -0.2555],\n",
       "                        [-0.1677, -0.0555,  0.0449]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2179,  0.0416,  0.1664],\n",
       "                        [ 0.1895,  0.1240, -0.2714],\n",
       "                        [-0.0561, -0.2904,  0.1815]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0931, -0.2447, -0.1122],\n",
       "                        [ 0.2836, -0.3144,  0.2693],\n",
       "                        [ 0.0475,  0.0702,  0.2088]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2935, -0.0657,  0.2059],\n",
       "                        [-0.2644,  0.2140,  0.0178],\n",
       "                        [-0.0679, -0.2655, -0.0174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1912, -0.0838, -0.1078],\n",
       "                        [ 0.2290,  0.2124, -0.2783],\n",
       "                        [-0.0186,  0.2010, -0.1156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2628, -0.2447,  0.0938],\n",
       "                        [-0.1858, -0.2919, -0.2134],\n",
       "                        [ 0.2410, -0.0449,  0.1174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3145, -0.2647,  0.2348],\n",
       "                        [ 0.1423, -0.1619, -0.1704],\n",
       "                        [ 0.3221, -0.1983, -0.0801]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0133, -0.3084,  0.1228],\n",
       "                        [ 0.1514,  0.0796, -0.1055],\n",
       "                        [ 0.2269,  0.1001, -0.2295]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1243,  0.1812,  0.0307],\n",
       "                        [ 0.2902,  0.2480, -0.0722],\n",
       "                        [-0.1125,  0.2348,  0.0912]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2855,  0.0356,  0.2712],\n",
       "                        [ 0.3197, -0.0580,  0.0020],\n",
       "                        [-0.2933, -0.1005,  0.2072]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1050, -0.2946,  0.0811],\n",
       "                        [-0.0863,  0.2160, -0.2627],\n",
       "                        [-0.1286,  0.0596, -0.1345]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0546, -0.0362,  0.0594],\n",
       "                        [ 0.0646,  0.1745, -0.0352],\n",
       "                        [-0.1120, -0.0474,  0.0383]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1332, -0.2500, -0.1542],\n",
       "                        [-0.2412, -0.3166, -0.0210],\n",
       "                        [ 0.1060,  0.1158,  0.0057]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2678, -0.2166,  0.0712],\n",
       "                        [-0.0535,  0.1413,  0.2406],\n",
       "                        [-0.2855, -0.3059, -0.2075]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2055, -0.2482,  0.1404],\n",
       "                        [-0.2513, -0.1904,  0.1103],\n",
       "                        [-0.2845,  0.0184,  0.2082]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0582,  0.2715,  0.1728],\n",
       "                        [-0.1080,  0.1155,  0.1371],\n",
       "                        [ 0.2162, -0.0247, -0.2244]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1486,  0.0659,  0.1559],\n",
       "                        [-0.2081,  0.0449,  0.3216],\n",
       "                        [ 0.2564,  0.2344, -0.0866]]]])),\n",
       "             ('module_list.0.posterior_params.0.param_std_log',\n",
       "              tensor([[[[-7.6443, -6.8122, -6.2178],\n",
       "                        [-4.6537, -8.1042, -5.0853],\n",
       "                        [-6.9559, -4.9253, -4.6574]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.9750, -6.1978, -5.7079],\n",
       "                        [-5.8540, -7.7156, -6.2078],\n",
       "                        [-4.9556, -5.0383, -6.1048]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7616, -5.4980, -4.7636],\n",
       "                        [-4.9685, -8.0552, -6.3784],\n",
       "                        [-4.9320, -6.9730, -6.1062]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8593, -5.2212, -4.8359],\n",
       "                        [-4.9786, -7.6505, -5.0176],\n",
       "                        [-5.6760, -5.2133, -5.7229]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.5549, -5.6953, -7.5045],\n",
       "                        [-4.8243, -5.2325, -8.2682],\n",
       "                        [-4.7497, -5.2409, -6.0584]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.2319, -5.1681, -5.0143],\n",
       "                        [-4.6465, -4.7084, -6.2273],\n",
       "                        [-4.7883, -5.2719, -4.9517]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0582, -5.2466, -5.4416],\n",
       "                        [-5.1359, -5.2855, -5.4410],\n",
       "                        [-5.7903, -4.6311, -5.1965]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9802, -4.6867, -5.9103],\n",
       "                        [-4.9393, -7.2178, -5.2489],\n",
       "                        [-4.6243, -5.9567, -5.4351]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6969, -5.5580, -5.1405],\n",
       "                        [-4.7906, -5.6145, -7.0589],\n",
       "                        [-5.0275, -4.7744, -5.2552]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.2480, -6.9430, -4.8825],\n",
       "                        [-5.6597, -6.6762, -4.9689],\n",
       "                        [-5.1752, -4.9931, -5.0197]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6701, -4.8942, -5.5445],\n",
       "                        [-5.9894, -5.5842, -4.8125],\n",
       "                        [-5.2390, -4.8248, -6.3544]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0899, -6.3075, -5.0728],\n",
       "                        [-4.7244, -4.7276, -5.5322],\n",
       "                        [-6.5785, -5.2176, -8.2081]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.8461, -6.0238, -5.0947],\n",
       "                        [-4.7004, -4.7245, -4.9359],\n",
       "                        [-5.4876, -4.8804, -5.2382]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7568, -4.7962, -4.8076],\n",
       "                        [-4.8334, -4.6812, -4.8790],\n",
       "                        [-5.2112, -4.6500, -5.2285]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1571, -5.5234, -5.3730],\n",
       "                        [-6.3554, -4.7353, -5.0411],\n",
       "                        [-4.7423, -5.0554, -5.8877]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.4057, -5.4768, -5.8319],\n",
       "                        [-4.8379, -4.8591, -7.9367],\n",
       "                        [-6.0085, -4.6697, -5.8908]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7667, -5.2830, -4.8108],\n",
       "                        [-4.7277, -5.0035, -4.8743],\n",
       "                        [-4.7109, -7.0394, -4.8987]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5578, -5.4441, -4.7811],\n",
       "                        [-4.6132, -5.0880, -4.7208],\n",
       "                        [-5.2930, -4.7753, -5.3517]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0392, -6.9003, -6.4838],\n",
       "                        [-6.2912, -4.9652, -6.3513],\n",
       "                        [-5.4759, -4.9867, -5.3265]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.6965, -5.1672, -4.6054],\n",
       "                        [-5.8090, -4.9806, -5.4375],\n",
       "                        [-5.2273, -5.3135, -5.2484]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8862, -4.9312, -5.9119],\n",
       "                        [-5.3062, -5.0569, -4.6850],\n",
       "                        [-5.4883, -6.1027, -5.0738]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.3343, -6.1922, -6.2508],\n",
       "                        [-5.0133, -4.8441, -6.0976],\n",
       "                        [-7.5900, -5.7515, -4.6156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5193, -6.1760, -5.7592],\n",
       "                        [-5.5590, -4.8624, -5.6229],\n",
       "                        [-4.9285, -4.8645, -5.8739]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6902, -5.6837, -4.9300],\n",
       "                        [-5.4640, -6.1872, -5.1738],\n",
       "                        [-4.6249, -4.7705, -4.9058]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1386, -4.6787, -4.8687],\n",
       "                        [-4.7995, -6.2731, -5.5295],\n",
       "                        [-7.9139, -5.6268, -4.8398]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4830, -5.1139, -5.3729],\n",
       "                        [-4.6113, -5.2906, -5.0130],\n",
       "                        [-5.5503, -4.9968, -4.6078]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.3845, -6.3526, -5.5192],\n",
       "                        [-6.8718, -5.3505, -5.9623],\n",
       "                        [-5.2600, -5.0851, -5.2559]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.5084, -6.8383, -6.7434],\n",
       "                        [-5.1087, -5.0522, -5.0362],\n",
       "                        [-4.8434, -4.6105, -5.9471]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0541, -6.8497, -5.4263],\n",
       "                        [-5.1009, -4.6458, -5.4793],\n",
       "                        [-5.4213, -4.9003, -4.8682]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4279, -8.2878, -5.5914],\n",
       "                        [-5.8017, -5.5931, -4.8151],\n",
       "                        [-4.7875, -5.1253, -4.8293]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6792, -5.2176, -6.3633],\n",
       "                        [-6.5483, -4.7496, -5.1030],\n",
       "                        [-4.7008, -4.6548, -4.8405]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9131, -5.5380, -5.7411],\n",
       "                        [-8.2987, -4.6276, -5.5294],\n",
       "                        [-5.5955, -4.9558, -8.0978]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_alphas_log',\n",
       "              tensor([[[[-3.9730, -3.8184, -2.7370],\n",
       "                        [-2.8423, -3.3155, -3.7674],\n",
       "                        [-2.8688, -3.4832, -3.3337]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4496, -3.1676, -2.3279],\n",
       "                        [-2.5704, -2.6994, -2.5631],\n",
       "                        [-2.3078, -3.7059, -3.1989]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3379, -3.3761, -2.0345],\n",
       "                        [-3.8821, -2.3943, -3.7338],\n",
       "                        [-3.1945, -2.8338, -3.7807]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3331, -3.7250, -3.6263],\n",
       "                        [-3.3903, -2.8828, -3.6775],\n",
       "                        [-3.0060, -2.4066, -2.8119]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3633, -2.0377, -2.0332],\n",
       "                        [-3.5051, -3.9339, -3.9972],\n",
       "                        [-2.8213, -2.7204, -2.4167]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4371, -3.7661, -2.8416],\n",
       "                        [-2.1897, -2.4125, -2.5461],\n",
       "                        [-3.4732, -3.3259, -2.3366]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2825, -3.0099, -2.5968],\n",
       "                        [-3.0321, -3.8588, -3.2249],\n",
       "                        [-3.7188, -3.9843, -3.5802]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8530, -3.9986, -3.0276],\n",
       "                        [-2.0767, -3.6595, -2.9175],\n",
       "                        [-3.2203, -2.1420, -3.6336]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5784, -2.8119, -2.3119],\n",
       "                        [-3.2846, -3.0844, -2.5892],\n",
       "                        [-3.3545, -2.3341, -3.3552]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5695, -2.5832, -2.3026],\n",
       "                        [-3.3705, -3.8097, -3.8492],\n",
       "                        [-2.4600, -2.2967, -3.7054]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3626, -3.4220, -3.9690],\n",
       "                        [-2.0460, -2.1348, -3.8663],\n",
       "                        [-2.3202, -3.0671, -2.3580]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1191, -3.4663, -3.9155],\n",
       "                        [-2.9626, -2.6909, -2.0241],\n",
       "                        [-3.6772, -2.0887, -2.8112]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5335, -2.2046, -3.8070],\n",
       "                        [-2.0733, -3.4714, -3.3680],\n",
       "                        [-2.0920, -3.3321, -3.0712]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9456, -3.9397, -2.3680],\n",
       "                        [-2.0659, -3.5653, -2.3071],\n",
       "                        [-3.2517, -3.4542, -2.0715]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2097, -3.9403, -2.1460],\n",
       "                        [-3.0559, -3.4030, -2.5687],\n",
       "                        [-3.4692, -2.5501, -3.5228]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8775, -3.4609, -3.5841],\n",
       "                        [-3.2468, -3.9733, -3.9215],\n",
       "                        [-3.4708, -3.8749, -3.1619]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4536, -3.0306, -3.1692],\n",
       "                        [-2.9309, -2.0621, -2.1662],\n",
       "                        [-2.1606, -2.5014, -2.8317]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8540, -3.1003, -2.3888],\n",
       "                        [-2.9370, -2.7015, -3.5162],\n",
       "                        [-2.7293, -2.3345, -3.2506]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4800, -3.4780, -2.7654],\n",
       "                        [-2.0434, -2.3557, -2.0213],\n",
       "                        [-2.2703, -2.0352, -3.7971]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9834, -3.0913, -2.8502],\n",
       "                        [-2.8904, -2.8264, -3.4881],\n",
       "                        [-3.3516, -3.2357, -2.9829]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1380, -3.2730, -3.5269],\n",
       "                        [-2.6177, -3.5875, -3.6728],\n",
       "                        [-2.7636, -3.6273, -3.2167]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4872, -3.5043, -2.3076],\n",
       "                        [-2.8557, -3.3450, -2.6795],\n",
       "                        [-2.7737, -2.7499, -3.3472]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2195, -2.7689, -2.0130],\n",
       "                        [-3.5297, -3.6577, -2.2098],\n",
       "                        [-2.0077, -3.4508, -3.4853]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1046, -3.8315, -3.3988],\n",
       "                        [-2.0476, -3.0053, -3.8965],\n",
       "                        [-2.1855, -2.1632, -2.1847]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9850, -2.6428, -2.9310],\n",
       "                        [-2.1326, -3.2657, -2.4740],\n",
       "                        [-3.1584, -2.4350, -3.3533]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9450, -2.5128, -3.1556],\n",
       "                        [-3.2801, -3.5410, -2.8983],\n",
       "                        [-2.5519, -3.2341, -2.8721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8494, -3.8954, -3.0426],\n",
       "                        [-3.2585, -3.2226, -3.6094],\n",
       "                        [-3.2983, -3.4633, -3.9118]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4175, -2.1018, -2.3832],\n",
       "                        [-2.6769, -2.5597, -3.1847],\n",
       "                        [-3.8278, -2.5293, -3.5093]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6108, -3.0801, -2.6812],\n",
       "                        [-2.7818, -3.4267, -3.2687],\n",
       "                        [-2.1624, -2.1442, -2.5664]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5382, -2.5531, -3.3821],\n",
       "                        [-2.7202, -3.1200, -3.5994],\n",
       "                        [-3.7090, -3.5544, -3.7490]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9206, -2.9339, -2.6854],\n",
       "                        [-2.8685, -3.9728, -2.4037],\n",
       "                        [-3.7632, -2.0636, -2.3169]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5363, -2.2065, -3.9187],\n",
       "                        [-2.5296, -2.8139, -2.1778],\n",
       "                        [-3.0076, -2.6238, -3.4175]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.1.param_mus',\n",
       "              tensor([-0.0917,  0.2394,  0.0686, -0.2604, -0.0798,  0.2396, -0.0338,  0.2310,\n",
       "                       0.0511, -0.0118,  0.1305,  0.2870,  0.1377,  0.0071, -0.0213, -0.0859,\n",
       "                       0.1393, -0.0984, -0.1080,  0.1917,  0.1436, -0.2344,  0.0637, -0.2897,\n",
       "                      -0.2618, -0.2384, -0.1295,  0.1794, -0.0685, -0.0023, -0.2036, -0.0473])),\n",
       "             ('module_list.0.posterior_params.1.param_std_log',\n",
       "              tensor([-5.6001, -5.0561, -7.3938, -4.6664, -5.3911, -4.6895, -5.8183, -4.6080,\n",
       "                      -4.9778, -5.0134, -5.1747, -6.2682, -5.6235, -4.6147, -4.6179, -5.5958,\n",
       "                      -7.3049, -5.8125, -5.3669, -6.1171, -5.4824, -4.6084, -4.8485, -5.1090,\n",
       "                      -4.6260, -4.8618, -4.6064, -5.7304, -4.9281, -6.2759, -6.1592, -4.6723])),\n",
       "             ('module_list.0.posterior_params.1.scale_alphas_log',\n",
       "              tensor([-3.8439, -3.2271, -3.3951, -2.1596, -3.5587, -3.3096, -3.8678, -3.2271,\n",
       "                      -3.7286, -2.2776, -3.4039, -2.1131, -3.8562, -2.1256, -2.6956, -2.0418,\n",
       "                      -3.5359, -3.6205, -3.8657, -2.2383, -2.6532, -2.0978, -2.3008, -3.0798,\n",
       "                      -3.8545, -2.1004, -2.2579, -3.7659, -2.8519, -2.2167, -2.4384, -3.4444])),\n",
       "             ('module_list.0.posterior_params.1.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.2.param_mus',\n",
       "              tensor([[[[-0.0196,  0.0454,  0.0391],\n",
       "                        [ 0.0089,  0.0444,  0.0319],\n",
       "                        [ 0.0151, -0.0048, -0.0067]],\n",
       "              \n",
       "                       [[ 0.0389,  0.0052, -0.0038],\n",
       "                        [ 0.0210, -0.0377,  0.0379],\n",
       "                        [-0.0082, -0.0270,  0.0123]],\n",
       "              \n",
       "                       [[-0.0195, -0.0450, -0.0348],\n",
       "                        [-0.0266,  0.0158,  0.0558],\n",
       "                        [ 0.0572, -0.0150, -0.0562]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0117, -0.0527,  0.0530],\n",
       "                        [-0.0441, -0.0011,  0.0099],\n",
       "                        [ 0.0460, -0.0206,  0.0311]],\n",
       "              \n",
       "                       [[ 0.0086, -0.0104,  0.0082],\n",
       "                        [-0.0060,  0.0010,  0.0508],\n",
       "                        [ 0.0234, -0.0204, -0.0198]],\n",
       "              \n",
       "                       [[ 0.0014,  0.0375, -0.0589],\n",
       "                        [-0.0500, -0.0523, -0.0287],\n",
       "                        [-0.0491,  0.0049,  0.0422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0086, -0.0462,  0.0437],\n",
       "                        [-0.0584, -0.0168, -0.0261],\n",
       "                        [-0.0548, -0.0186, -0.0516]],\n",
       "              \n",
       "                       [[ 0.0359, -0.0341,  0.0119],\n",
       "                        [-0.0516, -0.0310, -0.0073],\n",
       "                        [-0.0050,  0.0106,  0.0388]],\n",
       "              \n",
       "                       [[ 0.0335,  0.0242, -0.0266],\n",
       "                        [-0.0136,  0.0261,  0.0277],\n",
       "                        [-0.0235, -0.0340, -0.0570]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0397, -0.0346,  0.0134],\n",
       "                        [-0.0087,  0.0414,  0.0012],\n",
       "                        [-0.0219,  0.0087,  0.0025]],\n",
       "              \n",
       "                       [[-0.0426,  0.0360, -0.0347],\n",
       "                        [-0.0527, -0.0319,  0.0490],\n",
       "                        [ 0.0425,  0.0571,  0.0575]],\n",
       "              \n",
       "                       [[ 0.0446,  0.0385,  0.0485],\n",
       "                        [ 0.0124,  0.0016, -0.0074],\n",
       "                        [ 0.0091, -0.0570, -0.0402]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0326, -0.0093, -0.0427],\n",
       "                        [-0.0027, -0.0183,  0.0407],\n",
       "                        [ 0.0067,  0.0192, -0.0295]],\n",
       "              \n",
       "                       [[ 0.0398, -0.0258, -0.0529],\n",
       "                        [ 0.0533, -0.0561,  0.0226],\n",
       "                        [-0.0508, -0.0089, -0.0217]],\n",
       "              \n",
       "                       [[-0.0574,  0.0053,  0.0086],\n",
       "                        [ 0.0176, -0.0122,  0.0389],\n",
       "                        [ 0.0315, -0.0262,  0.0497]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0496,  0.0429, -0.0389],\n",
       "                        [ 0.0564,  0.0134, -0.0487],\n",
       "                        [ 0.0151, -0.0558, -0.0526]],\n",
       "              \n",
       "                       [[ 0.0041,  0.0085,  0.0242],\n",
       "                        [-0.0357,  0.0532, -0.0053],\n",
       "                        [ 0.0320,  0.0389, -0.0084]],\n",
       "              \n",
       "                       [[-0.0232, -0.0328, -0.0265],\n",
       "                        [ 0.0073,  0.0322,  0.0154],\n",
       "                        [ 0.0334, -0.0364, -0.0399]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0362, -0.0152, -0.0356],\n",
       "                        [-0.0227,  0.0356,  0.0551],\n",
       "                        [ 0.0449,  0.0479,  0.0460]],\n",
       "              \n",
       "                       [[ 0.0109, -0.0216,  0.0328],\n",
       "                        [ 0.0278,  0.0500, -0.0082],\n",
       "                        [ 0.0543, -0.0203,  0.0153]],\n",
       "              \n",
       "                       [[ 0.0102,  0.0585, -0.0482],\n",
       "                        [ 0.0470,  0.0210,  0.0068],\n",
       "                        [ 0.0122,  0.0472, -0.0473]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0350,  0.0331,  0.0211],\n",
       "                        [ 0.0469,  0.0194, -0.0124],\n",
       "                        [ 0.0085,  0.0097,  0.0335]],\n",
       "              \n",
       "                       [[-0.0213, -0.0421,  0.0169],\n",
       "                        [ 0.0271,  0.0084, -0.0281],\n",
       "                        [-0.0009,  0.0395,  0.0552]],\n",
       "              \n",
       "                       [[-0.0405,  0.0506,  0.0431],\n",
       "                        [ 0.0378,  0.0429,  0.0452],\n",
       "                        [ 0.0226,  0.0213, -0.0085]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0589, -0.0413,  0.0375],\n",
       "                        [-0.0113,  0.0128, -0.0504],\n",
       "                        [ 0.0348,  0.0297, -0.0023]],\n",
       "              \n",
       "                       [[ 0.0142, -0.0146,  0.0395],\n",
       "                        [-0.0279,  0.0025, -0.0369],\n",
       "                        [-0.0193,  0.0065,  0.0184]],\n",
       "              \n",
       "                       [[ 0.0535, -0.0271,  0.0205],\n",
       "                        [ 0.0521,  0.0121,  0.0178],\n",
       "                        [-0.0015, -0.0246,  0.0102]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0374,  0.0082,  0.0361],\n",
       "                        [-0.0384, -0.0128,  0.0242],\n",
       "                        [ 0.0210,  0.0459, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0085,  0.0549, -0.0122],\n",
       "                        [ 0.0470, -0.0425,  0.0118],\n",
       "                        [-0.0259, -0.0331,  0.0163]],\n",
       "              \n",
       "                       [[-0.0175,  0.0018,  0.0136],\n",
       "                        [ 0.0412, -0.0085, -0.0292],\n",
       "                        [ 0.0508, -0.0501,  0.0192]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0055, -0.0442, -0.0088],\n",
       "                        [-0.0253, -0.0387, -0.0068],\n",
       "                        [-0.0327,  0.0401,  0.0176]],\n",
       "              \n",
       "                       [[-0.0053, -0.0276,  0.0089],\n",
       "                        [ 0.0546,  0.0484, -0.0486],\n",
       "                        [ 0.0030,  0.0041, -0.0256]],\n",
       "              \n",
       "                       [[ 0.0418,  0.0024, -0.0539],\n",
       "                        [ 0.0261, -0.0357, -0.0540],\n",
       "                        [ 0.0082, -0.0161,  0.0249]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0420, -0.0219, -0.0447],\n",
       "                        [-0.0553, -0.0467, -0.0041],\n",
       "                        [-0.0133, -0.0239,  0.0284]],\n",
       "              \n",
       "                       [[-0.0090,  0.0331,  0.0218],\n",
       "                        [-0.0550, -0.0575, -0.0531],\n",
       "                        [ 0.0528, -0.0313,  0.0230]],\n",
       "              \n",
       "                       [[-0.0138,  0.0412, -0.0435],\n",
       "                        [ 0.0420, -0.0355,  0.0162],\n",
       "                        [ 0.0510,  0.0107,  0.0575]]]])),\n",
       "             ('module_list.0.posterior_params.2.param_std_log',\n",
       "              tensor([[[[ -4.8953,  -5.0285,  -6.2216],\n",
       "                        [ -4.9035,  -8.6040,  -6.4262],\n",
       "                        [ -5.3935,  -6.4831,  -5.3591]],\n",
       "              \n",
       "                       [[ -5.5549,  -5.1110,  -4.7856],\n",
       "                        [ -5.0981,  -4.8755,  -5.7412],\n",
       "                        [ -5.6913,  -5.1175,  -5.4186]],\n",
       "              \n",
       "                       [[ -7.5934,  -4.9929,  -4.8682],\n",
       "                        [ -6.5329,  -6.7392,  -5.7023],\n",
       "                        [ -4.6655,  -6.5716,  -5.0604]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.6578,  -4.9114,  -5.8949],\n",
       "                        [ -5.4794,  -5.1367,  -5.2141],\n",
       "                        [ -7.1503,  -5.0723,  -6.8911]],\n",
       "              \n",
       "                       [[ -7.7260,  -4.7098,  -4.7194],\n",
       "                        [ -4.8400,  -5.9135,  -5.9438],\n",
       "                        [ -4.6816,  -5.5583,  -4.6564]],\n",
       "              \n",
       "                       [[ -5.4169,  -4.8717,  -4.7754],\n",
       "                        [ -5.1123,  -4.8388,  -5.6561],\n",
       "                        [ -5.6101,  -5.9402,  -5.5524]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3646,  -6.1044,  -4.8309],\n",
       "                        [ -4.9290,  -6.4702,  -4.7857],\n",
       "                        [ -4.7454,  -6.7668,  -4.7657]],\n",
       "              \n",
       "                       [[ -5.3774,  -6.1290,  -5.3385],\n",
       "                        [ -8.1817,  -5.3416,  -4.6654],\n",
       "                        [ -6.9278,  -5.2007,  -5.8790]],\n",
       "              \n",
       "                       [[ -6.2015,  -4.7918,  -7.0114],\n",
       "                        [ -6.6029,  -4.9880,  -5.1994],\n",
       "                        [ -4.7158,  -4.6187,  -4.7050]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -7.0537,  -5.3076,  -5.5863],\n",
       "                        [ -5.8178,  -5.1174,  -5.0456],\n",
       "                        [ -5.3676,  -5.2478,  -5.6625]],\n",
       "              \n",
       "                       [[ -5.3646,  -6.0331,  -4.8292],\n",
       "                        [ -5.1204,  -5.0109,  -5.4891],\n",
       "                        [ -6.4985,  -4.7923,  -4.8494]],\n",
       "              \n",
       "                       [[ -5.2417,  -5.3264,  -4.9075],\n",
       "                        [ -4.6669,  -5.7886,  -5.0299],\n",
       "                        [ -4.8249,  -4.7134,  -5.8615]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.3013,  -5.6837,  -6.1340],\n",
       "                        [ -4.8347,  -6.8893,  -6.6270],\n",
       "                        [ -5.4885,  -6.7957,  -4.8725]],\n",
       "              \n",
       "                       [[ -4.7680,  -7.2965,  -6.8039],\n",
       "                        [ -7.3785,  -4.9002,  -5.0066],\n",
       "                        [ -4.6913,  -5.5690,  -4.6084]],\n",
       "              \n",
       "                       [[ -4.8951,  -7.2483,  -4.8205],\n",
       "                        [ -5.4375,  -5.4348,  -5.8624],\n",
       "                        [ -5.6269,  -4.8600,  -8.1621]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.9090,  -5.1043,  -6.6300],\n",
       "                        [ -4.9572,  -5.2812,  -4.9467],\n",
       "                        [ -6.9966,  -5.9345,  -5.1252]],\n",
       "              \n",
       "                       [[ -4.6989,  -4.8439,  -5.2943],\n",
       "                        [ -5.1051,  -5.7968,  -5.8932],\n",
       "                        [-10.1077,  -4.7491,  -8.4951]],\n",
       "              \n",
       "                       [[ -5.6271,  -5.8009,  -5.6112],\n",
       "                        [ -5.6509,  -4.7704,  -6.9457],\n",
       "                        [ -6.5300,  -5.8772,  -6.3974]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ -6.2656,  -6.2033,  -4.9923],\n",
       "                        [ -4.8826,  -8.2525,  -5.1309],\n",
       "                        [ -4.8151,  -5.6355,  -5.0209]],\n",
       "              \n",
       "                       [[ -6.3848,  -6.0805,  -7.8335],\n",
       "                        [ -4.8021,  -5.2011,  -4.9359],\n",
       "                        [ -5.2328,  -6.5811,  -4.6836]],\n",
       "              \n",
       "                       [[ -4.6560,  -4.6885, -11.7446],\n",
       "                        [ -6.5880,  -4.7699,  -5.2749],\n",
       "                        [ -5.6483,  -4.7934,  -6.8433]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.2342,  -5.2849,  -6.0316],\n",
       "                        [ -5.3714,  -4.7595,  -5.4207],\n",
       "                        [ -6.7571,  -9.9357,  -7.0918]],\n",
       "              \n",
       "                       [[ -7.8484,  -7.9049,  -4.8852],\n",
       "                        [ -8.5928,  -6.9321,  -4.7064],\n",
       "                        [ -4.6875,  -4.8348,  -5.5023]],\n",
       "              \n",
       "                       [[ -4.7033,  -4.6839,  -5.3626],\n",
       "                        [ -5.8149,  -4.6163,  -4.7024],\n",
       "                        [ -5.2816,  -5.4297,  -4.8385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7027,  -4.6516,  -5.3516],\n",
       "                        [ -5.2600,  -4.8881,  -5.0138],\n",
       "                        [ -5.9239,  -5.4689,  -4.6260]],\n",
       "              \n",
       "                       [[ -4.9607,  -5.8558,  -5.9619],\n",
       "                        [ -5.1053,  -7.0853,  -5.5569],\n",
       "                        [ -4.6085,  -6.3642,  -4.8830]],\n",
       "              \n",
       "                       [[ -5.5688,  -4.9501,  -6.1348],\n",
       "                        [ -6.3153,  -5.5237,  -4.7659],\n",
       "                        [ -4.6286,  -5.5474,  -6.4980]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.5645,  -4.6941,  -5.2743],\n",
       "                        [ -5.4054,  -4.9133,  -6.4651],\n",
       "                        [ -7.0040,  -4.9656,  -7.0266]],\n",
       "              \n",
       "                       [[ -5.2028,  -5.1697,  -4.7442],\n",
       "                        [ -4.8667,  -5.2562,  -6.2058],\n",
       "                        [ -7.5951,  -4.6418,  -4.9033]],\n",
       "              \n",
       "                       [[ -4.6518,  -5.0600,  -5.0147],\n",
       "                        [ -6.5606,  -5.0663,  -5.1944],\n",
       "                        [ -7.4739,  -4.6704,  -4.6449]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.6330,  -6.6073,  -5.0135],\n",
       "                        [ -4.9958,  -4.8325,  -4.6252],\n",
       "                        [ -4.9012,  -6.2909,  -6.0797]],\n",
       "              \n",
       "                       [[ -4.8079,  -7.8986,  -5.3821],\n",
       "                        [ -5.9537,  -7.2645,  -5.7079],\n",
       "                        [ -4.7860,  -5.0177,  -5.3445]],\n",
       "              \n",
       "                       [[ -4.9210,  -5.5095,  -4.9153],\n",
       "                        [ -9.2945,  -5.2109,  -5.0991],\n",
       "                        [ -4.6786,  -4.8999,  -4.7837]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.0940,  -6.4246,  -6.0016],\n",
       "                        [ -5.9106,  -4.6236,  -9.3768],\n",
       "                        [ -4.8565,  -4.6549,  -4.8105]],\n",
       "              \n",
       "                       [[ -5.0449,  -5.1650,  -4.6892],\n",
       "                        [ -5.7240,  -5.5601,  -4.7530],\n",
       "                        [ -4.6144,  -5.6058,  -7.4718]],\n",
       "              \n",
       "                       [[ -6.1598,  -4.6782,  -5.3052],\n",
       "                        [ -5.1732,  -5.6023,  -5.3645],\n",
       "                        [ -5.2507,  -5.4567,  -4.8220]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_alphas_log',\n",
       "              tensor([[[[-2.9031, -3.5752, -3.1913],\n",
       "                        [-2.2432, -3.7676, -3.9219],\n",
       "                        [-2.2315, -3.3817, -3.0104]],\n",
       "              \n",
       "                       [[-3.4620, -2.1322, -2.3796],\n",
       "                        [-3.2906, -3.9242, -2.4920],\n",
       "                        [-2.6064, -2.2625, -3.8039]],\n",
       "              \n",
       "                       [[-3.0305, -3.3771, -3.4199],\n",
       "                        [-2.7889, -2.9304, -3.7615],\n",
       "                        [-2.1174, -2.1470, -3.9918]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2688, -2.4659, -3.1240],\n",
       "                        [-3.7692, -3.6450, -3.6797],\n",
       "                        [-3.3195, -2.8639, -2.6135]],\n",
       "              \n",
       "                       [[-2.1157, -2.3645, -3.2899],\n",
       "                        [-3.4988, -3.0115, -2.7938],\n",
       "                        [-3.8293, -3.2961, -2.8436]],\n",
       "              \n",
       "                       [[-3.9779, -2.0617, -3.1237],\n",
       "                        [-3.9790, -2.6218, -2.4551],\n",
       "                        [-3.5406, -3.1608, -3.2890]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6755, -2.0339, -3.6471],\n",
       "                        [-3.1715, -3.2779, -2.7492],\n",
       "                        [-2.6883, -3.9882, -3.6644]],\n",
       "              \n",
       "                       [[-2.4057, -2.0133, -2.1821],\n",
       "                        [-2.7596, -2.0538, -2.6359],\n",
       "                        [-3.5137, -3.3185, -3.5885]],\n",
       "              \n",
       "                       [[-3.0351, -2.9763, -2.0979],\n",
       "                        [-3.3766, -3.9956, -2.0556],\n",
       "                        [-2.8010, -3.5787, -3.6768]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.9227, -3.6770, -3.7636],\n",
       "                        [-3.2002, -2.1039, -2.2279],\n",
       "                        [-3.7049, -2.7865, -2.1264]],\n",
       "              \n",
       "                       [[-3.0326, -2.2067, -2.2916],\n",
       "                        [-2.1105, -3.7049, -2.5112],\n",
       "                        [-3.1940, -2.1001, -3.4853]],\n",
       "              \n",
       "                       [[-2.8792, -3.0937, -2.7589],\n",
       "                        [-2.6047, -2.2957, -3.1234],\n",
       "                        [-3.8853, -2.5147, -2.4693]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4313, -3.4454, -2.5228],\n",
       "                        [-2.2018, -3.2355, -2.3762],\n",
       "                        [-3.8663, -3.0295, -3.5700]],\n",
       "              \n",
       "                       [[-3.5861, -2.0395, -2.0020],\n",
       "                        [-2.1038, -3.2346, -2.7971],\n",
       "                        [-2.3657, -2.5616, -3.5310]],\n",
       "              \n",
       "                       [[-3.3006, -3.3535, -3.3189],\n",
       "                        [-3.1244, -3.3003, -3.5692],\n",
       "                        [-2.7795, -2.1361, -2.3262]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.1123, -3.5558, -2.4190],\n",
       "                        [-2.8286, -2.1191, -2.5490],\n",
       "                        [-2.3278, -2.8362, -3.7079]],\n",
       "              \n",
       "                       [[-2.0250, -2.0361, -2.2242],\n",
       "                        [-3.5920, -2.1569, -3.2739],\n",
       "                        [-2.3617, -3.3745, -2.4369]],\n",
       "              \n",
       "                       [[-3.4996, -2.8253, -2.5848],\n",
       "                        [-3.4868, -3.3970, -3.3454],\n",
       "                        [-3.3596, -3.8827, -3.4139]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.1325, -2.0101, -2.3009],\n",
       "                        [-3.3946, -3.7420, -2.2947],\n",
       "                        [-2.8810, -3.1959, -2.4976]],\n",
       "              \n",
       "                       [[-3.0886, -3.6569, -2.8172],\n",
       "                        [-3.7599, -3.9197, -2.1939],\n",
       "                        [-3.7000, -2.5793, -3.5384]],\n",
       "              \n",
       "                       [[-2.8714, -2.3903, -2.9222],\n",
       "                        [-2.1279, -3.4309, -2.6593],\n",
       "                        [-3.9820, -2.9647, -3.0653]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4074, -3.5453, -2.9808],\n",
       "                        [-2.2863, -3.9489, -2.0954],\n",
       "                        [-3.8373, -3.9608, -3.8983]],\n",
       "              \n",
       "                       [[-3.3889, -2.3294, -3.8718],\n",
       "                        [-2.4368, -2.1073, -2.8512],\n",
       "                        [-3.6483, -3.7381, -3.0208]],\n",
       "              \n",
       "                       [[-2.0715, -3.7128, -2.4285],\n",
       "                        [-3.7453, -2.5793, -3.9045],\n",
       "                        [-2.2144, -2.8838, -3.2419]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8225, -2.4760, -2.3612],\n",
       "                        [-3.4040, -2.1312, -3.9279],\n",
       "                        [-3.2219, -3.0139, -2.9078]],\n",
       "              \n",
       "                       [[-3.9570, -3.6798, -3.8169],\n",
       "                        [-2.9281, -3.5607, -2.0121],\n",
       "                        [-2.0334, -3.3228, -3.2737]],\n",
       "              \n",
       "                       [[-3.0264, -2.6413, -2.7952],\n",
       "                        [-2.6720, -2.2991, -3.6808],\n",
       "                        [-2.9856, -3.2928, -3.7279]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2259, -2.7306, -3.2844],\n",
       "                        [-3.2082, -2.3142, -3.7642],\n",
       "                        [-2.4837, -2.9002, -2.0545]],\n",
       "              \n",
       "                       [[-3.8918, -3.5356, -2.0444],\n",
       "                        [-2.3271, -2.4968, -3.9083],\n",
       "                        [-2.4074, -2.6570, -2.4153]],\n",
       "              \n",
       "                       [[-2.0498, -3.5175, -2.1168],\n",
       "                        [-3.9951, -2.7050, -2.6350],\n",
       "                        [-2.7071, -2.6911, -3.2756]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4691, -2.6418, -3.3070],\n",
       "                        [-2.0403, -3.3388, -3.3410],\n",
       "                        [-3.4311, -2.3567, -2.7274]],\n",
       "              \n",
       "                       [[-2.9643, -3.1868, -2.6083],\n",
       "                        [-3.9008, -2.3488, -2.8015],\n",
       "                        [-3.6829, -3.6533, -3.1903]],\n",
       "              \n",
       "                       [[-3.1084, -2.5719, -3.7105],\n",
       "                        [-2.5479, -3.8481, -2.2664],\n",
       "                        [-2.6867, -2.7838, -3.6353]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0250, -2.3754, -2.1942],\n",
       "                        [-2.2754, -2.2488, -2.5304],\n",
       "                        [-3.6430, -2.9638, -3.1415]],\n",
       "              \n",
       "                       [[-3.1872, -2.3818, -3.4090],\n",
       "                        [-3.5182, -3.5750, -3.3125],\n",
       "                        [-2.8591, -2.2255, -3.4907]],\n",
       "              \n",
       "                       [[-2.1073, -3.1520, -3.7595],\n",
       "                        [-2.5730, -2.0243, -3.1251],\n",
       "                        [-3.6950, -3.2891, -3.7837]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.3.param_mus',\n",
       "              tensor([-0.0347, -0.0540, -0.0008,  0.0293, -0.0292,  0.0349, -0.0176,  0.0116,\n",
       "                       0.0173,  0.0239,  0.0535,  0.0285,  0.0451, -0.0420,  0.0108, -0.0409,\n",
       "                       0.0453, -0.0289, -0.0493, -0.0556, -0.0361, -0.0034, -0.0584,  0.0529,\n",
       "                       0.0162, -0.0444,  0.0243,  0.0210, -0.0163,  0.0040,  0.0075, -0.0225,\n",
       "                      -0.0476,  0.0339,  0.0409, -0.0459,  0.0447,  0.0547,  0.0345, -0.0486,\n",
       "                       0.0053, -0.0136,  0.0179, -0.0266,  0.0421, -0.0030, -0.0182, -0.0482,\n",
       "                      -0.0340, -0.0338,  0.0125, -0.0354,  0.0531, -0.0226, -0.0371, -0.0432,\n",
       "                       0.0315,  0.0339, -0.0145,  0.0430,  0.0406,  0.0375, -0.0415, -0.0373])),\n",
       "             ('module_list.0.posterior_params.3.param_std_log',\n",
       "              tensor([-5.4569, -4.6801, -4.7204, -5.3099, -5.5642, -7.9669, -5.1158, -5.7351,\n",
       "                      -4.8519, -5.2321, -6.6220, -5.4749, -5.7233, -5.7436, -4.8307, -5.3099,\n",
       "                      -5.5596, -6.0521, -5.2583, -4.7860, -4.8898, -5.6637, -4.7467, -4.6643,\n",
       "                      -5.3782, -6.6473, -4.6510, -5.2890, -4.7336, -4.6367, -4.8326, -7.7491,\n",
       "                      -5.7414, -5.3058, -5.7958, -4.8864, -4.6670, -5.3566, -6.6464, -6.9234,\n",
       "                      -6.2836, -4.6365, -7.2882, -6.8838, -4.6835, -5.1239, -7.1621, -5.2982,\n",
       "                      -5.1323, -6.3269, -5.4452, -6.2584, -6.0409, -5.0412, -4.7253, -4.7920,\n",
       "                      -4.8736, -4.7333, -4.9122, -4.8091, -6.4931, -5.7098, -8.9380, -4.7787])),\n",
       "             ('module_list.0.posterior_params.3.scale_alphas_log',\n",
       "              tensor([-2.0096, -3.1070, -2.4744, -2.8249, -2.1330, -2.1949, -3.7866, -3.2097,\n",
       "                      -3.8550, -3.1583, -3.0586, -2.9922, -2.6323, -2.1886, -2.5555, -2.2712,\n",
       "                      -2.9222, -2.3903, -2.9189, -2.6913, -2.1877, -2.3527, -2.1297, -3.1475,\n",
       "                      -2.6098, -2.0891, -3.4339, -2.4926, -3.6903, -2.8732, -2.1957, -3.5118,\n",
       "                      -2.2983, -3.3832, -3.4829, -2.7464, -3.3553, -3.5355, -2.4428, -3.0015,\n",
       "                      -2.7173, -2.5134, -3.9719, -2.8202, -2.6662, -3.1703, -2.6489, -2.1131,\n",
       "                      -2.0383, -3.8398, -2.6632, -2.2751, -2.4046, -2.9891, -2.8446, -3.0018,\n",
       "                      -2.0600, -3.5996, -3.0579, -2.5789, -3.7129, -2.4109, -2.5351, -3.2553])),\n",
       "             ('module_list.0.posterior_params.3.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.4.param_mus',\n",
       "              tensor([[ 0.0009,  0.0158,  0.0126,  ..., -0.0105, -0.0025, -0.0128],\n",
       "                      [ 0.0080, -0.0029, -0.0087,  ...,  0.0028, -0.0101,  0.0126],\n",
       "                      [ 0.0150, -0.0064, -0.0075,  ..., -0.0084, -0.0034, -0.0038],\n",
       "                      ...,\n",
       "                      [-0.0002, -0.0109,  0.0178,  ..., -0.0034, -0.0082, -0.0020],\n",
       "                      [-0.0095,  0.0160, -0.0090,  ..., -0.0084,  0.0039,  0.0121],\n",
       "                      [-0.0176, -0.0070,  0.0146,  ..., -0.0085,  0.0145, -0.0063]])),\n",
       "             ('module_list.0.posterior_params.4.param_std_log',\n",
       "              tensor([[-5.0882, -5.6143, -5.0647,  ..., -5.6104, -4.6591, -4.9445],\n",
       "                      [-4.6745, -5.9688, -5.0048,  ..., -6.3473, -4.6243, -6.2210],\n",
       "                      [-4.7615, -7.7854, -5.7147,  ..., -7.3079, -5.9162, -5.9307],\n",
       "                      ...,\n",
       "                      [-6.7976, -5.2108, -5.6782,  ..., -5.2774, -5.6684, -6.0092],\n",
       "                      [-6.6351, -4.8296, -5.0264,  ..., -7.7251, -5.2107, -4.8150],\n",
       "                      [-7.3702, -8.7021, -4.7729,  ..., -4.8881, -4.7526, -5.0925]])),\n",
       "             ('module_list.0.posterior_params.4.scale_alphas_log',\n",
       "              tensor([[-2.3414, -2.7704, -3.4864,  ..., -2.1757, -3.9189, -2.2035],\n",
       "                      [-2.3410, -2.2061, -3.1260,  ..., -3.4673, -2.0878, -3.4667],\n",
       "                      [-3.9802, -2.7468, -2.0136,  ..., -2.2748, -3.8034, -2.2377],\n",
       "                      ...,\n",
       "                      [-2.4080, -2.7311, -2.1504,  ..., -3.6135, -2.4462, -2.0026],\n",
       "                      [-3.4683, -2.5169, -2.6618,  ..., -2.9077, -2.7889, -2.0861],\n",
       "                      [-2.1884, -3.1091, -3.6772,  ..., -2.2174, -2.0252, -2.5327]])),\n",
       "             ('module_list.0.posterior_params.4.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.5.param_mus',\n",
       "              tensor([-0.0112,  0.0141,  0.0014,  0.0127, -0.0057, -0.0123, -0.0136,  0.0164,\n",
       "                       0.0140,  0.0152,  0.0077,  0.0159, -0.0018, -0.0005,  0.0025,  0.0036,\n",
       "                       0.0174, -0.0110,  0.0078, -0.0102,  0.0028,  0.0009,  0.0105,  0.0106,\n",
       "                       0.0002, -0.0018,  0.0092, -0.0014, -0.0002,  0.0019,  0.0001,  0.0019,\n",
       "                      -0.0122,  0.0073, -0.0102, -0.0153, -0.0162,  0.0075,  0.0051,  0.0153,\n",
       "                       0.0129, -0.0160, -0.0173, -0.0098, -0.0150,  0.0157, -0.0045,  0.0022,\n",
       "                      -0.0135,  0.0099,  0.0101,  0.0171,  0.0014, -0.0172,  0.0025, -0.0021,\n",
       "                       0.0169,  0.0017,  0.0117, -0.0016,  0.0121, -0.0066, -0.0090, -0.0044,\n",
       "                      -0.0091,  0.0011, -0.0143,  0.0033, -0.0132, -0.0091, -0.0091, -0.0157,\n",
       "                       0.0127,  0.0111, -0.0166,  0.0143,  0.0017, -0.0061, -0.0174,  0.0098,\n",
       "                       0.0034, -0.0063,  0.0041, -0.0007, -0.0088, -0.0068, -0.0123, -0.0048,\n",
       "                       0.0054, -0.0105, -0.0157,  0.0175, -0.0124,  0.0101,  0.0101,  0.0164,\n",
       "                       0.0117, -0.0088, -0.0032,  0.0164,  0.0047,  0.0089, -0.0158, -0.0005,\n",
       "                       0.0097, -0.0070,  0.0082,  0.0131, -0.0131, -0.0050,  0.0024, -0.0050,\n",
       "                       0.0152,  0.0010, -0.0035, -0.0169,  0.0012, -0.0119, -0.0085, -0.0127,\n",
       "                       0.0139,  0.0060,  0.0050, -0.0074, -0.0137,  0.0144,  0.0127, -0.0140])),\n",
       "             ('module_list.0.posterior_params.5.param_std_log',\n",
       "              tensor([ -8.5058,  -4.9983,  -4.7748,  -6.4515,  -8.2332, -10.5456,  -5.4021,\n",
       "                       -8.7938,  -6.3761,  -5.5005,  -7.5101,  -5.7537,  -4.8349,  -6.5463,\n",
       "                       -4.9158,  -6.0935,  -7.2662,  -5.4875,  -5.6636,  -4.8700,  -4.7151,\n",
       "                       -4.7584,  -4.8736,  -5.3312,  -4.9649,  -4.9046,  -4.9326,  -7.3845,\n",
       "                       -6.0946,  -5.0042,  -4.9009,  -4.6594,  -5.4126,  -4.7578,  -5.2708,\n",
       "                       -7.4743,  -5.6484,  -5.0898,  -5.7023,  -5.2178,  -6.5615,  -7.9420,\n",
       "                       -5.2271,  -5.7446,  -5.1716,  -5.5231,  -5.2031,  -6.4824,  -4.7606,\n",
       "                       -5.7502,  -5.2827,  -6.0781,  -5.8726,  -5.0141,  -4.9438,  -8.0827,\n",
       "                       -5.3131,  -5.7115,  -4.7213,  -4.6253,  -4.7276,  -4.6258,  -5.1091,\n",
       "                       -5.2092,  -5.5085,  -5.6953,  -4.6783,  -4.9021,  -4.7901,  -4.9724,\n",
       "                       -5.9262,  -6.1041,  -5.0713,  -4.6735,  -6.4833,  -5.2216,  -5.1605,\n",
       "                       -4.9854,  -5.7718,  -6.8357,  -4.9983,  -6.0955,  -5.8611,  -5.9829,\n",
       "                       -4.8589,  -5.1603,  -6.4991,  -5.6061,  -5.8304,  -5.4435,  -4.6777,\n",
       "                       -4.7764,  -5.0857,  -4.9599,  -4.7925,  -4.8101,  -4.6988,  -4.6460,\n",
       "                       -5.2655,  -6.4285,  -5.7866,  -5.3847,  -5.1084,  -5.3568,  -5.4592,\n",
       "                       -5.4557,  -7.1196,  -4.6417,  -6.3491,  -4.9110,  -5.1545,  -4.8412,\n",
       "                       -5.2638,  -6.0338,  -4.9269,  -7.4436,  -5.8754,  -4.9944,  -5.3159,\n",
       "                       -5.9607,  -6.5675,  -6.2111,  -5.1559,  -7.5439,  -4.7024,  -5.7944,\n",
       "                       -4.7159,  -5.0060])),\n",
       "             ('module_list.0.posterior_params.5.scale_alphas_log',\n",
       "              tensor([-2.9711, -2.3029, -3.2661, -3.8841, -3.9730, -2.9972, -3.0801, -2.8908,\n",
       "                      -3.2214, -2.5367, -3.7855, -3.5761, -3.2829, -2.4807, -3.7627, -3.3901,\n",
       "                      -3.2457, -2.9323, -3.2918, -3.2453, -3.4675, -2.9678, -3.9310, -2.9987,\n",
       "                      -2.2035, -2.3976, -3.5818, -3.1568, -2.2656, -3.4460, -3.9424, -3.2561,\n",
       "                      -2.0742, -3.8532, -3.1280, -2.8851, -2.0143, -2.0730, -2.5920, -3.7779,\n",
       "                      -2.5698, -3.7920, -3.6548, -2.3358, -3.9477, -3.6476, -3.8149, -2.5764,\n",
       "                      -2.8168, -3.6043, -3.2515, -3.9662, -3.3422, -2.4601, -2.8934, -2.9427,\n",
       "                      -3.4763, -2.3204, -2.2301, -2.4737, -3.8858, -3.7568, -3.4567, -3.1788,\n",
       "                      -2.4339, -2.0268, -2.8586, -3.4026, -2.9261, -2.2214, -3.0145, -3.9870,\n",
       "                      -2.0210, -3.2889, -2.6818, -2.6525, -2.6215, -2.5191, -3.3091, -2.5133,\n",
       "                      -2.1772, -2.7749, -3.2064, -2.7597, -2.0681, -2.4307, -2.3182, -3.3219,\n",
       "                      -3.7947, -3.7979, -2.5180, -2.9864, -2.1951, -3.9902, -2.8577, -3.3741,\n",
       "                      -3.5462, -3.3496, -2.4838, -2.2125, -3.5979, -2.9471, -3.3925, -3.8978,\n",
       "                      -3.0267, -2.5021, -2.3832, -3.2529, -2.6711, -3.8071, -3.5777, -3.3519,\n",
       "                      -2.8422, -2.2266, -2.3704, -2.8740, -2.7499, -2.9441, -2.7132, -3.9846,\n",
       "                      -2.8880, -3.0201, -3.8964, -2.4971, -3.7383, -2.5198, -2.3017, -3.7625])),\n",
       "             ('module_list.0.posterior_params.5.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('module_list.0.posterior_params.6.param_mus',\n",
       "              tensor([[ 0.0861,  0.0572,  0.0623,  ...,  0.0349, -0.0029,  0.0783],\n",
       "                      [ 0.0663, -0.0496, -0.0471,  ...,  0.0246, -0.0090,  0.0290],\n",
       "                      [ 0.0787, -0.0569, -0.0074,  ...,  0.0223,  0.0753,  0.0849],\n",
       "                      ...,\n",
       "                      [-0.0752, -0.0523,  0.0439,  ..., -0.0768, -0.0083, -0.0679],\n",
       "                      [-0.0070, -0.0547, -0.0404,  ...,  0.0185, -0.0464, -0.0533],\n",
       "                      [-0.0087, -0.0757, -0.0331,  ...,  0.0254, -0.0312,  0.0815]])),\n",
       "             ('module_list.0.posterior_params.6.param_std_log',\n",
       "              tensor([[-5.2017, -7.5709, -4.9455,  ..., -5.7424, -5.2740, -7.6515],\n",
       "                      [-5.7487, -5.2041, -5.0962,  ..., -6.7837, -5.8445, -6.4197],\n",
       "                      [-5.0128, -4.9754, -5.1209,  ..., -5.3098, -6.3397, -8.8992],\n",
       "                      ...,\n",
       "                      [-6.1798, -5.0020, -5.8882,  ..., -4.7352, -8.7045, -4.7601],\n",
       "                      [-6.9533, -5.3401, -4.6249,  ..., -4.6350, -4.9398, -4.7976],\n",
       "                      [-5.3153, -4.6354, -5.0823,  ..., -5.2240, -5.2665, -4.6325]])),\n",
       "             ('module_list.0.posterior_params.6.scale_alphas_log',\n",
       "              tensor([[-3.4896, -2.3144, -3.2581,  ..., -2.1586, -3.0065, -2.2661],\n",
       "                      [-2.4441, -2.0589, -2.5914,  ..., -3.1640, -3.8862, -2.6127],\n",
       "                      [-2.4363, -2.7432, -2.3645,  ..., -2.4624, -2.6623, -2.2037],\n",
       "                      ...,\n",
       "                      [-3.5581, -3.5343, -3.9614,  ..., -3.5155, -3.0719, -3.5733],\n",
       "                      [-3.6154, -3.6500, -2.4728,  ..., -2.0083, -3.4753, -2.4960],\n",
       "                      [-3.1972, -3.5865, -2.2273,  ..., -3.9335, -3.2613, -3.5673]])),\n",
       "             ('module_list.0.posterior_params.6.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.7.param_mus',\n",
       "              tensor([ 0.0045,  0.0808, -0.0811,  0.0353,  0.0298, -0.0510, -0.0097,  0.0499,\n",
       "                       0.0105, -0.0429])),\n",
       "             ('module_list.0.posterior_params.7.param_std_log',\n",
       "              tensor([-5.2095, -5.1445, -5.7701, -4.7362, -6.1606, -5.0685, -5.4482, -5.0233,\n",
       "                      -5.1172, -4.9747])),\n",
       "             ('module_list.0.posterior_params.7.scale_alphas_log',\n",
       "              tensor([-2.7219, -3.5050, -3.6166, -2.6818, -2.5404, -2.2111, -2.9576, -3.6258,\n",
       "                      -2.4424, -2.8427])),\n",
       "             ('module_list.0.posterior_params.7.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_bayes.pt'))\n",
    "image1, label1 = test_dataset[10]\n",
    "image2, label2 = test_dataset[11]\n",
    "model(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:16906.90234375, KL Loss: 1690681.375, FitLoss: 0.09073139727115631, Accuracy 0.98, Prune parameters: 221821.0/421642\n"
     ]
    }
   ],
   "source": [
    "val_loss = 0.0\n",
    "val_acc = 0.0\n",
    "PRUNE = 1.0\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,  \n",
    "                                         batch_size=BATCH_SIZE,  \n",
    "                                         shuffle=False, \n",
    "                                         pin_memory=True) \n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "trainer.params.prune_threshold = PRUNE\n",
    "test_result = trainer.eval(model, test_loader)\n",
    "acc = test_result.custom_losses['val_accuracy']\n",
    "print(f'Loss:{test_result.val_loss}, KL Loss: {test_result.dist_loss}, FitLoss: {test_result.fit_loss}, Accuracy {acc}, Prune parameters: {test_result.cnt_prune_parameters}/{test_result.cnt_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device=device)\n",
    "model.prune({'threshold': 1.0})\n",
    "model.set_map_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 4.2992e-03, -5.4342e-01, -0.0000e+00],\n",
      "          [ 3.9089e-01, -0.0000e+00, -0.0000e+00],\n",
      "          [ 8.2518e-01,  3.0815e-01, -2.3478e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8153e-02,  0.0000e+00, -0.0000e+00],\n",
      "          [ 4.4879e-01,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.4131e+00, -7.5729e-01, -0.0000e+00],\n",
      "          [ 2.0788e-01,  4.6619e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  2.6288e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  9.8380e-01,  3.4592e-01],\n",
      "          [-0.0000e+00,  4.0430e-01,  0.0000e+00],\n",
      "          [-8.4115e-01, -3.8792e-01, -1.5979e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0565e-01,  0.0000e+00,  2.3229e-01],\n",
      "          [ 0.0000e+00,  6.6020e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -3.2411e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00,  3.8068e-01,  0.0000e+00],\n",
      "          [-1.7023e-03,  7.2274e-01,  1.6451e-01],\n",
      "          [-2.6313e-01,  0.0000e+00, -8.0280e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  7.1311e-01, -0.0000e+00],\n",
      "          [ 7.3480e-01,  0.0000e+00, -6.3528e-01],\n",
      "          [ 1.7638e-02, -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8662e-01,  4.1352e-01,  7.5745e-01],\n",
      "          [ 3.4204e-03, -2.4012e-03,  1.9629e-01],\n",
      "          [-0.0000e+00, -1.8996e+00, -5.4733e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7047e-01, -0.0000e+00, -4.2426e-02],\n",
      "          [-0.0000e+00,  8.9670e-01,  8.5076e-01],\n",
      "          [-4.0429e-01,  5.5609e-01, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  1.1400e-01],\n",
      "          [ 0.0000e+00,  4.4838e-01, -0.0000e+00],\n",
      "          [ 4.5566e-02, -0.0000e+00, -1.9310e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.7405e-02,  2.3569e-01, -0.0000e+00],\n",
      "          [ 4.6704e-01,  8.9131e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -1.1183e-02, -6.1903e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 5.3916e-02,  1.3328e-02, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4441e-01,  0.0000e+00, -2.3364e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  7.9347e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6268e-01,  0.0000e+00, -0.0000e+00],\n",
      "          [ 6.3382e-01,  3.4143e-01, -0.0000e+00],\n",
      "          [-0.0000e+00, -3.0772e-01, -8.3751e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0354e-01,  0.0000e+00, -0.0000e+00],\n",
      "          [ 4.2287e-01,  0.0000e+00,  3.6846e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.1328e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0544e-01, -1.0880e+00, -1.3626e+00],\n",
      "          [ 0.0000e+00,  4.4564e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  6.4581e-01,  3.5768e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  3.1633e-01, -6.6071e-01],\n",
      "          [ 0.0000e+00,  2.3753e-01, -0.0000e+00],\n",
      "          [ 3.6975e-01, -5.6517e-03, -6.6312e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.1901e-01,  6.4522e-02,  2.1885e-01],\n",
      "          [-0.0000e+00,  6.1452e-01,  4.0866e-01],\n",
      "          [-1.2748e-01,  5.6207e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.3363e-01, -0.0000e+00, -0.0000e+00],\n",
      "          [ 2.1696e-01,  0.0000e+00,  6.1144e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.8670e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  6.6921e-01,  3.2235e-01],\n",
      "          [-0.0000e+00,  4.6664e-01,  1.8888e-01],\n",
      "          [-5.4447e-01, -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.0248e-01, -0.0000e+00,  1.2330e-01],\n",
      "          [-0.0000e+00,  0.0000e+00,  6.1526e-01],\n",
      "          [-1.3471e-01,  3.3910e-01,  2.8420e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  2.2249e-01,  0.0000e+00],\n",
      "          [ 1.4262e-01,  8.8915e-01,  0.0000e+00],\n",
      "          [-0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1939e+00, -4.6484e-01, -0.0000e+00],\n",
      "          [-8.6274e-01,  1.4272e-01,  0.0000e+00],\n",
      "          [ 1.0309e-01,  4.9730e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1762e-01, -1.4468e-01, -0.0000e+00],\n",
      "          [ 3.6268e-01,  5.3481e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  5.2241e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00,  0.0000e+00,  1.2648e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.5915e-01],\n",
      "          [-0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3550e-02,  0.0000e+00,  6.7948e-02],\n",
      "          [ 5.6981e-01,  0.0000e+00,  4.5842e-01],\n",
      "          [ 2.9938e-02,  1.7861e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  3.6278e-01, -2.5424e-01],\n",
      "          [ 9.4070e-01,  0.0000e+00, -2.1502e-02],\n",
      "          [ 9.6985e-03,  6.5121e-02, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  9.1819e-02],\n",
      "          [ 0.0000e+00, -0.0000e+00, -3.3740e-01],\n",
      "          [-0.0000e+00, -0.0000e+00, -2.1633e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3137e-02, -0.0000e+00, -0.0000e+00],\n",
      "          [ 5.4615e-01,  2.9908e-01, -0.0000e+00],\n",
      "          [ 9.4902e-01,  2.2312e-01, -3.2910e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6456e-02, -3.2759e-01, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.7491e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -1.7607e-01, -7.8085e-02],\n",
      "          [-0.0000e+00,  1.0843e+00,  0.0000e+00],\n",
      "          [-7.0030e-02,  0.0000e+00,  1.0573e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  9.0907e-01],\n",
      "          [-1.3929e-01, -2.4492e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00]]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.base_module.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = test_dataset[100]\n",
    "plt.imshow(image.permute(1, 2, 0), cmap = 'gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2.1405], device='cuda:0'),\n",
       "indices=tensor([5], device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(model(image.cuda()).data, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
