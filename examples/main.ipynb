{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем путь к нашей библиотеке в переменную окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../', '/home/sasha/BMM/bayes_deep_compression/examples', '/home/sasha/anaconda3/lib/python312.zip', '/home/sasha/anaconda3/lib/python3.12', '/home/sasha/anaconda3/lib/python3.12/lib-dynload', '', '/home/sasha/anaconda3/lib/python3.12/site-packages', '/home/sasha/anaconda3/lib/python3.12/site-packages/setuptools/_vendor', '/tmp/tmp6v_cw2kc']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем простой классификтор, который будет нашей базовой моделью, кторую мы хотим обучить и запрунить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier(nn.Module): \n",
    "    def __init__(self, classes: int = 10): \n",
    "        super().__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) \n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        #self.dropout1 = nn.Dropout2d(0.25) \n",
    "        #self.dropout2 = nn.Dropout2d(0.5) \n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128) \n",
    "        self.fc2 = nn.Linear(128, classes) \n",
    "  \n",
    "    def forward(self, x): \n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        #x = self.dropout1(x) \n",
    "        x = self.pool(F.relu(self.conv2(x))) \n",
    "        #x = self.dropout2(x) \n",
    "        x = x.view(-1, 64 * 7 * 7) \n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.fc2(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как работают распределения в нашей библиотеке(Их не обязательно импортировать для работы и обучения байесовской модели)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый вид это привычные нам распределения на числа. Импортируем тот, который используется у нас в модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.bayes.variational.distribution import LogUniformVarDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый вид это привычные нам распределения на числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.bayes.variational.net_distribution import VarBayesModuleNetDistribution #Необязательно импортировать для обучения, оно встроено в нашу байесовскую модель\n",
    "from src.methods.bayes.base.net_distribution import BaseNetDistributionPruner #Также не обязательно для обучения, но нужен, если вы хотите запрунить модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем инициализировать веса распределения просто из параметров модели. При этом используется рекомендуемая начальная инициализация параметров распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogUniformVarDist(param_mus: torch.Size([2]), param_std_log: torch.Size([2]), scale_mus: torch.Size([2]), scale_alphas_log: torch.Size([2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = nn.Parameter(torch.tensor([0.0, 1.0])) \n",
    "LogUniformVarDist.from_parameter(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это три модуля являются основными для байесовского обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.bayes.variational.net import LogUniformVarLayer, VarBayesNet #Первым модулоем мы оборачиваем те слои модели, которые мы хотим сделать байесовыми, второй модуль это сама байесовская сеть\n",
    "from src.methods.bayes.variational.optimization import LogUniformVarKLLoss #Это лосс байесовской модели, который отвечает за тип обучения. Всегда рекомендуется использовать специализированный лосс, но для большинства распределений его нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет MNIST, на котором мы хотим обучить наш классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.42MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 219kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 864kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.30MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посомтрим внимательнее как нужно создавать байесовскую сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом создадим нашу базовую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы часть слоев превратим в байесовски с помощью LogUniformVarBayesModule. И создадим список всех слоев nn.ModuleList([layer1, layer2, ...]), которые мы хотим обучить (в том чилсе слои, которые не являются байесовыми). Заметим, что можно обернуть и всю сеть целиком и передать список состоящий только из нее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayes_model = BayesModule(module)\n",
    "#var_module = LogUniformVarBayesModule(module)\n",
    "var_module1 = LogUniformVarLayer(module.conv1)\n",
    "#bayes_model = VarBayesModuleNet(module, nn.ModuleList([var_module])) #Первый аргумент базовая сеть, второй список всех слоев (где нужные из них являются байесовыми)\n",
    "bayes_model = VarBayesNet(module, nn.ModuleDict({'conv1': var_module1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0051,  0.0443, -0.0515],\n",
       "            [ 0.0142,  0.0112, -0.0043],\n",
       "            [ 0.0119,  0.0147, -0.0322]],\n",
       "  \n",
       "           [[-0.0333, -0.0216,  0.0563],\n",
       "            [-0.0500,  0.0431,  0.0271],\n",
       "            [ 0.0336, -0.0206, -0.0539]],\n",
       "  \n",
       "           [[-0.0348,  0.0104,  0.0049],\n",
       "            [ 0.0453,  0.0032,  0.0195],\n",
       "            [-0.0460, -0.0035,  0.0529]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0367, -0.0261,  0.0311],\n",
       "            [-0.0228, -0.0467, -0.0221],\n",
       "            [ 0.0007,  0.0294, -0.0141]],\n",
       "  \n",
       "           [[ 0.0003,  0.0146, -0.0511],\n",
       "            [ 0.0216, -0.0257,  0.0491],\n",
       "            [-0.0030,  0.0078, -0.0418]],\n",
       "  \n",
       "           [[ 0.0204, -0.0195, -0.0276],\n",
       "            [ 0.0428, -0.0102, -0.0485],\n",
       "            [ 0.0585,  0.0419, -0.0113]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0288, -0.0062,  0.0086],\n",
       "            [-0.0111, -0.0235,  0.0182],\n",
       "            [ 0.0084,  0.0055, -0.0392]],\n",
       "  \n",
       "           [[-0.0587, -0.0173, -0.0492],\n",
       "            [-0.0214,  0.0327, -0.0041],\n",
       "            [-0.0071, -0.0236, -0.0307]],\n",
       "  \n",
       "           [[ 0.0353, -0.0375, -0.0186],\n",
       "            [-0.0310, -0.0086,  0.0073],\n",
       "            [ 0.0002, -0.0346, -0.0031]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0106, -0.0472,  0.0330],\n",
       "            [-0.0081,  0.0483, -0.0273],\n",
       "            [ 0.0184,  0.0224,  0.0564]],\n",
       "  \n",
       "           [[-0.0207,  0.0570, -0.0435],\n",
       "            [-0.0126, -0.0515, -0.0058],\n",
       "            [ 0.0555, -0.0479,  0.0563]],\n",
       "  \n",
       "           [[ 0.0223, -0.0335, -0.0309],\n",
       "            [-0.0098, -0.0267,  0.0574],\n",
       "            [ 0.0266,  0.0183,  0.0261]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0202,  0.0273, -0.0381],\n",
       "            [ 0.0164,  0.0125,  0.0390],\n",
       "            [-0.0339, -0.0022,  0.0211]],\n",
       "  \n",
       "           [[ 0.0095, -0.0527,  0.0290],\n",
       "            [ 0.0207,  0.0134,  0.0153],\n",
       "            [-0.0061, -0.0146,  0.0074]],\n",
       "  \n",
       "           [[-0.0172, -0.0288,  0.0477],\n",
       "            [-0.0307, -0.0356, -0.0052],\n",
       "            [-0.0217, -0.0068, -0.0039]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0034,  0.0500, -0.0159],\n",
       "            [ 0.0389, -0.0483,  0.0149],\n",
       "            [-0.0356, -0.0141, -0.0320]],\n",
       "  \n",
       "           [[-0.0078, -0.0060, -0.0357],\n",
       "            [ 0.0295, -0.0337, -0.0107],\n",
       "            [-0.0139,  0.0142,  0.0085]],\n",
       "  \n",
       "           [[-0.0077,  0.0020, -0.0094],\n",
       "            [ 0.0524,  0.0217,  0.0025],\n",
       "            [-0.0034,  0.0140,  0.0518]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 0.0226,  0.0269, -0.0398],\n",
       "            [ 0.0103, -0.0251, -0.0196],\n",
       "            [ 0.0341,  0.0226,  0.0017]],\n",
       "  \n",
       "           [[-0.0319,  0.0308,  0.0140],\n",
       "            [-0.0259,  0.0155, -0.0358],\n",
       "            [ 0.0488,  0.0219,  0.0041]],\n",
       "  \n",
       "           [[ 0.0504,  0.0411, -0.0459],\n",
       "            [ 0.0291, -0.0110, -0.0308],\n",
       "            [-0.0579,  0.0132,  0.0573]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0043, -0.0124, -0.0435],\n",
       "            [-0.0243,  0.0091,  0.0460],\n",
       "            [-0.0248, -0.0385, -0.0318]],\n",
       "  \n",
       "           [[-0.0122, -0.0205, -0.0314],\n",
       "            [ 0.0438, -0.0508, -0.0551],\n",
       "            [-0.0505, -0.0366,  0.0219]],\n",
       "  \n",
       "           [[ 0.0345,  0.0221,  0.0550],\n",
       "            [-0.0309, -0.0553,  0.0151],\n",
       "            [ 0.0462,  0.0244, -0.0029]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0276,  0.0581,  0.0248],\n",
       "            [-0.0533, -0.0030,  0.0081],\n",
       "            [ 0.0086,  0.0181,  0.0193]],\n",
       "  \n",
       "           [[ 0.0248,  0.0451,  0.0441],\n",
       "            [ 0.0080, -0.0305,  0.0580],\n",
       "            [ 0.0500,  0.0293,  0.0190]],\n",
       "  \n",
       "           [[ 0.0184, -0.0231,  0.0282],\n",
       "            [ 0.0332,  0.0192, -0.0455],\n",
       "            [ 0.0241,  0.0133,  0.0142]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0403,  0.0215,  0.0341],\n",
       "            [-0.0427, -0.0083, -0.0240],\n",
       "            [ 0.0237,  0.0066,  0.0211]],\n",
       "  \n",
       "           [[-0.0502,  0.0273, -0.0284],\n",
       "            [-0.0174, -0.0378, -0.0578],\n",
       "            [ 0.0293,  0.0083, -0.0401]],\n",
       "  \n",
       "           [[ 0.0427, -0.0575,  0.0047],\n",
       "            [ 0.0533,  0.0045, -0.0348],\n",
       "            [-0.0447, -0.0332, -0.0002]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0301, -0.0147, -0.0117],\n",
       "            [-0.0196,  0.0494, -0.0135],\n",
       "            [ 0.0168,  0.0086, -0.0272]],\n",
       "  \n",
       "           [[ 0.0014,  0.0523, -0.0438],\n",
       "            [ 0.0541, -0.0371,  0.0555],\n",
       "            [-0.0030, -0.0268, -0.0558]],\n",
       "  \n",
       "           [[ 0.0113,  0.0517,  0.0138],\n",
       "            [ 0.0096, -0.0007,  0.0462],\n",
       "            [ 0.0425,  0.0184, -0.0034]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-0.0410,  0.0570, -0.0456],\n",
       "            [-0.0513, -0.0418, -0.0454],\n",
       "            [ 0.0348, -0.0020, -0.0359]],\n",
       "  \n",
       "           [[-0.0227, -0.0286, -0.0346],\n",
       "            [ 0.0473, -0.0472, -0.0032],\n",
       "            [-0.0341,  0.0025,  0.0362]],\n",
       "  \n",
       "           [[-0.0305,  0.0025, -0.0212],\n",
       "            [-0.0337, -0.0410,  0.0479],\n",
       "            [-0.0266, -0.0475,  0.0340]]]], requires_grad=True)),\n",
       " ('conv2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0487, -0.0184,  0.0404, -0.0319,  0.0386, -0.0349, -0.0340,  0.0307,\n",
       "           0.0469,  0.0565,  0.0356, -0.0455, -0.0033,  0.0415, -0.0574,  0.0031,\n",
       "           0.0239, -0.0380,  0.0536,  0.0206,  0.0042,  0.0029,  0.0212, -0.0430,\n",
       "          -0.0345, -0.0139,  0.0566,  0.0545, -0.0331, -0.0087, -0.0556,  0.0206,\n",
       "          -0.0365, -0.0187,  0.0334, -0.0479, -0.0178, -0.0210,  0.0189, -0.0164,\n",
       "          -0.0428, -0.0272,  0.0155, -0.0405,  0.0473,  0.0323,  0.0220, -0.0366,\n",
       "           0.0250, -0.0427,  0.0561,  0.0084, -0.0091, -0.0342,  0.0107,  0.0134,\n",
       "           0.0454,  0.0028,  0.0400, -0.0421,  0.0077,  0.0186,  0.0481,  0.0203],\n",
       "         requires_grad=True)),\n",
       " ('fc1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0002, -0.0015, -0.0115,  ..., -0.0104,  0.0089, -0.0071],\n",
       "          [-0.0016, -0.0148, -0.0069,  ..., -0.0054,  0.0065,  0.0078],\n",
       "          [-0.0045, -0.0090,  0.0116,  ...,  0.0068, -0.0122,  0.0053],\n",
       "          ...,\n",
       "          [-0.0099,  0.0138,  0.0090,  ..., -0.0004,  0.0051, -0.0062],\n",
       "          [-0.0042,  0.0020, -0.0007,  ...,  0.0025, -0.0004, -0.0117],\n",
       "          [ 0.0032, -0.0081,  0.0123,  ...,  0.0097, -0.0084,  0.0148]],\n",
       "         requires_grad=True)),\n",
       " ('fc1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 2.3490e-03,  1.2687e-02,  1.3444e-02,  1.1783e-02,  9.5353e-03,\n",
       "          -9.2839e-03,  1.6556e-03, -3.1612e-03,  1.0278e-02, -2.5520e-03,\n",
       "          -1.5581e-03, -1.3017e-02,  5.7710e-03, -1.3064e-02,  1.5495e-02,\n",
       "           7.4203e-03, -1.4058e-02,  5.7930e-03,  1.4866e-02,  1.0100e-04,\n",
       "           1.3602e-02,  8.3261e-03,  3.5535e-03, -1.1876e-02,  1.7469e-02,\n",
       "           1.2769e-02,  1.0116e-02, -2.0669e-03,  4.2273e-03, -4.3093e-03,\n",
       "           3.4133e-03, -1.6815e-02, -1.6988e-02, -1.3987e-03, -9.2163e-03,\n",
       "           2.9196e-03, -1.3616e-02,  7.9250e-03,  3.5134e-03, -5.5174e-03,\n",
       "           1.7649e-02, -1.4295e-02, -1.1718e-02,  5.3197e-03, -4.7939e-04,\n",
       "           1.7375e-02, -9.8695e-03, -3.8659e-03, -9.2376e-03, -1.3717e-02,\n",
       "           3.5539e-03, -1.7702e-03, -9.8083e-03, -1.2776e-02, -5.9482e-04,\n",
       "           4.4149e-04, -1.6945e-02, -1.2829e-02, -1.2532e-02, -4.6355e-03,\n",
       "           2.8156e-03,  1.3668e-02, -1.4223e-02, -7.1791e-03, -1.1129e-02,\n",
       "          -6.9485e-03, -5.0366e-04,  1.5630e-02,  4.2183e-05,  1.0893e-02,\n",
       "          -9.3234e-03, -1.4973e-02, -1.1215e-02,  1.6873e-02, -3.8033e-03,\n",
       "          -1.6254e-02, -1.4711e-02,  2.3034e-03, -1.4627e-02, -1.5004e-02,\n",
       "           1.2757e-02, -1.5932e-02,  1.1130e-03, -1.0276e-02,  2.4894e-03,\n",
       "           1.3197e-02,  1.6783e-02,  1.0240e-02, -1.6119e-02,  1.3581e-02,\n",
       "          -9.6584e-03, -4.6442e-03, -4.8705e-03, -1.5271e-03,  5.8325e-04,\n",
       "           8.1040e-03, -1.0500e-02,  1.5195e-02, -1.2867e-02, -1.4418e-02,\n",
       "          -1.6708e-02,  6.7357e-03, -4.8651e-03,  1.6341e-02,  5.1737e-03,\n",
       "          -2.0813e-03,  1.7576e-02, -1.0617e-02,  1.1732e-02,  1.3789e-02,\n",
       "          -4.0230e-03,  8.5602e-03,  3.1623e-03,  1.7073e-02,  1.1094e-02,\n",
       "           1.9571e-03,  7.2724e-05,  1.3429e-02, -8.1194e-03, -1.1108e-03,\n",
       "           8.6217e-03, -1.5172e-02, -1.0204e-02, -9.9629e-03,  1.4234e-02,\n",
       "           1.4241e-02, -1.2204e-04,  1.7260e-03], requires_grad=True)),\n",
       " ('fc2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0075, -0.0585, -0.0666,  ..., -0.0420,  0.0299,  0.0555],\n",
       "          [ 0.0647, -0.0121,  0.0151,  ...,  0.0565,  0.0526, -0.0366],\n",
       "          [-0.0188,  0.0685, -0.0760,  ...,  0.0345, -0.0644, -0.0439],\n",
       "          ...,\n",
       "          [ 0.0412, -0.0778,  0.0333,  ...,  0.0280, -0.0385, -0.0036],\n",
       "          [ 0.0108, -0.0279,  0.0540,  ..., -0.0568,  0.0759,  0.0389],\n",
       "          [-0.0514, -0.0267, -0.0461,  ...,  0.0467,  0.0304,  0.0394]],\n",
       "         requires_grad=True)),\n",
       " ('fc2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0607, -0.0017, -0.0633, -0.0795,  0.0480, -0.0032, -0.0090, -0.0304,\n",
       "          -0.0575, -0.0779], requires_grad=True))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посомтрим на струкутру получившейся сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VarBayesNet(\n",
      "  (base_module): Classifier(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "    (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (module_dict): ModuleDict(\n",
      "    (conv1): LogUniformVarLayer(\n",
      "      (posterior_params): ParameterList(\n",
      "          (0): Object of type: ParameterDict\n",
      "          (1): Object of type: ParameterDict\n",
      "        (0): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "        )\n",
      "        (1): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        )\n",
      "      )\n",
      "      (prior_params): ParameterList()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(bayes_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У выбранной сети отсутвует prior на параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': None, 'bias': None, 'conv1.weight': None, 'conv1.bias': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_model.prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посомотрим как выглядит шаг обучения для сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(bayes_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом он ничем не отличается от обычного шага, нам только нужно парвильно агрегировать лоссы от нескольких семплов на одном шаге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get one sample\n",
    "#========\n",
    "image, label = test_dataset[10]\n",
    "y = bayes_model(torch.ones_like(image))\n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "#========\n",
    "\n",
    "#list of fit_loss for each sample (we have one sample)\n",
    "fit_loss = [y.sum()]\n",
    " #list of dist_loss for each sample (we have one sample)\n",
    "dist_loss = [kl_loss(posterior = bayes_model.posterior, prior = bayes_model.prior, param_sample_dict = bayes_model.weights)]\n",
    "beta = 0.1 # scale factor betwenn dist_loss and data_loss\n",
    "#aggregation result is stored in total_loss attribute, all others are provided for statistic of traininghow important each part is\n",
    "aggregation_result = kl_loss.aggregate(fit_loss, dist_loss, beta) \n",
    "out = aggregation_result.total_loss # calculated loss for one step\n",
    "#optimizer step\n",
    "optimizer.zero_grad() \n",
    "out.backward() \n",
    "optimizer.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создать распределение сетей можно просто из распределения на параметры и базовой сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_distributon = VarBayesModuleNetDistribution(bayes_model.base_module, bayes_model.posterior)\n",
    "#Это прунер, которые зануляет веса в зависимости от плотности распределения при 0\n",
    "net_distributon_pruner = BaseNetDistributionPruner(net_distributon)\n",
    "#Здесь мы устанавливаем средние веса модели  \n",
    "net_distributon.set_map_params()\n",
    "#Пруним на основе определенного порога\n",
    "net_distributon_pruner.prune(1.9)\n",
    "#get basic model for evaluation\n",
    "eval_model = net_distributon.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили модель с той же архитектурой что и изначальная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.0902,  0.1707, -0.0707],\n",
      "          [ 0.0186, -0.3256, -0.0603],\n",
      "          [-0.2999,  0.2481, -0.1511]]],\n",
      "\n",
      "\n",
      "        [[[-0.1627, -0.0081, -0.0716],\n",
      "          [ 0.1351, -0.1272,  0.2407],\n",
      "          [ 0.1409, -0.1332,  0.2248]]],\n",
      "\n",
      "\n",
      "        [[[-0.3269,  0.2538,  0.2718],\n",
      "          [-0.0718, -0.1498, -0.1461],\n",
      "          [ 0.3001, -0.2323,  0.2633]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1695,  0.1394,  0.2616],\n",
      "          [ 0.0581,  0.2032, -0.2948],\n",
      "          [-0.3307, -0.2388, -0.0835]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0225,  0.1862, -0.0485],\n",
      "          [-0.1546,  0.2089,  0.0221],\n",
      "          [-0.0804, -0.2801, -0.2247]]],\n",
      "\n",
      "\n",
      "        [[[-0.1759,  0.1806,  0.1717],\n",
      "          [ 0.1532, -0.2478,  0.0651],\n",
      "          [ 0.1325,  0.2898,  0.2971]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0267, -0.0907,  0.1670],\n",
      "          [ 0.1165, -0.0227, -0.1577],\n",
      "          [-0.2488,  0.0038,  0.1973]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1994, -0.1658, -0.2528],\n",
      "          [-0.1690, -0.2176,  0.0138],\n",
      "          [ 0.0286,  0.0010,  0.1582]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3015,  0.1455,  0.0064],\n",
      "          [-0.0795,  0.2488, -0.3215],\n",
      "          [ 0.0178, -0.3046,  0.1793]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2774,  0.2488,  0.2748],\n",
      "          [ 0.0585, -0.2761, -0.1039],\n",
      "          [-0.0599, -0.2182,  0.1970]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0116,  0.0409,  0.0177],\n",
      "          [-0.1829,  0.2532,  0.0030],\n",
      "          [-0.1595,  0.2344, -0.0097]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2374,  0.1794,  0.0143],\n",
      "          [ 0.1528,  0.3098, -0.2139],\n",
      "          [ 0.3260,  0.0513,  0.2792]]],\n",
      "\n",
      "\n",
      "        [[[-0.0641,  0.3212,  0.2454],\n",
      "          [-0.0656, -0.0802, -0.2274],\n",
      "          [ 0.3110,  0.2672, -0.0817]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2124,  0.0369,  0.2223],\n",
      "          [ 0.1696, -0.1237, -0.2418],\n",
      "          [ 0.3161,  0.1410, -0.3166]]],\n",
      "\n",
      "\n",
      "        [[[-0.2634,  0.2456,  0.2088],\n",
      "          [-0.0158,  0.2704,  0.3139],\n",
      "          [ 0.3141, -0.0517, -0.3225]]],\n",
      "\n",
      "\n",
      "        [[[-0.3304, -0.2783, -0.2787],\n",
      "          [-0.1227,  0.0809,  0.3237],\n",
      "          [-0.0605, -0.1067,  0.1962]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2973, -0.1468, -0.1268],\n",
      "          [-0.0449, -0.0407, -0.3123],\n",
      "          [ 0.2837, -0.0564,  0.1136]]],\n",
      "\n",
      "\n",
      "        [[[-0.0217, -0.3268, -0.3176],\n",
      "          [-0.1761,  0.1000,  0.2070],\n",
      "          [-0.2233,  0.1781, -0.3013]]],\n",
      "\n",
      "\n",
      "        [[[-0.0268, -0.0033,  0.0110],\n",
      "          [ 0.1243, -0.0936,  0.1041],\n",
      "          [ 0.3267,  0.2728, -0.2970]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0163, -0.0192, -0.1575],\n",
      "          [-0.2174,  0.1650, -0.1404],\n",
      "          [ 0.2084, -0.1308, -0.2548]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3097, -0.1694,  0.1883],\n",
      "          [-0.0787,  0.0335, -0.0229],\n",
      "          [ 0.2924, -0.0130,  0.2793]]],\n",
      "\n",
      "\n",
      "        [[[-0.2214, -0.2193,  0.1996],\n",
      "          [ 0.0162,  0.0089,  0.2774],\n",
      "          [ 0.3017,  0.1525,  0.0389]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0976,  0.0235, -0.2312],\n",
      "          [-0.1753,  0.1986,  0.2132],\n",
      "          [-0.1515, -0.1634,  0.1403]]],\n",
      "\n",
      "\n",
      "        [[[-0.1570, -0.0328,  0.1061],\n",
      "          [ 0.0378,  0.1898,  0.1617],\n",
      "          [ 0.3153, -0.2829,  0.2136]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0560, -0.2792,  0.1556],\n",
      "          [-0.3320,  0.2784, -0.1367],\n",
      "          [ 0.1084,  0.3044,  0.1281]]],\n",
      "\n",
      "\n",
      "        [[[-0.0857, -0.2924, -0.3067],\n",
      "          [ 0.2327, -0.1643, -0.0076],\n",
      "          [-0.2484, -0.1163,  0.0038]]],\n",
      "\n",
      "\n",
      "        [[[-0.0230,  0.2327, -0.2663],\n",
      "          [-0.2986,  0.2664, -0.2728],\n",
      "          [-0.3149,  0.1756, -0.3000]]],\n",
      "\n",
      "\n",
      "        [[[-0.1320, -0.1658, -0.1768],\n",
      "          [ 0.2732, -0.2582,  0.2182],\n",
      "          [-0.3070,  0.2157, -0.1935]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0631, -0.2058,  0.1797],\n",
      "          [-0.1476, -0.1781,  0.1817],\n",
      "          [ 0.3005,  0.0422,  0.2408]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2359,  0.1593,  0.3188],\n",
      "          [-0.0949,  0.0461, -0.2104],\n",
      "          [-0.2482,  0.2830,  0.3078]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2564, -0.1279, -0.2179],\n",
      "          [-0.2949,  0.2417,  0.1565],\n",
      "          [-0.0220,  0.1242, -0.1150]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0899,  0.0358,  0.1637],\n",
      "          [ 0.2377, -0.2478,  0.0585],\n",
      "          [ 0.0986,  0.0814, -0.2673]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(eval_model.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('base_module.conv1.weight',\n",
       "              tensor([[[[-0.0902,  0.1707, -0.0707],\n",
       "                        [ 0.0186, -0.3256, -0.0603],\n",
       "                        [-0.2999,  0.2481, -0.1511]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1627, -0.0081, -0.0716],\n",
       "                        [ 0.1351, -0.1272,  0.2407],\n",
       "                        [ 0.1409, -0.1332,  0.2248]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3269,  0.2538,  0.2718],\n",
       "                        [-0.0718, -0.1498, -0.1461],\n",
       "                        [ 0.3001, -0.2323,  0.2633]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1695,  0.1394,  0.2616],\n",
       "                        [ 0.0581,  0.2032, -0.2948],\n",
       "                        [-0.3307, -0.2388, -0.0835]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0225,  0.1862, -0.0485],\n",
       "                        [-0.1546,  0.2089,  0.0221],\n",
       "                        [-0.0804, -0.2801, -0.2247]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1759,  0.1806,  0.1717],\n",
       "                        [ 0.1532, -0.2478,  0.0651],\n",
       "                        [ 0.1325,  0.2898,  0.2971]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0267, -0.0907,  0.1670],\n",
       "                        [ 0.1165, -0.0227, -0.1577],\n",
       "                        [-0.2488,  0.0038,  0.1973]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1994, -0.1658, -0.2528],\n",
       "                        [-0.1690, -0.2176,  0.0138],\n",
       "                        [ 0.0286,  0.0010,  0.1582]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3015,  0.1455,  0.0064],\n",
       "                        [-0.0795,  0.2488, -0.3215],\n",
       "                        [ 0.0178, -0.3046,  0.1793]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2774,  0.2488,  0.2748],\n",
       "                        [ 0.0585, -0.2761, -0.1039],\n",
       "                        [-0.0599, -0.2182,  0.1970]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0116,  0.0409,  0.0177],\n",
       "                        [-0.1829,  0.2532,  0.0030],\n",
       "                        [-0.1595,  0.2344, -0.0097]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2374,  0.1794,  0.0143],\n",
       "                        [ 0.1528,  0.3098, -0.2139],\n",
       "                        [ 0.3260,  0.0513,  0.2792]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0641,  0.3212,  0.2454],\n",
       "                        [-0.0656, -0.0802, -0.2274],\n",
       "                        [ 0.3110,  0.2672, -0.0817]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2124,  0.0369,  0.2223],\n",
       "                        [ 0.1696, -0.1237, -0.2418],\n",
       "                        [ 0.3161,  0.1410, -0.3166]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2634,  0.2456,  0.2088],\n",
       "                        [-0.0158,  0.2704,  0.3139],\n",
       "                        [ 0.3141, -0.0517, -0.3225]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3304, -0.2783, -0.2787],\n",
       "                        [-0.1227,  0.0809,  0.3237],\n",
       "                        [-0.0605, -0.1067,  0.1962]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2973, -0.1468, -0.1268],\n",
       "                        [-0.0449, -0.0407, -0.3123],\n",
       "                        [ 0.2837, -0.0564,  0.1136]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0217, -0.3268, -0.3176],\n",
       "                        [-0.1761,  0.1000,  0.2070],\n",
       "                        [-0.2233,  0.1781, -0.3013]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0268, -0.0033,  0.0110],\n",
       "                        [ 0.1243, -0.0936,  0.1041],\n",
       "                        [ 0.3267,  0.2728, -0.2970]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0163, -0.0192, -0.1575],\n",
       "                        [-0.2174,  0.1650, -0.1404],\n",
       "                        [ 0.2084, -0.1308, -0.2548]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3097, -0.1694,  0.1883],\n",
       "                        [-0.0787,  0.0335, -0.0229],\n",
       "                        [ 0.2924, -0.0130,  0.2793]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2214, -0.2193,  0.1996],\n",
       "                        [ 0.0162,  0.0089,  0.2774],\n",
       "                        [ 0.3017,  0.1525,  0.0389]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0976,  0.0235, -0.2312],\n",
       "                        [-0.1753,  0.1986,  0.2132],\n",
       "                        [-0.1515, -0.1634,  0.1403]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1570, -0.0328,  0.1061],\n",
       "                        [ 0.0378,  0.1898,  0.1617],\n",
       "                        [ 0.3153, -0.2829,  0.2136]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0560, -0.2792,  0.1556],\n",
       "                        [-0.3320,  0.2784, -0.1367],\n",
       "                        [ 0.1084,  0.3044,  0.1281]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0857, -0.2924, -0.3067],\n",
       "                        [ 0.2327, -0.1643, -0.0076],\n",
       "                        [-0.2484, -0.1163,  0.0038]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0230,  0.2327, -0.2663],\n",
       "                        [-0.2986,  0.2664, -0.2728],\n",
       "                        [-0.3149,  0.1756, -0.3000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1320, -0.1658, -0.1768],\n",
       "                        [ 0.2732, -0.2582,  0.2182],\n",
       "                        [-0.3070,  0.2157, -0.1935]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0631, -0.2058,  0.1797],\n",
       "                        [-0.1476, -0.1781,  0.1817],\n",
       "                        [ 0.3005,  0.0422,  0.2408]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2359,  0.1593,  0.3188],\n",
       "                        [-0.0949,  0.0461, -0.2104],\n",
       "                        [-0.2482,  0.2830,  0.3078]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2564, -0.1279, -0.2179],\n",
       "                        [-0.2949,  0.2417,  0.1565],\n",
       "                        [-0.0220,  0.1242, -0.1150]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0899,  0.0358,  0.1637],\n",
       "                        [ 0.2377, -0.2478,  0.0585],\n",
       "                        [ 0.0986,  0.0814, -0.2673]]]])),\n",
       "             ('base_module.conv1.bias',\n",
       "              tensor([ 0.0144, -0.2056, -0.0386,  0.3120,  0.1717, -0.1268, -0.1720, -0.1447,\n",
       "                      -0.2601,  0.2955, -0.0384, -0.1463,  0.1860,  0.2521,  0.3220,  0.1074,\n",
       "                      -0.1214, -0.3035,  0.1633, -0.0217, -0.0500, -0.2178,  0.0399, -0.0744,\n",
       "                      -0.2905,  0.0998, -0.2442, -0.2428, -0.2584, -0.1778, -0.0021, -0.2278])),\n",
       "             ('base_module.conv2.weight',\n",
       "              tensor([[[[ 0.0338, -0.0531, -0.0215],\n",
       "                        [-0.0054,  0.0206,  0.0009],\n",
       "                        [ 0.0045, -0.0585, -0.0521]],\n",
       "              \n",
       "                       [[-0.0169,  0.0030, -0.0470],\n",
       "                        [-0.0568,  0.0394,  0.0189],\n",
       "                        [ 0.0262,  0.0504,  0.0197]],\n",
       "              \n",
       "                       [[ 0.0495,  0.0063,  0.0390],\n",
       "                        [-0.0168, -0.0088, -0.0217],\n",
       "                        [ 0.0302,  0.0274,  0.0372]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0552, -0.0112, -0.0385],\n",
       "                        [ 0.0061,  0.0377,  0.0431],\n",
       "                        [-0.0314,  0.0473,  0.0463]],\n",
       "              \n",
       "                       [[-0.0308, -0.0147,  0.0114],\n",
       "                        [-0.0349,  0.0270, -0.0292],\n",
       "                        [-0.0487,  0.0132,  0.0484]],\n",
       "              \n",
       "                       [[-0.0411,  0.0080, -0.0532],\n",
       "                        [ 0.0402,  0.0200,  0.0176],\n",
       "                        [ 0.0516,  0.0204,  0.0183]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0570, -0.0440,  0.0076],\n",
       "                        [ 0.0188,  0.0268, -0.0325],\n",
       "                        [ 0.0214,  0.0199,  0.0042]],\n",
       "              \n",
       "                       [[-0.0003, -0.0523,  0.0352],\n",
       "                        [ 0.0194, -0.0144,  0.0116],\n",
       "                        [-0.0533,  0.0006, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0510,  0.0259, -0.0216],\n",
       "                        [-0.0068, -0.0563, -0.0153],\n",
       "                        [ 0.0567,  0.0081,  0.0085]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0032,  0.0205,  0.0550],\n",
       "                        [-0.0229,  0.0095,  0.0521],\n",
       "                        [ 0.0103, -0.0107,  0.0417]],\n",
       "              \n",
       "                       [[-0.0428, -0.0213,  0.0298],\n",
       "                        [ 0.0039,  0.0576,  0.0466],\n",
       "                        [-0.0559, -0.0161,  0.0363]],\n",
       "              \n",
       "                       [[ 0.0397, -0.0255,  0.0215],\n",
       "                        [ 0.0380,  0.0173,  0.0262],\n",
       "                        [ 0.0149, -0.0518,  0.0161]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0133, -0.0003, -0.0418],\n",
       "                        [ 0.0253,  0.0339, -0.0460],\n",
       "                        [-0.0478,  0.0082,  0.0149]],\n",
       "              \n",
       "                       [[-0.0441, -0.0176,  0.0125],\n",
       "                        [-0.0037,  0.0558, -0.0554],\n",
       "                        [-0.0560,  0.0034, -0.0498]],\n",
       "              \n",
       "                       [[-0.0375,  0.0186, -0.0180],\n",
       "                        [ 0.0069, -0.0546, -0.0312],\n",
       "                        [ 0.0393,  0.0481,  0.0474]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0081,  0.0380, -0.0554],\n",
       "                        [-0.0172,  0.0419,  0.0415],\n",
       "                        [-0.0081, -0.0372, -0.0231]],\n",
       "              \n",
       "                       [[-0.0095, -0.0365, -0.0064],\n",
       "                        [ 0.0314, -0.0175,  0.0033],\n",
       "                        [-0.0521, -0.0372, -0.0450]],\n",
       "              \n",
       "                       [[ 0.0522,  0.0532, -0.0488],\n",
       "                        [-0.0002, -0.0215, -0.0155],\n",
       "                        [ 0.0569,  0.0030,  0.0485]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0134, -0.0188,  0.0284],\n",
       "                        [ 0.0046, -0.0081, -0.0107],\n",
       "                        [ 0.0406, -0.0422,  0.0444]],\n",
       "              \n",
       "                       [[ 0.0568,  0.0212, -0.0380],\n",
       "                        [ 0.0237, -0.0342, -0.0473],\n",
       "                        [-0.0145,  0.0082, -0.0412]],\n",
       "              \n",
       "                       [[ 0.0183,  0.0264, -0.0072],\n",
       "                        [-0.0268,  0.0175, -0.0327],\n",
       "                        [ 0.0257,  0.0139,  0.0155]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0436, -0.0230, -0.0233],\n",
       "                        [ 0.0474,  0.0514, -0.0512],\n",
       "                        [ 0.0166, -0.0246, -0.0372]],\n",
       "              \n",
       "                       [[ 0.0578, -0.0281,  0.0051],\n",
       "                        [-0.0127,  0.0037,  0.0235],\n",
       "                        [-0.0468,  0.0537, -0.0587]],\n",
       "              \n",
       "                       [[ 0.0230,  0.0529, -0.0118],\n",
       "                        [ 0.0223,  0.0153,  0.0437],\n",
       "                        [-0.0196, -0.0161,  0.0519]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0458, -0.0566,  0.0557],\n",
       "                        [ 0.0020,  0.0137, -0.0173],\n",
       "                        [-0.0558,  0.0311,  0.0296]],\n",
       "              \n",
       "                       [[ 0.0160, -0.0066,  0.0085],\n",
       "                        [ 0.0026, -0.0236, -0.0497],\n",
       "                        [ 0.0062, -0.0364,  0.0038]],\n",
       "              \n",
       "                       [[-0.0396,  0.0433, -0.0074],\n",
       "                        [-0.0564,  0.0444, -0.0044],\n",
       "                        [ 0.0065,  0.0527,  0.0287]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0510, -0.0020,  0.0176],\n",
       "                        [-0.0392, -0.0179, -0.0033],\n",
       "                        [ 0.0266,  0.0365, -0.0134]],\n",
       "              \n",
       "                       [[-0.0553,  0.0184, -0.0116],\n",
       "                        [-0.0470, -0.0193,  0.0246],\n",
       "                        [-0.0340,  0.0294, -0.0539]],\n",
       "              \n",
       "                       [[ 0.0546, -0.0516, -0.0304],\n",
       "                        [ 0.0162, -0.0349,  0.0562],\n",
       "                        [ 0.0211,  0.0020,  0.0227]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0223,  0.0417, -0.0503],\n",
       "                        [-0.0055,  0.0575, -0.0427],\n",
       "                        [-0.0006,  0.0212,  0.0182]],\n",
       "              \n",
       "                       [[ 0.0076, -0.0163,  0.0544],\n",
       "                        [-0.0260,  0.0266, -0.0292],\n",
       "                        [-0.0093,  0.0212,  0.0125]],\n",
       "              \n",
       "                       [[ 0.0125,  0.0520,  0.0325],\n",
       "                        [-0.0145,  0.0218, -0.0058],\n",
       "                        [ 0.0490, -0.0291,  0.0128]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0086, -0.0579, -0.0304],\n",
       "                        [-0.0439, -0.0432,  0.0277],\n",
       "                        [-0.0261, -0.0323,  0.0113]],\n",
       "              \n",
       "                       [[-0.0525,  0.0264,  0.0188],\n",
       "                        [-0.0003, -0.0222, -0.0241],\n",
       "                        [-0.0435, -0.0322, -0.0282]],\n",
       "              \n",
       "                       [[ 0.0108, -0.0588,  0.0095],\n",
       "                        [-0.0057, -0.0442,  0.0375],\n",
       "                        [ 0.0332,  0.0218, -0.0008]]]])),\n",
       "             ('base_module.conv2.bias',\n",
       "              tensor([ 0.0140, -0.0332,  0.0244,  0.0398, -0.0563, -0.0216, -0.0360,  0.0292,\n",
       "                       0.0375,  0.0015, -0.0494,  0.0294, -0.0297, -0.0339, -0.0260,  0.0249,\n",
       "                       0.0027, -0.0492,  0.0144,  0.0050,  0.0504, -0.0259, -0.0448, -0.0466,\n",
       "                      -0.0335,  0.0403, -0.0233,  0.0024, -0.0313, -0.0552,  0.0215, -0.0420,\n",
       "                      -0.0003,  0.0375, -0.0340, -0.0476, -0.0408,  0.0110, -0.0556, -0.0242,\n",
       "                       0.0226,  0.0586, -0.0196, -0.0074, -0.0200,  0.0519, -0.0217, -0.0529,\n",
       "                       0.0549,  0.0307,  0.0252, -0.0038, -0.0170, -0.0506, -0.0389, -0.0286,\n",
       "                      -0.0319, -0.0168, -0.0065,  0.0271, -0.0495, -0.0054,  0.0527, -0.0044])),\n",
       "             ('base_module.fc1.weight',\n",
       "              tensor([[ 0.0010, -0.0094, -0.0103,  ...,  0.0160,  0.0152,  0.0039],\n",
       "                      [ 0.0148,  0.0146, -0.0074,  ..., -0.0148,  0.0065,  0.0178],\n",
       "                      [-0.0049,  0.0034, -0.0060,  ..., -0.0041, -0.0152, -0.0146],\n",
       "                      ...,\n",
       "                      [-0.0001, -0.0152, -0.0120,  ..., -0.0041,  0.0083, -0.0169],\n",
       "                      [-0.0149,  0.0062, -0.0015,  ...,  0.0053,  0.0063, -0.0146],\n",
       "                      [-0.0111,  0.0094,  0.0083,  ..., -0.0134, -0.0086,  0.0170]])),\n",
       "             ('base_module.fc1.bias',\n",
       "              tensor([ 0.0041, -0.0143, -0.0064,  0.0052, -0.0010, -0.0142, -0.0081,  0.0175,\n",
       "                      -0.0164,  0.0073, -0.0142,  0.0079,  0.0038,  0.0008, -0.0153, -0.0010,\n",
       "                       0.0187, -0.0136, -0.0053, -0.0050,  0.0097, -0.0118, -0.0077, -0.0122,\n",
       "                       0.0103,  0.0064, -0.0029, -0.0111, -0.0020, -0.0153,  0.0118, -0.0057,\n",
       "                      -0.0164, -0.0161, -0.0080, -0.0085,  0.0139,  0.0041, -0.0006,  0.0025,\n",
       "                       0.0009, -0.0017,  0.0028, -0.0008, -0.0013,  0.0010, -0.0071,  0.0167,\n",
       "                       0.0134,  0.0138,  0.0143, -0.0128, -0.0088, -0.0175, -0.0065,  0.0099,\n",
       "                       0.0111,  0.0011, -0.0069, -0.0157, -0.0047,  0.0177,  0.0097,  0.0050,\n",
       "                      -0.0014,  0.0146, -0.0111, -0.0176, -0.0171,  0.0131,  0.0135, -0.0100,\n",
       "                       0.0121,  0.0021,  0.0007, -0.0146, -0.0082,  0.0072, -0.0106, -0.0093,\n",
       "                      -0.0146,  0.0055, -0.0137, -0.0024,  0.0006,  0.0030, -0.0057,  0.0147,\n",
       "                       0.0015,  0.0078, -0.0174, -0.0062, -0.0017,  0.0110,  0.0111,  0.0119,\n",
       "                      -0.0155, -0.0074, -0.0024, -0.0106, -0.0099, -0.0029, -0.0111,  0.0061,\n",
       "                      -0.0005,  0.0050,  0.0127, -0.0147,  0.0180,  0.0099,  0.0048, -0.0131,\n",
       "                       0.0114, -0.0041, -0.0009,  0.0169, -0.0090,  0.0152,  0.0077, -0.0060,\n",
       "                      -0.0148,  0.0072,  0.0077,  0.0059, -0.0068, -0.0043, -0.0162,  0.0067])),\n",
       "             ('base_module.fc2.weight',\n",
       "              tensor([[-0.0579,  0.0128, -0.0767,  ..., -0.0552, -0.0552,  0.0607],\n",
       "                      [-0.0513, -0.0189, -0.0134,  ...,  0.0837,  0.0868, -0.0115],\n",
       "                      [-0.0137, -0.0807, -0.0175,  ..., -0.0492,  0.0404,  0.0120],\n",
       "                      ...,\n",
       "                      [ 0.0327,  0.0068, -0.0172,  ..., -0.0321,  0.0589, -0.0607],\n",
       "                      [-0.0756, -0.0359,  0.0148,  ...,  0.0314, -0.0158,  0.0503],\n",
       "                      [ 0.0108, -0.0657,  0.0834,  ...,  0.0865,  0.0877,  0.0855]])),\n",
       "             ('base_module.fc2.bias',\n",
       "              tensor([-0.0799,  0.0771, -0.0741, -0.0598,  0.0281,  0.0582, -0.0384,  0.0243,\n",
       "                       0.0273,  0.0480])),\n",
       "             ('module_dict.conv1.posterior_params.0.param_mus',\n",
       "              tensor([[[[-0.0902,  0.1707, -0.0707],\n",
       "                        [ 0.0186, -0.3256, -0.0603],\n",
       "                        [-0.2999,  0.2481, -0.1511]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1627, -0.0081, -0.0716],\n",
       "                        [ 0.1351, -0.1272,  0.2407],\n",
       "                        [ 0.1409, -0.1332,  0.2248]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3269,  0.2538,  0.2718],\n",
       "                        [-0.0718, -0.1498, -0.1461],\n",
       "                        [ 0.3001, -0.2323,  0.2633]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1695,  0.1394,  0.2616],\n",
       "                        [ 0.0581,  0.2032, -0.2948],\n",
       "                        [-0.3307, -0.2388, -0.0835]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0225,  0.1862, -0.0485],\n",
       "                        [-0.1546,  0.2089,  0.0221],\n",
       "                        [-0.0804, -0.2801, -0.2247]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1759,  0.1806,  0.1717],\n",
       "                        [ 0.1532, -0.2478,  0.0651],\n",
       "                        [ 0.1325,  0.2898,  0.2971]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0267, -0.0907,  0.1670],\n",
       "                        [ 0.1165, -0.0227, -0.1577],\n",
       "                        [-0.2488,  0.0038,  0.1973]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1994, -0.1658, -0.2528],\n",
       "                        [-0.1690, -0.2176,  0.0138],\n",
       "                        [ 0.0286,  0.0010,  0.1582]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3015,  0.1455,  0.0064],\n",
       "                        [-0.0795,  0.2488, -0.3215],\n",
       "                        [ 0.0178, -0.3046,  0.1793]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2774,  0.2488,  0.2748],\n",
       "                        [ 0.0585, -0.2761, -0.1039],\n",
       "                        [-0.0599, -0.2182,  0.1970]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0116,  0.0409,  0.0177],\n",
       "                        [-0.1829,  0.2532,  0.0030],\n",
       "                        [-0.1595,  0.2344, -0.0097]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2374,  0.1794,  0.0143],\n",
       "                        [ 0.1528,  0.3098, -0.2139],\n",
       "                        [ 0.3260,  0.0513,  0.2792]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0641,  0.3212,  0.2454],\n",
       "                        [-0.0656, -0.0802, -0.2274],\n",
       "                        [ 0.3110,  0.2672, -0.0817]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2124,  0.0369,  0.2223],\n",
       "                        [ 0.1696, -0.1237, -0.2418],\n",
       "                        [ 0.3161,  0.1410, -0.3166]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2634,  0.2456,  0.2088],\n",
       "                        [-0.0158,  0.2704,  0.3139],\n",
       "                        [ 0.3141, -0.0517, -0.3225]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3304, -0.2783, -0.2787],\n",
       "                        [-0.1227,  0.0809,  0.3237],\n",
       "                        [-0.0605, -0.1067,  0.1962]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2973, -0.1468, -0.1268],\n",
       "                        [-0.0449, -0.0407, -0.3123],\n",
       "                        [ 0.2837, -0.0564,  0.1136]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0217, -0.3268, -0.3176],\n",
       "                        [-0.1761,  0.1000,  0.2070],\n",
       "                        [-0.2233,  0.1781, -0.3013]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0268, -0.0033,  0.0110],\n",
       "                        [ 0.1243, -0.0936,  0.1041],\n",
       "                        [ 0.3267,  0.2728, -0.2970]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0163, -0.0192, -0.1575],\n",
       "                        [-0.2174,  0.1650, -0.1404],\n",
       "                        [ 0.2084, -0.1308, -0.2548]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3097, -0.1694,  0.1883],\n",
       "                        [-0.0787,  0.0335, -0.0229],\n",
       "                        [ 0.2924, -0.0130,  0.2793]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2214, -0.2193,  0.1996],\n",
       "                        [ 0.0162,  0.0089,  0.2774],\n",
       "                        [ 0.3017,  0.1525,  0.0389]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0976,  0.0235, -0.2312],\n",
       "                        [-0.1753,  0.1986,  0.2132],\n",
       "                        [-0.1515, -0.1634,  0.1403]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1570, -0.0328,  0.1061],\n",
       "                        [ 0.0378,  0.1898,  0.1617],\n",
       "                        [ 0.3153, -0.2829,  0.2136]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0560, -0.2792,  0.1556],\n",
       "                        [-0.3320,  0.2784, -0.1367],\n",
       "                        [ 0.1084,  0.3044,  0.1281]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0857, -0.2924, -0.3067],\n",
       "                        [ 0.2327, -0.1643, -0.0076],\n",
       "                        [-0.2484, -0.1163,  0.0038]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0230,  0.2327, -0.2663],\n",
       "                        [-0.2986,  0.2664, -0.2728],\n",
       "                        [-0.3149,  0.1756, -0.3000]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1320, -0.1658, -0.1768],\n",
       "                        [ 0.2732, -0.2582,  0.2182],\n",
       "                        [-0.3070,  0.2157, -0.1935]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0631, -0.2058,  0.1797],\n",
       "                        [-0.1476, -0.1781,  0.1817],\n",
       "                        [ 0.3005,  0.0422,  0.2408]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2359,  0.1593,  0.3188],\n",
       "                        [-0.0949,  0.0461, -0.2104],\n",
       "                        [-0.2482,  0.2830,  0.3078]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2564, -0.1279, -0.2179],\n",
       "                        [-0.2949,  0.2417,  0.1565],\n",
       "                        [-0.0220,  0.1242, -0.1150]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0899,  0.0358,  0.1637],\n",
       "                        [ 0.2377, -0.2478,  0.0585],\n",
       "                        [ 0.0986,  0.0814, -0.2673]]]])),\n",
       "             ('module_dict.conv1.posterior_params.0.param_std_log',\n",
       "              tensor([[[[ -4.6899,  -5.2810,  -5.0001],\n",
       "                        [ -6.9465,  -4.6146,  -4.9793],\n",
       "                        [ -5.0963,  -6.3348,  -5.1632]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.1637,  -4.6935,  -4.8209],\n",
       "                        [ -5.4513,  -4.6682,  -6.2368],\n",
       "                        [ -4.6405,  -7.0685,  -4.7018]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -7.1095,  -5.4956,  -4.6165],\n",
       "                        [ -6.4453,  -4.6512,  -4.7730],\n",
       "                        [ -6.6137,  -4.9678,  -4.7054]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3524,  -4.7607,  -4.6989],\n",
       "                        [ -7.3471,  -5.2181,  -6.4655],\n",
       "                        [ -4.7278,  -6.4766,  -5.0308]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3280,  -5.2611,  -5.5262],\n",
       "                        [ -4.6598,  -4.9877,  -4.8012],\n",
       "                        [ -4.8775,  -4.8825,  -4.6316]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.9598,  -6.4697,  -5.2207],\n",
       "                        [ -5.8799,  -5.2543,  -5.3392],\n",
       "                        [ -5.1117,  -4.9091,  -5.2920]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.2533,  -4.8626,  -5.9937],\n",
       "                        [ -6.7031,  -5.4685,  -5.9248],\n",
       "                        [ -4.8728,  -5.1575,  -7.8560]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -7.7680,  -6.8911,  -5.0198],\n",
       "                        [ -4.6106,  -6.5931,  -6.3551],\n",
       "                        [ -8.1401,  -4.8638,  -5.2002]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6827,  -5.0015,  -5.4608],\n",
       "                        [ -5.2634,  -5.4183,  -5.2577],\n",
       "                        [ -6.5269,  -5.6842,  -5.7217]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9250,  -6.5136,  -4.9196],\n",
       "                        [ -5.0392,  -4.6480,  -5.6895],\n",
       "                        [ -4.6846,  -4.6069,  -5.4409]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.6796,  -4.7226,  -6.5947],\n",
       "                        [ -5.1971,  -5.0170,  -5.7803],\n",
       "                        [ -5.1581,  -5.0332,  -6.7005]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3331,  -4.6954,  -6.6056],\n",
       "                        [ -5.1272,  -4.8918,  -4.8840],\n",
       "                        [ -5.1111,  -4.7902,  -4.7908]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.0539,  -6.8260,  -7.9841],\n",
       "                        [ -5.4042,  -5.3340,  -4.9366],\n",
       "                        [ -5.0615,  -5.7586,  -7.0267]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9161,  -5.5642,  -4.7446],\n",
       "                        [-10.7360,  -6.6713,  -4.9802],\n",
       "                        [ -4.6576,  -5.0672,  -4.7093]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9128,  -5.7588,  -4.9270],\n",
       "                        [ -5.2674,  -4.6584,  -5.7012],\n",
       "                        [ -4.8279,  -5.3466,  -4.6520]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -7.1389,  -9.8704,  -6.6314],\n",
       "                        [ -4.7990,  -5.0881,  -4.9119],\n",
       "                        [ -8.5480,  -5.0490,  -6.5290]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -7.4612,  -5.7931,  -9.7477],\n",
       "                        [ -4.7003,  -4.8191,  -5.0605],\n",
       "                        [ -5.4640,  -5.4872,  -8.0558]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.3890,  -4.7335,  -5.7712],\n",
       "                        [ -5.5559,  -5.1795,  -6.8049],\n",
       "                        [ -5.3394,  -4.8366,  -5.4689]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.0129,  -6.0855,  -4.6063],\n",
       "                        [ -5.5376,  -4.9226,  -4.6500],\n",
       "                        [ -5.3070,  -5.0777,  -4.9504]]],\n",
       "              \n",
       "              \n",
       "                      [[[-10.7250,  -6.3616,  -4.6888],\n",
       "                        [ -4.9307,  -8.0683,  -5.8653],\n",
       "                        [ -4.9844,  -4.8626,  -4.8838]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9522,  -5.9515,  -5.3213],\n",
       "                        [ -5.0442,  -7.1451,  -5.4207],\n",
       "                        [ -6.1803,  -8.5795,  -4.8203]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.4823,  -5.1130,  -4.9860],\n",
       "                        [ -4.9390,  -5.9671,  -5.7322],\n",
       "                        [ -6.8669,  -6.9743,  -8.1920]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -9.2522,  -4.9191,  -6.3108],\n",
       "                        [ -4.7215,  -5.3593,  -7.7040],\n",
       "                        [ -5.2401,  -5.1809,  -4.7360]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9009,  -9.9256,  -5.9219],\n",
       "                        [ -8.4126,  -5.5671,  -5.8366],\n",
       "                        [ -5.0871,  -4.8961,  -4.7250]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.7073,  -5.9927,  -4.7053],\n",
       "                        [ -5.9070,  -4.6173,  -5.8924],\n",
       "                        [ -4.7665,  -4.6421,  -6.5592]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.0562,  -8.2876,  -5.1841],\n",
       "                        [ -4.8110,  -4.6898,  -4.7025],\n",
       "                        [ -6.4047,  -4.7231,  -4.8660]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7318,  -5.5059,  -4.9320],\n",
       "                        [ -6.0697,  -5.5937,  -4.8953],\n",
       "                        [ -6.1324,  -5.1061,  -5.8462]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.2845,  -5.2879,  -4.7802],\n",
       "                        [ -8.6988,  -5.9212,  -6.7257],\n",
       "                        [ -5.2462,  -6.1787,  -4.6096]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.0995,  -5.2856,  -5.6601],\n",
       "                        [ -4.6070,  -6.1830,  -7.0711],\n",
       "                        [ -4.8581,  -5.1557,  -6.7357]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.5708,  -4.8328,  -6.2026],\n",
       "                        [ -5.7016,  -8.0139,  -5.1290],\n",
       "                        [ -6.3261,  -5.5953,  -6.0517]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.1181,  -6.9070,  -5.8618],\n",
       "                        [ -5.0408,  -4.7528, -12.6240],\n",
       "                        [ -6.0903,  -5.3935,  -5.6319]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9633,  -5.5327,  -4.7444],\n",
       "                        [ -5.5843,  -4.8533,  -4.9012],\n",
       "                        [ -5.2023,  -8.4973,  -4.7477]]]])),\n",
       "             ('module_dict.conv1.posterior_params.0.scale_alphas_log',\n",
       "              tensor([[[[-2.7349, -2.7652, -3.4295],\n",
       "                        [-3.7049, -2.7713, -3.3801],\n",
       "                        [-2.0007, -3.4947, -3.8994]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1634, -2.0000, -2.0487],\n",
       "                        [-3.8895, -2.2158, -2.8131],\n",
       "                        [-3.5768, -3.0740, -3.6513]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6668, -2.0789, -3.4861],\n",
       "                        [-3.1650, -3.8831, -3.8689],\n",
       "                        [-2.7686, -2.0827, -2.5079]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4093, -3.5259, -2.0778],\n",
       "                        [-2.5228, -3.4799, -2.0696],\n",
       "                        [-3.4541, -3.3211, -2.5562]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9377, -3.2577, -3.4069],\n",
       "                        [-3.8317, -2.0971, -3.8216],\n",
       "                        [-2.8859, -3.1940, -2.9863]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1334, -3.1644, -2.2539],\n",
       "                        [-2.2816, -3.6658, -3.2575],\n",
       "                        [-3.0435, -3.1200, -3.6367]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1272, -2.6857, -2.1965],\n",
       "                        [-2.2304, -3.0714, -3.0464],\n",
       "                        [-3.9903, -2.6357, -2.7106]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.7020, -2.3505, -3.7041],\n",
       "                        [-3.0060, -3.6203, -2.9544],\n",
       "                        [-3.1178, -3.6238, -3.1534]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6089, -3.2212, -3.8130],\n",
       "                        [-2.7538, -2.2784, -2.4204],\n",
       "                        [-3.2402, -3.6783, -2.4317]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8513, -2.9318, -3.3987],\n",
       "                        [-3.6520, -2.1805, -2.4130],\n",
       "                        [-2.3640, -2.1934, -2.8728]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7363, -3.7266, -2.1685],\n",
       "                        [-3.9598, -3.3971, -2.1732],\n",
       "                        [-2.8160, -2.9715, -2.9002]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5821, -3.4030, -3.1057],\n",
       "                        [-2.4938, -2.5869, -3.9451],\n",
       "                        [-2.6501, -3.2277, -2.0479]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1219, -3.1778, -2.3445],\n",
       "                        [-3.5371, -2.3266, -2.0763],\n",
       "                        [-3.1371, -2.5248, -3.5097]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.7957, -2.5670, -3.0994],\n",
       "                        [-3.6081, -3.6254, -2.2701],\n",
       "                        [-2.6589, -3.7941, -2.1494]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6183, -3.0234, -2.2612],\n",
       "                        [-2.0074, -3.7899, -3.5605],\n",
       "                        [-3.9083, -2.1154, -3.8738]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5659, -3.0873, -3.1767],\n",
       "                        [-3.5671, -3.9331, -3.2068],\n",
       "                        [-3.8379, -3.2411, -2.0098]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6495, -3.0569, -2.8197],\n",
       "                        [-3.2149, -2.4905, -3.7305],\n",
       "                        [-2.4380, -3.4270, -3.7167]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.7463, -2.7067, -2.6610],\n",
       "                        [-2.5932, -3.2382, -3.5289],\n",
       "                        [-3.4293, -2.8424, -3.4685]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9660, -3.0564, -2.6766],\n",
       "                        [-3.3087, -3.5881, -2.4084],\n",
       "                        [-3.8593, -3.1942, -2.0720]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8524, -2.7610, -2.8230],\n",
       "                        [-2.7969, -2.1821, -2.0686],\n",
       "                        [-3.4404, -2.2421, -2.9068]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9252, -3.7583, -3.4289],\n",
       "                        [-2.7850, -3.1990, -3.9664],\n",
       "                        [-2.2338, -3.6931, -3.4928]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5221, -2.8558, -3.7239],\n",
       "                        [-2.6923, -3.6413, -3.6148],\n",
       "                        [-2.4317, -2.1346, -2.5284]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3558, -2.5533, -3.4362],\n",
       "                        [-2.0086, -2.0241, -2.7675],\n",
       "                        [-3.5483, -3.2575, -3.0896]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9172, -3.2459, -2.2699],\n",
       "                        [-3.5757, -3.6816, -3.0789],\n",
       "                        [-3.0716, -3.5902, -2.6418]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8479, -3.7205, -2.3143],\n",
       "                        [-2.8709, -3.0101, -3.1835],\n",
       "                        [-3.9756, -2.2042, -3.0513]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2753, -3.9340, -3.2523],\n",
       "                        [-3.2080, -2.2314, -3.0223],\n",
       "                        [-3.8774, -2.1897, -3.2154]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6432, -2.4475, -2.6173],\n",
       "                        [-3.4122, -3.5223, -2.4563],\n",
       "                        [-2.6760, -3.0697, -2.1087]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6857, -2.6627, -3.4741],\n",
       "                        [-2.4057, -2.0959, -2.6316],\n",
       "                        [-2.1195, -2.4188, -2.8685]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2648, -3.2495, -3.4408],\n",
       "                        [-2.4135, -3.4915, -2.6054],\n",
       "                        [-3.9329, -3.0376, -3.4394]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3278, -2.7164, -3.5837],\n",
       "                        [-2.6044, -2.5099, -3.2668],\n",
       "                        [-2.8721, -3.0134, -3.7334]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5463, -3.6538, -3.0149],\n",
       "                        [-3.7764, -3.8059, -2.7386],\n",
       "                        [-3.4896, -3.8273, -2.4855]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0211, -2.2693, -2.6946],\n",
       "                        [-2.9909, -2.1360, -3.6804],\n",
       "                        [-2.9995, -2.9871, -3.9279]]]])),\n",
       "             ('module_dict.conv1.posterior_params.0.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_dict.conv1.posterior_params.1.param_mus',\n",
       "              tensor([ 0.0144, -0.2056, -0.0386,  0.3120,  0.1717, -0.1268, -0.1720, -0.1447,\n",
       "                      -0.2601,  0.2955, -0.0384, -0.1463,  0.1860,  0.2521,  0.3220,  0.1074,\n",
       "                      -0.1214, -0.3035,  0.1633, -0.0217, -0.0500, -0.2178,  0.0399, -0.0744,\n",
       "                      -0.2905,  0.0998, -0.2442, -0.2428, -0.2584, -0.1778, -0.0021, -0.2278])),\n",
       "             ('module_dict.conv1.posterior_params.1.param_std_log',\n",
       "              tensor([-4.7729, -5.1733, -6.9399, -5.9008, -5.4086, -5.1476, -5.3602, -4.6774,\n",
       "                      -4.7845, -4.8633, -5.4951, -5.3049, -4.9489, -6.1355, -7.2216, -4.7198,\n",
       "                      -4.7807, -5.5205, -6.8970, -5.5570, -6.6897, -5.2107, -5.7699, -7.1735,\n",
       "                      -5.4124, -5.2284, -7.2902, -4.8427, -4.7442, -5.7411, -6.7521, -7.9879])),\n",
       "             ('module_dict.conv1.posterior_params.1.scale_alphas_log',\n",
       "              tensor([-2.7363, -2.7115, -2.0347, -3.8307, -3.6922, -3.9552, -2.0543, -3.0022,\n",
       "                      -3.4893, -3.8938, -2.4110, -3.2132, -2.6291, -3.3687, -2.8908, -2.7671,\n",
       "                      -3.8566, -2.0465, -3.1056, -3.1378, -3.7154, -3.9766, -3.8674, -3.9792,\n",
       "                      -2.3863, -2.7848, -2.0352, -2.0560, -2.0056, -2.6474, -3.7663, -2.9865])),\n",
       "             ('module_dict.conv1.posterior_params.1.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward делается по последнему сохраненному сэмплу. Заметим, что мы нигде не копируем данные, и модели не инкапсулируется. Поэтому, чтобы отвязать, их неободимо скопировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1036,  0.0260, -0.1381, -0.1764, -0.0195, -0.0053, -0.0959, -0.0431,\n",
      "         -0.0043,  0.0271]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.1036,  0.0260, -0.1381, -0.1764, -0.0195, -0.0053, -0.0959, -0.0431,\n",
      "         -0.0043,  0.0271]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(bayes_model(torch.zeros_like(image)))\n",
    "#print(bayes_model(torch.zeros_like(image), sample = False))\n",
    "print(module(torch.zeros_like(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы импортируем несколько модулей для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.bayes.variational.trainer import VarBayesTrainer, VarTrainerParams, Beta_Scheduler_Plato, CallbackLossAccuracy #Сам тренер, Параметры тренера, Планировщик beta(коэффициент сооьношения между обычным лоссом и байесовским), и callback для метрики точности\n",
    "from src.methods.report.base import ReportChain #Это просто список callback\n",
    "from src.methods.report.variational import VarBaseReport #Этот модуль callback просто выводит каждый шаг данные от тренера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = Beta_Scheduler_Plato()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4e8fd9936a4540bfaac7e52cd6b535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4000],Loss:25.163509368896484, KL Loss: 2312.739013671875. FitLoss: 2.0361196994781494,Accuracy:0.4752749999999999,Validation Loss:24.60753631591797,Validation Accuracy:0.719, Prune parameters: 0.0/320,Beta: 0.01\n",
      "Epoch [2/4000],Loss:24.153614044189453, KL Loss: 2308.729248046875. FitLoss: 1.0663198232650757,Accuracy:0.7587874999999997,Validation Loss:23.739910125732422,Validation Accuracy:0.784, Prune parameters: 0.0/320,Beta: 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#Если зотим сделать бету фиксированной, то нунжо убрать аргумент [post_train_step]\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#trainer = VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader, [post_train_step])\u001b[39;00m\n\u001b[1;32m     60\u001b[0m trainer \u001b[38;5;241m=\u001b[39m VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader)\n\u001b[0;32m---> 61\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(model)\n",
      "File \u001b[0;32m~/BMM/bayes_deep_compression/examples/../src/methods/bayes/variational/trainer.py:164\u001b[0m, in \u001b[0;36mVarBayesTrainer.train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    162\u001b[0m train_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(model, objects, labels)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__post_train_step(train_output)\n\u001b[0;32m--> 164\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(train_output\u001b[38;5;241m.\u001b[39mtotal_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    165\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_output\u001b[38;5;241m.\u001b[39mtotal_loss\n\u001b[1;32m    166\u001b[0m train_dist_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_output\u001b[38;5;241m.\u001b[39mdist_loss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=1000\n",
    "EPOCHS=4000\n",
    "LR = 1e-3 #5e-4\n",
    "# Split the training set into training and validation sets \n",
    "VAL_PERCENT = 0.2 # percentage of the data used for validation \n",
    "SAMPLES = 10\n",
    "BETA = 0.01 #5e-5 #0.01\n",
    "BETA_FAC = 5e-1\n",
    "PRUNE = 1.9#1.99, 2.1, 1.9\n",
    "PLATO_TOL = 20\n",
    "\n",
    "\"\"\"\n",
    "base_module = Classifier()\n",
    "var_module = LogUniformVarBayesModule(base_module)\n",
    "model = VarBayesModuleNet(base_module, nn.ModuleList([var_module]))\n",
    "\"\"\"\n",
    "base_module = Classifier()\n",
    "var_module1 = LogUniformVarLayer(base_module.conv1)\n",
    "#bayes_model = VarBayesModuleNet(module, nn.ModuleList([var_module])) #Первый аргумент базовая сеть, второй список всех слоев (где нужные из них являются байесовыми)\n",
    "model = VarBayesNet(base_module, nn.ModuleDict({'conv1': var_module1}))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "#Первый лосс это обычный лосс на данные, второй лосс это лосс байесковской модели\n",
    "fit_loss = nn.CrossEntropyLoss() \n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "\n",
    "#Используем планировщик коэффицента пропорциональности между fit_loss и kl_loss\n",
    "beta = Beta_Scheduler_Plato(BETA, BETA_FAC, PLATO_TOL)\n",
    "beta_KL = Beta_Scheduler_Plato(beta.beta, 1 / BETA_FAC, PLATO_TOL, ref = beta, threshold=1e-4)\n",
    "\n",
    "#Данная функция будет выполнятся после каждого шага тренера, соответсвенно нам требуется сделать шаг планировщика и изменить соотвествующий коэффициент\n",
    "def post_train_step(trainer: VarTrainerParams, train_result: VarBayesTrainer.TrainResult):\n",
    "    beta.step(train_result.fit_loss)\n",
    "    beta_KL.step(train_result.dist_loss)\n",
    "    trainer.params.beta = float(beta)\n",
    "    \n",
    "#print(model.base_module.state_dict().keys())\n",
    "val_size    = int(VAL_PERCENT * len(train_dataset)) \n",
    "train_size  = len(train_dataset) - val_size \n",
    "\n",
    "t_dataset, v_dataset = torch.utils.data.random_split(train_dataset,  \n",
    "                                                        [train_size,  \n",
    "                                                            val_size]) \n",
    "\n",
    "# Create DataLoaders for the training and validation sets \n",
    "train_loader = torch.utils.data.DataLoader(t_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=True, \n",
    "                                        pin_memory=True) \n",
    "eval_loader = torch.utils.data.DataLoader(v_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=False, \n",
    "                                        pin_memory=True) \n",
    "\n",
    "model.to(device) \n",
    "train_params = VarTrainerParams(EPOCHS, optimizer,fit_loss, kl_loss, SAMPLES, PRUNE, BETA, {'accuracy': CallbackLossAccuracy()})\n",
    "#Если хотим сделать бету фиксированной, то нунжо убрать аргумент [post_train_step]\n",
    "#trainer = VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader, [post_train_step])\n",
    "trainer = VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader)\n",
    "trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('module_list.0.posterior_params.0.param_mus', tensor([[[[ 2.5841e-07, -1.2233e-02,  7.9962e-03],\n",
      "          [ 1.3414e-06,  4.4800e-03,  1.1717e-02],\n",
      "          [ 2.4174e-03,  6.1303e-06, -6.3872e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.4067e-06, -1.3908e-02, -2.3774e-05],\n",
      "          [-2.2695e-06,  1.2359e-03,  9.2660e-03],\n",
      "          [-9.2873e-07, -1.4729e-02,  3.6886e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7811e-02, -1.4421e-02,  1.6615e-02],\n",
      "          [-2.2942e-02, -3.1714e-05, -2.1503e-04],\n",
      "          [-8.1395e-08, -1.0686e-04, -6.5693e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5442e-03,  1.5579e-06, -2.7291e-04],\n",
      "          [-1.1265e-07, -1.4138e-06, -4.5947e-07],\n",
      "          [ 1.7760e-04, -2.5134e-02,  9.3481e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.5268e-03,  3.9635e-04,  3.5783e-06],\n",
      "          [ 1.2107e-06,  3.2627e-03,  8.3468e-03],\n",
      "          [ 7.4476e-06, -2.1339e-02,  2.7009e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5353e-02, -9.2420e-07, -3.7983e-06],\n",
      "          [-2.5550e-06, -2.7675e-05, -1.0869e-04],\n",
      "          [-1.4504e-06,  1.9404e-05, -8.4981e-07]]],\n",
      "\n",
      "\n",
      "        [[[-3.8399e-03, -2.5052e-07, -2.0034e-06],\n",
      "          [-5.5306e-04, -2.5338e-03, -1.2210e-05],\n",
      "          [ 9.5218e-04,  1.9900e-06, -4.4763e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4457e-06,  1.1123e-06, -1.1624e-02],\n",
      "          [ 6.8779e-06,  2.3516e-02, -1.7141e-02],\n",
      "          [ 9.7272e-03, -4.4036e-04,  1.3211e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7049e-06, -3.5580e-03, -6.5792e-03],\n",
      "          [-2.9534e-06,  1.3538e-03,  8.1825e-07],\n",
      "          [-1.4674e-06,  1.1792e-04, -6.9995e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8178e-03, -9.9942e-03,  5.7007e-03],\n",
      "          [-7.4708e-03, -7.0736e-04, -1.4455e-02],\n",
      "          [ 5.1561e-07, -3.7707e-07, -2.0521e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.1705e-06, -1.5740e-02, -3.5101e-03],\n",
      "          [ 3.7418e-06, -1.2803e-06, -8.0729e-04],\n",
      "          [-2.9114e-04,  2.0301e-02, -3.1997e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.9674e-07,  2.2417e-03,  1.1206e-03],\n",
      "          [-2.1884e-03,  2.2577e-06,  1.4350e-06],\n",
      "          [ 7.0208e-04,  1.0231e-06,  9.8961e-05]]],\n",
      "\n",
      "\n",
      "        [[[-8.4516e-05, -2.1553e-06, -2.3925e-06],\n",
      "          [ 6.9866e-03,  1.8799e-07, -2.4777e-02],\n",
      "          [-1.4826e-04,  3.4318e-08, -6.9202e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0188e-02, -2.1013e-02,  8.9118e-07],\n",
      "          [ 2.5531e-06,  2.6224e-03,  7.5206e-07],\n",
      "          [ 2.3221e-06,  3.5996e-06, -4.1197e-05]]],\n",
      "\n",
      "\n",
      "        [[[-5.9595e-03,  2.2925e-02, -1.1386e-05],\n",
      "          [ 3.4927e-07, -1.3098e-02, -3.2014e-05],\n",
      "          [-8.6633e-07, -3.9421e-04, -4.2186e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7765e-06,  5.4831e-07, -2.9066e-03],\n",
      "          [ 7.5810e-03, -2.6054e-06, -1.4417e-02],\n",
      "          [-2.5630e-04, -9.4736e-07, -5.7113e-07]]],\n",
      "\n",
      "\n",
      "        [[[-8.1127e-07, -1.3509e-06, -1.5762e-02],\n",
      "          [-3.7876e-07,  1.7251e-06,  2.4386e-04],\n",
      "          [-2.6539e-07, -6.0890e-03,  2.2171e-06]]],\n",
      "\n",
      "\n",
      "        [[[-8.8495e-04, -9.7259e-07,  4.4731e-07],\n",
      "          [-1.0542e-06,  2.3935e-02,  1.0181e-06],\n",
      "          [-1.2230e-06, -7.2804e-03,  1.1936e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.4825e-07,  2.1650e-04, -3.5296e-05],\n",
      "          [-1.1395e-06, -1.3727e-06,  1.9522e-05],\n",
      "          [-8.4116e-03,  3.8269e-05, -5.5530e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0988e-02,  6.4126e-05,  1.4931e-03],\n",
      "          [ 1.0168e-06, -1.2128e-02,  3.5826e-03],\n",
      "          [-1.3709e-02, -1.2379e-04,  1.0219e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.8645e-02, -8.1126e-07, -1.0590e-02],\n",
      "          [ 8.5649e-03, -2.0394e-03, -6.2270e-03],\n",
      "          [ 2.2023e-03,  7.5435e-06,  6.3066e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8194e-02, -1.1267e-04,  1.8598e-02],\n",
      "          [-6.1799e-05, -1.3620e-02, -1.5005e-03],\n",
      "          [-3.4143e-06,  1.6790e-06,  1.9621e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7392e-06,  3.0987e-03, -4.4467e-07],\n",
      "          [-1.8661e-02, -7.0661e-03, -1.0677e-03],\n",
      "          [ 2.1647e-07,  1.3368e-07, -1.1692e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9927e-07,  1.4092e-06, -5.2444e-04],\n",
      "          [-1.2161e-02,  6.1470e-04, -1.3498e-06],\n",
      "          [ 1.9385e-06,  1.8943e-06, -4.1283e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2883e-05,  1.8315e-06, -7.7233e-05],\n",
      "          [ 1.5017e-02, -4.2808e-03,  3.5370e-05],\n",
      "          [ 2.4729e-06,  2.1222e-06,  1.8174e-06]]],\n",
      "\n",
      "\n",
      "        [[[-3.0790e-04, -3.8316e-06, -4.7024e-03],\n",
      "          [-1.2708e-04,  4.7764e-07,  1.4075e-06],\n",
      "          [ 2.3562e-03, -4.8971e-08, -7.9573e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9270e-03, -6.5889e-03, -1.4460e-03],\n",
      "          [-1.7272e-07,  1.8683e-02, -1.5902e-02],\n",
      "          [ 9.5538e-06,  4.8826e-03, -1.1734e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3494e-02,  7.2270e-05, -2.4825e-02],\n",
      "          [-1.4074e-06,  1.5573e-02, -2.5925e-03],\n",
      "          [-1.8734e-06,  3.0182e-06,  2.4122e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2379e-04,  1.6725e-05,  1.8395e-03],\n",
      "          [-3.0169e-04,  1.2857e-03, -3.2004e-06],\n",
      "          [ 1.6853e-02, -4.6542e-03,  2.1320e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2230e-03,  2.6678e-04, -9.2836e-04],\n",
      "          [-3.9959e-03,  3.6144e-06, -3.1123e-03],\n",
      "          [-2.1747e-03, -1.9918e-05,  5.2954e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0836e-06, -4.0457e-03,  6.2489e-08],\n",
      "          [-2.3826e-02, -1.7704e-02, -1.1916e-06],\n",
      "          [ 6.5739e-04, -1.7009e-02,  6.4079e-06]]],\n",
      "\n",
      "\n",
      "        [[[-9.5706e-07,  8.3995e-03, -1.2415e-06],\n",
      "          [ 5.4498e-05,  5.2341e-04, -1.1777e-06],\n",
      "          [-2.6259e-04, -8.3315e-04,  1.1353e-06]]]], device='cuda:0')), ('module_list.0.posterior_params.0.param_std_log', tensor([[[[ -6.4947,  -4.8136,  -5.0328],\n",
      "          [ -7.6453,  -4.2656,  -4.3566],\n",
      "          [ -4.2898,  -7.6268,  -6.0105]]],\n",
      "\n",
      "\n",
      "        [[[ -4.1271,  -4.5163,  -5.1858],\n",
      "          [ -4.1565,  -4.2845,  -4.1073],\n",
      "          [ -7.4305,  -8.6512,  -5.8681]]],\n",
      "\n",
      "\n",
      "        [[[ -6.3825,  -4.2237,  -4.2113],\n",
      "          [ -4.4821,  -5.7181,  -4.1175],\n",
      "          [ -6.7994,  -4.3845,  -4.1148]]],\n",
      "\n",
      "\n",
      "        [[[ -4.6909,  -4.8016,  -4.0855],\n",
      "          [ -4.9422,  -4.6441,  -4.7017],\n",
      "          [ -4.9211,  -4.1100,  -5.1002]]],\n",
      "\n",
      "\n",
      "        [[[ -4.2920,  -4.3239,  -4.5325],\n",
      "          [ -5.1915,  -4.5259,  -4.0820],\n",
      "          [ -4.0948,  -4.6235,  -5.7959]]],\n",
      "\n",
      "\n",
      "        [[[ -4.3704,  -5.9859,  -4.4459],\n",
      "          [ -4.6160,  -5.7275,  -6.7973],\n",
      "          [ -4.3566,  -6.7673,  -4.7654]]],\n",
      "\n",
      "\n",
      "        [[[ -5.7650,  -4.1605,  -5.8985],\n",
      "          [ -5.1199,  -5.7967,  -4.9592],\n",
      "          [ -4.7941,  -4.1116,  -4.2244]]],\n",
      "\n",
      "\n",
      "        [[[ -5.1886,  -5.2568,  -7.7655],\n",
      "          [ -6.5778,  -6.2892,  -5.1249],\n",
      "          [ -4.5659,  -4.9816,  -6.0430]]],\n",
      "\n",
      "\n",
      "        [[[ -4.7287,  -4.1266,  -4.6495],\n",
      "          [ -4.4167,  -4.3834,  -6.1884],\n",
      "          [ -4.1874,  -4.2177,  -4.1857]]],\n",
      "\n",
      "\n",
      "        [[[ -4.5810,  -4.3147,  -6.1409],\n",
      "          [ -5.5924,  -4.0988,  -5.2937],\n",
      "          [ -7.8960,  -4.6583,  -4.3158]]],\n",
      "\n",
      "\n",
      "        [[[ -4.9624,  -4.5981,  -4.5308],\n",
      "          [ -4.4490,  -6.7644,  -5.1914],\n",
      "          [ -4.2664,  -4.2077,  -6.9489]]],\n",
      "\n",
      "\n",
      "        [[[ -4.1636,  -4.1361,  -7.8102],\n",
      "          [ -4.7175,  -5.1445,  -6.3258],\n",
      "          [ -4.1896,  -5.0145,  -6.3289]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0983,  -4.1674,  -4.2762],\n",
      "          [ -6.1255,  -4.2754,  -4.0955],\n",
      "          [ -5.3578,  -4.3699,  -4.4131]]],\n",
      "\n",
      "\n",
      "        [[[ -7.1214,  -5.0823,  -4.2594],\n",
      "          [ -4.4361,  -4.6151,  -5.8066],\n",
      "          [ -4.2009,  -5.0831,  -4.6804]]],\n",
      "\n",
      "\n",
      "        [[[ -4.5088,  -5.4152,  -5.1288],\n",
      "          [ -4.6035,  -4.7254,  -5.7152],\n",
      "          [ -5.0038,  -6.5429,  -4.0981]]],\n",
      "\n",
      "\n",
      "        [[[ -4.5363,  -4.8731,  -4.8805],\n",
      "          [ -4.7824,  -4.2325,  -4.0919],\n",
      "          [ -5.0284,  -8.2136,  -4.9477]]],\n",
      "\n",
      "\n",
      "        [[[ -4.4562,  -5.5288,  -4.2321],\n",
      "          [ -4.4242,  -4.4076,  -4.9019],\n",
      "          [ -4.3468,  -5.4421,  -4.8742]]],\n",
      "\n",
      "\n",
      "        [[[ -5.0770,  -4.2979,  -4.3266],\n",
      "          [ -4.5704,  -4.3644,  -6.2678],\n",
      "          [ -5.2841,  -5.3317,  -5.0125]]],\n",
      "\n",
      "\n",
      "        [[[ -4.9148,  -5.0182,  -4.4737],\n",
      "          [ -4.3254,  -5.3739,  -4.1148],\n",
      "          [ -6.0593,  -5.1290,  -5.1282]]],\n",
      "\n",
      "\n",
      "        [[[ -8.2877,  -6.0262,  -4.4019],\n",
      "          [ -7.9581,  -5.7533,  -5.4131],\n",
      "          [ -4.7670,  -4.6744,  -4.7482]]],\n",
      "\n",
      "\n",
      "        [[[ -4.3429,  -4.8270, -15.5712],\n",
      "          [ -4.8831,  -4.8744,  -4.5434],\n",
      "          [ -5.0165,  -4.6874,  -4.1868]]],\n",
      "\n",
      "\n",
      "        [[[ -5.6218,  -6.4461,  -5.8217],\n",
      "          [ -5.0565,  -6.0657,  -6.9629],\n",
      "          [ -5.2774,  -4.2602,  -4.8775]]],\n",
      "\n",
      "\n",
      "        [[[ -4.8660,  -4.1483,  -5.2323],\n",
      "          [ -4.9379,  -4.3428,  -4.9693],\n",
      "          [ -5.3985,  -5.2386,  -4.4587]]],\n",
      "\n",
      "\n",
      "        [[[ -4.2932,  -5.0413,  -4.3289],\n",
      "          [ -6.1493,  -9.1325,  -4.1244],\n",
      "          [ -4.5825,  -9.1810,  -5.7587]]],\n",
      "\n",
      "\n",
      "        [[[ -4.2070,  -4.2394,  -6.4879],\n",
      "          [ -4.1195,  -4.0842,  -4.6166],\n",
      "          [ -4.0841,  -4.3548,  -5.7479]]],\n",
      "\n",
      "\n",
      "        [[[ -4.1200,  -5.0215,  -7.1456],\n",
      "          [ -5.4086,  -4.7420,  -5.2495],\n",
      "          [ -4.7415,  -4.1130,  -4.8952]]],\n",
      "\n",
      "\n",
      "        [[[ -4.7114, -10.5682,  -4.2073],\n",
      "          [ -5.3579,  -5.6020,  -5.0559],\n",
      "          [ -4.1904,  -4.0829,  -4.9937]]],\n",
      "\n",
      "\n",
      "        [[[ -4.5668,  -5.0432,  -5.4627],\n",
      "          [ -4.6322,  -4.0996,  -5.2199],\n",
      "          [ -5.1886,  -6.1052,  -4.6022]]],\n",
      "\n",
      "\n",
      "        [[[ -5.1187,  -4.7148,  -4.2369],\n",
      "          [ -5.6662,  -4.5525,  -4.1182],\n",
      "          [ -5.1343,  -6.5005,  -6.3188]]],\n",
      "\n",
      "\n",
      "        [[[ -5.6133,  -5.2211,  -5.8710],\n",
      "          [ -4.8951,  -4.3601,  -6.2380],\n",
      "          [ -4.6509,  -5.0081,  -5.3717]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0941,  -5.6758,  -4.2624],\n",
      "          [ -4.4637,  -4.1345,  -4.1423],\n",
      "          [ -6.7226,  -4.0953,  -5.4928]]],\n",
      "\n",
      "\n",
      "        [[[ -4.3568,  -4.8428,  -4.4974],\n",
      "          [ -4.8351,  -4.4515,  -4.5175],\n",
      "          [ -7.0287,  -4.8522,  -5.2154]]]], device='cuda:0')), ('module_list.0.posterior_params.0.scale_alphas_log', tensor([[[[-1.5143, -1.6702, -1.7355],\n",
      "          [-3.0596, -2.6939, -2.9428],\n",
      "          [-2.4466, -1.9143, -3.3280]]],\n",
      "\n",
      "\n",
      "        [[[-1.4974, -2.7475, -1.5643],\n",
      "          [-2.2650, -3.0770, -1.7259],\n",
      "          [-2.7601, -1.6276, -2.0488]]],\n",
      "\n",
      "\n",
      "        [[[-1.5618, -3.4170, -3.0931],\n",
      "          [-2.6324, -2.2942, -2.6316],\n",
      "          [-2.6447, -1.6211, -2.7037]]],\n",
      "\n",
      "\n",
      "        [[[-2.0898, -1.9632, -1.9947],\n",
      "          [-2.2216, -2.3907, -1.6943],\n",
      "          [-2.3713, -2.6683, -2.9659]]],\n",
      "\n",
      "\n",
      "        [[[-2.6022, -3.4589, -2.5222],\n",
      "          [-2.1975, -3.2835, -2.5828],\n",
      "          [-2.2270, -3.0520, -1.4690]]],\n",
      "\n",
      "\n",
      "        [[[-3.3150, -2.0771, -2.9250],\n",
      "          [-3.0550, -2.3820, -3.0133],\n",
      "          [-3.1761, -1.6274, -2.2223]]],\n",
      "\n",
      "\n",
      "        [[[-2.3899, -1.7964, -2.1803],\n",
      "          [-2.1285, -1.5593, -2.1531],\n",
      "          [-1.7850, -2.3856, -2.8680]]],\n",
      "\n",
      "\n",
      "        [[[-3.1190, -1.9465, -2.2797],\n",
      "          [-2.1140, -2.4607, -2.2329],\n",
      "          [-2.1240, -3.3683, -2.0952]]],\n",
      "\n",
      "\n",
      "        [[[-2.0876, -2.2839, -1.9793],\n",
      "          [-1.5604, -2.5574, -2.0900],\n",
      "          [-3.1472, -2.9995, -2.8056]]],\n",
      "\n",
      "\n",
      "        [[[-2.0306, -2.5217, -2.0960],\n",
      "          [-1.4933, -2.5549, -2.9502],\n",
      "          [-1.6183, -2.3095, -2.3817]]],\n",
      "\n",
      "\n",
      "        [[[-2.9363, -1.4834, -1.5270],\n",
      "          [-2.4014, -3.3054, -1.7744],\n",
      "          [-2.7878, -2.5627, -1.7769]]],\n",
      "\n",
      "\n",
      "        [[[-1.8806, -3.1516, -3.2003],\n",
      "          [-3.2425, -2.7471, -1.9943],\n",
      "          [-1.6107, -2.3261, -2.6771]]],\n",
      "\n",
      "\n",
      "        [[[-2.5268, -2.9877, -3.0557],\n",
      "          [-1.7652, -2.8254, -2.0759],\n",
      "          [-2.9532, -1.7305, -2.2036]]],\n",
      "\n",
      "\n",
      "        [[[-2.3056, -1.7525, -2.1404],\n",
      "          [-2.2451, -2.9075, -2.9538],\n",
      "          [-1.8668, -1.9535, -2.6078]]],\n",
      "\n",
      "\n",
      "        [[[-2.8300, -1.4730, -1.4846],\n",
      "          [-2.6596, -2.3834, -2.1372],\n",
      "          [-2.8679, -3.0708, -2.3254]]],\n",
      "\n",
      "\n",
      "        [[[-2.3378, -2.3957, -2.5042],\n",
      "          [-2.7481, -1.7163, -2.8710],\n",
      "          [-2.0650, -2.7900, -2.9818]]],\n",
      "\n",
      "\n",
      "        [[[-2.7795, -1.7511, -2.0931],\n",
      "          [-2.6497, -3.1897, -2.5810],\n",
      "          [-2.4555, -1.9024, -2.7998]]],\n",
      "\n",
      "\n",
      "        [[[-1.8374, -3.3530, -1.5469],\n",
      "          [-3.1824, -1.6265, -2.4078],\n",
      "          [-2.5545, -2.3736, -1.9663]]],\n",
      "\n",
      "\n",
      "        [[[-2.9063, -2.8036, -3.3350],\n",
      "          [-1.6826, -1.4968, -2.4460],\n",
      "          [-2.0034, -3.0920, -3.2840]]],\n",
      "\n",
      "\n",
      "        [[[-2.7975, -1.8752, -2.4376],\n",
      "          [-3.3421, -2.4437, -2.1233],\n",
      "          [-3.3700, -3.4085, -2.2232]]],\n",
      "\n",
      "\n",
      "        [[[-2.0924, -1.7304, -3.0575],\n",
      "          [-1.9674, -2.4607, -1.5331],\n",
      "          [-1.4999, -2.7755, -1.8071]]],\n",
      "\n",
      "\n",
      "        [[[-2.8776, -2.8902, -3.1476],\n",
      "          [-3.3036, -2.6815, -1.5593],\n",
      "          [-2.0882, -2.2513, -2.9860]]],\n",
      "\n",
      "\n",
      "        [[[-3.4249, -2.8258, -3.2320],\n",
      "          [-3.1896, -2.3955, -2.8106],\n",
      "          [-2.4224, -2.8759, -3.3649]]],\n",
      "\n",
      "\n",
      "        [[[-2.7089, -2.2672, -2.4551],\n",
      "          [-3.1919, -1.5723, -1.9661],\n",
      "          [-1.4860, -3.1146, -2.6679]]],\n",
      "\n",
      "\n",
      "        [[[-2.8256, -3.0310, -1.4849],\n",
      "          [-3.3486, -1.8318, -2.7723],\n",
      "          [-1.7415, -3.0374, -3.2885]]],\n",
      "\n",
      "\n",
      "        [[[-3.1892, -1.7211, -1.5851],\n",
      "          [-2.1683, -3.3811, -1.5784],\n",
      "          [-1.6685, -2.2583, -2.2286]]],\n",
      "\n",
      "\n",
      "        [[[-3.3414, -2.4805, -2.9179],\n",
      "          [-2.0798, -2.9344, -2.4395],\n",
      "          [-1.4954, -3.1694, -1.5002]]],\n",
      "\n",
      "\n",
      "        [[[-2.7612, -2.9043, -2.8418],\n",
      "          [-3.1497, -3.2447, -2.4384],\n",
      "          [-2.8824, -1.6642, -2.3667]]],\n",
      "\n",
      "\n",
      "        [[[-3.1605, -2.4096, -1.9485],\n",
      "          [-3.2840, -3.2157, -3.1445],\n",
      "          [-1.4726, -2.7458, -3.1156]]],\n",
      "\n",
      "\n",
      "        [[[-2.7008, -3.2307, -2.2640],\n",
      "          [-1.6348, -3.2305, -2.9108],\n",
      "          [-3.1003, -3.2952, -3.1832]]],\n",
      "\n",
      "\n",
      "        [[[-2.5660, -2.9847, -3.2215],\n",
      "          [-1.8051, -2.0058, -3.1018],\n",
      "          [-2.5875, -3.0386, -2.3712]]],\n",
      "\n",
      "\n",
      "        [[[-3.1834, -2.9611, -2.0927],\n",
      "          [-3.3368, -1.7620, -1.9541],\n",
      "          [-1.4729, -2.2604, -2.0798]]]], device='cuda:0')), ('module_list.0.posterior_params.0.scale_mus', tensor([[[[1.0269, 0.9694, 1.0311],\n",
      "          [1.0307, 1.0373, 1.0341],\n",
      "          [1.0365, 1.0281, 0.9645]]],\n",
      "\n",
      "\n",
      "        [[[0.9904, 0.9765, 0.9691],\n",
      "          [1.0151, 1.0259, 1.0329],\n",
      "          [0.9768, 0.9720, 1.0311]]],\n",
      "\n",
      "\n",
      "        [[[0.9863, 1.0056, 1.0144],\n",
      "          [0.9950, 0.9846, 0.9838],\n",
      "          [0.9951, 1.0037, 0.9984]]],\n",
      "\n",
      "\n",
      "        [[[1.0159, 1.0116, 0.9952],\n",
      "          [0.9874, 1.0132, 1.0107],\n",
      "          [1.0137, 0.9843, 1.0191]]],\n",
      "\n",
      "\n",
      "        [[[0.9799, 1.0295, 1.0302],\n",
      "          [1.0241, 1.0315, 1.0303],\n",
      "          [1.0321, 0.9681, 0.9668]]],\n",
      "\n",
      "\n",
      "        [[[1.0217, 0.9944, 1.0049],\n",
      "          [1.0251, 0.9798, 0.9885],\n",
      "          [0.9753, 0.9983, 0.9853]]],\n",
      "\n",
      "\n",
      "        [[[1.0066, 0.9913, 0.9846],\n",
      "          [0.9834, 0.9795, 1.0019],\n",
      "          [1.0194, 1.0222, 0.9876]]],\n",
      "\n",
      "\n",
      "        [[[1.0082, 0.9737, 0.9861],\n",
      "          [0.9856, 1.0284, 0.9868],\n",
      "          [1.0183, 0.9771, 1.0054]]],\n",
      "\n",
      "\n",
      "        [[[1.0094, 0.9846, 0.9925],\n",
      "          [1.0189, 1.0228, 1.0164],\n",
      "          [0.9807, 1.0179, 0.9843]]],\n",
      "\n",
      "\n",
      "        [[[1.0071, 1.0019, 0.9965],\n",
      "          [0.9820, 0.9870, 1.0060],\n",
      "          [1.0079, 0.9859, 0.9896]]],\n",
      "\n",
      "\n",
      "        [[[0.9789, 0.9969, 1.0275],\n",
      "          [1.0108, 0.9912, 1.0173],\n",
      "          [0.9852, 1.0015, 0.9922]]],\n",
      "\n",
      "\n",
      "        [[[0.9760, 1.0308, 1.0305],\n",
      "          [0.9720, 1.0300, 0.9725],\n",
      "          [1.0265, 0.9736, 1.0274]]],\n",
      "\n",
      "\n",
      "        [[[1.0265, 0.9799, 1.0158],\n",
      "          [0.9771, 1.0237, 1.0269],\n",
      "          [1.0279, 1.0140, 1.0076]]],\n",
      "\n",
      "\n",
      "        [[[1.0010, 1.0056, 0.9842],\n",
      "          [0.9920, 0.9991, 0.9928],\n",
      "          [0.9992, 1.0038, 0.9923]]],\n",
      "\n",
      "\n",
      "        [[[1.0110, 0.9873, 0.9846],\n",
      "          [1.0054, 1.0092, 1.0050],\n",
      "          [0.9830, 1.0042, 0.9647]]],\n",
      "\n",
      "\n",
      "        [[[1.0136, 0.9857, 0.9887],\n",
      "          [1.0156, 1.0216, 0.9826],\n",
      "          [0.9864, 0.9831, 1.0163]]],\n",
      "\n",
      "\n",
      "        [[[0.9921, 0.9832, 0.9744],\n",
      "          [0.9764, 1.0138, 1.0180],\n",
      "          [1.0202, 1.0028, 0.9850]]],\n",
      "\n",
      "\n",
      "        [[[1.0107, 1.0088, 1.0114],\n",
      "          [1.0201, 1.0244, 1.0188],\n",
      "          [0.9774, 0.9740, 1.0262]]],\n",
      "\n",
      "\n",
      "        [[[1.0236, 1.0251, 0.9975],\n",
      "          [1.0202, 1.0279, 1.0188],\n",
      "          [0.9834, 1.0248, 0.9820]]],\n",
      "\n",
      "\n",
      "        [[[1.0192, 1.0241, 1.0304],\n",
      "          [0.9925, 0.9776, 1.0284],\n",
      "          [1.0112, 0.9871, 1.0255]]],\n",
      "\n",
      "\n",
      "        [[[0.9762, 0.9823, 1.0176],\n",
      "          [1.0266, 0.9788, 1.0107],\n",
      "          [1.0300, 1.0104, 0.9913]]],\n",
      "\n",
      "\n",
      "        [[[1.0173, 1.0005, 0.9950],\n",
      "          [0.9788, 1.0021, 1.0083],\n",
      "          [1.0015, 0.9950, 0.9905]]],\n",
      "\n",
      "\n",
      "        [[[1.0101, 0.9859, 1.0154],\n",
      "          [1.0214, 1.0222, 1.0234],\n",
      "          [1.0007, 0.9947, 0.9925]]],\n",
      "\n",
      "\n",
      "        [[[0.9949, 1.0172, 0.9748],\n",
      "          [0.9949, 1.0160, 1.0184],\n",
      "          [0.9832, 1.0065, 0.9915]]],\n",
      "\n",
      "\n",
      "        [[[1.0329, 1.0101, 1.0228],\n",
      "          [1.0340, 0.9822, 1.0091],\n",
      "          [1.0298, 1.0237, 1.0266]]],\n",
      "\n",
      "\n",
      "        [[[1.0203, 0.9899, 0.9721],\n",
      "          [0.9840, 1.0242, 0.9922],\n",
      "          [1.0333, 1.0284, 0.9901]]],\n",
      "\n",
      "\n",
      "        [[[1.0250, 0.9782, 0.9833],\n",
      "          [0.9770, 1.0258, 0.9771],\n",
      "          [1.0246, 1.0265, 0.9745]]],\n",
      "\n",
      "\n",
      "        [[[1.0381, 1.0374, 0.9642],\n",
      "          [0.9673, 1.0384, 0.9650],\n",
      "          [1.0361, 1.0324, 1.0299]]],\n",
      "\n",
      "\n",
      "        [[[1.0122, 1.0125, 1.0112],\n",
      "          [0.9871, 1.0137, 0.9879],\n",
      "          [1.0212, 0.9799, 1.0128]]],\n",
      "\n",
      "\n",
      "        [[[1.0111, 0.9944, 0.9751],\n",
      "          [0.9862, 1.0183, 0.9730],\n",
      "          [1.0060, 0.9898, 1.0304]]],\n",
      "\n",
      "\n",
      "        [[[0.9881, 1.0018, 0.9942],\n",
      "          [0.9853, 0.9705, 1.0131],\n",
      "          [1.0165, 0.9918, 0.9935]]],\n",
      "\n",
      "\n",
      "        [[[1.0210, 1.0198, 0.9967],\n",
      "          [1.0219, 1.0114, 0.9959],\n",
      "          [0.9846, 0.9829, 0.9869]]]], device='cuda:0')), ('module_list.0.posterior_params.1.param_mus', tensor([ 1.1550e-06,  4.7274e-07, -6.2620e-06,  6.5583e-03,  8.1219e-03,\n",
      "         3.6230e-04, -1.5061e-02,  7.7570e-06, -8.9144e-04,  2.1388e-07,\n",
      "        -3.5672e-03, -5.9058e-05,  1.2210e-02, -2.3283e-02, -1.5512e-02,\n",
      "        -2.2575e-02,  1.2710e-03,  3.0569e-06,  1.9752e-06,  2.5718e-06,\n",
      "        -1.5768e-06,  4.8040e-06,  3.7901e-04,  1.9328e-06,  2.0451e-04,\n",
      "         3.9062e-05,  7.7367e-09,  1.3911e-02,  2.6251e-04,  1.7829e-06,\n",
      "        -6.4918e-03, -1.0056e-02], device='cuda:0')), ('module_list.0.posterior_params.1.param_std_log', tensor([-4.1593, -4.3317, -6.0343, -4.8871, -5.3405, -5.8841, -4.1936, -4.3391,\n",
      "        -4.6150, -4.9606, -4.2102, -4.1023, -4.1343, -4.7892, -4.2105, -4.0998,\n",
      "        -4.1669, -4.1276, -4.3750, -4.3629, -4.5065, -4.7476, -4.9526, -4.6440,\n",
      "        -4.1418, -6.4263, -4.3648, -5.2927, -4.6181, -4.1051, -4.2543, -4.5189],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.1.scale_alphas_log', tensor([-1.9959, -2.0880, -3.3180, -2.8506, -1.7171, -3.3408, -1.5161, -3.4499,\n",
      "        -3.1400, -2.0602, -1.7883, -2.5354, -1.5036, -3.2240, -2.9984, -1.8829,\n",
      "        -2.1218, -2.6661, -2.5252, -1.8825, -2.0705, -2.3608, -2.0346, -1.5672,\n",
      "        -1.7009, -2.9427, -2.2079, -1.8316, -2.0547, -2.1299, -2.1954, -2.4297],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.1.scale_mus', tensor([0.9674, 0.9881, 0.9913, 0.9863, 1.0129, 1.0082, 0.9792, 1.0000, 0.9785,\n",
      "        0.9954, 0.9983, 0.9726, 0.9922, 0.9975, 1.0125, 0.9851, 1.0132, 0.9798,\n",
      "        0.9809, 0.9752, 0.9723, 0.9887, 1.0132, 1.0030, 1.0055, 0.9933, 0.9998,\n",
      "        1.0000, 0.9792, 0.9748, 1.0028, 0.9838], device='cuda:0')), ('module_list.0.posterior_params.2.param_mus', tensor([[[[-1.5895e-06,  3.0069e-07, -1.0353e-06],\n",
      "          [-1.0632e-06,  4.2397e-07,  1.1708e-07],\n",
      "          [-1.0479e-06,  1.8781e-08, -1.0691e-06]],\n",
      "\n",
      "         [[-1.7970e-06, -3.6943e-07, -3.5270e-07],\n",
      "          [ 2.6234e-07, -1.5053e-07, -4.3719e-10],\n",
      "          [-1.0900e-07, -1.1772e-07, -1.3156e-07]],\n",
      "\n",
      "         [[-3.1881e-07,  3.1596e-07,  3.0193e-07],\n",
      "          [-5.1184e-07, -1.0289e-05, -1.8825e-07],\n",
      "          [-1.7217e-07,  8.4086e-07, -8.7788e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6474e-07,  2.3668e-07, -1.3876e-07],\n",
      "          [ 6.5383e-08,  1.1551e-06, -8.5503e-08],\n",
      "          [ 1.3757e-07,  1.4441e-09, -1.4863e-07]],\n",
      "\n",
      "         [[-5.3876e-08,  1.4688e-07,  3.8505e-08],\n",
      "          [ 7.1429e-08,  3.1808e-07, -1.8541e-08],\n",
      "          [-4.4602e-07,  3.9563e-07, -3.2244e-08]],\n",
      "\n",
      "         [[ 5.9270e-07, -1.5097e-06,  8.2276e-07],\n",
      "          [ 1.7497e-06,  9.4856e-07,  2.7302e-06],\n",
      "          [-1.1974e-08,  1.9542e-07, -2.0261e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6518e-06,  3.2413e-07,  8.2712e-07],\n",
      "          [ 2.1557e-07, -3.6300e-07, -7.7495e-07],\n",
      "          [ 4.8890e-07, -2.1358e-07, -2.7405e-06]],\n",
      "\n",
      "         [[ 4.4793e-08,  3.5072e-07,  5.6150e-07],\n",
      "          [ 2.1818e-06,  1.9201e-08,  2.6875e-07],\n",
      "          [ 4.9720e-08,  5.7665e-06,  8.7268e-08]],\n",
      "\n",
      "         [[-2.8880e-07,  2.7698e-07, -4.7568e-08],\n",
      "          [-2.7191e-07, -3.8970e-07, -6.3534e-08],\n",
      "          [-3.9971e-07, -8.9112e-08,  7.0740e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3219e-06,  7.9511e-07, -7.9785e-06],\n",
      "          [ 7.6809e-07,  3.8573e-07, -1.3559e-07],\n",
      "          [ 9.6683e-07, -2.5674e-07,  1.2407e-06]],\n",
      "\n",
      "         [[ 4.2459e-07, -1.5197e-06,  8.7352e-08],\n",
      "          [ 1.2380e-06,  4.1063e-07,  1.1793e-06],\n",
      "          [ 1.1059e-06,  7.4497e-07,  4.7749e-07]],\n",
      "\n",
      "         [[-2.6952e-07, -5.3448e-07,  2.1005e-07],\n",
      "          [-1.1082e-06,  8.8718e-07, -9.9881e-08],\n",
      "          [-5.1297e-07, -2.8078e-07,  4.5264e-07]]],\n",
      "\n",
      "\n",
      "        [[[-4.3678e-07, -1.1083e-06, -7.5110e-07],\n",
      "          [-3.8313e-07, -3.6403e-07, -5.9122e-07],\n",
      "          [-1.5308e-06,  2.3551e-07, -1.6088e-07]],\n",
      "\n",
      "         [[-2.2147e-06, -1.0290e-06, -2.3009e-06],\n",
      "          [-2.9296e-06, -7.7655e-07,  2.3380e-06],\n",
      "          [-1.1487e-06, -3.4383e-07, -7.4392e-07]],\n",
      "\n",
      "         [[ 3.7448e-07,  4.7154e-07,  1.3823e-07],\n",
      "          [-5.0974e-07, -2.2867e-07,  3.5526e-07],\n",
      "          [-2.8299e-07,  1.1956e-05, -2.5504e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8560e-07, -1.2021e-06, -1.4964e-07],\n",
      "          [ 1.6091e-07,  5.1963e-07,  1.5821e-07],\n",
      "          [-3.1158e-07,  1.7032e-07,  2.9512e-07]],\n",
      "\n",
      "         [[-1.8056e-07, -6.6259e-08, -6.8801e-07],\n",
      "          [-2.3034e-07, -3.0153e-08, -1.3869e-06],\n",
      "          [ 2.3993e-07, -3.3705e-07, -7.3268e-07]],\n",
      "\n",
      "         [[ 3.4847e-07,  3.4395e-08, -1.4016e-06],\n",
      "          [ 1.3074e-07,  8.3181e-07, -2.3831e-07],\n",
      "          [-1.2170e-06, -2.0974e-08, -4.9376e-07]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.2393e-07,  7.5510e-07,  1.7252e-07],\n",
      "          [ 4.3854e-07,  2.3878e-07,  1.5533e-06],\n",
      "          [ 9.2922e-07,  1.3853e-07,  6.1897e-07]],\n",
      "\n",
      "         [[ 2.1000e-07,  7.1220e-07, -8.0132e-07],\n",
      "          [ 1.3094e-06, -1.0071e-06, -1.4660e-07],\n",
      "          [-4.9619e-08, -3.1004e-06,  8.7277e-07]],\n",
      "\n",
      "         [[ 6.5123e-08, -1.1416e-07,  5.9335e-08],\n",
      "          [ 6.6849e-07, -1.6460e-07,  2.4077e-07],\n",
      "          [ 7.8931e-08, -1.0635e-07, -3.8229e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0494e-07, -4.4100e-07, -2.7253e-07],\n",
      "          [-2.2379e-07, -5.2714e-07, -1.1531e-08],\n",
      "          [ 7.9407e-07,  5.3108e-07,  1.2248e-06]],\n",
      "\n",
      "         [[ 2.9926e-07,  2.2954e-07, -5.3736e-08],\n",
      "          [-8.5010e-07, -1.2845e-08, -1.9762e-07],\n",
      "          [ 1.8816e-07, -3.4850e-07, -1.9287e-07]],\n",
      "\n",
      "         [[ 3.5081e-07,  4.6032e-07, -8.3947e-07],\n",
      "          [ 9.8442e-07,  2.7021e-07, -1.5595e-07],\n",
      "          [ 1.0478e-06,  5.6294e-07, -3.3945e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6445e-08,  8.8183e-07,  3.7462e-07],\n",
      "          [ 4.4209e-07,  3.8997e-07,  1.5134e-06],\n",
      "          [-8.7750e-07,  3.1085e-07,  5.8364e-07]],\n",
      "\n",
      "         [[-1.4427e-08,  1.7696e-07,  2.0621e-07],\n",
      "          [-2.8510e-07, -6.1702e-07, -5.1615e-07],\n",
      "          [-5.0328e-07,  2.3500e-08,  3.6084e-07]],\n",
      "\n",
      "         [[-1.5693e-07, -4.8504e-07,  2.4960e-07],\n",
      "          [ 1.4423e-07,  3.3649e-06,  5.3069e-07],\n",
      "          [ 4.2593e-07, -1.1391e-06,  8.6017e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9853e-07,  3.0671e-07,  5.6652e-06],\n",
      "          [-1.0219e-06,  4.8225e-06,  2.1662e-06],\n",
      "          [-4.0638e-07, -3.1099e-07, -1.1460e-07]],\n",
      "\n",
      "         [[-5.1648e-07,  1.1006e-07, -6.5007e-07],\n",
      "          [-5.6266e-08,  2.3041e-08, -5.5865e-07],\n",
      "          [ 3.8550e-08,  1.6126e-06, -2.3776e-07]],\n",
      "\n",
      "         [[ 3.4279e-07, -1.3584e-07,  2.9724e-07],\n",
      "          [-4.1838e-07, -8.3003e-08,  3.4051e-07],\n",
      "          [-5.2079e-07, -3.1470e-07, -7.6979e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1091e-06, -2.4814e-07, -1.3688e-06],\n",
      "          [ 6.2042e-08, -4.9970e-07, -7.7271e-08],\n",
      "          [ 7.0370e-07, -3.9886e-07, -4.5787e-07]],\n",
      "\n",
      "         [[-4.5686e-07,  3.8654e-07, -1.5878e-07],\n",
      "          [ 1.1717e-07, -7.6118e-08,  8.3957e-07],\n",
      "          [ 4.0807e-07, -2.5120e-07, -1.3197e-07]],\n",
      "\n",
      "         [[ 6.3085e-07,  2.3866e-07,  2.5275e-07],\n",
      "          [-2.7498e-08,  1.1581e-07,  2.0936e-07],\n",
      "          [-3.7705e-07,  2.1668e-06,  2.0308e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6670e-07, -3.1232e-07, -5.9156e-08],\n",
      "          [ 3.2850e-07,  4.0916e-07,  3.4502e-06],\n",
      "          [-2.3883e-06,  4.0099e-07,  2.5098e-07]],\n",
      "\n",
      "         [[ 6.9067e-08,  1.5044e-07, -1.7478e-07],\n",
      "          [-1.5452e-07, -8.0860e-07, -2.5402e-07],\n",
      "          [-1.9175e-07, -9.2206e-08, -4.6353e-07]],\n",
      "\n",
      "         [[ 4.2045e-07, -2.0603e-07, -5.3511e-07],\n",
      "          [ 4.6721e-08, -3.0942e-06, -4.7221e-07],\n",
      "          [-1.7576e-07, -7.1284e-07, -3.7647e-07]]]], device='cuda:0')), ('module_list.0.posterior_params.2.param_std_log', tensor([[[[-6.5890, -6.3248, -4.2001],\n",
      "          [-4.4853, -5.6661, -4.2658],\n",
      "          [-4.7315, -4.6523, -4.2705]],\n",
      "\n",
      "         [[-4.9140, -4.6685, -4.1060],\n",
      "          [-4.5979, -4.3367, -5.1337],\n",
      "          [-4.5705, -4.2887, -6.1359]],\n",
      "\n",
      "         [[-4.3663, -6.4064, -4.0824],\n",
      "          [-4.2380, -5.3166, -5.0618],\n",
      "          [-5.0412, -4.6756, -4.2025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.8154, -4.6372, -4.1100],\n",
      "          [-6.0635, -7.0058, -6.1157],\n",
      "          [-5.1309, -4.7105, -5.1222]],\n",
      "\n",
      "         [[-4.3893, -4.7472, -4.6416],\n",
      "          [-5.4763, -5.7922, -4.4296],\n",
      "          [-5.6737, -4.3552, -4.6320]],\n",
      "\n",
      "         [[-4.7445, -5.3910, -5.6141],\n",
      "          [-5.6867, -5.4272, -4.2943],\n",
      "          [-4.1893, -5.4943, -5.5207]]],\n",
      "\n",
      "\n",
      "        [[[-4.9895, -4.2902, -7.1863],\n",
      "          [-5.1400, -4.1525, -4.6151],\n",
      "          [-5.1633, -4.1205, -4.5670]],\n",
      "\n",
      "         [[-4.4017, -8.6900, -4.1762],\n",
      "          [-4.7537, -4.9603, -4.3402],\n",
      "          [-6.6264, -9.5298, -4.8126]],\n",
      "\n",
      "         [[-4.2459, -6.2183, -5.3111],\n",
      "          [-5.0906, -5.1635, -4.1602],\n",
      "          [-5.4708, -4.2228, -5.9979]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7297, -4.9450, -4.1168],\n",
      "          [-5.2267, -4.2769, -5.1146],\n",
      "          [-5.4860, -4.4138, -5.1908]],\n",
      "\n",
      "         [[-4.1059, -4.2602, -5.3324],\n",
      "          [-4.1246, -4.3648, -5.3433],\n",
      "          [-4.9279, -4.5776, -4.1924]],\n",
      "\n",
      "         [[-5.0657, -5.8347, -4.1183],\n",
      "          [-4.0762, -5.7430, -5.6106],\n",
      "          [-4.2195, -6.2510, -4.9298]]],\n",
      "\n",
      "\n",
      "        [[[-4.0939, -5.2511, -5.1759],\n",
      "          [-4.3015, -5.0527, -4.4217],\n",
      "          [-5.5738, -4.1981, -6.0245]],\n",
      "\n",
      "         [[-4.7491, -6.7971, -5.1523],\n",
      "          [-4.6635, -6.4692, -5.8278],\n",
      "          [-4.1019, -5.0103, -5.2205]],\n",
      "\n",
      "         [[-4.2303, -7.5290, -4.2249],\n",
      "          [-4.5017, -4.3475, -5.3617],\n",
      "          [-4.7791, -4.9418, -4.2008]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.1967, -5.6204, -5.3884],\n",
      "          [-4.2053, -4.3802, -5.0183],\n",
      "          [-4.6764, -4.1643, -4.1793]],\n",
      "\n",
      "         [[-5.9145, -5.4538, -4.7985],\n",
      "          [-4.3181, -5.2849, -5.2292],\n",
      "          [-4.4458, -4.4068, -4.1099]],\n",
      "\n",
      "         [[-4.8473, -4.7101, -5.3092],\n",
      "          [-5.3163, -5.6945, -4.5449],\n",
      "          [-4.0769, -4.7520, -5.3711]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.1085, -4.6366, -4.4832],\n",
      "          [-4.5079, -6.9968, -4.2626],\n",
      "          [-4.6224, -5.8424, -4.8314]],\n",
      "\n",
      "         [[-4.9858, -4.2272, -5.4539],\n",
      "          [-6.7818, -4.1048, -5.0170],\n",
      "          [-6.0654, -5.1898, -4.8668]],\n",
      "\n",
      "         [[-4.3708, -5.7923, -4.5193],\n",
      "          [-5.9892, -4.5415, -5.1675],\n",
      "          [-4.2166, -4.5677, -4.6772]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1362, -4.4363, -4.2799],\n",
      "          [-4.1543, -5.5358, -4.2531],\n",
      "          [-4.2231, -5.7460, -5.5312]],\n",
      "\n",
      "         [[-5.5447, -4.9171, -5.6421],\n",
      "          [-6.8079, -5.7413, -4.7678],\n",
      "          [-5.9305, -4.1311, -9.8447]],\n",
      "\n",
      "         [[-6.5626, -8.1611, -6.4684],\n",
      "          [-5.0019, -5.7471, -4.2666],\n",
      "          [-4.3501, -5.5868, -5.2413]]],\n",
      "\n",
      "\n",
      "        [[[-6.4085, -4.3217, -4.4249],\n",
      "          [-4.2690, -5.2052, -4.5134],\n",
      "          [-4.4690, -5.1753, -4.2262]],\n",
      "\n",
      "         [[-4.6327, -5.6117, -5.1182],\n",
      "          [-4.8379, -5.1353, -5.2613],\n",
      "          [-4.2172, -6.7396, -4.5858]],\n",
      "\n",
      "         [[-4.2163, -4.5718, -4.7340],\n",
      "          [-7.2768, -4.6184, -5.1894],\n",
      "          [-4.3884, -5.1769, -6.0240]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.3540, -4.0876, -5.3067],\n",
      "          [-4.5091, -4.3834, -4.1994],\n",
      "          [-4.1305, -5.5996, -4.6195]],\n",
      "\n",
      "         [[-4.2421, -4.7490, -6.7896],\n",
      "          [-4.8791, -5.3958, -4.6455],\n",
      "          [-4.6527, -4.5696, -4.9342]],\n",
      "\n",
      "         [[-5.5782, -4.9756, -4.1937],\n",
      "          [-5.0094, -4.2196, -7.1123],\n",
      "          [-6.3730, -6.5725, -5.0658]]],\n",
      "\n",
      "\n",
      "        [[[-4.0770, -6.0930, -4.7330],\n",
      "          [-5.2536, -5.7684, -4.1731],\n",
      "          [-4.9365, -4.5163, -4.8961]],\n",
      "\n",
      "         [[-4.1084, -5.2812, -4.8491],\n",
      "          [-4.5249, -5.2921, -4.7213],\n",
      "          [-4.4597, -4.1702, -5.9216]],\n",
      "\n",
      "         [[-4.6472, -4.4557, -7.2130],\n",
      "          [-7.5295, -6.2885, -4.2154],\n",
      "          [-4.5591, -4.4380, -4.5613]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.4212, -4.3814, -6.2654],\n",
      "          [-5.2409, -4.9268, -4.3706],\n",
      "          [-4.2094, -5.0594, -4.7448]],\n",
      "\n",
      "         [[-4.1042, -4.4071, -4.1265],\n",
      "          [-4.1616, -4.1580, -4.2280],\n",
      "          [-4.5427, -4.3313, -4.4009]],\n",
      "\n",
      "         [[-5.4502, -4.6675, -5.7618],\n",
      "          [-6.0163, -4.5448, -4.5029],\n",
      "          [-4.2505, -5.1605, -4.9706]]]], device='cuda:0')), ('module_list.0.posterior_params.2.scale_alphas_log', tensor([[[[-2.9027, -3.1765, -1.8186],\n",
      "          [-2.0010, -2.1367, -2.8437],\n",
      "          [-2.0727, -2.0095, -2.2420]],\n",
      "\n",
      "         [[-3.2733, -1.6348, -1.7445],\n",
      "          [-2.8132, -3.1815, -2.0431],\n",
      "          [-1.9943, -2.1886, -1.8663]],\n",
      "\n",
      "         [[-2.3995, -1.4811, -1.6496],\n",
      "          [-2.0029, -2.0383, -1.6856],\n",
      "          [-2.1883, -3.0176, -2.0423]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4137, -2.6287, -2.0827],\n",
      "          [-2.0580, -2.5595, -1.8611],\n",
      "          [-3.2885, -2.2321, -1.4986]],\n",
      "\n",
      "         [[-1.8708, -2.7482, -3.4150],\n",
      "          [-1.8256, -2.6590, -3.3792],\n",
      "          [-1.9272, -1.9146, -2.9028]],\n",
      "\n",
      "         [[-1.4950, -3.0938, -2.2738],\n",
      "          [-3.0456, -2.3813, -2.3133],\n",
      "          [-3.3432, -1.4709, -3.2521]]],\n",
      "\n",
      "\n",
      "        [[[-2.0798, -2.2833, -3.0442],\n",
      "          [-2.8234, -2.3432, -3.2192],\n",
      "          [-3.1337, -2.3670, -2.7544]],\n",
      "\n",
      "         [[-3.3680, -1.7232, -3.3753],\n",
      "          [-2.4777, -2.7981, -1.7649],\n",
      "          [-2.8648, -2.8095, -2.6137]],\n",
      "\n",
      "         [[-2.2355, -2.8331, -1.6104],\n",
      "          [-3.2719, -3.1793, -2.7915],\n",
      "          [-1.9414, -2.9227, -3.0779]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8682, -2.3126, -1.9213],\n",
      "          [-2.8627, -3.2399, -1.7122],\n",
      "          [-1.8666, -2.7817, -1.8911]],\n",
      "\n",
      "         [[-2.5635, -1.9620, -3.3148],\n",
      "          [-1.6758, -3.2333, -3.3801],\n",
      "          [-2.9123, -1.6472, -3.0173]],\n",
      "\n",
      "         [[-2.6704, -2.1980, -2.7254],\n",
      "          [-2.1655, -2.1764, -2.6433],\n",
      "          [-2.3406, -3.2941, -1.6926]]],\n",
      "\n",
      "\n",
      "        [[[-1.9834, -2.1860, -3.4417],\n",
      "          [-3.1744, -1.8720, -2.0006],\n",
      "          [-2.6756, -2.0601, -3.0397]],\n",
      "\n",
      "         [[-2.6550, -2.7163, -2.5833],\n",
      "          [-2.6113, -3.3631, -3.1318],\n",
      "          [-2.7233, -2.1933, -2.2543]],\n",
      "\n",
      "         [[-2.9365, -2.9629, -3.0840],\n",
      "          [-2.7588, -3.0139, -2.9350],\n",
      "          [-2.5523, -1.6324, -3.2073]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7703, -3.1818, -3.3893],\n",
      "          [-2.4395, -2.1524, -3.3657],\n",
      "          [-2.0656, -2.3280, -2.8312]],\n",
      "\n",
      "         [[-2.1194, -3.4132, -2.0629],\n",
      "          [-2.0176, -2.6345, -3.1633],\n",
      "          [-3.3234, -2.0473, -1.7857]],\n",
      "\n",
      "         [[-1.6341, -1.9836, -2.8559],\n",
      "          [-2.0917, -2.3373, -2.4369],\n",
      "          [-2.4107, -3.3237, -1.8982]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.0919, -2.0308, -2.8131],\n",
      "          [-3.3092, -1.5351, -1.5684],\n",
      "          [-1.5192, -1.7451, -3.3497]],\n",
      "\n",
      "         [[-3.0697, -1.6451, -3.3215],\n",
      "          [-3.2596, -2.3897, -1.6913],\n",
      "          [-2.5563, -3.0545, -3.2820]],\n",
      "\n",
      "         [[-2.6075, -1.9977, -2.6795],\n",
      "          [-1.4739, -1.7542, -3.0725],\n",
      "          [-2.6733, -2.4163, -1.6912]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1445, -1.8961, -3.2182],\n",
      "          [-3.3740, -1.8673, -1.7777],\n",
      "          [-2.1306, -2.7517, -2.2103]],\n",
      "\n",
      "         [[-3.3742, -1.8693, -2.8180],\n",
      "          [-2.4707, -3.3560, -2.5173],\n",
      "          [-3.1282, -2.2164, -2.0457]],\n",
      "\n",
      "         [[-2.0540, -2.8550, -3.3660],\n",
      "          [-1.7791, -2.5949, -2.4194],\n",
      "          [-2.2373, -1.6468, -1.6768]]],\n",
      "\n",
      "\n",
      "        [[[-2.9449, -2.0436, -2.9840],\n",
      "          [-2.9414, -3.1276, -3.1406],\n",
      "          [-2.1657, -3.4221, -2.3664]],\n",
      "\n",
      "         [[-2.5326, -2.4150, -2.0522],\n",
      "          [-2.0702, -1.9128, -3.1835],\n",
      "          [-2.6952, -3.2303, -3.1654]],\n",
      "\n",
      "         [[-1.9809, -1.5246, -3.3886],\n",
      "          [-1.8245, -3.2746, -3.1702],\n",
      "          [-1.8541, -3.2559, -1.9116]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6581, -2.0739, -2.2248],\n",
      "          [-3.0379, -1.5303, -2.0161],\n",
      "          [-3.1879, -2.5360, -3.1005]],\n",
      "\n",
      "         [[-2.4607, -1.4696, -2.9895],\n",
      "          [-1.6676, -2.1962, -3.1573],\n",
      "          [-1.9870, -2.0105, -1.8804]],\n",
      "\n",
      "         [[-1.4711, -1.6702, -2.5683],\n",
      "          [-1.6911, -2.4352, -3.3607],\n",
      "          [-2.5179, -2.9967, -2.1629]]],\n",
      "\n",
      "\n",
      "        [[[-2.5507, -2.4328, -2.8459],\n",
      "          [-2.6406, -1.9164, -2.5868],\n",
      "          [-2.5266, -1.7563, -2.3590]],\n",
      "\n",
      "         [[-3.2493, -3.4597, -3.1626],\n",
      "          [-1.6325, -2.7686, -2.3004],\n",
      "          [-3.3834, -1.5570, -2.4527]],\n",
      "\n",
      "         [[-1.7849, -2.6773, -2.5766],\n",
      "          [-2.0843, -2.9883, -3.0129],\n",
      "          [-2.7736, -3.3909, -1.6421]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8356, -1.7361, -2.7961],\n",
      "          [-2.4395, -2.0150, -3.4110],\n",
      "          [-2.8148, -1.8766, -2.5169]],\n",
      "\n",
      "         [[-3.0109, -1.9607, -2.5613],\n",
      "          [-2.2352, -3.1708, -3.3421],\n",
      "          [-2.4779, -2.5896, -1.9093]],\n",
      "\n",
      "         [[-1.8677, -3.1321, -1.9809],\n",
      "          [-1.8500, -2.6939, -1.9791],\n",
      "          [-3.3189, -2.6765, -1.7129]]]], device='cuda:0')), ('module_list.0.posterior_params.2.scale_mus', tensor([[[[0.9897, 1.0103, 0.9944],\n",
      "          [1.0175, 0.9941, 0.9962],\n",
      "          [1.0164, 0.9977, 1.0117]],\n",
      "\n",
      "         [[1.0046, 1.0119, 0.9939],\n",
      "          [1.0110, 1.0038, 1.0130],\n",
      "          [1.0062, 1.0076, 0.9892]],\n",
      "\n",
      "         [[0.9808, 1.0192, 0.9826],\n",
      "          [1.0066, 1.0097, 0.9880],\n",
      "          [1.0123, 1.0148, 0.9941]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.9881, 0.9800, 1.0129],\n",
      "          [0.9838, 0.9922, 1.0120],\n",
      "          [1.0162, 1.0112, 1.0195]],\n",
      "\n",
      "         [[0.9974, 1.0031, 0.9995],\n",
      "          [0.9983, 1.0055, 0.9988],\n",
      "          [1.0002, 1.0003, 1.0006]],\n",
      "\n",
      "         [[1.0203, 0.9965, 1.0024],\n",
      "          [0.9839, 1.0113, 1.0019],\n",
      "          [1.0082, 0.9901, 0.9897]]],\n",
      "\n",
      "\n",
      "        [[[0.9844, 1.0189, 0.9838],\n",
      "          [1.0216, 0.9760, 0.9838],\n",
      "          [0.9788, 1.0203, 1.0135]],\n",
      "\n",
      "         [[1.0195, 0.9874, 0.9842],\n",
      "          [0.9908, 1.0173, 0.9921],\n",
      "          [1.0100, 1.0012, 0.9856]],\n",
      "\n",
      "         [[1.0174, 1.0155, 1.0060],\n",
      "          [1.0124, 0.9852, 0.9888],\n",
      "          [1.0132, 1.0040, 0.9858]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.0147, 0.9999, 0.9829],\n",
      "          [0.9966, 1.0054, 0.9861],\n",
      "          [0.9957, 1.0046, 1.0185]],\n",
      "\n",
      "         [[1.0060, 0.9986, 1.0127],\n",
      "          [0.9985, 1.0136, 0.9935],\n",
      "          [0.9994, 0.9994, 0.9981]],\n",
      "\n",
      "         [[0.9777, 1.0217, 0.9893],\n",
      "          [0.9967, 1.0179, 0.9841],\n",
      "          [0.9774, 1.0205, 0.9841]]],\n",
      "\n",
      "\n",
      "        [[[1.0154, 1.0081, 1.0005],\n",
      "          [1.0029, 0.9929, 1.0163],\n",
      "          [1.0087, 1.0186, 1.0185]],\n",
      "\n",
      "         [[0.9867, 1.0052, 0.9821],\n",
      "          [0.9944, 1.0207, 1.0075],\n",
      "          [1.0149, 1.0173, 1.0181]],\n",
      "\n",
      "         [[1.0164, 0.9814, 1.0197],\n",
      "          [0.9821, 0.9791, 0.9886],\n",
      "          [1.0174, 0.9980, 0.9947]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.9838, 1.0138, 0.9810],\n",
      "          [0.9965, 1.0206, 1.0234],\n",
      "          [1.0082, 0.9891, 1.0153]],\n",
      "\n",
      "         [[0.9922, 0.9956, 1.0047],\n",
      "          [1.0025, 0.9968, 1.0039],\n",
      "          [0.9898, 0.9940, 1.0049]],\n",
      "\n",
      "         [[0.9790, 0.9778, 0.9907],\n",
      "          [0.9810, 1.0041, 0.9932],\n",
      "          [1.0060, 0.9924, 1.0140]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.0093, 1.0010, 0.9822],\n",
      "          [0.9759, 1.0058, 1.0075],\n",
      "          [1.0087, 0.9791, 0.9748]],\n",
      "\n",
      "         [[1.0128, 0.9938, 1.0089],\n",
      "          [0.9962, 1.0106, 0.9859],\n",
      "          [1.0194, 1.0038, 0.9881]],\n",
      "\n",
      "         [[0.9892, 0.9820, 1.0019],\n",
      "          [0.9780, 0.9838, 1.0220],\n",
      "          [0.9821, 1.0201, 1.0182]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.9830, 0.9795, 1.0053],\n",
      "          [0.9781, 1.0216, 0.9915],\n",
      "          [0.9966, 0.9893, 1.0097]],\n",
      "\n",
      "         [[0.9930, 0.9970, 0.9881],\n",
      "          [0.9997, 0.9955, 1.0010],\n",
      "          [0.9942, 0.9869, 1.0049]],\n",
      "\n",
      "         [[1.0058, 0.9871, 0.9836],\n",
      "          [0.9785, 0.9782, 1.0226],\n",
      "          [1.0043, 0.9920, 0.9961]]],\n",
      "\n",
      "\n",
      "        [[[0.9947, 1.0083, 0.9990],\n",
      "          [0.9947, 1.0020, 0.9884],\n",
      "          [0.9898, 0.9891, 1.0073]],\n",
      "\n",
      "         [[1.0009, 0.9997, 0.9996],\n",
      "          [1.0232, 0.9879, 1.0152],\n",
      "          [0.9932, 1.0150, 0.9861]],\n",
      "\n",
      "         [[1.0124, 1.0123, 1.0149],\n",
      "          [1.0133, 1.0033, 1.0046],\n",
      "          [0.9872, 0.9930, 0.9893]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.0116, 0.9825, 1.0033],\n",
      "          [0.9879, 1.0033, 0.9976],\n",
      "          [0.9887, 1.0227, 0.9983]],\n",
      "\n",
      "         [[0.9955, 0.9934, 1.0007],\n",
      "          [0.9903, 1.0100, 1.0038],\n",
      "          [0.9941, 1.0010, 0.9992]],\n",
      "\n",
      "         [[0.9898, 0.9856, 0.9894],\n",
      "          [0.9997, 0.9950, 1.0048],\n",
      "          [1.0052, 1.0010, 0.9992]]],\n",
      "\n",
      "\n",
      "        [[[1.0133, 0.9882, 1.0111],\n",
      "          [1.0068, 0.9844, 0.9902],\n",
      "          [1.0043, 0.9829, 1.0007]],\n",
      "\n",
      "         [[0.9943, 1.0057, 1.0127],\n",
      "          [1.0141, 0.9862, 0.9934],\n",
      "          [1.0028, 1.0058, 0.9996]],\n",
      "\n",
      "         [[1.0149, 1.0095, 0.9892],\n",
      "          [1.0114, 0.9890, 1.0103],\n",
      "          [0.9934, 0.9983, 0.9991]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.9871, 0.9834, 0.9985],\n",
      "          [1.0117, 0.9924, 0.9962],\n",
      "          [0.9776, 0.9846, 0.9884]],\n",
      "\n",
      "         [[0.9948, 0.9972, 0.9969],\n",
      "          [0.9985, 0.9999, 0.9991],\n",
      "          [1.0040, 0.9948, 0.9947]],\n",
      "\n",
      "         [[1.0148, 1.0132, 0.9871],\n",
      "          [0.9876, 1.0054, 1.0129],\n",
      "          [1.0071, 0.9981, 0.9849]]]], device='cuda:0')), ('module_list.0.posterior_params.3.param_mus', tensor([-1.3675e-05,  3.6191e-05, -2.8626e-05,  1.3600e-05,  5.8396e-06,\n",
      "         1.2092e-04,  1.7517e-05,  6.1901e-07, -1.4434e-05,  6.1941e-05,\n",
      "         5.3204e-05, -2.2353e-05, -1.9727e-05,  5.1075e-05,  3.6460e-06,\n",
      "         3.4245e-05, -1.7955e-05,  1.1759e-05,  8.5117e-06,  6.4907e-06,\n",
      "        -3.4984e-06,  1.3426e-05, -2.0614e-05, -6.7045e-06,  2.0095e-07,\n",
      "        -2.9300e-05, -7.6743e-06,  3.7508e-05, -1.6321e-05,  2.1065e-05,\n",
      "         1.4926e-05,  4.1130e-05,  8.9225e-05,  3.2987e-05, -6.4706e-05,\n",
      "         3.3843e-05,  5.3134e-06,  3.5223e-05,  1.5761e-05, -1.1158e-05,\n",
      "         6.3431e-05, -5.9516e-05,  1.9982e-05, -1.2703e-06,  7.5484e-05,\n",
      "         1.6941e-05,  1.8051e-04,  3.0665e-05,  5.6479e-05, -4.6766e-05,\n",
      "         4.3595e-05, -3.8435e-05, -3.7263e-05, -1.3595e-04, -5.2845e-05,\n",
      "        -6.0033e-06, -1.3097e-05, -7.8922e-06,  7.0953e-07,  2.2126e-06,\n",
      "        -1.1941e-05,  1.9430e-05,  4.0778e-06,  2.2884e-05], device='cuda:0')), ('module_list.0.posterior_params.3.param_std_log', tensor([-4.6329, -4.7048, -4.8204, -5.1808, -4.2200, -4.1367, -4.4752, -4.2638,\n",
      "        -4.2800, -5.9466, -6.1655, -4.8182, -6.4267, -6.7604, -4.3847, -4.7129,\n",
      "        -6.6825, -4.2083, -5.0966, -4.0812, -4.3230, -9.0457, -5.3733, -4.4808,\n",
      "        -6.1630, -5.1324, -4.2157, -4.1638, -5.4418, -4.3873, -4.5671, -4.4069,\n",
      "        -5.0601, -4.4625, -4.2045, -4.5176, -4.1274, -4.5064, -4.4529, -4.5499,\n",
      "        -4.3959, -4.9638, -4.3302, -8.3069, -4.6865, -4.8943, -4.1730, -4.1640,\n",
      "        -4.5224, -4.6641, -4.9044, -4.6127, -4.1384, -4.6067, -4.6450, -4.4136,\n",
      "        -4.2111, -4.2415, -5.1994, -5.1779, -5.9756, -6.9464, -4.1643, -5.0457],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.3.scale_alphas_log', tensor([-2.9016, -1.9239, -1.6896, -1.5281, -2.9227, -2.0680, -1.8946, -1.6426,\n",
      "        -2.3780, -2.6794, -1.5340, -2.9062, -1.9918, -1.8627, -2.4514, -2.6900,\n",
      "        -2.7655, -3.3402, -2.5627, -1.9509, -2.0325, -1.5763, -3.0221, -3.3830,\n",
      "        -2.4564, -2.1571, -2.5340, -2.1054, -2.0292, -2.2108, -2.6625, -2.7619,\n",
      "        -1.5064, -1.5517, -1.6856, -2.8830, -1.8870, -3.1858, -2.4289, -1.7730,\n",
      "        -1.6051, -2.7785, -2.2097, -2.3171, -2.0395, -2.8545, -2.8967, -1.7947,\n",
      "        -3.1318, -2.5243, -1.9748, -1.4684, -2.4934, -3.0428, -2.1706, -3.3056,\n",
      "        -1.8300, -2.3662, -2.3089, -1.8573, -2.2349, -2.5968, -1.7866, -2.9300],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.3.scale_mus', tensor([0.9914, 1.0041, 0.9891, 1.0042, 1.0124, 1.0077, 0.9936, 1.0182, 0.9918,\n",
      "        1.0263, 0.9857, 0.9776, 0.9814, 0.9861, 0.9824, 0.9917, 1.0066, 0.9891,\n",
      "        0.9841, 0.9908, 0.9972, 0.9988, 0.9968, 1.0058, 0.9922, 1.0162, 0.9980,\n",
      "        0.9885, 0.9973, 1.0338, 0.9980, 0.9979, 0.9924, 0.9909, 1.0169, 1.0072,\n",
      "        1.0091, 1.0006, 1.0089, 0.9946, 1.0084, 1.0003, 1.0040, 0.9883, 1.0057,\n",
      "        1.0047, 1.0123, 0.9891, 0.9828, 0.9954, 0.9914, 0.9788, 1.0039, 0.9879,\n",
      "        1.0015, 1.0166, 0.9976, 0.9812, 1.0096, 0.9968, 1.0084, 1.0122, 1.0169,\n",
      "        1.0144], device='cuda:0')), ('module_list.0.posterior_params.4.param_mus', tensor([[ 7.7214e-07,  6.4135e-07, -3.5022e-08,  ...,  4.4236e-07,\n",
      "          5.7630e-07,  4.4649e-07],\n",
      "        [ 8.9819e-07,  1.0495e-06,  5.8324e-07,  ...,  2.0223e-07,\n",
      "          1.2570e-07, -2.3573e-07],\n",
      "        [-8.2865e-07,  1.2426e-06, -8.8034e-07,  ...,  2.9729e-07,\n",
      "          1.7603e-07,  1.0326e-07],\n",
      "        ...,\n",
      "        [ 2.8484e-07,  5.6520e-07,  7.1044e-07,  ...,  3.4535e-07,\n",
      "          2.7041e-07, -1.0691e-07],\n",
      "        [ 4.3289e-07,  1.1174e-06,  4.8300e-07,  ..., -3.0016e-07,\n",
      "          1.3107e-06, -4.2176e-07],\n",
      "        [-8.7451e-07, -1.5636e-06, -5.5524e-07,  ..., -1.9713e-08,\n",
      "         -4.4409e-08, -9.6311e-08]], device='cuda:0')), ('module_list.0.posterior_params.4.param_std_log', tensor([[-4.8102, -4.3481, -4.5148,  ..., -5.7909, -4.1275, -6.8039],\n",
      "        [-4.9555, -4.3504, -4.1693,  ..., -4.1622, -4.6549, -4.2014],\n",
      "        [-4.1751, -4.9333, -6.2750,  ..., -4.7329, -4.3478, -4.5356],\n",
      "        ...,\n",
      "        [-5.3807, -5.8564, -4.4367,  ..., -5.0838, -6.4157, -6.4450],\n",
      "        [-4.3783, -5.8415, -4.3810,  ..., -6.1343, -4.1599, -4.3801],\n",
      "        [-7.2108, -4.2671, -7.7434,  ..., -6.2028, -4.6343, -5.0981]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.4.scale_alphas_log', tensor([[-2.8528, -2.3756, -3.3441,  ..., -1.4779, -1.6322, -2.9854],\n",
      "        [-1.9694, -1.6667, -1.8622,  ..., -2.5192, -3.4126, -2.7231],\n",
      "        [-2.8640, -1.9590, -2.1168,  ..., -2.8486, -1.6212, -1.6197],\n",
      "        ...,\n",
      "        [-2.7906, -2.5162, -2.3845,  ..., -2.2912, -1.6506, -3.3543],\n",
      "        [-3.3989, -2.6947, -2.4611,  ..., -2.0967, -2.7224, -3.3147],\n",
      "        [-1.4934, -2.2239, -3.0375,  ..., -2.9213, -2.4150, -3.4128]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.4.scale_mus', tensor([[1.0050, 0.9971, 1.0083,  ..., 1.0111, 0.9970, 0.9974],\n",
      "        [1.0120, 1.0088, 0.9865,  ..., 1.0043, 1.0038, 0.9992],\n",
      "        [1.0065, 0.9929, 0.9841,  ..., 0.9833, 1.0105, 0.9926],\n",
      "        ...,\n",
      "        [0.9885, 0.9916, 0.9901,  ..., 0.9946, 0.9923, 1.0069],\n",
      "        [0.9899, 1.0102, 0.9875,  ..., 1.0137, 1.0016, 1.0026],\n",
      "        [0.9992, 0.9861, 1.0185,  ..., 0.9928, 1.0147, 0.9984]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.5.param_mus', tensor([ 1.0126e-04, -3.0732e-05,  1.5005e-04, -1.3251e-05,  3.1156e-05,\n",
      "        -3.1162e-04,  1.1707e-05, -3.8285e-05, -6.0643e-05, -5.2154e-05,\n",
      "         3.5783e-06,  3.0618e-05, -1.0358e-04,  9.0169e-05, -4.5457e-05,\n",
      "        -2.7410e-04, -4.4688e-05,  1.1500e-05,  3.1372e-06,  2.3341e-05,\n",
      "         3.8841e-05, -2.8488e-05, -2.3813e-04,  3.3488e-05,  4.6640e-05,\n",
      "         7.1639e-06, -1.3089e-04,  2.8863e-05, -2.1503e-05,  1.2085e-04,\n",
      "         3.9436e-05,  3.8132e-05, -9.7394e-05, -3.8975e-05,  1.0530e-04,\n",
      "         7.0130e-05, -1.3494e-04,  2.3243e-05,  7.5965e-05, -7.1859e-05,\n",
      "        -1.3304e-04,  6.2286e-05, -6.2110e-05,  3.4751e-05, -1.4015e-05,\n",
      "         1.3210e-04, -4.8236e-05,  6.6013e-05,  2.1965e-05, -1.3317e-05,\n",
      "         1.7659e-05,  2.4720e-04,  5.6599e-05,  6.9831e-05,  3.6818e-05,\n",
      "        -5.4295e-05,  8.1837e-05,  1.4124e-04,  3.1197e-05,  2.9947e-06,\n",
      "        -2.4051e-04,  4.4384e-05, -6.4361e-05,  2.5019e-05,  2.7385e-05,\n",
      "         5.4480e-05,  4.1333e-05,  8.3446e-05,  1.1698e-04, -1.3213e-04,\n",
      "        -4.2699e-05, -5.5693e-05, -1.3834e-04,  4.8278e-05,  8.8281e-06,\n",
      "         1.2911e-04,  2.3370e-05, -3.8703e-06, -1.7124e-04, -1.1162e-05,\n",
      "         1.2662e-04,  8.0303e-05, -7.3462e-05, -2.9224e-05,  8.2819e-05,\n",
      "         1.0725e-04,  5.1070e-05, -1.4058e-05,  6.0345e-05,  1.8120e-06,\n",
      "         1.8212e-04,  1.8808e-05, -7.8314e-05, -1.5819e-05,  1.6749e-05,\n",
      "        -1.0087e-04, -1.1775e-04,  6.0418e-05, -1.4325e-04, -1.0287e-04,\n",
      "         8.3538e-05,  1.6551e-05,  2.6679e-05,  2.2021e-05,  1.2118e-04,\n",
      "        -5.6805e-06, -5.1861e-05, -1.2939e-05,  4.7907e-05,  5.1091e-05,\n",
      "        -6.8882e-05, -5.8546e-05, -1.3051e-04, -5.1336e-05, -9.8631e-05,\n",
      "        -2.7002e-05, -2.3968e-05,  1.5682e-04, -1.5217e-05, -1.6092e-04,\n",
      "         2.0477e-05,  5.7489e-05,  2.8222e-04, -8.6123e-05, -1.8131e-05,\n",
      "         3.0935e-05, -6.6018e-05, -4.4375e-05], device='cuda:0')), ('module_list.0.posterior_params.5.param_std_log', tensor([-4.6252, -4.7416, -7.0787, -8.7415, -5.3575, -5.2833, -4.7366, -6.3542,\n",
      "        -4.8557, -6.1012, -4.3770, -4.7718, -6.0773, -4.8643, -4.7288, -4.6637,\n",
      "        -5.2612, -4.1396, -5.4804, -4.4581, -8.0171, -4.4094, -4.9519, -4.0911,\n",
      "        -4.3617, -4.8610, -6.3570, -4.8475, -6.5148, -4.8297, -4.6059, -4.1451,\n",
      "        -4.9506, -4.1181, -6.4814, -4.3216, -4.4425, -4.9607, -7.5173, -4.3134,\n",
      "        -4.6068, -4.1120, -6.2206, -4.2715, -4.4058, -4.1391, -5.5679, -4.5191,\n",
      "        -5.2667, -5.7917, -4.6578, -4.8200, -4.3735, -5.7690, -4.1738, -4.8715,\n",
      "        -4.2083, -4.5068, -5.6779, -4.5627, -5.6629, -5.0279, -5.1459, -8.4292,\n",
      "        -7.8994, -5.7681, -4.1163, -5.4181, -4.1041, -4.8459, -4.6583, -4.1869,\n",
      "        -5.6251, -4.1555, -5.8078, -5.2061, -4.8658, -5.0538, -4.1063, -4.5862,\n",
      "        -4.2972, -4.8337, -5.5609, -5.1165, -4.2063, -7.8278, -4.6987, -7.6644,\n",
      "        -5.8072, -4.6641, -4.5253, -4.7158, -5.0862, -4.9425, -5.1011, -5.3184,\n",
      "        -4.2736, -5.0045, -4.7809, -4.3939, -4.5215, -5.0803, -4.2563, -9.5756,\n",
      "        -8.0862, -9.1523, -5.1018, -4.2555, -6.9762, -4.1255, -4.9667, -7.7900,\n",
      "        -8.0893, -4.2488, -6.8200, -4.3719, -4.4819, -4.2120, -4.8147, -4.2613,\n",
      "        -4.3823, -8.1299, -4.1724, -7.5255, -5.7071, -6.9015, -4.5191, -4.8045],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.5.scale_alphas_log', tensor([-1.8258, -2.8037, -2.3154, -2.5535, -2.4260, -3.2006, -3.2061, -2.4725,\n",
      "        -1.6093, -2.5312, -2.1329, -2.2615, -2.7024, -2.4028, -1.4727, -2.7177,\n",
      "        -2.0055, -2.8505, -3.1376, -3.0867, -2.1756, -2.2197, -3.3985, -3.4323,\n",
      "        -2.9009, -2.1536, -1.4856, -1.9881, -2.9202, -1.5835, -2.1354, -1.7681,\n",
      "        -3.4036, -3.3131, -2.9370, -1.8758, -2.1885, -2.0978, -2.5003, -1.7644,\n",
      "        -2.8572, -2.7915, -2.7250, -2.1611, -3.0477, -3.2371, -1.5148, -1.5486,\n",
      "        -1.4769, -1.8454, -1.9769, -2.3484, -1.5881, -2.4532, -1.8776, -2.2279,\n",
      "        -3.3724, -2.6801, -1.5402, -3.2540, -3.4385, -2.3128, -3.0979, -1.4822,\n",
      "        -1.5370, -2.1676, -2.4254, -2.2733, -2.3382, -3.2384, -2.5028, -3.0731,\n",
      "        -3.0505, -2.9951, -3.3269, -3.3321, -2.2167, -3.4510, -2.1434, -2.6928,\n",
      "        -2.2668, -2.9750, -1.6458, -2.5225, -1.6759, -3.3780, -3.1134, -2.9890,\n",
      "        -3.1368, -2.7823, -3.3227, -2.8655, -3.2959, -1.9201, -2.1885, -3.0100,\n",
      "        -2.8227, -2.5815, -3.1384, -1.4715, -3.0460, -3.2832, -2.9988, -1.9474,\n",
      "        -2.1300, -3.1837, -3.3593, -2.3948, -2.3995, -2.4306, -1.8495, -2.8879,\n",
      "        -2.3656, -1.9714, -2.0148, -3.0182, -3.4135, -2.9672, -1.6794, -2.2252,\n",
      "        -2.8059, -1.8527, -2.3326, -1.8732, -1.8646, -2.6823, -3.2207, -3.0711],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.5.scale_mus', tensor([0.9966, 1.0018, 1.0171, 0.9840, 1.0243, 0.9820, 0.9978, 0.9839, 1.0247,\n",
      "        0.9964, 0.9772, 0.9805, 1.0006, 0.9892, 1.0089, 1.0108, 1.0089, 1.0086,\n",
      "        1.0179, 0.9772, 0.9955, 0.9582, 1.0199, 0.9919, 1.0065, 1.0193, 0.9998,\n",
      "        1.0132, 1.0151, 0.9879, 0.9956, 0.9870, 1.0043, 1.0602, 0.9978, 0.9688,\n",
      "        0.9977, 1.0089, 1.0004, 0.9920, 1.0249, 1.0322, 1.0159, 1.0333, 1.0048,\n",
      "        0.9916, 0.9883, 0.9725, 0.9902, 1.0037, 0.9904, 0.9821, 0.9497, 1.0127,\n",
      "        0.9723, 1.0165, 0.9992, 1.0515, 0.9752, 1.0041, 1.0005, 1.0017, 0.9927,\n",
      "        1.0174, 1.0081, 1.0002, 1.0008, 1.0202, 0.9728, 0.9805, 1.0041, 1.0524,\n",
      "        0.9945, 0.9791, 0.9945, 0.9886, 1.0314, 0.9905, 1.0140, 0.9556, 0.9997,\n",
      "        1.0148, 1.0035, 1.0124, 1.0203, 1.0040, 1.0240, 1.0112, 0.9894, 0.9845,\n",
      "        0.9847, 1.0253, 0.9798, 1.0110, 1.0090, 1.0178, 1.0147, 1.0022, 1.0200,\n",
      "        1.0122, 0.9956, 1.0105, 1.0046, 1.0102, 1.0152, 1.0189, 0.9958, 0.9959,\n",
      "        0.9817, 1.0151, 0.9883, 1.0125, 1.0058, 1.0168, 1.0149, 0.9910, 1.0131,\n",
      "        0.9894, 1.0053, 1.0352, 1.0159, 0.9858, 0.9567, 1.0043, 1.0134, 1.0092,\n",
      "        1.0003, 0.9996], device='cuda:0')), ('module_list.0.posterior_params.6.param_mus', tensor([[-4.4623e-05, -4.2848e-06, -1.3377e-06,  ..., -1.3500e-06,\n",
      "         -7.3083e-06, -3.6073e-05],\n",
      "        [ 4.5588e-05,  4.2054e-05,  5.4489e-06,  ...,  1.4135e-05,\n",
      "          1.3749e-04,  3.6736e-05],\n",
      "        [ 9.2180e-06,  8.7745e-06,  8.5275e-07,  ..., -9.4198e-07,\n",
      "          1.1030e-05,  4.4352e-06],\n",
      "        ...,\n",
      "        [ 8.0495e-06,  9.1625e-06,  4.5206e-06,  ...,  2.8083e-06,\n",
      "         -2.4002e-06, -1.1862e-06],\n",
      "        [-2.3887e-07, -1.3081e-05,  3.0694e-06,  ..., -2.4738e-05,\n",
      "         -1.0163e-06, -2.0965e-06],\n",
      "        [ 1.4343e-07,  1.0473e-05, -7.7101e-06,  ...,  1.5385e-06,\n",
      "         -2.5420e-05,  4.1828e-06]], device='cuda:0')), ('module_list.0.posterior_params.6.param_std_log', tensor([[-4.1813, -4.4268, -4.6795,  ..., -4.2055, -4.8927, -4.1284],\n",
      "        [-4.4651, -4.3323, -4.2909,  ..., -6.2008, -5.7658, -4.8787],\n",
      "        [-5.3534, -5.4736, -4.0873,  ..., -4.3633, -5.3206, -5.3694],\n",
      "        ...,\n",
      "        [-5.1401, -4.0772, -4.3220,  ..., -5.2889, -4.0800, -4.4325],\n",
      "        [-5.3501, -4.9262, -4.6256,  ..., -4.2371, -5.1621, -4.1631],\n",
      "        [-4.6956, -5.2086, -4.6908,  ..., -8.0793, -6.1039, -5.2715]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.6.scale_alphas_log', tensor([[-2.9681, -2.9959, -1.9126,  ..., -2.0726, -3.3883, -2.8816],\n",
      "        [-2.6644, -3.1065, -3.1406,  ..., -1.4957, -1.7779, -2.0162],\n",
      "        [-2.4882, -2.7269, -3.2243,  ..., -2.2977, -2.0736, -1.8672],\n",
      "        ...,\n",
      "        [-2.1892, -2.0337, -2.5144,  ..., -2.5039, -2.4651, -1.9543],\n",
      "        [-1.6062, -3.1331, -3.2969,  ..., -2.7061, -3.1160, -2.2386],\n",
      "        [-2.2411, -1.9841, -1.9708,  ..., -2.2110, -2.2385, -2.7110]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.6.scale_mus', tensor([[1.0064, 0.9998, 0.9989,  ..., 0.9959, 0.9961, 0.9966],\n",
      "        [0.9844, 0.9935, 0.9934,  ..., 1.0124, 1.0021, 1.0163],\n",
      "        [1.0114, 1.0115, 0.9850,  ..., 0.9863, 0.9913, 1.0208],\n",
      "        ...,\n",
      "        [0.9898, 1.0150, 0.9852,  ..., 0.9891, 1.0003, 1.0191],\n",
      "        [0.9919, 1.0006, 1.0130,  ..., 0.9978, 1.0142, 0.9978],\n",
      "        [1.0035, 1.0058, 1.0115,  ..., 1.0091, 1.0037, 1.0011]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.7.param_mus', tensor([-0.0019,  0.0134,  0.0008, -0.0007, -0.0009, -0.0078, -0.0081,  0.0014,\n",
      "        -0.0005,  0.0020], device='cuda:0')), ('module_list.0.posterior_params.7.param_std_log', tensor([-5.3637, -4.3256, -5.3654, -5.4082, -4.2301, -4.4158, -5.8792, -4.1335,\n",
      "        -4.1724, -4.6708], device='cuda:0')), ('module_list.0.posterior_params.7.scale_alphas_log', tensor([-1.8752, -2.6005, -3.3077, -3.1848, -3.1316, -2.2628, -2.7549, -1.4825,\n",
      "        -2.6679, -3.3542], device='cuda:0')), ('module_list.0.posterior_params.7.scale_mus', tensor([1.0652, 1.1322, 1.0039, 0.9870, 0.9223, 1.1191, 1.2574, 0.8067, 0.8125,\n",
      "        0.9759], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_module.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_bayes.pt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(409356., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.prune({'threshold': 1.9})\n",
    "print(model.prune_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47343., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.prune([{'threshold': -2.2}])\n",
    "print(model.prune_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = Classifier()\n",
    "var_module = LogUniformVarLayer(module)\n",
    "model = VarBayesNet(module, nn.ModuleList([var_module]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('module_list.0.posterior_params.0.param_mus',\n",
       "              tensor([[[[-0.2737, -0.0213, -0.1784],\n",
       "                        [-0.0449,  0.1339,  0.2884],\n",
       "                        [ 0.1757,  0.2454,  0.0318]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2829,  0.1125,  0.2672],\n",
       "                        [-0.0329,  0.1954,  0.2326],\n",
       "                        [-0.0857, -0.2534,  0.0893]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1525,  0.0669, -0.2533],\n",
       "                        [-0.1758,  0.1672,  0.1206],\n",
       "                        [ 0.0153,  0.1936, -0.3305]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0107,  0.3182,  0.2102],\n",
       "                        [-0.1029,  0.3132, -0.2125],\n",
       "                        [-0.2650,  0.0061,  0.2422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1922,  0.1445, -0.1445],\n",
       "                        [-0.1862, -0.1703,  0.1814],\n",
       "                        [-0.3061, -0.1629,  0.1818]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2469, -0.2962, -0.1922],\n",
       "                        [-0.1502, -0.0190, -0.1009],\n",
       "                        [ 0.1418,  0.0435, -0.2017]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2999,  0.2396,  0.0861],\n",
       "                        [-0.1399,  0.0275, -0.3024],\n",
       "                        [-0.1098, -0.1394, -0.2101]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0273,  0.2970, -0.2747],\n",
       "                        [ 0.1127,  0.2224,  0.0496],\n",
       "                        [-0.2127,  0.1349, -0.2917]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0222,  0.2411,  0.0425],\n",
       "                        [ 0.0817,  0.1037,  0.2716],\n",
       "                        [ 0.0878, -0.2382, -0.0517]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0719,  0.1895,  0.1076],\n",
       "                        [-0.1426, -0.1827,  0.3090],\n",
       "                        [-0.1734,  0.0608, -0.1394]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2088,  0.1865,  0.1586],\n",
       "                        [-0.1817, -0.1410, -0.1049],\n",
       "                        [-0.1832, -0.3061, -0.3109]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2269,  0.1814, -0.3188],\n",
       "                        [ 0.2725, -0.0902, -0.2374],\n",
       "                        [-0.1628, -0.2985, -0.0739]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2382, -0.0886,  0.2284],\n",
       "                        [ 0.0932, -0.0300,  0.1199],\n",
       "                        [-0.3036,  0.0679,  0.3242]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2995, -0.0269,  0.2335],\n",
       "                        [-0.2868,  0.1297,  0.2263],\n",
       "                        [-0.1365,  0.0827, -0.1368]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2408, -0.1476,  0.1649],\n",
       "                        [ 0.1636, -0.0114, -0.1543],\n",
       "                        [ 0.1516,  0.2401, -0.3093]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0533,  0.1382,  0.0024],\n",
       "                        [-0.1546,  0.2536, -0.2555],\n",
       "                        [-0.1677, -0.0555,  0.0449]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2179,  0.0416,  0.1664],\n",
       "                        [ 0.1895,  0.1240, -0.2714],\n",
       "                        [-0.0561, -0.2904,  0.1815]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0931, -0.2447, -0.1122],\n",
       "                        [ 0.2836, -0.3144,  0.2693],\n",
       "                        [ 0.0475,  0.0702,  0.2088]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2935, -0.0657,  0.2059],\n",
       "                        [-0.2644,  0.2140,  0.0178],\n",
       "                        [-0.0679, -0.2655, -0.0174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1912, -0.0838, -0.1078],\n",
       "                        [ 0.2290,  0.2124, -0.2783],\n",
       "                        [-0.0186,  0.2010, -0.1156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2628, -0.2447,  0.0938],\n",
       "                        [-0.1858, -0.2919, -0.2134],\n",
       "                        [ 0.2410, -0.0449,  0.1174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3145, -0.2647,  0.2348],\n",
       "                        [ 0.1423, -0.1619, -0.1704],\n",
       "                        [ 0.3221, -0.1983, -0.0801]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0133, -0.3084,  0.1228],\n",
       "                        [ 0.1514,  0.0796, -0.1055],\n",
       "                        [ 0.2269,  0.1001, -0.2295]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1243,  0.1812,  0.0307],\n",
       "                        [ 0.2902,  0.2480, -0.0722],\n",
       "                        [-0.1125,  0.2348,  0.0912]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2855,  0.0356,  0.2712],\n",
       "                        [ 0.3197, -0.0580,  0.0020],\n",
       "                        [-0.2933, -0.1005,  0.2072]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1050, -0.2946,  0.0811],\n",
       "                        [-0.0863,  0.2160, -0.2627],\n",
       "                        [-0.1286,  0.0596, -0.1345]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0546, -0.0362,  0.0594],\n",
       "                        [ 0.0646,  0.1745, -0.0352],\n",
       "                        [-0.1120, -0.0474,  0.0383]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1332, -0.2500, -0.1542],\n",
       "                        [-0.2412, -0.3166, -0.0210],\n",
       "                        [ 0.1060,  0.1158,  0.0057]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2678, -0.2166,  0.0712],\n",
       "                        [-0.0535,  0.1413,  0.2406],\n",
       "                        [-0.2855, -0.3059, -0.2075]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2055, -0.2482,  0.1404],\n",
       "                        [-0.2513, -0.1904,  0.1103],\n",
       "                        [-0.2845,  0.0184,  0.2082]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0582,  0.2715,  0.1728],\n",
       "                        [-0.1080,  0.1155,  0.1371],\n",
       "                        [ 0.2162, -0.0247, -0.2244]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1486,  0.0659,  0.1559],\n",
       "                        [-0.2081,  0.0449,  0.3216],\n",
       "                        [ 0.2564,  0.2344, -0.0866]]]])),\n",
       "             ('module_list.0.posterior_params.0.param_std_log',\n",
       "              tensor([[[[-7.6443, -6.8122, -6.2178],\n",
       "                        [-4.6537, -8.1042, -5.0853],\n",
       "                        [-6.9559, -4.9253, -4.6574]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.9750, -6.1978, -5.7079],\n",
       "                        [-5.8540, -7.7156, -6.2078],\n",
       "                        [-4.9556, -5.0383, -6.1048]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7616, -5.4980, -4.7636],\n",
       "                        [-4.9685, -8.0552, -6.3784],\n",
       "                        [-4.9320, -6.9730, -6.1062]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8593, -5.2212, -4.8359],\n",
       "                        [-4.9786, -7.6505, -5.0176],\n",
       "                        [-5.6760, -5.2133, -5.7229]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.5549, -5.6953, -7.5045],\n",
       "                        [-4.8243, -5.2325, -8.2682],\n",
       "                        [-4.7497, -5.2409, -6.0584]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.2319, -5.1681, -5.0143],\n",
       "                        [-4.6465, -4.7084, -6.2273],\n",
       "                        [-4.7883, -5.2719, -4.9517]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0582, -5.2466, -5.4416],\n",
       "                        [-5.1359, -5.2855, -5.4410],\n",
       "                        [-5.7903, -4.6311, -5.1965]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9802, -4.6867, -5.9103],\n",
       "                        [-4.9393, -7.2178, -5.2489],\n",
       "                        [-4.6243, -5.9567, -5.4351]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6969, -5.5580, -5.1405],\n",
       "                        [-4.7906, -5.6145, -7.0589],\n",
       "                        [-5.0275, -4.7744, -5.2552]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.2480, -6.9430, -4.8825],\n",
       "                        [-5.6597, -6.6762, -4.9689],\n",
       "                        [-5.1752, -4.9931, -5.0197]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6701, -4.8942, -5.5445],\n",
       "                        [-5.9894, -5.5842, -4.8125],\n",
       "                        [-5.2390, -4.8248, -6.3544]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0899, -6.3075, -5.0728],\n",
       "                        [-4.7244, -4.7276, -5.5322],\n",
       "                        [-6.5785, -5.2176, -8.2081]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.8461, -6.0238, -5.0947],\n",
       "                        [-4.7004, -4.7245, -4.9359],\n",
       "                        [-5.4876, -4.8804, -5.2382]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7568, -4.7962, -4.8076],\n",
       "                        [-4.8334, -4.6812, -4.8790],\n",
       "                        [-5.2112, -4.6500, -5.2285]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1571, -5.5234, -5.3730],\n",
       "                        [-6.3554, -4.7353, -5.0411],\n",
       "                        [-4.7423, -5.0554, -5.8877]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.4057, -5.4768, -5.8319],\n",
       "                        [-4.8379, -4.8591, -7.9367],\n",
       "                        [-6.0085, -4.6697, -5.8908]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7667, -5.2830, -4.8108],\n",
       "                        [-4.7277, -5.0035, -4.8743],\n",
       "                        [-4.7109, -7.0394, -4.8987]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5578, -5.4441, -4.7811],\n",
       "                        [-4.6132, -5.0880, -4.7208],\n",
       "                        [-5.2930, -4.7753, -5.3517]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0392, -6.9003, -6.4838],\n",
       "                        [-6.2912, -4.9652, -6.3513],\n",
       "                        [-5.4759, -4.9867, -5.3265]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.6965, -5.1672, -4.6054],\n",
       "                        [-5.8090, -4.9806, -5.4375],\n",
       "                        [-5.2273, -5.3135, -5.2484]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8862, -4.9312, -5.9119],\n",
       "                        [-5.3062, -5.0569, -4.6850],\n",
       "                        [-5.4883, -6.1027, -5.0738]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.3343, -6.1922, -6.2508],\n",
       "                        [-5.0133, -4.8441, -6.0976],\n",
       "                        [-7.5900, -5.7515, -4.6156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5193, -6.1760, -5.7592],\n",
       "                        [-5.5590, -4.8624, -5.6229],\n",
       "                        [-4.9285, -4.8645, -5.8739]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6902, -5.6837, -4.9300],\n",
       "                        [-5.4640, -6.1872, -5.1738],\n",
       "                        [-4.6249, -4.7705, -4.9058]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1386, -4.6787, -4.8687],\n",
       "                        [-4.7995, -6.2731, -5.5295],\n",
       "                        [-7.9139, -5.6268, -4.8398]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4830, -5.1139, -5.3729],\n",
       "                        [-4.6113, -5.2906, -5.0130],\n",
       "                        [-5.5503, -4.9968, -4.6078]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.3845, -6.3526, -5.5192],\n",
       "                        [-6.8718, -5.3505, -5.9623],\n",
       "                        [-5.2600, -5.0851, -5.2559]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.5084, -6.8383, -6.7434],\n",
       "                        [-5.1087, -5.0522, -5.0362],\n",
       "                        [-4.8434, -4.6105, -5.9471]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0541, -6.8497, -5.4263],\n",
       "                        [-5.1009, -4.6458, -5.4793],\n",
       "                        [-5.4213, -4.9003, -4.8682]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4279, -8.2878, -5.5914],\n",
       "                        [-5.8017, -5.5931, -4.8151],\n",
       "                        [-4.7875, -5.1253, -4.8293]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6792, -5.2176, -6.3633],\n",
       "                        [-6.5483, -4.7496, -5.1030],\n",
       "                        [-4.7008, -4.6548, -4.8405]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9131, -5.5380, -5.7411],\n",
       "                        [-8.2987, -4.6276, -5.5294],\n",
       "                        [-5.5955, -4.9558, -8.0978]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_alphas_log',\n",
       "              tensor([[[[-3.9730, -3.8184, -2.7370],\n",
       "                        [-2.8423, -3.3155, -3.7674],\n",
       "                        [-2.8688, -3.4832, -3.3337]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4496, -3.1676, -2.3279],\n",
       "                        [-2.5704, -2.6994, -2.5631],\n",
       "                        [-2.3078, -3.7059, -3.1989]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3379, -3.3761, -2.0345],\n",
       "                        [-3.8821, -2.3943, -3.7338],\n",
       "                        [-3.1945, -2.8338, -3.7807]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3331, -3.7250, -3.6263],\n",
       "                        [-3.3903, -2.8828, -3.6775],\n",
       "                        [-3.0060, -2.4066, -2.8119]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3633, -2.0377, -2.0332],\n",
       "                        [-3.5051, -3.9339, -3.9972],\n",
       "                        [-2.8213, -2.7204, -2.4167]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4371, -3.7661, -2.8416],\n",
       "                        [-2.1897, -2.4125, -2.5461],\n",
       "                        [-3.4732, -3.3259, -2.3366]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2825, -3.0099, -2.5968],\n",
       "                        [-3.0321, -3.8588, -3.2249],\n",
       "                        [-3.7188, -3.9843, -3.5802]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8530, -3.9986, -3.0276],\n",
       "                        [-2.0767, -3.6595, -2.9175],\n",
       "                        [-3.2203, -2.1420, -3.6336]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5784, -2.8119, -2.3119],\n",
       "                        [-3.2846, -3.0844, -2.5892],\n",
       "                        [-3.3545, -2.3341, -3.3552]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5695, -2.5832, -2.3026],\n",
       "                        [-3.3705, -3.8097, -3.8492],\n",
       "                        [-2.4600, -2.2967, -3.7054]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3626, -3.4220, -3.9690],\n",
       "                        [-2.0460, -2.1348, -3.8663],\n",
       "                        [-2.3202, -3.0671, -2.3580]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1191, -3.4663, -3.9155],\n",
       "                        [-2.9626, -2.6909, -2.0241],\n",
       "                        [-3.6772, -2.0887, -2.8112]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5335, -2.2046, -3.8070],\n",
       "                        [-2.0733, -3.4714, -3.3680],\n",
       "                        [-2.0920, -3.3321, -3.0712]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9456, -3.9397, -2.3680],\n",
       "                        [-2.0659, -3.5653, -2.3071],\n",
       "                        [-3.2517, -3.4542, -2.0715]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2097, -3.9403, -2.1460],\n",
       "                        [-3.0559, -3.4030, -2.5687],\n",
       "                        [-3.4692, -2.5501, -3.5228]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8775, -3.4609, -3.5841],\n",
       "                        [-3.2468, -3.9733, -3.9215],\n",
       "                        [-3.4708, -3.8749, -3.1619]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4536, -3.0306, -3.1692],\n",
       "                        [-2.9309, -2.0621, -2.1662],\n",
       "                        [-2.1606, -2.5014, -2.8317]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8540, -3.1003, -2.3888],\n",
       "                        [-2.9370, -2.7015, -3.5162],\n",
       "                        [-2.7293, -2.3345, -3.2506]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4800, -3.4780, -2.7654],\n",
       "                        [-2.0434, -2.3557, -2.0213],\n",
       "                        [-2.2703, -2.0352, -3.7971]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9834, -3.0913, -2.8502],\n",
       "                        [-2.8904, -2.8264, -3.4881],\n",
       "                        [-3.3516, -3.2357, -2.9829]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1380, -3.2730, -3.5269],\n",
       "                        [-2.6177, -3.5875, -3.6728],\n",
       "                        [-2.7636, -3.6273, -3.2167]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4872, -3.5043, -2.3076],\n",
       "                        [-2.8557, -3.3450, -2.6795],\n",
       "                        [-2.7737, -2.7499, -3.3472]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2195, -2.7689, -2.0130],\n",
       "                        [-3.5297, -3.6577, -2.2098],\n",
       "                        [-2.0077, -3.4508, -3.4853]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1046, -3.8315, -3.3988],\n",
       "                        [-2.0476, -3.0053, -3.8965],\n",
       "                        [-2.1855, -2.1632, -2.1847]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9850, -2.6428, -2.9310],\n",
       "                        [-2.1326, -3.2657, -2.4740],\n",
       "                        [-3.1584, -2.4350, -3.3533]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9450, -2.5128, -3.1556],\n",
       "                        [-3.2801, -3.5410, -2.8983],\n",
       "                        [-2.5519, -3.2341, -2.8721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8494, -3.8954, -3.0426],\n",
       "                        [-3.2585, -3.2226, -3.6094],\n",
       "                        [-3.2983, -3.4633, -3.9118]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4175, -2.1018, -2.3832],\n",
       "                        [-2.6769, -2.5597, -3.1847],\n",
       "                        [-3.8278, -2.5293, -3.5093]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6108, -3.0801, -2.6812],\n",
       "                        [-2.7818, -3.4267, -3.2687],\n",
       "                        [-2.1624, -2.1442, -2.5664]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5382, -2.5531, -3.3821],\n",
       "                        [-2.7202, -3.1200, -3.5994],\n",
       "                        [-3.7090, -3.5544, -3.7490]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9206, -2.9339, -2.6854],\n",
       "                        [-2.8685, -3.9728, -2.4037],\n",
       "                        [-3.7632, -2.0636, -2.3169]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5363, -2.2065, -3.9187],\n",
       "                        [-2.5296, -2.8139, -2.1778],\n",
       "                        [-3.0076, -2.6238, -3.4175]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.1.param_mus',\n",
       "              tensor([-0.0917,  0.2394,  0.0686, -0.2604, -0.0798,  0.2396, -0.0338,  0.2310,\n",
       "                       0.0511, -0.0118,  0.1305,  0.2870,  0.1377,  0.0071, -0.0213, -0.0859,\n",
       "                       0.1393, -0.0984, -0.1080,  0.1917,  0.1436, -0.2344,  0.0637, -0.2897,\n",
       "                      -0.2618, -0.2384, -0.1295,  0.1794, -0.0685, -0.0023, -0.2036, -0.0473])),\n",
       "             ('module_list.0.posterior_params.1.param_std_log',\n",
       "              tensor([-5.6001, -5.0561, -7.3938, -4.6664, -5.3911, -4.6895, -5.8183, -4.6080,\n",
       "                      -4.9778, -5.0134, -5.1747, -6.2682, -5.6235, -4.6147, -4.6179, -5.5958,\n",
       "                      -7.3049, -5.8125, -5.3669, -6.1171, -5.4824, -4.6084, -4.8485, -5.1090,\n",
       "                      -4.6260, -4.8618, -4.6064, -5.7304, -4.9281, -6.2759, -6.1592, -4.6723])),\n",
       "             ('module_list.0.posterior_params.1.scale_alphas_log',\n",
       "              tensor([-3.8439, -3.2271, -3.3951, -2.1596, -3.5587, -3.3096, -3.8678, -3.2271,\n",
       "                      -3.7286, -2.2776, -3.4039, -2.1131, -3.8562, -2.1256, -2.6956, -2.0418,\n",
       "                      -3.5359, -3.6205, -3.8657, -2.2383, -2.6532, -2.0978, -2.3008, -3.0798,\n",
       "                      -3.8545, -2.1004, -2.2579, -3.7659, -2.8519, -2.2167, -2.4384, -3.4444])),\n",
       "             ('module_list.0.posterior_params.1.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.2.param_mus',\n",
       "              tensor([[[[-0.0196,  0.0454,  0.0391],\n",
       "                        [ 0.0089,  0.0444,  0.0319],\n",
       "                        [ 0.0151, -0.0048, -0.0067]],\n",
       "              \n",
       "                       [[ 0.0389,  0.0052, -0.0038],\n",
       "                        [ 0.0210, -0.0377,  0.0379],\n",
       "                        [-0.0082, -0.0270,  0.0123]],\n",
       "              \n",
       "                       [[-0.0195, -0.0450, -0.0348],\n",
       "                        [-0.0266,  0.0158,  0.0558],\n",
       "                        [ 0.0572, -0.0150, -0.0562]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0117, -0.0527,  0.0530],\n",
       "                        [-0.0441, -0.0011,  0.0099],\n",
       "                        [ 0.0460, -0.0206,  0.0311]],\n",
       "              \n",
       "                       [[ 0.0086, -0.0104,  0.0082],\n",
       "                        [-0.0060,  0.0010,  0.0508],\n",
       "                        [ 0.0234, -0.0204, -0.0198]],\n",
       "              \n",
       "                       [[ 0.0014,  0.0375, -0.0589],\n",
       "                        [-0.0500, -0.0523, -0.0287],\n",
       "                        [-0.0491,  0.0049,  0.0422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0086, -0.0462,  0.0437],\n",
       "                        [-0.0584, -0.0168, -0.0261],\n",
       "                        [-0.0548, -0.0186, -0.0516]],\n",
       "              \n",
       "                       [[ 0.0359, -0.0341,  0.0119],\n",
       "                        [-0.0516, -0.0310, -0.0073],\n",
       "                        [-0.0050,  0.0106,  0.0388]],\n",
       "              \n",
       "                       [[ 0.0335,  0.0242, -0.0266],\n",
       "                        [-0.0136,  0.0261,  0.0277],\n",
       "                        [-0.0235, -0.0340, -0.0570]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0397, -0.0346,  0.0134],\n",
       "                        [-0.0087,  0.0414,  0.0012],\n",
       "                        [-0.0219,  0.0087,  0.0025]],\n",
       "              \n",
       "                       [[-0.0426,  0.0360, -0.0347],\n",
       "                        [-0.0527, -0.0319,  0.0490],\n",
       "                        [ 0.0425,  0.0571,  0.0575]],\n",
       "              \n",
       "                       [[ 0.0446,  0.0385,  0.0485],\n",
       "                        [ 0.0124,  0.0016, -0.0074],\n",
       "                        [ 0.0091, -0.0570, -0.0402]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0326, -0.0093, -0.0427],\n",
       "                        [-0.0027, -0.0183,  0.0407],\n",
       "                        [ 0.0067,  0.0192, -0.0295]],\n",
       "              \n",
       "                       [[ 0.0398, -0.0258, -0.0529],\n",
       "                        [ 0.0533, -0.0561,  0.0226],\n",
       "                        [-0.0508, -0.0089, -0.0217]],\n",
       "              \n",
       "                       [[-0.0574,  0.0053,  0.0086],\n",
       "                        [ 0.0176, -0.0122,  0.0389],\n",
       "                        [ 0.0315, -0.0262,  0.0497]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0496,  0.0429, -0.0389],\n",
       "                        [ 0.0564,  0.0134, -0.0487],\n",
       "                        [ 0.0151, -0.0558, -0.0526]],\n",
       "              \n",
       "                       [[ 0.0041,  0.0085,  0.0242],\n",
       "                        [-0.0357,  0.0532, -0.0053],\n",
       "                        [ 0.0320,  0.0389, -0.0084]],\n",
       "              \n",
       "                       [[-0.0232, -0.0328, -0.0265],\n",
       "                        [ 0.0073,  0.0322,  0.0154],\n",
       "                        [ 0.0334, -0.0364, -0.0399]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0362, -0.0152, -0.0356],\n",
       "                        [-0.0227,  0.0356,  0.0551],\n",
       "                        [ 0.0449,  0.0479,  0.0460]],\n",
       "              \n",
       "                       [[ 0.0109, -0.0216,  0.0328],\n",
       "                        [ 0.0278,  0.0500, -0.0082],\n",
       "                        [ 0.0543, -0.0203,  0.0153]],\n",
       "              \n",
       "                       [[ 0.0102,  0.0585, -0.0482],\n",
       "                        [ 0.0470,  0.0210,  0.0068],\n",
       "                        [ 0.0122,  0.0472, -0.0473]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0350,  0.0331,  0.0211],\n",
       "                        [ 0.0469,  0.0194, -0.0124],\n",
       "                        [ 0.0085,  0.0097,  0.0335]],\n",
       "              \n",
       "                       [[-0.0213, -0.0421,  0.0169],\n",
       "                        [ 0.0271,  0.0084, -0.0281],\n",
       "                        [-0.0009,  0.0395,  0.0552]],\n",
       "              \n",
       "                       [[-0.0405,  0.0506,  0.0431],\n",
       "                        [ 0.0378,  0.0429,  0.0452],\n",
       "                        [ 0.0226,  0.0213, -0.0085]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0589, -0.0413,  0.0375],\n",
       "                        [-0.0113,  0.0128, -0.0504],\n",
       "                        [ 0.0348,  0.0297, -0.0023]],\n",
       "              \n",
       "                       [[ 0.0142, -0.0146,  0.0395],\n",
       "                        [-0.0279,  0.0025, -0.0369],\n",
       "                        [-0.0193,  0.0065,  0.0184]],\n",
       "              \n",
       "                       [[ 0.0535, -0.0271,  0.0205],\n",
       "                        [ 0.0521,  0.0121,  0.0178],\n",
       "                        [-0.0015, -0.0246,  0.0102]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0374,  0.0082,  0.0361],\n",
       "                        [-0.0384, -0.0128,  0.0242],\n",
       "                        [ 0.0210,  0.0459, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0085,  0.0549, -0.0122],\n",
       "                        [ 0.0470, -0.0425,  0.0118],\n",
       "                        [-0.0259, -0.0331,  0.0163]],\n",
       "              \n",
       "                       [[-0.0175,  0.0018,  0.0136],\n",
       "                        [ 0.0412, -0.0085, -0.0292],\n",
       "                        [ 0.0508, -0.0501,  0.0192]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0055, -0.0442, -0.0088],\n",
       "                        [-0.0253, -0.0387, -0.0068],\n",
       "                        [-0.0327,  0.0401,  0.0176]],\n",
       "              \n",
       "                       [[-0.0053, -0.0276,  0.0089],\n",
       "                        [ 0.0546,  0.0484, -0.0486],\n",
       "                        [ 0.0030,  0.0041, -0.0256]],\n",
       "              \n",
       "                       [[ 0.0418,  0.0024, -0.0539],\n",
       "                        [ 0.0261, -0.0357, -0.0540],\n",
       "                        [ 0.0082, -0.0161,  0.0249]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0420, -0.0219, -0.0447],\n",
       "                        [-0.0553, -0.0467, -0.0041],\n",
       "                        [-0.0133, -0.0239,  0.0284]],\n",
       "              \n",
       "                       [[-0.0090,  0.0331,  0.0218],\n",
       "                        [-0.0550, -0.0575, -0.0531],\n",
       "                        [ 0.0528, -0.0313,  0.0230]],\n",
       "              \n",
       "                       [[-0.0138,  0.0412, -0.0435],\n",
       "                        [ 0.0420, -0.0355,  0.0162],\n",
       "                        [ 0.0510,  0.0107,  0.0575]]]])),\n",
       "             ('module_list.0.posterior_params.2.param_std_log',\n",
       "              tensor([[[[ -4.8953,  -5.0285,  -6.2216],\n",
       "                        [ -4.9035,  -8.6040,  -6.4262],\n",
       "                        [ -5.3935,  -6.4831,  -5.3591]],\n",
       "              \n",
       "                       [[ -5.5549,  -5.1110,  -4.7856],\n",
       "                        [ -5.0981,  -4.8755,  -5.7412],\n",
       "                        [ -5.6913,  -5.1175,  -5.4186]],\n",
       "              \n",
       "                       [[ -7.5934,  -4.9929,  -4.8682],\n",
       "                        [ -6.5329,  -6.7392,  -5.7023],\n",
       "                        [ -4.6655,  -6.5716,  -5.0604]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.6578,  -4.9114,  -5.8949],\n",
       "                        [ -5.4794,  -5.1367,  -5.2141],\n",
       "                        [ -7.1503,  -5.0723,  -6.8911]],\n",
       "              \n",
       "                       [[ -7.7260,  -4.7098,  -4.7194],\n",
       "                        [ -4.8400,  -5.9135,  -5.9438],\n",
       "                        [ -4.6816,  -5.5583,  -4.6564]],\n",
       "              \n",
       "                       [[ -5.4169,  -4.8717,  -4.7754],\n",
       "                        [ -5.1123,  -4.8388,  -5.6561],\n",
       "                        [ -5.6101,  -5.9402,  -5.5524]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3646,  -6.1044,  -4.8309],\n",
       "                        [ -4.9290,  -6.4702,  -4.7857],\n",
       "                        [ -4.7454,  -6.7668,  -4.7657]],\n",
       "              \n",
       "                       [[ -5.3774,  -6.1290,  -5.3385],\n",
       "                        [ -8.1817,  -5.3416,  -4.6654],\n",
       "                        [ -6.9278,  -5.2007,  -5.8790]],\n",
       "              \n",
       "                       [[ -6.2015,  -4.7918,  -7.0114],\n",
       "                        [ -6.6029,  -4.9880,  -5.1994],\n",
       "                        [ -4.7158,  -4.6187,  -4.7050]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -7.0537,  -5.3076,  -5.5863],\n",
       "                        [ -5.8178,  -5.1174,  -5.0456],\n",
       "                        [ -5.3676,  -5.2478,  -5.6625]],\n",
       "              \n",
       "                       [[ -5.3646,  -6.0331,  -4.8292],\n",
       "                        [ -5.1204,  -5.0109,  -5.4891],\n",
       "                        [ -6.4985,  -4.7923,  -4.8494]],\n",
       "              \n",
       "                       [[ -5.2417,  -5.3264,  -4.9075],\n",
       "                        [ -4.6669,  -5.7886,  -5.0299],\n",
       "                        [ -4.8249,  -4.7134,  -5.8615]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.3013,  -5.6837,  -6.1340],\n",
       "                        [ -4.8347,  -6.8893,  -6.6270],\n",
       "                        [ -5.4885,  -6.7957,  -4.8725]],\n",
       "              \n",
       "                       [[ -4.7680,  -7.2965,  -6.8039],\n",
       "                        [ -7.3785,  -4.9002,  -5.0066],\n",
       "                        [ -4.6913,  -5.5690,  -4.6084]],\n",
       "              \n",
       "                       [[ -4.8951,  -7.2483,  -4.8205],\n",
       "                        [ -5.4375,  -5.4348,  -5.8624],\n",
       "                        [ -5.6269,  -4.8600,  -8.1621]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.9090,  -5.1043,  -6.6300],\n",
       "                        [ -4.9572,  -5.2812,  -4.9467],\n",
       "                        [ -6.9966,  -5.9345,  -5.1252]],\n",
       "              \n",
       "                       [[ -4.6989,  -4.8439,  -5.2943],\n",
       "                        [ -5.1051,  -5.7968,  -5.8932],\n",
       "                        [-10.1077,  -4.7491,  -8.4951]],\n",
       "              \n",
       "                       [[ -5.6271,  -5.8009,  -5.6112],\n",
       "                        [ -5.6509,  -4.7704,  -6.9457],\n",
       "                        [ -6.5300,  -5.8772,  -6.3974]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ -6.2656,  -6.2033,  -4.9923],\n",
       "                        [ -4.8826,  -8.2525,  -5.1309],\n",
       "                        [ -4.8151,  -5.6355,  -5.0209]],\n",
       "              \n",
       "                       [[ -6.3848,  -6.0805,  -7.8335],\n",
       "                        [ -4.8021,  -5.2011,  -4.9359],\n",
       "                        [ -5.2328,  -6.5811,  -4.6836]],\n",
       "              \n",
       "                       [[ -4.6560,  -4.6885, -11.7446],\n",
       "                        [ -6.5880,  -4.7699,  -5.2749],\n",
       "                        [ -5.6483,  -4.7934,  -6.8433]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.2342,  -5.2849,  -6.0316],\n",
       "                        [ -5.3714,  -4.7595,  -5.4207],\n",
       "                        [ -6.7571,  -9.9357,  -7.0918]],\n",
       "              \n",
       "                       [[ -7.8484,  -7.9049,  -4.8852],\n",
       "                        [ -8.5928,  -6.9321,  -4.7064],\n",
       "                        [ -4.6875,  -4.8348,  -5.5023]],\n",
       "              \n",
       "                       [[ -4.7033,  -4.6839,  -5.3626],\n",
       "                        [ -5.8149,  -4.6163,  -4.7024],\n",
       "                        [ -5.2816,  -5.4297,  -4.8385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7027,  -4.6516,  -5.3516],\n",
       "                        [ -5.2600,  -4.8881,  -5.0138],\n",
       "                        [ -5.9239,  -5.4689,  -4.6260]],\n",
       "              \n",
       "                       [[ -4.9607,  -5.8558,  -5.9619],\n",
       "                        [ -5.1053,  -7.0853,  -5.5569],\n",
       "                        [ -4.6085,  -6.3642,  -4.8830]],\n",
       "              \n",
       "                       [[ -5.5688,  -4.9501,  -6.1348],\n",
       "                        [ -6.3153,  -5.5237,  -4.7659],\n",
       "                        [ -4.6286,  -5.5474,  -6.4980]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.5645,  -4.6941,  -5.2743],\n",
       "                        [ -5.4054,  -4.9133,  -6.4651],\n",
       "                        [ -7.0040,  -4.9656,  -7.0266]],\n",
       "              \n",
       "                       [[ -5.2028,  -5.1697,  -4.7442],\n",
       "                        [ -4.8667,  -5.2562,  -6.2058],\n",
       "                        [ -7.5951,  -4.6418,  -4.9033]],\n",
       "              \n",
       "                       [[ -4.6518,  -5.0600,  -5.0147],\n",
       "                        [ -6.5606,  -5.0663,  -5.1944],\n",
       "                        [ -7.4739,  -4.6704,  -4.6449]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.6330,  -6.6073,  -5.0135],\n",
       "                        [ -4.9958,  -4.8325,  -4.6252],\n",
       "                        [ -4.9012,  -6.2909,  -6.0797]],\n",
       "              \n",
       "                       [[ -4.8079,  -7.8986,  -5.3821],\n",
       "                        [ -5.9537,  -7.2645,  -5.7079],\n",
       "                        [ -4.7860,  -5.0177,  -5.3445]],\n",
       "              \n",
       "                       [[ -4.9210,  -5.5095,  -4.9153],\n",
       "                        [ -9.2945,  -5.2109,  -5.0991],\n",
       "                        [ -4.6786,  -4.8999,  -4.7837]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.0940,  -6.4246,  -6.0016],\n",
       "                        [ -5.9106,  -4.6236,  -9.3768],\n",
       "                        [ -4.8565,  -4.6549,  -4.8105]],\n",
       "              \n",
       "                       [[ -5.0449,  -5.1650,  -4.6892],\n",
       "                        [ -5.7240,  -5.5601,  -4.7530],\n",
       "                        [ -4.6144,  -5.6058,  -7.4718]],\n",
       "              \n",
       "                       [[ -6.1598,  -4.6782,  -5.3052],\n",
       "                        [ -5.1732,  -5.6023,  -5.3645],\n",
       "                        [ -5.2507,  -5.4567,  -4.8220]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_alphas_log',\n",
       "              tensor([[[[-2.9031, -3.5752, -3.1913],\n",
       "                        [-2.2432, -3.7676, -3.9219],\n",
       "                        [-2.2315, -3.3817, -3.0104]],\n",
       "              \n",
       "                       [[-3.4620, -2.1322, -2.3796],\n",
       "                        [-3.2906, -3.9242, -2.4920],\n",
       "                        [-2.6064, -2.2625, -3.8039]],\n",
       "              \n",
       "                       [[-3.0305, -3.3771, -3.4199],\n",
       "                        [-2.7889, -2.9304, -3.7615],\n",
       "                        [-2.1174, -2.1470, -3.9918]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2688, -2.4659, -3.1240],\n",
       "                        [-3.7692, -3.6450, -3.6797],\n",
       "                        [-3.3195, -2.8639, -2.6135]],\n",
       "              \n",
       "                       [[-2.1157, -2.3645, -3.2899],\n",
       "                        [-3.4988, -3.0115, -2.7938],\n",
       "                        [-3.8293, -3.2961, -2.8436]],\n",
       "              \n",
       "                       [[-3.9779, -2.0617, -3.1237],\n",
       "                        [-3.9790, -2.6218, -2.4551],\n",
       "                        [-3.5406, -3.1608, -3.2890]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6755, -2.0339, -3.6471],\n",
       "                        [-3.1715, -3.2779, -2.7492],\n",
       "                        [-2.6883, -3.9882, -3.6644]],\n",
       "              \n",
       "                       [[-2.4057, -2.0133, -2.1821],\n",
       "                        [-2.7596, -2.0538, -2.6359],\n",
       "                        [-3.5137, -3.3185, -3.5885]],\n",
       "              \n",
       "                       [[-3.0351, -2.9763, -2.0979],\n",
       "                        [-3.3766, -3.9956, -2.0556],\n",
       "                        [-2.8010, -3.5787, -3.6768]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.9227, -3.6770, -3.7636],\n",
       "                        [-3.2002, -2.1039, -2.2279],\n",
       "                        [-3.7049, -2.7865, -2.1264]],\n",
       "              \n",
       "                       [[-3.0326, -2.2067, -2.2916],\n",
       "                        [-2.1105, -3.7049, -2.5112],\n",
       "                        [-3.1940, -2.1001, -3.4853]],\n",
       "              \n",
       "                       [[-2.8792, -3.0937, -2.7589],\n",
       "                        [-2.6047, -2.2957, -3.1234],\n",
       "                        [-3.8853, -2.5147, -2.4693]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4313, -3.4454, -2.5228],\n",
       "                        [-2.2018, -3.2355, -2.3762],\n",
       "                        [-3.8663, -3.0295, -3.5700]],\n",
       "              \n",
       "                       [[-3.5861, -2.0395, -2.0020],\n",
       "                        [-2.1038, -3.2346, -2.7971],\n",
       "                        [-2.3657, -2.5616, -3.5310]],\n",
       "              \n",
       "                       [[-3.3006, -3.3535, -3.3189],\n",
       "                        [-3.1244, -3.3003, -3.5692],\n",
       "                        [-2.7795, -2.1361, -2.3262]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.1123, -3.5558, -2.4190],\n",
       "                        [-2.8286, -2.1191, -2.5490],\n",
       "                        [-2.3278, -2.8362, -3.7079]],\n",
       "              \n",
       "                       [[-2.0250, -2.0361, -2.2242],\n",
       "                        [-3.5920, -2.1569, -3.2739],\n",
       "                        [-2.3617, -3.3745, -2.4369]],\n",
       "              \n",
       "                       [[-3.4996, -2.8253, -2.5848],\n",
       "                        [-3.4868, -3.3970, -3.3454],\n",
       "                        [-3.3596, -3.8827, -3.4139]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.1325, -2.0101, -2.3009],\n",
       "                        [-3.3946, -3.7420, -2.2947],\n",
       "                        [-2.8810, -3.1959, -2.4976]],\n",
       "              \n",
       "                       [[-3.0886, -3.6569, -2.8172],\n",
       "                        [-3.7599, -3.9197, -2.1939],\n",
       "                        [-3.7000, -2.5793, -3.5384]],\n",
       "              \n",
       "                       [[-2.8714, -2.3903, -2.9222],\n",
       "                        [-2.1279, -3.4309, -2.6593],\n",
       "                        [-3.9820, -2.9647, -3.0653]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4074, -3.5453, -2.9808],\n",
       "                        [-2.2863, -3.9489, -2.0954],\n",
       "                        [-3.8373, -3.9608, -3.8983]],\n",
       "              \n",
       "                       [[-3.3889, -2.3294, -3.8718],\n",
       "                        [-2.4368, -2.1073, -2.8512],\n",
       "                        [-3.6483, -3.7381, -3.0208]],\n",
       "              \n",
       "                       [[-2.0715, -3.7128, -2.4285],\n",
       "                        [-3.7453, -2.5793, -3.9045],\n",
       "                        [-2.2144, -2.8838, -3.2419]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8225, -2.4760, -2.3612],\n",
       "                        [-3.4040, -2.1312, -3.9279],\n",
       "                        [-3.2219, -3.0139, -2.9078]],\n",
       "              \n",
       "                       [[-3.9570, -3.6798, -3.8169],\n",
       "                        [-2.9281, -3.5607, -2.0121],\n",
       "                        [-2.0334, -3.3228, -3.2737]],\n",
       "              \n",
       "                       [[-3.0264, -2.6413, -2.7952],\n",
       "                        [-2.6720, -2.2991, -3.6808],\n",
       "                        [-2.9856, -3.2928, -3.7279]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2259, -2.7306, -3.2844],\n",
       "                        [-3.2082, -2.3142, -3.7642],\n",
       "                        [-2.4837, -2.9002, -2.0545]],\n",
       "              \n",
       "                       [[-3.8918, -3.5356, -2.0444],\n",
       "                        [-2.3271, -2.4968, -3.9083],\n",
       "                        [-2.4074, -2.6570, -2.4153]],\n",
       "              \n",
       "                       [[-2.0498, -3.5175, -2.1168],\n",
       "                        [-3.9951, -2.7050, -2.6350],\n",
       "                        [-2.7071, -2.6911, -3.2756]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4691, -2.6418, -3.3070],\n",
       "                        [-2.0403, -3.3388, -3.3410],\n",
       "                        [-3.4311, -2.3567, -2.7274]],\n",
       "              \n",
       "                       [[-2.9643, -3.1868, -2.6083],\n",
       "                        [-3.9008, -2.3488, -2.8015],\n",
       "                        [-3.6829, -3.6533, -3.1903]],\n",
       "              \n",
       "                       [[-3.1084, -2.5719, -3.7105],\n",
       "                        [-2.5479, -3.8481, -2.2664],\n",
       "                        [-2.6867, -2.7838, -3.6353]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0250, -2.3754, -2.1942],\n",
       "                        [-2.2754, -2.2488, -2.5304],\n",
       "                        [-3.6430, -2.9638, -3.1415]],\n",
       "              \n",
       "                       [[-3.1872, -2.3818, -3.4090],\n",
       "                        [-3.5182, -3.5750, -3.3125],\n",
       "                        [-2.8591, -2.2255, -3.4907]],\n",
       "              \n",
       "                       [[-2.1073, -3.1520, -3.7595],\n",
       "                        [-2.5730, -2.0243, -3.1251],\n",
       "                        [-3.6950, -3.2891, -3.7837]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.3.param_mus',\n",
       "              tensor([-0.0347, -0.0540, -0.0008,  0.0293, -0.0292,  0.0349, -0.0176,  0.0116,\n",
       "                       0.0173,  0.0239,  0.0535,  0.0285,  0.0451, -0.0420,  0.0108, -0.0409,\n",
       "                       0.0453, -0.0289, -0.0493, -0.0556, -0.0361, -0.0034, -0.0584,  0.0529,\n",
       "                       0.0162, -0.0444,  0.0243,  0.0210, -0.0163,  0.0040,  0.0075, -0.0225,\n",
       "                      -0.0476,  0.0339,  0.0409, -0.0459,  0.0447,  0.0547,  0.0345, -0.0486,\n",
       "                       0.0053, -0.0136,  0.0179, -0.0266,  0.0421, -0.0030, -0.0182, -0.0482,\n",
       "                      -0.0340, -0.0338,  0.0125, -0.0354,  0.0531, -0.0226, -0.0371, -0.0432,\n",
       "                       0.0315,  0.0339, -0.0145,  0.0430,  0.0406,  0.0375, -0.0415, -0.0373])),\n",
       "             ('module_list.0.posterior_params.3.param_std_log',\n",
       "              tensor([-5.4569, -4.6801, -4.7204, -5.3099, -5.5642, -7.9669, -5.1158, -5.7351,\n",
       "                      -4.8519, -5.2321, -6.6220, -5.4749, -5.7233, -5.7436, -4.8307, -5.3099,\n",
       "                      -5.5596, -6.0521, -5.2583, -4.7860, -4.8898, -5.6637, -4.7467, -4.6643,\n",
       "                      -5.3782, -6.6473, -4.6510, -5.2890, -4.7336, -4.6367, -4.8326, -7.7491,\n",
       "                      -5.7414, -5.3058, -5.7958, -4.8864, -4.6670, -5.3566, -6.6464, -6.9234,\n",
       "                      -6.2836, -4.6365, -7.2882, -6.8838, -4.6835, -5.1239, -7.1621, -5.2982,\n",
       "                      -5.1323, -6.3269, -5.4452, -6.2584, -6.0409, -5.0412, -4.7253, -4.7920,\n",
       "                      -4.8736, -4.7333, -4.9122, -4.8091, -6.4931, -5.7098, -8.9380, -4.7787])),\n",
       "             ('module_list.0.posterior_params.3.scale_alphas_log',\n",
       "              tensor([-2.0096, -3.1070, -2.4744, -2.8249, -2.1330, -2.1949, -3.7866, -3.2097,\n",
       "                      -3.8550, -3.1583, -3.0586, -2.9922, -2.6323, -2.1886, -2.5555, -2.2712,\n",
       "                      -2.9222, -2.3903, -2.9189, -2.6913, -2.1877, -2.3527, -2.1297, -3.1475,\n",
       "                      -2.6098, -2.0891, -3.4339, -2.4926, -3.6903, -2.8732, -2.1957, -3.5118,\n",
       "                      -2.2983, -3.3832, -3.4829, -2.7464, -3.3553, -3.5355, -2.4428, -3.0015,\n",
       "                      -2.7173, -2.5134, -3.9719, -2.8202, -2.6662, -3.1703, -2.6489, -2.1131,\n",
       "                      -2.0383, -3.8398, -2.6632, -2.2751, -2.4046, -2.9891, -2.8446, -3.0018,\n",
       "                      -2.0600, -3.5996, -3.0579, -2.5789, -3.7129, -2.4109, -2.5351, -3.2553])),\n",
       "             ('module_list.0.posterior_params.3.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.4.param_mus',\n",
       "              tensor([[ 0.0009,  0.0158,  0.0126,  ..., -0.0105, -0.0025, -0.0128],\n",
       "                      [ 0.0080, -0.0029, -0.0087,  ...,  0.0028, -0.0101,  0.0126],\n",
       "                      [ 0.0150, -0.0064, -0.0075,  ..., -0.0084, -0.0034, -0.0038],\n",
       "                      ...,\n",
       "                      [-0.0002, -0.0109,  0.0178,  ..., -0.0034, -0.0082, -0.0020],\n",
       "                      [-0.0095,  0.0160, -0.0090,  ..., -0.0084,  0.0039,  0.0121],\n",
       "                      [-0.0176, -0.0070,  0.0146,  ..., -0.0085,  0.0145, -0.0063]])),\n",
       "             ('module_list.0.posterior_params.4.param_std_log',\n",
       "              tensor([[-5.0882, -5.6143, -5.0647,  ..., -5.6104, -4.6591, -4.9445],\n",
       "                      [-4.6745, -5.9688, -5.0048,  ..., -6.3473, -4.6243, -6.2210],\n",
       "                      [-4.7615, -7.7854, -5.7147,  ..., -7.3079, -5.9162, -5.9307],\n",
       "                      ...,\n",
       "                      [-6.7976, -5.2108, -5.6782,  ..., -5.2774, -5.6684, -6.0092],\n",
       "                      [-6.6351, -4.8296, -5.0264,  ..., -7.7251, -5.2107, -4.8150],\n",
       "                      [-7.3702, -8.7021, -4.7729,  ..., -4.8881, -4.7526, -5.0925]])),\n",
       "             ('module_list.0.posterior_params.4.scale_alphas_log',\n",
       "              tensor([[-2.3414, -2.7704, -3.4864,  ..., -2.1757, -3.9189, -2.2035],\n",
       "                      [-2.3410, -2.2061, -3.1260,  ..., -3.4673, -2.0878, -3.4667],\n",
       "                      [-3.9802, -2.7468, -2.0136,  ..., -2.2748, -3.8034, -2.2377],\n",
       "                      ...,\n",
       "                      [-2.4080, -2.7311, -2.1504,  ..., -3.6135, -2.4462, -2.0026],\n",
       "                      [-3.4683, -2.5169, -2.6618,  ..., -2.9077, -2.7889, -2.0861],\n",
       "                      [-2.1884, -3.1091, -3.6772,  ..., -2.2174, -2.0252, -2.5327]])),\n",
       "             ('module_list.0.posterior_params.4.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.5.param_mus',\n",
       "              tensor([-0.0112,  0.0141,  0.0014,  0.0127, -0.0057, -0.0123, -0.0136,  0.0164,\n",
       "                       0.0140,  0.0152,  0.0077,  0.0159, -0.0018, -0.0005,  0.0025,  0.0036,\n",
       "                       0.0174, -0.0110,  0.0078, -0.0102,  0.0028,  0.0009,  0.0105,  0.0106,\n",
       "                       0.0002, -0.0018,  0.0092, -0.0014, -0.0002,  0.0019,  0.0001,  0.0019,\n",
       "                      -0.0122,  0.0073, -0.0102, -0.0153, -0.0162,  0.0075,  0.0051,  0.0153,\n",
       "                       0.0129, -0.0160, -0.0173, -0.0098, -0.0150,  0.0157, -0.0045,  0.0022,\n",
       "                      -0.0135,  0.0099,  0.0101,  0.0171,  0.0014, -0.0172,  0.0025, -0.0021,\n",
       "                       0.0169,  0.0017,  0.0117, -0.0016,  0.0121, -0.0066, -0.0090, -0.0044,\n",
       "                      -0.0091,  0.0011, -0.0143,  0.0033, -0.0132, -0.0091, -0.0091, -0.0157,\n",
       "                       0.0127,  0.0111, -0.0166,  0.0143,  0.0017, -0.0061, -0.0174,  0.0098,\n",
       "                       0.0034, -0.0063,  0.0041, -0.0007, -0.0088, -0.0068, -0.0123, -0.0048,\n",
       "                       0.0054, -0.0105, -0.0157,  0.0175, -0.0124,  0.0101,  0.0101,  0.0164,\n",
       "                       0.0117, -0.0088, -0.0032,  0.0164,  0.0047,  0.0089, -0.0158, -0.0005,\n",
       "                       0.0097, -0.0070,  0.0082,  0.0131, -0.0131, -0.0050,  0.0024, -0.0050,\n",
       "                       0.0152,  0.0010, -0.0035, -0.0169,  0.0012, -0.0119, -0.0085, -0.0127,\n",
       "                       0.0139,  0.0060,  0.0050, -0.0074, -0.0137,  0.0144,  0.0127, -0.0140])),\n",
       "             ('module_list.0.posterior_params.5.param_std_log',\n",
       "              tensor([ -8.5058,  -4.9983,  -4.7748,  -6.4515,  -8.2332, -10.5456,  -5.4021,\n",
       "                       -8.7938,  -6.3761,  -5.5005,  -7.5101,  -5.7537,  -4.8349,  -6.5463,\n",
       "                       -4.9158,  -6.0935,  -7.2662,  -5.4875,  -5.6636,  -4.8700,  -4.7151,\n",
       "                       -4.7584,  -4.8736,  -5.3312,  -4.9649,  -4.9046,  -4.9326,  -7.3845,\n",
       "                       -6.0946,  -5.0042,  -4.9009,  -4.6594,  -5.4126,  -4.7578,  -5.2708,\n",
       "                       -7.4743,  -5.6484,  -5.0898,  -5.7023,  -5.2178,  -6.5615,  -7.9420,\n",
       "                       -5.2271,  -5.7446,  -5.1716,  -5.5231,  -5.2031,  -6.4824,  -4.7606,\n",
       "                       -5.7502,  -5.2827,  -6.0781,  -5.8726,  -5.0141,  -4.9438,  -8.0827,\n",
       "                       -5.3131,  -5.7115,  -4.7213,  -4.6253,  -4.7276,  -4.6258,  -5.1091,\n",
       "                       -5.2092,  -5.5085,  -5.6953,  -4.6783,  -4.9021,  -4.7901,  -4.9724,\n",
       "                       -5.9262,  -6.1041,  -5.0713,  -4.6735,  -6.4833,  -5.2216,  -5.1605,\n",
       "                       -4.9854,  -5.7718,  -6.8357,  -4.9983,  -6.0955,  -5.8611,  -5.9829,\n",
       "                       -4.8589,  -5.1603,  -6.4991,  -5.6061,  -5.8304,  -5.4435,  -4.6777,\n",
       "                       -4.7764,  -5.0857,  -4.9599,  -4.7925,  -4.8101,  -4.6988,  -4.6460,\n",
       "                       -5.2655,  -6.4285,  -5.7866,  -5.3847,  -5.1084,  -5.3568,  -5.4592,\n",
       "                       -5.4557,  -7.1196,  -4.6417,  -6.3491,  -4.9110,  -5.1545,  -4.8412,\n",
       "                       -5.2638,  -6.0338,  -4.9269,  -7.4436,  -5.8754,  -4.9944,  -5.3159,\n",
       "                       -5.9607,  -6.5675,  -6.2111,  -5.1559,  -7.5439,  -4.7024,  -5.7944,\n",
       "                       -4.7159,  -5.0060])),\n",
       "             ('module_list.0.posterior_params.5.scale_alphas_log',\n",
       "              tensor([-2.9711, -2.3029, -3.2661, -3.8841, -3.9730, -2.9972, -3.0801, -2.8908,\n",
       "                      -3.2214, -2.5367, -3.7855, -3.5761, -3.2829, -2.4807, -3.7627, -3.3901,\n",
       "                      -3.2457, -2.9323, -3.2918, -3.2453, -3.4675, -2.9678, -3.9310, -2.9987,\n",
       "                      -2.2035, -2.3976, -3.5818, -3.1568, -2.2656, -3.4460, -3.9424, -3.2561,\n",
       "                      -2.0742, -3.8532, -3.1280, -2.8851, -2.0143, -2.0730, -2.5920, -3.7779,\n",
       "                      -2.5698, -3.7920, -3.6548, -2.3358, -3.9477, -3.6476, -3.8149, -2.5764,\n",
       "                      -2.8168, -3.6043, -3.2515, -3.9662, -3.3422, -2.4601, -2.8934, -2.9427,\n",
       "                      -3.4763, -2.3204, -2.2301, -2.4737, -3.8858, -3.7568, -3.4567, -3.1788,\n",
       "                      -2.4339, -2.0268, -2.8586, -3.4026, -2.9261, -2.2214, -3.0145, -3.9870,\n",
       "                      -2.0210, -3.2889, -2.6818, -2.6525, -2.6215, -2.5191, -3.3091, -2.5133,\n",
       "                      -2.1772, -2.7749, -3.2064, -2.7597, -2.0681, -2.4307, -2.3182, -3.3219,\n",
       "                      -3.7947, -3.7979, -2.5180, -2.9864, -2.1951, -3.9902, -2.8577, -3.3741,\n",
       "                      -3.5462, -3.3496, -2.4838, -2.2125, -3.5979, -2.9471, -3.3925, -3.8978,\n",
       "                      -3.0267, -2.5021, -2.3832, -3.2529, -2.6711, -3.8071, -3.5777, -3.3519,\n",
       "                      -2.8422, -2.2266, -2.3704, -2.8740, -2.7499, -2.9441, -2.7132, -3.9846,\n",
       "                      -2.8880, -3.0201, -3.8964, -2.4971, -3.7383, -2.5198, -2.3017, -3.7625])),\n",
       "             ('module_list.0.posterior_params.5.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('module_list.0.posterior_params.6.param_mus',\n",
       "              tensor([[ 0.0861,  0.0572,  0.0623,  ...,  0.0349, -0.0029,  0.0783],\n",
       "                      [ 0.0663, -0.0496, -0.0471,  ...,  0.0246, -0.0090,  0.0290],\n",
       "                      [ 0.0787, -0.0569, -0.0074,  ...,  0.0223,  0.0753,  0.0849],\n",
       "                      ...,\n",
       "                      [-0.0752, -0.0523,  0.0439,  ..., -0.0768, -0.0083, -0.0679],\n",
       "                      [-0.0070, -0.0547, -0.0404,  ...,  0.0185, -0.0464, -0.0533],\n",
       "                      [-0.0087, -0.0757, -0.0331,  ...,  0.0254, -0.0312,  0.0815]])),\n",
       "             ('module_list.0.posterior_params.6.param_std_log',\n",
       "              tensor([[-5.2017, -7.5709, -4.9455,  ..., -5.7424, -5.2740, -7.6515],\n",
       "                      [-5.7487, -5.2041, -5.0962,  ..., -6.7837, -5.8445, -6.4197],\n",
       "                      [-5.0128, -4.9754, -5.1209,  ..., -5.3098, -6.3397, -8.8992],\n",
       "                      ...,\n",
       "                      [-6.1798, -5.0020, -5.8882,  ..., -4.7352, -8.7045, -4.7601],\n",
       "                      [-6.9533, -5.3401, -4.6249,  ..., -4.6350, -4.9398, -4.7976],\n",
       "                      [-5.3153, -4.6354, -5.0823,  ..., -5.2240, -5.2665, -4.6325]])),\n",
       "             ('module_list.0.posterior_params.6.scale_alphas_log',\n",
       "              tensor([[-3.4896, -2.3144, -3.2581,  ..., -2.1586, -3.0065, -2.2661],\n",
       "                      [-2.4441, -2.0589, -2.5914,  ..., -3.1640, -3.8862, -2.6127],\n",
       "                      [-2.4363, -2.7432, -2.3645,  ..., -2.4624, -2.6623, -2.2037],\n",
       "                      ...,\n",
       "                      [-3.5581, -3.5343, -3.9614,  ..., -3.5155, -3.0719, -3.5733],\n",
       "                      [-3.6154, -3.6500, -2.4728,  ..., -2.0083, -3.4753, -2.4960],\n",
       "                      [-3.1972, -3.5865, -2.2273,  ..., -3.9335, -3.2613, -3.5673]])),\n",
       "             ('module_list.0.posterior_params.6.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.7.param_mus',\n",
       "              tensor([ 0.0045,  0.0808, -0.0811,  0.0353,  0.0298, -0.0510, -0.0097,  0.0499,\n",
       "                       0.0105, -0.0429])),\n",
       "             ('module_list.0.posterior_params.7.param_std_log',\n",
       "              tensor([-5.2095, -5.1445, -5.7701, -4.7362, -6.1606, -5.0685, -5.4482, -5.0233,\n",
       "                      -5.1172, -4.9747])),\n",
       "             ('module_list.0.posterior_params.7.scale_alphas_log',\n",
       "              tensor([-2.7219, -3.5050, -3.6166, -2.6818, -2.5404, -2.2111, -2.9576, -3.6258,\n",
       "                      -2.4424, -2.8427])),\n",
       "             ('module_list.0.posterior_params.7.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_bayes.pt'))\n",
    "image1, label1 = test_dataset[10]\n",
    "image2, label2 = test_dataset[11]\n",
    "model(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:16906.90234375, KL Loss: 1690681.375, FitLoss: 0.09073139727115631, Accuracy 0.98, Prune parameters: 221821.0/421642\n"
     ]
    }
   ],
   "source": [
    "val_loss = 0.0\n",
    "val_acc = 0.0\n",
    "PRUNE = 1.0\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,  \n",
    "                                         batch_size=BATCH_SIZE,  \n",
    "                                         shuffle=False, \n",
    "                                         pin_memory=True) \n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "trainer.params.prune_threshold = PRUNE\n",
    "test_result = trainer.eval(model, test_loader)\n",
    "acc = test_result.custom_losses['val_accuracy']\n",
    "print(f'Loss:{test_result.val_loss}, KL Loss: {test_result.dist_loss}, FitLoss: {test_result.fit_loss}, Accuracy {acc}, Prune parameters: {test_result.cnt_prune_parameters}/{test_result.cnt_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device=device)\n",
    "model.prune({'threshold': 1.0})\n",
    "model.set_map_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 4.2992e-03, -5.4342e-01, -0.0000e+00],\n",
      "          [ 3.9089e-01, -0.0000e+00, -0.0000e+00],\n",
      "          [ 8.2518e-01,  3.0815e-01, -2.3478e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8153e-02,  0.0000e+00, -0.0000e+00],\n",
      "          [ 4.4879e-01,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.4131e+00, -7.5729e-01, -0.0000e+00],\n",
      "          [ 2.0788e-01,  4.6619e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  2.6288e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  9.8380e-01,  3.4592e-01],\n",
      "          [-0.0000e+00,  4.0430e-01,  0.0000e+00],\n",
      "          [-8.4115e-01, -3.8792e-01, -1.5979e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0565e-01,  0.0000e+00,  2.3229e-01],\n",
      "          [ 0.0000e+00,  6.6020e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -3.2411e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00,  3.8068e-01,  0.0000e+00],\n",
      "          [-1.7023e-03,  7.2274e-01,  1.6451e-01],\n",
      "          [-2.6313e-01,  0.0000e+00, -8.0280e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  7.1311e-01, -0.0000e+00],\n",
      "          [ 7.3480e-01,  0.0000e+00, -6.3528e-01],\n",
      "          [ 1.7638e-02, -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8662e-01,  4.1352e-01,  7.5745e-01],\n",
      "          [ 3.4204e-03, -2.4012e-03,  1.9629e-01],\n",
      "          [-0.0000e+00, -1.8996e+00, -5.4733e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7047e-01, -0.0000e+00, -4.2426e-02],\n",
      "          [-0.0000e+00,  8.9670e-01,  8.5076e-01],\n",
      "          [-4.0429e-01,  5.5609e-01, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  1.1400e-01],\n",
      "          [ 0.0000e+00,  4.4838e-01, -0.0000e+00],\n",
      "          [ 4.5566e-02, -0.0000e+00, -1.9310e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.7405e-02,  2.3569e-01, -0.0000e+00],\n",
      "          [ 4.6704e-01,  8.9131e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -1.1183e-02, -6.1903e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 5.3916e-02,  1.3328e-02, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4441e-01,  0.0000e+00, -2.3364e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  7.9347e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6268e-01,  0.0000e+00, -0.0000e+00],\n",
      "          [ 6.3382e-01,  3.4143e-01, -0.0000e+00],\n",
      "          [-0.0000e+00, -3.0772e-01, -8.3751e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0354e-01,  0.0000e+00, -0.0000e+00],\n",
      "          [ 4.2287e-01,  0.0000e+00,  3.6846e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.1328e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0544e-01, -1.0880e+00, -1.3626e+00],\n",
      "          [ 0.0000e+00,  4.4564e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  6.4581e-01,  3.5768e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  3.1633e-01, -6.6071e-01],\n",
      "          [ 0.0000e+00,  2.3753e-01, -0.0000e+00],\n",
      "          [ 3.6975e-01, -5.6517e-03, -6.6312e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.1901e-01,  6.4522e-02,  2.1885e-01],\n",
      "          [-0.0000e+00,  6.1452e-01,  4.0866e-01],\n",
      "          [-1.2748e-01,  5.6207e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.3363e-01, -0.0000e+00, -0.0000e+00],\n",
      "          [ 2.1696e-01,  0.0000e+00,  6.1144e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.8670e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  6.6921e-01,  3.2235e-01],\n",
      "          [-0.0000e+00,  4.6664e-01,  1.8888e-01],\n",
      "          [-5.4447e-01, -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.0248e-01, -0.0000e+00,  1.2330e-01],\n",
      "          [-0.0000e+00,  0.0000e+00,  6.1526e-01],\n",
      "          [-1.3471e-01,  3.3910e-01,  2.8420e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  2.2249e-01,  0.0000e+00],\n",
      "          [ 1.4262e-01,  8.8915e-01,  0.0000e+00],\n",
      "          [-0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1939e+00, -4.6484e-01, -0.0000e+00],\n",
      "          [-8.6274e-01,  1.4272e-01,  0.0000e+00],\n",
      "          [ 1.0309e-01,  4.9730e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1762e-01, -1.4468e-01, -0.0000e+00],\n",
      "          [ 3.6268e-01,  5.3481e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  5.2241e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00,  0.0000e+00,  1.2648e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.5915e-01],\n",
      "          [-0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3550e-02,  0.0000e+00,  6.7948e-02],\n",
      "          [ 5.6981e-01,  0.0000e+00,  4.5842e-01],\n",
      "          [ 2.9938e-02,  1.7861e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  3.6278e-01, -2.5424e-01],\n",
      "          [ 9.4070e-01,  0.0000e+00, -2.1502e-02],\n",
      "          [ 9.6985e-03,  6.5121e-02, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  9.1819e-02],\n",
      "          [ 0.0000e+00, -0.0000e+00, -3.3740e-01],\n",
      "          [-0.0000e+00, -0.0000e+00, -2.1633e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3137e-02, -0.0000e+00, -0.0000e+00],\n",
      "          [ 5.4615e-01,  2.9908e-01, -0.0000e+00],\n",
      "          [ 9.4902e-01,  2.2312e-01, -3.2910e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6456e-02, -3.2759e-01, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.7491e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -1.7607e-01, -7.8085e-02],\n",
      "          [-0.0000e+00,  1.0843e+00,  0.0000e+00],\n",
      "          [-7.0030e-02,  0.0000e+00,  1.0573e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  9.0907e-01],\n",
      "          [-1.3929e-01, -2.4492e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00]]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.base_module.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = test_dataset[100]\n",
    "plt.imshow(image.permute(1, 2, 0), cmap=\"gray\")\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2.1405], device='cuda:0'),\n",
       "indices=tensor([5], device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(model(image.cuda()).data, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
