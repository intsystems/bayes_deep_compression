{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем путь к нашей библиотеке в переменную окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../', '../', '../', '../', '/home/sasha/BMM/bayes_deep_compression/examples', '/home/sasha/anaconda3/lib/python311.zip', '/home/sasha/anaconda3/lib/python3.11', '/home/sasha/anaconda3/lib/python3.11/lib-dynload', '', '/home/sasha/anaconda3/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем простой классификтор, который будет нашей базовой моделью, кторую мы хотим обучить и запрунить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier(nn.Module): \n",
    "    def __init__(self, classes: int = 10): \n",
    "        super().__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) \n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        #self.dropout1 = nn.Dropout2d(0.25) \n",
    "        #self.dropout2 = nn.Dropout2d(0.5) \n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128) \n",
    "        self.fc2 = nn.Linear(128, classes) \n",
    "  \n",
    "    def forward(self, x): \n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        #x = self.dropout1(x) \n",
    "        x = self.pool(F.relu(self.conv2(x))) \n",
    "        #x = self.dropout2(x) \n",
    "        x = x.view(-1, 64 * 7 * 7) \n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.fc2(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как работают распределения в нашей библиотеке(Их не обязательно импортировать для работы и обучения байесовской модели)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый вид это привычные нам распределения на числа. Импортируем тот, который используется у нас в модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.bayes.variational.distribution import LogUniformVarDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый вид это привычные нам распределения на числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.bayes.variational.net_distribution import VarBayesModuleNetDistribution #Необязательно импортировать для обучения, оно встроено в нашу байесовскую модель\n",
    "from src.methods.bayes.base.net_distribution import BaseNetDistributionPruner #Также не обязательно для обучения, но нужен, если вы хотите запрунить модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем инициализировать веса распределения просто из параметров модели. При этом используется рекомендуемая начальная инициализация параметров распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogUniformVarDist(param_mus: torch.Size([2]), param_std_log: torch.Size([2]), scale_mus: torch.Size([2]), scale_alphas_log: torch.Size([2]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = nn.Parameter(torch.tensor([0.0, 1.0])) \n",
    "LogUniformVarDist.from_parameter(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это три модуля являются основными для байесовского обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.bayes.variational.net import LogUniformVarBayesModule, VarBayesModuleNet #Первым модулоем мы оборачиваем те слои модели, которые мы хотим сделать байесовыми, второй модуль это сама байесовская сеть\n",
    "from src.methods.bayes.variational.optimization import LogUniformVarKLLoss #Это лосс байесовской модели, который отвечает за тип обучения. Всегда рекомендуется использовать специализированный лосс, но для большинства распределений его нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет MNIST, на котором мы хотим обучить наш классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посомтрим внимательнее как нужно создавать байесовскую сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом создадим нашу базовую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы часть слоев превратим в байесовски с помощью LogUniformVarBayesModule. И создадим список всех слоев nn.ModuleList([layer1, layer2, ...]), которые мы хотим обучить (в том чилсе слои, которые не являются байесовыми). Заметим, что можно обернуть и всю сеть целиком и передать список состоящий только из нее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayes_model = BayesModule(module)\n",
    "var_module = LogUniformVarBayesModule(module)\n",
    "bayes_model = VarBayesModuleNet(module, nn.ModuleList([var_module])) #Первый аргумент базовая сеть, второй список всех слоев (где нужные из них являются байесовыми)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посомтрим на струкутру получившейся сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VarBayesModuleNet(\n",
      "  (module_list): ModuleList(\n",
      "    (0): LogUniformVarBayesModule(\n",
      "      (posterior_params): ParameterList(\n",
      "          (0): Object of type: ParameterDict\n",
      "          (1): Object of type: ParameterDict\n",
      "          (2): Object of type: ParameterDict\n",
      "          (3): Object of type: ParameterDict\n",
      "          (4): Object of type: ParameterDict\n",
      "          (5): Object of type: ParameterDict\n",
      "          (6): Object of type: ParameterDict\n",
      "          (7): Object of type: ParameterDict\n",
      "        (0): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "        )\n",
      "        (1): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        )\n",
      "        (2): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "        )\n",
      "        (3): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        )\n",
      "        (4): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "        )\n",
      "        (5): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 128]\n",
      "        )\n",
      "        (6): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "        )\n",
      "        (7): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 10]\n",
      "        )\n",
      "      )\n",
      "      (prior_params): ParameterList()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(bayes_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У выбранной сети отсутвует prior на параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1.weight': None,\n",
       " 'conv1.bias': None,\n",
       " 'conv2.weight': None,\n",
       " 'conv2.bias': None,\n",
       " 'fc1.weight': None,\n",
       " 'fc1.bias': None,\n",
       " 'fc2.weight': None,\n",
       " 'fc2.bias': None}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_model.prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посомотрим как выглядит шаг обучения для сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(bayes_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом он ничем не отличается от обычного шага, нам только нужно парвильно агрегировать лоссы от нескольких семплов на одном шаге"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = test_dataset[10]\n",
    "y = bayes_model(torch.ones_like(image))\n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "bayes_model.prior\n",
    "out = y.sum() + kl_loss(bayes_model.weights, bayes_model.posterior, bayes_model.prior)\n",
    "optimizer.zero_grad() \n",
    "out.backward() \n",
    "optimizer.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создать распределение сетей можно просто из распределения на параметры и базовой сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_distributon = VarBayesModuleNetDistribution(bayes_model.base_module, bayes_model.posterior)\n",
    "#Это прунер, которые зануляет веса в зависимости от плотности распределения при 0\n",
    "net_distributon_pruner = BaseNetDistributionPruner(net_distributon)\n",
    "#Здесь мы устанавливаем средние веса модели  \n",
    "net_distributon.set_map_params()\n",
    "#Пруним на основе определенного порога\n",
    "net_distributon_pruner.prune(1.9)\n",
    "#get basic model for evaluation\n",
    "eval_model = net_distributon.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили модель с той же архитектурой что и изначальная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 6.3249e-02,  1.5814e-01,  3.8829e-03],\n",
      "          [ 2.4058e-02, -2.3178e-01, -2.8446e-01],\n",
      "          [ 5.6721e-02,  1.8439e-01,  5.5126e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9575e-01,  1.4609e-02, -2.7889e-01],\n",
      "          [-1.9905e-02,  3.0885e-02, -9.1769e-03],\n",
      "          [-9.8800e-02,  1.0842e-01,  1.7173e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1514e-01,  2.3758e-01,  2.0561e-01],\n",
      "          [ 2.0869e-01,  3.7424e-02,  6.4716e-02],\n",
      "          [-2.3855e-01,  1.6314e-01, -1.3886e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2516e-01,  3.3954e-02, -2.1445e-01],\n",
      "          [-1.8017e-01, -1.0833e-01, -1.1456e-01],\n",
      "          [-3.1149e-01,  1.5491e-01, -9.1677e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6446e-01,  3.0714e-01,  6.7620e-02],\n",
      "          [-1.9942e-01, -4.7077e-02, -1.7820e-01],\n",
      "          [ 1.9929e-01, -1.5130e-02,  1.0482e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9565e-02, -3.2283e-01,  1.9363e-01],\n",
      "          [ 2.6283e-01, -2.5207e-01, -1.0031e-02],\n",
      "          [ 1.7877e-01,  2.4172e-01, -1.3343e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3626e-01, -1.1830e-01, -1.2918e-01],\n",
      "          [-1.6836e-01, -9.1709e-02,  7.2194e-03],\n",
      "          [ 2.5705e-02,  7.6537e-02, -1.2673e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9695e-01, -2.3112e-01, -2.3371e-02],\n",
      "          [ 2.0073e-01, -3.0053e-01,  9.6293e-02],\n",
      "          [ 2.0370e-01,  1.7394e-01, -2.4864e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9696e-01,  7.8698e-02, -2.2164e-01],\n",
      "          [-2.1264e-01,  1.2573e-01,  6.5880e-02],\n",
      "          [ 2.9747e-01,  1.5707e-01, -1.4481e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8944e-01,  8.8339e-02,  7.8998e-02],\n",
      "          [-6.5380e-02,  1.9769e-01, -3.1147e-01],\n",
      "          [ 1.7297e-01,  2.9047e-01,  2.4110e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.8665e-01,  3.0767e-01, -3.1222e-01],\n",
      "          [-1.2304e-01, -2.5287e-01, -1.8176e-01],\n",
      "          [-5.0821e-02,  3.0983e-01, -1.2575e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3420e-01, -3.2278e-01,  2.8678e-01],\n",
      "          [ 2.6469e-01, -2.1271e-01, -2.7315e-01],\n",
      "          [-2.8843e-01, -2.5024e-01,  7.7301e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8531e-01, -2.1587e-01, -2.6545e-04],\n",
      "          [-2.7060e-01,  1.8189e-01,  1.3029e-01],\n",
      "          [-2.7768e-01, -1.7507e-01,  1.1301e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4784e-01,  2.2392e-01, -2.9540e-01],\n",
      "          [ 1.2716e-01,  2.3161e-01, -1.9501e-01],\n",
      "          [ 1.0234e-01, -1.3075e-01,  1.3138e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6674e-01, -1.2254e-02,  2.6442e-01],\n",
      "          [ 3.1545e-01, -2.4576e-01, -8.5596e-02],\n",
      "          [-8.8103e-02, -2.2416e-01,  1.8649e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0032e-01, -2.0432e-01,  6.6860e-02],\n",
      "          [ 8.6090e-02,  2.9695e-01,  2.8527e-01],\n",
      "          [-1.5879e-01,  1.8676e-01, -8.1545e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.4853e-01,  3.1922e-02,  1.0349e-01],\n",
      "          [-3.0823e-01, -2.2675e-01,  2.8323e-02],\n",
      "          [-1.7681e-01, -2.2863e-01,  2.0410e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2377e-02,  8.3482e-02, -1.8226e-01],\n",
      "          [-2.1483e-01,  1.1903e-01,  2.0637e-01],\n",
      "          [ 2.1208e-01,  2.2130e-01,  1.3679e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6002e-01,  1.3583e-01,  1.7042e-01],\n",
      "          [ 2.5910e-01,  5.9848e-02,  3.1669e-01],\n",
      "          [ 9.3051e-02, -9.0814e-02, -2.4995e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5547e-03,  2.0088e-01,  5.7244e-03],\n",
      "          [-1.3015e-01,  1.1891e-01,  2.1488e-01],\n",
      "          [-7.8003e-02, -2.0601e-01, -2.1591e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8816e-02, -8.2538e-04, -4.2326e-02],\n",
      "          [ 1.4072e-01,  9.6806e-02, -1.7587e-01],\n",
      "          [-1.1362e-01,  7.6905e-02, -3.1993e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.0626e-02, -3.2943e-01, -3.5143e-02],\n",
      "          [-1.3995e-01, -1.9037e-01, -2.4683e-01],\n",
      "          [ 2.0962e-01,  2.4926e-01, -2.7932e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7484e-01,  9.1847e-02,  3.2501e-01],\n",
      "          [ 1.1889e-01,  3.6765e-02,  1.0645e-01],\n",
      "          [-2.4057e-02,  2.4987e-01,  4.9561e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1675e-01,  2.4712e-01, -6.8908e-02],\n",
      "          [ 2.0797e-01, -1.4337e-01,  8.0453e-03],\n",
      "          [-3.9585e-03,  1.4603e-01,  1.7111e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3605e-01, -2.2173e-01,  5.0235e-02],\n",
      "          [-1.1369e-01,  1.0464e-01,  2.6568e-02],\n",
      "          [ 2.1208e-01,  1.0322e-01,  1.3689e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7867e-02,  1.2308e-01,  1.0654e-01],\n",
      "          [-6.7606e-02,  1.2722e-01, -7.6818e-02],\n",
      "          [-2.6292e-01,  1.2193e-01,  2.5598e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3263e-01, -1.5623e-01, -2.2328e-01],\n",
      "          [ 1.9868e-01, -7.2249e-02, -2.8202e-03],\n",
      "          [ 3.0318e-01, -2.7814e-01, -1.8768e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6085e-01,  1.7006e-01,  9.2686e-04],\n",
      "          [-2.1519e-02, -1.9549e-01, -2.8367e-03],\n",
      "          [-1.5456e-01, -1.1120e-01, -1.1946e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2577e-01,  2.9979e-01,  1.1551e-01],\n",
      "          [-1.0732e-01, -8.8393e-02, -2.6835e-01],\n",
      "          [ 1.6268e-02,  5.3342e-02, -1.5783e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1320e-01, -3.1266e-01,  2.1240e-01],\n",
      "          [ 1.4327e-01,  1.1969e-01,  3.1493e-01],\n",
      "          [ 1.9854e-01, -5.4385e-02,  3.1162e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.3908e-02,  8.4433e-02, -3.2920e-01],\n",
      "          [ 2.7080e-01,  2.4936e-01,  9.5659e-02],\n",
      "          [-1.8552e-01, -1.2064e-03, -2.9935e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9535e-01, -1.2418e-01,  3.2047e-01],\n",
      "          [ 1.7816e-01,  3.1537e-01,  1.1571e-01],\n",
      "          [-6.5247e-02, -9.2289e-02,  7.4054e-02]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(eval_model.conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('module_list.0.posterior_params.0.param_mus',\n",
       "              tensor([[[[ 6.3249e-02,  1.5814e-01,  3.8829e-03],\n",
       "                        [ 2.4058e-02, -2.3178e-01, -2.8446e-01],\n",
       "                        [ 5.6721e-02,  1.8439e-01,  5.5126e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9575e-01,  1.4609e-02, -2.7889e-01],\n",
       "                        [-1.9905e-02,  3.0885e-02, -9.1769e-03],\n",
       "                        [-9.8800e-02,  1.0842e-01,  1.7173e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1514e-01,  2.3758e-01,  2.0561e-01],\n",
       "                        [ 2.0869e-01,  3.7424e-02,  6.4716e-02],\n",
       "                        [-2.3855e-01,  1.6314e-01, -1.3886e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2516e-01,  3.3954e-02, -2.1445e-01],\n",
       "                        [-1.8017e-01, -1.0833e-01, -1.1456e-01],\n",
       "                        [-3.1149e-01,  1.5491e-01, -9.1677e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6446e-01,  3.0714e-01,  6.7620e-02],\n",
       "                        [-1.9942e-01, -4.7077e-02, -1.7820e-01],\n",
       "                        [ 1.9929e-01, -1.5130e-02,  1.0482e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.9565e-02, -3.2283e-01,  1.9363e-01],\n",
       "                        [ 2.6283e-01, -2.5207e-01, -1.0031e-02],\n",
       "                        [ 1.7877e-01,  2.4172e-01, -1.3343e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3626e-01, -1.1830e-01, -1.2918e-01],\n",
       "                        [-1.6836e-01, -9.1709e-02,  7.2194e-03],\n",
       "                        [ 2.5705e-02,  7.6537e-02, -1.2673e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9695e-01, -2.3112e-01, -2.3371e-02],\n",
       "                        [ 2.0073e-01, -3.0053e-01,  9.6293e-02],\n",
       "                        [ 2.0370e-01,  1.7394e-01, -2.4864e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9696e-01,  7.8698e-02, -2.2164e-01],\n",
       "                        [-2.1264e-01,  1.2573e-01,  6.5880e-02],\n",
       "                        [ 2.9747e-01,  1.5707e-01, -1.4481e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8944e-01,  8.8339e-02,  7.8998e-02],\n",
       "                        [-6.5380e-02,  1.9769e-01, -3.1147e-01],\n",
       "                        [ 1.7297e-01,  2.9047e-01,  2.4110e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8665e-01,  3.0767e-01, -3.1222e-01],\n",
       "                        [-1.2304e-01, -2.5287e-01, -1.8176e-01],\n",
       "                        [-5.0821e-02,  3.0983e-01, -1.2575e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3420e-01, -3.2278e-01,  2.8678e-01],\n",
       "                        [ 2.6469e-01, -2.1271e-01, -2.7315e-01],\n",
       "                        [-2.8843e-01, -2.5024e-01,  7.7301e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.8531e-01, -2.1587e-01, -2.6545e-04],\n",
       "                        [-2.7060e-01,  1.8189e-01,  1.3029e-01],\n",
       "                        [-2.7768e-01, -1.7507e-01,  1.1301e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4784e-01,  2.2392e-01, -2.9540e-01],\n",
       "                        [ 1.2716e-01,  2.3161e-01, -1.9501e-01],\n",
       "                        [ 1.0234e-01, -1.3075e-01,  1.3138e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6674e-01, -1.2254e-02,  2.6442e-01],\n",
       "                        [ 3.1545e-01, -2.4576e-01, -8.5596e-02],\n",
       "                        [-8.8103e-02, -2.2416e-01,  1.8649e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0032e-01, -2.0432e-01,  6.6860e-02],\n",
       "                        [ 8.6090e-02,  2.9695e-01,  2.8527e-01],\n",
       "                        [-1.5879e-01,  1.8676e-01, -8.1545e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4853e-01,  3.1922e-02,  1.0349e-01],\n",
       "                        [-3.0823e-01, -2.2675e-01,  2.8323e-02],\n",
       "                        [-1.7681e-01, -2.2863e-01,  2.0410e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2377e-02,  8.3482e-02, -1.8226e-01],\n",
       "                        [-2.1483e-01,  1.1903e-01,  2.0637e-01],\n",
       "                        [ 2.1208e-01,  2.2130e-01,  1.3679e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.6002e-01,  1.3583e-01,  1.7042e-01],\n",
       "                        [ 2.5910e-01,  5.9848e-02,  3.1669e-01],\n",
       "                        [ 9.3051e-02, -9.0814e-02, -2.4995e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.5547e-03,  2.0088e-01,  5.7244e-03],\n",
       "                        [-1.3015e-01,  1.1891e-01,  2.1488e-01],\n",
       "                        [-7.8003e-02, -2.0601e-01, -2.1591e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.8816e-02, -8.2538e-04, -4.2326e-02],\n",
       "                        [ 1.4072e-01,  9.6806e-02, -1.7587e-01],\n",
       "                        [-1.1362e-01,  7.6905e-02, -3.1993e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0626e-02, -3.2943e-01, -3.5143e-02],\n",
       "                        [-1.3995e-01, -1.9037e-01, -2.4683e-01],\n",
       "                        [ 2.0962e-01,  2.4926e-01, -2.7932e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7484e-01,  9.1847e-02,  3.2501e-01],\n",
       "                        [ 1.1889e-01,  3.6765e-02,  1.0645e-01],\n",
       "                        [-2.4057e-02,  2.4987e-01,  4.9561e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1675e-01,  2.4712e-01, -6.8908e-02],\n",
       "                        [ 2.0797e-01, -1.4337e-01,  8.0453e-03],\n",
       "                        [-3.9585e-03,  1.4603e-01,  1.7111e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3605e-01, -2.2173e-01,  5.0235e-02],\n",
       "                        [-1.1369e-01,  1.0464e-01,  2.6568e-02],\n",
       "                        [ 2.1208e-01,  1.0322e-01,  1.3689e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.7867e-02,  1.2308e-01,  1.0654e-01],\n",
       "                        [-6.7606e-02,  1.2722e-01, -7.6818e-02],\n",
       "                        [-2.6292e-01,  1.2193e-01,  2.5598e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3263e-01, -1.5623e-01, -2.2328e-01],\n",
       "                        [ 1.9868e-01, -7.2249e-02, -2.8202e-03],\n",
       "                        [ 3.0318e-01, -2.7814e-01, -1.8768e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6085e-01,  1.7006e-01,  9.2686e-04],\n",
       "                        [-2.1519e-02, -1.9549e-01, -2.8367e-03],\n",
       "                        [-1.5456e-01, -1.1120e-01, -1.1946e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2577e-01,  2.9979e-01,  1.1551e-01],\n",
       "                        [-1.0732e-01, -8.8393e-02, -2.6835e-01],\n",
       "                        [ 1.6268e-02,  5.3342e-02, -1.5783e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1320e-01, -3.1266e-01,  2.1240e-01],\n",
       "                        [ 1.4327e-01,  1.1969e-01,  3.1493e-01],\n",
       "                        [ 1.9854e-01, -5.4385e-02,  3.1162e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.3908e-02,  8.4433e-02, -3.2920e-01],\n",
       "                        [ 2.7080e-01,  2.4936e-01,  9.5659e-02],\n",
       "                        [-1.8552e-01, -1.2064e-03, -2.9935e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9535e-01, -1.2418e-01,  3.2047e-01],\n",
       "                        [ 1.7816e-01,  3.1537e-01,  1.1571e-01],\n",
       "                        [-6.5247e-02, -9.2289e-02,  7.4054e-02]]]])),\n",
       "             ('module_list.0.posterior_params.0.param_std_log',\n",
       "              tensor([[[[ -7.3515,  -5.2463,  -4.9071],\n",
       "                        [ -5.3060,  -6.8302,  -5.2453],\n",
       "                        [ -7.7680,  -5.0732,  -6.2065]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.0724,  -4.6410,  -5.9014],\n",
       "                        [ -4.7862,  -5.4078,  -4.9103],\n",
       "                        [ -4.7145,  -5.4983,  -7.8047]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7109,  -5.0427,  -5.6726],\n",
       "                        [ -5.8571,  -5.7170,  -4.7109],\n",
       "                        [ -5.5420,  -5.5771,  -5.0829]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.7223,  -4.8858,  -5.7309],\n",
       "                        [ -4.9079,  -7.5026,  -5.0444],\n",
       "                        [ -5.5462,  -4.8925,  -5.2615]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6469,  -5.3758,  -8.8843],\n",
       "                        [ -5.8317,  -4.6245,  -6.3834],\n",
       "                        [ -5.1552,  -8.7662,  -4.7226]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7679,  -5.4544,  -6.6282],\n",
       "                        [ -4.6234,  -5.3469,  -6.2231],\n",
       "                        [ -4.7636,  -4.7669,  -6.9481]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9162,  -5.2031,  -4.9083],\n",
       "                        [ -7.3085,  -4.6843,  -5.8917],\n",
       "                        [ -5.4986,  -5.8640,  -5.4059]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9370,  -5.5448,  -7.2914],\n",
       "                        [ -4.9572,  -5.3014,  -4.6962],\n",
       "                        [ -5.1112,  -4.9328,  -5.5238]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3533,  -4.7612,  -4.8063],\n",
       "                        [ -4.6055,  -4.7900,  -5.5807],\n",
       "                        [ -5.4549,  -4.8628,  -5.8160]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.5101,  -4.8942,  -4.7928],\n",
       "                        [ -6.6635,  -4.7513,  -5.0937],\n",
       "                        [ -6.5157,  -4.8127,  -4.7679]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.4979,  -4.9100,  -5.2250],\n",
       "                        [ -4.6272,  -5.0323,  -5.0447],\n",
       "                        [ -4.9779,  -5.1057,  -5.1822]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.7351,  -5.7416,  -4.7786],\n",
       "                        [ -6.1465,  -5.2737,  -5.1062],\n",
       "                        [ -4.7615,  -7.0299,  -6.5246]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.8594,  -5.3781,  -4.9415],\n",
       "                        [ -4.6913,  -4.6994,  -5.5499],\n",
       "                        [ -7.1011,  -5.3390,  -4.6636]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3680,  -7.6991,  -5.2951],\n",
       "                        [ -5.0012,  -5.0201,  -4.8104],\n",
       "                        [ -4.8837,  -4.7905,  -5.1939]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.3289,  -4.7441,  -6.4981],\n",
       "                        [ -6.1563,  -4.8510,  -4.7324],\n",
       "                        [ -5.0683,  -4.7070,  -5.0610]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.5330,  -7.5205,  -5.9200],\n",
       "                        [ -5.1267,  -5.5949,  -5.1955],\n",
       "                        [ -7.5859,  -4.8425,  -5.4407]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.8303,  -4.8101,  -4.7206],\n",
       "                        [ -5.4487,  -6.1328,  -5.4390],\n",
       "                        [ -5.3332,  -5.1365,  -6.7253]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.7004,  -4.7052,  -7.7916],\n",
       "                        [ -5.5510,  -4.6368,  -5.8682],\n",
       "                        [ -4.6901,  -5.8867,  -6.2638]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3204,  -5.5871,  -4.8212],\n",
       "                        [ -7.0279,  -6.5942,  -5.4930],\n",
       "                        [ -6.2024,  -4.7259,  -6.1627]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6439, -11.0994,  -5.5555],\n",
       "                        [ -5.7178, -10.5367,  -6.8183],\n",
       "                        [ -5.1750,  -4.9240,  -5.2594]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.1401,  -4.6462,  -8.3173],\n",
       "                        [ -4.9770,  -5.7648,  -5.9260],\n",
       "                        [ -4.9078,  -8.0658, -10.7205]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7162,  -4.9934,  -5.6151],\n",
       "                        [ -5.1210,  -4.9262,  -5.3227],\n",
       "                        [ -4.9098,  -5.2116,  -4.8616]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7960,  -4.8719,  -4.6927],\n",
       "                        [ -4.8937,  -6.4543,  -5.8805],\n",
       "                        [ -5.9564,  -6.0126,  -4.7402]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.0888,  -4.7021,  -4.9542],\n",
       "                        [ -7.8473,  -4.8414,  -4.9480],\n",
       "                        [ -5.8167,  -5.7926,  -5.0922]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.6563,  -4.6083,  -5.5772],\n",
       "                        [ -5.3537,  -5.0514,  -9.0565],\n",
       "                        [ -7.0939,  -4.8812,  -4.8662]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6717,  -5.4814,  -5.4341],\n",
       "                        [ -4.9189,  -5.0522,  -4.9671],\n",
       "                        [ -5.4664,  -4.9375,  -5.8977]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6118,  -5.3913,  -4.7056],\n",
       "                        [ -4.6259,  -5.7436,  -4.9852],\n",
       "                        [ -4.6835,  -5.6139,  -5.0410]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.9462,  -4.8185,  -7.1864],\n",
       "                        [ -4.7210,  -6.0822,  -5.8156],\n",
       "                        [ -5.0227,  -4.6944,  -6.5048]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.1445,  -6.7917,  -5.7785],\n",
       "                        [ -5.6429,  -4.9710,  -8.3190],\n",
       "                        [ -5.2489,  -5.2838,  -5.4456]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.4935,  -5.7735,  -4.6931],\n",
       "                        [ -6.2042,  -4.8574,  -5.1008],\n",
       "                        [ -6.0842,  -5.4291,  -5.1339]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.0024,  -4.8047,  -5.0787],\n",
       "                        [ -4.9686,  -6.1786,  -5.2961],\n",
       "                        [ -5.1291,  -5.1845,  -4.7832]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7041,  -7.5893,  -6.6080],\n",
       "                        [ -6.1648,  -5.1126,  -6.5164],\n",
       "                        [ -7.3468,  -5.6689,  -6.4401]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_alphas_log',\n",
       "              tensor([[[[-2.9611, -3.6396, -2.9662],\n",
       "                        [-3.1127, -2.2807, -3.8028],\n",
       "                        [-2.9060, -2.8306, -2.5183]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2562, -2.0529, -3.5445],\n",
       "                        [-3.5948, -3.1314, -3.5103],\n",
       "                        [-3.2815, -2.2154, -2.2486]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0468, -2.4799, -2.1744],\n",
       "                        [-2.9349, -3.5979, -3.0821],\n",
       "                        [-2.7963, -2.6367, -2.6392]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7022, -3.5144, -2.6357],\n",
       "                        [-2.0097, -3.1587, -3.7668],\n",
       "                        [-2.0370, -3.0412, -3.9683]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9072, -2.8073, -3.6327],\n",
       "                        [-3.1679, -3.5771, -3.4897],\n",
       "                        [-2.0120, -2.4669, -3.4878]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3628, -3.8428, -3.6433],\n",
       "                        [-3.9893, -3.1925, -3.0485],\n",
       "                        [-2.0624, -3.0355, -3.8851]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6436, -2.6179, -3.6080],\n",
       "                        [-3.8454, -2.3246, -3.7567],\n",
       "                        [-3.2161, -2.2912, -3.9222]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3933, -2.8913, -3.2580],\n",
       "                        [-3.9649, -2.1849, -3.8794],\n",
       "                        [-3.5403, -2.2741, -3.8364]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9223, -2.9260, -2.0893],\n",
       "                        [-3.0566, -2.3970, -3.6454],\n",
       "                        [-2.2153, -2.4227, -3.3234]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8681, -3.3104, -3.8370],\n",
       "                        [-3.6544, -2.1132, -3.7938],\n",
       "                        [-3.8914, -3.0789, -3.7875]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7838, -3.0464, -3.0163],\n",
       "                        [-3.0018, -3.9111, -3.2328],\n",
       "                        [-2.4899, -3.6474, -2.2648]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0724, -2.1631, -2.8710],\n",
       "                        [-3.4011, -3.0230, -2.7900],\n",
       "                        [-3.1492, -2.3479, -2.2614]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0423, -2.8642, -2.5413],\n",
       "                        [-3.5222, -2.7747, -3.6300],\n",
       "                        [-3.7418, -3.3893, -3.1542]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9724, -3.1624, -3.4413],\n",
       "                        [-3.7537, -3.2950, -2.2962],\n",
       "                        [-3.9709, -2.1856, -3.5820]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5336, -2.8130, -3.8204],\n",
       "                        [-2.7577, -3.3169, -3.7279],\n",
       "                        [-3.8681, -3.2331, -3.4068]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0622, -3.1586, -3.1031],\n",
       "                        [-3.2343, -2.4221, -2.9652],\n",
       "                        [-2.9910, -3.4056, -3.2451]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3735, -2.6692, -3.3408],\n",
       "                        [-3.7974, -2.8201, -3.5073],\n",
       "                        [-3.8996, -2.3734, -2.5597]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8516, -3.4459, -2.3032],\n",
       "                        [-3.6751, -3.6376, -2.8033],\n",
       "                        [-2.4138, -3.1812, -2.5023]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2655, -3.1769, -3.7464],\n",
       "                        [-2.5345, -2.2901, -3.4413],\n",
       "                        [-3.3486, -2.1729, -3.8295]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0508, -3.2262, -3.0523],\n",
       "                        [-2.1387, -2.1132, -2.8607],\n",
       "                        [-2.7191, -3.6913, -3.9235]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6186, -2.7953, -2.4716],\n",
       "                        [-3.9200, -2.9231, -3.8626],\n",
       "                        [-2.6312, -2.4077, -2.7854]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5033, -3.1033, -2.0969],\n",
       "                        [-2.6928, -2.5236, -3.3082],\n",
       "                        [-2.7903, -2.4322, -3.4023]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0765, -2.6645, -2.2050],\n",
       "                        [-3.7245, -2.7599, -3.2469],\n",
       "                        [-3.3946, -3.0379, -3.5763]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4790, -2.9541, -3.5195],\n",
       "                        [-2.0777, -3.2979, -3.0967],\n",
       "                        [-2.8464, -2.2250, -2.9065]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2336, -3.4010, -3.4138],\n",
       "                        [-2.0024, -3.7452, -2.2492],\n",
       "                        [-3.7423, -2.7820, -2.2984]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9810, -3.1856, -3.2433],\n",
       "                        [-3.3192, -2.5447, -3.0919],\n",
       "                        [-3.6110, -2.3594, -2.3647]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2237, -2.7065, -3.4572],\n",
       "                        [-2.4799, -3.0022, -2.6226],\n",
       "                        [-3.5642, -2.1359, -2.8617]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2917, -2.2615, -2.9406],\n",
       "                        [-2.6230, -2.9765, -2.6468],\n",
       "                        [-2.5838, -2.8157, -2.5869]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6765, -2.9186, -3.4963],\n",
       "                        [-3.5249, -3.4294, -3.1755],\n",
       "                        [-2.9484, -3.1047, -2.6197]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0780, -2.7616, -3.1019],\n",
       "                        [-3.0770, -3.9048, -3.1264],\n",
       "                        [-2.4195, -2.1085, -2.7280]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.7928, -2.7029, -2.4305],\n",
       "                        [-2.2759, -2.8628, -2.5872],\n",
       "                        [-3.2432, -3.3631, -3.9655]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6783, -3.9190, -2.9328],\n",
       "                        [-3.2238, -2.4143, -2.7024],\n",
       "                        [-3.3079, -3.7001, -2.5789]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.1.param_mus',\n",
       "              tensor([-0.2067,  0.1599,  0.3307,  0.1790,  0.1650, -0.1181, -0.1114, -0.2091,\n",
       "                      -0.2848, -0.2739, -0.0239,  0.2835, -0.1754, -0.2761, -0.1140, -0.3034,\n",
       "                       0.1860, -0.1548,  0.0093,  0.2764, -0.1380, -0.3014, -0.2611,  0.2016,\n",
       "                       0.0550,  0.0925, -0.1419,  0.2309, -0.0190,  0.1320,  0.1669, -0.1706])),\n",
       "             ('module_list.0.posterior_params.1.param_std_log',\n",
       "              tensor([-5.7653, -5.7670, -6.8953, -5.1538, -4.7433, -4.8421, -6.3689, -5.1103,\n",
       "                      -4.6593, -4.9426, -5.0290, -7.5533, -5.0405, -6.2522, -5.0352, -5.8742,\n",
       "                      -5.6166, -4.9950, -5.3010, -6.0250, -5.2369, -6.2613, -6.7889, -5.0472,\n",
       "                      -5.5904, -4.9044, -4.8326, -4.9942, -5.3216, -4.8744, -5.7589, -5.2074])),\n",
       "             ('module_list.0.posterior_params.1.scale_alphas_log',\n",
       "              tensor([-3.9867, -3.6365, -3.4103, -2.0453, -2.5675, -2.8301, -2.9213, -3.8384,\n",
       "                      -3.3012, -2.5647, -2.2085, -2.5142, -2.6900, -3.7489, -2.9041, -2.5956,\n",
       "                      -3.3582, -2.3940, -2.8648, -3.3653, -2.4109, -2.0432, -2.4896, -3.5452,\n",
       "                      -2.8456, -2.3840, -2.4536, -2.3856, -3.4987, -2.4605, -2.6734, -3.0573])),\n",
       "             ('module_list.0.posterior_params.1.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.2.param_mus',\n",
       "              tensor([[[[-6.4704e-03, -5.0530e-03, -1.9033e-02],\n",
       "                        [ 4.4387e-02, -5.2150e-02,  5.7876e-02],\n",
       "                        [-2.9769e-02,  2.9614e-02, -3.7811e-02]],\n",
       "              \n",
       "                       [[-3.3487e-02, -4.6662e-02, -7.4531e-03],\n",
       "                        [ 2.9560e-02,  5.2400e-02, -4.2129e-02],\n",
       "                        [ 8.9295e-05, -3.8608e-02, -2.0325e-02]],\n",
       "              \n",
       "                       [[ 3.5341e-02,  4.1869e-02,  3.0087e-02],\n",
       "                        [-4.1318e-02, -4.3643e-03,  1.3479e-02],\n",
       "                        [ 1.1047e-02,  1.0129e-02,  2.9674e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0431e-02,  1.1759e-02, -4.3577e-02],\n",
       "                        [ 9.3718e-03,  3.6385e-02,  4.1468e-02],\n",
       "                        [ 2.0251e-02,  5.4449e-02, -1.9794e-03]],\n",
       "              \n",
       "                       [[ 3.2375e-02,  4.6132e-02, -1.4533e-02],\n",
       "                        [-1.3025e-02,  2.3946e-02,  5.2935e-02],\n",
       "                        [ 3.9364e-02,  4.3448e-02,  2.7013e-02]],\n",
       "              \n",
       "                       [[-4.9846e-03, -6.5588e-03, -3.2898e-03],\n",
       "                        [-3.9435e-02,  1.0376e-02,  5.1722e-02],\n",
       "                        [ 4.7437e-02,  2.8359e-04,  8.3822e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.9915e-03, -5.2238e-02, -1.9619e-02],\n",
       "                        [ 3.3858e-02,  5.8241e-03, -1.7749e-02],\n",
       "                        [-8.9084e-03, -8.4255e-03, -4.9514e-02]],\n",
       "              \n",
       "                       [[-2.6624e-02,  5.0517e-02,  5.4395e-02],\n",
       "                        [ 3.3063e-02,  5.0108e-02, -3.7014e-02],\n",
       "                        [-4.6669e-03,  2.8863e-02,  8.9150e-03]],\n",
       "              \n",
       "                       [[-3.7611e-02,  3.5992e-03,  4.3408e-03],\n",
       "                        [ 5.6703e-02, -3.6700e-02, -4.2476e-02],\n",
       "                        [ 1.0115e-02, -3.3908e-02, -1.0169e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.2578e-02,  4.7624e-02, -5.2423e-02],\n",
       "                        [-3.9817e-02, -4.5965e-02,  4.2980e-02],\n",
       "                        [ 2.9537e-02, -3.3227e-02, -3.5721e-02]],\n",
       "              \n",
       "                       [[ 3.9036e-02, -5.0940e-03, -2.7360e-02],\n",
       "                        [ 2.5877e-02,  5.6771e-02,  2.1745e-02],\n",
       "                        [ 2.2328e-02, -4.7128e-02, -5.0492e-02]],\n",
       "              \n",
       "                       [[-2.9892e-02, -3.1463e-02,  5.2476e-02],\n",
       "                        [ 5.5941e-02, -2.7829e-02,  2.5156e-02],\n",
       "                        [ 5.1203e-02, -3.9455e-02,  5.5633e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.3561e-02, -5.3080e-02, -4.7119e-02],\n",
       "                        [ 5.3259e-02, -5.6343e-02,  4.4385e-02],\n",
       "                        [ 5.0508e-02, -3.3386e-02, -2.4039e-02]],\n",
       "              \n",
       "                       [[ 2.6241e-02,  2.1625e-02,  3.5020e-02],\n",
       "                        [ 1.4754e-02,  3.6485e-02, -5.4338e-02],\n",
       "                        [-5.0275e-02, -4.5790e-02,  4.1195e-02]],\n",
       "              \n",
       "                       [[ 2.1931e-02, -3.4757e-02,  6.3590e-03],\n",
       "                        [ 4.1424e-02, -9.4087e-03,  1.8362e-02],\n",
       "                        [-2.9740e-03,  6.9835e-03,  4.0545e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.9553e-02, -1.9233e-02,  5.3479e-02],\n",
       "                        [ 1.6321e-02, -2.4311e-03,  4.8281e-02],\n",
       "                        [-2.5708e-02, -3.5455e-02, -4.1708e-02]],\n",
       "              \n",
       "                       [[ 4.0818e-03, -4.6542e-02,  4.1857e-02],\n",
       "                        [ 1.7171e-02,  3.2065e-02,  2.6196e-02],\n",
       "                        [ 5.5854e-02, -5.5591e-02, -3.1059e-02]],\n",
       "              \n",
       "                       [[ 2.4628e-02, -2.7404e-02,  1.5343e-02],\n",
       "                        [-3.2381e-02,  1.6646e-02,  4.4243e-02],\n",
       "                        [-5.7452e-02, -5.7665e-02,  2.6970e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0941e-02, -2.2617e-03, -6.6361e-03],\n",
       "                        [-3.9320e-03, -4.7195e-02,  5.5836e-02],\n",
       "                        [-3.1713e-02,  4.3756e-02,  5.6321e-02]],\n",
       "              \n",
       "                       [[ 2.0265e-02, -4.4928e-02, -3.9285e-02],\n",
       "                        [-5.0059e-02,  3.7810e-02, -5.7232e-02],\n",
       "                        [ 1.4346e-03, -6.8184e-03,  1.6466e-03]],\n",
       "              \n",
       "                       [[-3.6096e-02,  1.4406e-02,  2.8793e-02],\n",
       "                        [ 3.9850e-02, -3.2408e-02,  4.0353e-02],\n",
       "                        [ 1.0236e-02, -3.4895e-02,  2.7160e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3294e-02, -1.7116e-02, -2.5937e-02],\n",
       "                        [ 1.3062e-02,  3.8341e-02,  2.5474e-02],\n",
       "                        [ 3.8189e-02, -1.1626e-02,  4.9408e-03]],\n",
       "              \n",
       "                       [[-3.8716e-02,  3.0108e-02, -4.9922e-02],\n",
       "                        [ 1.6088e-02,  3.4904e-02,  2.7354e-02],\n",
       "                        [-5.6719e-02,  5.7246e-02, -1.0989e-02]],\n",
       "              \n",
       "                       [[-3.1076e-02,  5.4449e-03,  4.4220e-03],\n",
       "                        [ 4.1133e-02,  5.2677e-02, -1.9638e-02],\n",
       "                        [ 1.2994e-02, -2.9165e-02, -5.7411e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4179e-02, -3.7184e-02,  5.0874e-02],\n",
       "                        [ 1.4210e-02,  3.2090e-02, -4.8644e-02],\n",
       "                        [ 3.2551e-02,  4.1600e-03,  6.3523e-03]],\n",
       "              \n",
       "                       [[ 2.4416e-02, -3.2688e-02, -5.6044e-02],\n",
       "                        [ 9.2668e-03,  3.3855e-02,  5.2960e-02],\n",
       "                        [-4.3556e-02, -1.2837e-02, -4.3236e-02]],\n",
       "              \n",
       "                       [[-4.3584e-03, -4.2012e-02,  5.0095e-02],\n",
       "                        [-5.0688e-02,  5.5216e-02, -2.2135e-02],\n",
       "                        [ 1.1760e-02,  4.0273e-02, -3.0240e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.4367e-02, -3.2817e-02,  4.1966e-02],\n",
       "                        [-1.5881e-02, -4.9088e-02, -2.9996e-02],\n",
       "                        [-3.9078e-02, -3.8062e-02, -5.1944e-02]],\n",
       "              \n",
       "                       [[-1.7411e-02,  2.3463e-02, -4.1098e-02],\n",
       "                        [-2.1946e-02,  9.0807e-04, -3.1759e-02],\n",
       "                        [-3.9008e-02,  4.6809e-02,  1.9664e-02]],\n",
       "              \n",
       "                       [[ 1.3767e-02, -2.1606e-02,  3.7369e-02],\n",
       "                        [-6.9117e-03, -4.6030e-02, -1.2134e-02],\n",
       "                        [ 3.7795e-02, -4.1695e-02,  4.4639e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.0116e-03,  5.1199e-02, -4.9727e-02],\n",
       "                        [-5.7237e-02, -4.7722e-02, -3.3117e-03],\n",
       "                        [-5.3313e-03, -1.7633e-02,  4.7582e-02]],\n",
       "              \n",
       "                       [[ 9.5077e-03,  5.7793e-03, -2.6112e-02],\n",
       "                        [ 2.2335e-02, -4.9728e-02,  2.1185e-02],\n",
       "                        [-4.1599e-02,  3.5471e-03,  4.2075e-02]],\n",
       "              \n",
       "                       [[-3.9207e-02,  1.5690e-02,  1.0893e-02],\n",
       "                        [-1.4236e-02,  6.8124e-03,  5.6422e-02],\n",
       "                        [-5.6483e-02, -2.8125e-03,  5.2289e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.9834e-02,  4.5660e-02, -3.1352e-02],\n",
       "                        [-8.7755e-03, -8.5849e-03, -4.1054e-02],\n",
       "                        [ 3.7619e-02, -3.2868e-02, -6.2038e-03]],\n",
       "              \n",
       "                       [[ 5.1481e-02, -4.0861e-02,  2.8256e-02],\n",
       "                        [ 4.9224e-02, -1.6859e-03, -2.4208e-02],\n",
       "                        [-4.9254e-02, -4.0985e-03,  2.0708e-02]],\n",
       "              \n",
       "                       [[-4.3074e-02,  5.0606e-04,  3.6274e-02],\n",
       "                        [-4.5732e-02, -4.5078e-02,  5.2659e-02],\n",
       "                        [ 2.5298e-02, -3.5339e-02, -3.3501e-02]]]])),\n",
       "             ('module_list.0.posterior_params.2.param_std_log',\n",
       "              tensor([[[[ -5.1582,  -6.9072,  -4.9259],\n",
       "                        [ -5.1282,  -5.3971,  -6.0051],\n",
       "                        [ -5.4457,  -4.9287,  -7.9210]],\n",
       "              \n",
       "                       [[ -5.4885,  -6.9856,  -5.4544],\n",
       "                        [ -6.6170,  -5.8718,  -5.7073],\n",
       "                        [ -5.8406,  -4.6271,  -5.0281]],\n",
       "              \n",
       "                       [[ -5.1925,  -4.6073,  -5.4059],\n",
       "                        [ -6.9059,  -6.1863,  -4.8260],\n",
       "                        [ -6.2781,  -5.9114,  -4.7683]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.6695,  -4.8417,  -5.4606],\n",
       "                        [ -5.5567,  -5.6407,  -8.4410],\n",
       "                        [ -5.8505,  -5.5174,  -5.0388]],\n",
       "              \n",
       "                       [[ -5.3214,  -4.9805,  -5.4972],\n",
       "                        [ -5.6307,  -4.7011,  -5.6071],\n",
       "                        [ -4.6814,  -4.7717,  -5.9518]],\n",
       "              \n",
       "                       [[ -4.7282,  -5.5930,  -5.6261],\n",
       "                        [ -4.7642,  -4.7321,  -5.5908],\n",
       "                        [ -4.7554,  -4.8384,  -5.5481]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9609,  -6.3858,  -5.5094],\n",
       "                        [ -5.8379,  -5.7862,  -5.0045],\n",
       "                        [ -5.9030,  -6.7667,  -5.0470]],\n",
       "              \n",
       "                       [[ -5.5980,  -6.1284,  -6.2008],\n",
       "                        [ -4.6357,  -7.8348,  -4.7244],\n",
       "                        [ -6.4004,  -5.5966,  -4.6720]],\n",
       "              \n",
       "                       [[ -6.4062,  -4.7120,  -4.6063],\n",
       "                        [ -4.7252,  -4.6961,  -5.9515],\n",
       "                        [ -5.2513,  -5.0056,  -4.9411]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.0292,  -6.6118,  -5.4033],\n",
       "                        [ -4.8886,  -7.5799,  -5.4878],\n",
       "                        [ -4.6497,  -5.2816,  -5.6387]],\n",
       "              \n",
       "                       [[ -7.0945,  -4.7863,  -5.8599],\n",
       "                        [ -5.7417,  -5.0171,  -5.2042],\n",
       "                        [ -5.0442,  -5.2591,  -4.7287]],\n",
       "              \n",
       "                       [[ -5.8734,  -4.6444,  -5.4499],\n",
       "                        [ -5.4319,  -4.9883,  -4.8333],\n",
       "                        [ -6.5782,  -4.6551,  -5.0808]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.8792,  -4.6940,  -5.0429],\n",
       "                        [ -5.8996,  -5.7665,  -4.6609],\n",
       "                        [ -4.6452,  -4.8849,  -4.6769]],\n",
       "              \n",
       "                       [[ -4.8268,  -4.7228,  -6.3688],\n",
       "                        [ -5.8179,  -4.8246,  -6.1462],\n",
       "                        [ -4.7585,  -5.1783,  -4.6886]],\n",
       "              \n",
       "                       [[ -6.2012,  -8.2320,  -5.2290],\n",
       "                        [ -5.7108,  -7.5284,  -5.0407],\n",
       "                        [ -4.7422,  -5.2593,  -5.3229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -6.3035,  -6.6534,  -5.4430],\n",
       "                        [ -6.1873,  -5.0303,  -4.8205],\n",
       "                        [ -4.8338,  -8.7668,  -4.8565]],\n",
       "              \n",
       "                       [[ -6.2997,  -5.1643,  -5.4332],\n",
       "                        [ -5.3585,  -5.5881,  -6.7834],\n",
       "                        [ -4.9736,  -5.2408,  -5.2734]],\n",
       "              \n",
       "                       [[ -6.7080,  -6.1985,  -4.6598],\n",
       "                        [ -5.5043,  -6.3881,  -4.7572],\n",
       "                        [ -7.1049,  -5.6703,  -7.1532]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ -5.2207,  -5.0924, -10.0883],\n",
       "                        [ -6.3758,  -4.6161, -11.3404],\n",
       "                        [ -4.9091,  -5.9513,  -5.9919]],\n",
       "              \n",
       "                       [[ -5.8796,  -5.6956,  -5.1983],\n",
       "                        [ -5.9486,  -5.2722,  -5.0571],\n",
       "                        [ -5.8033,  -4.9490,  -5.6488]],\n",
       "              \n",
       "                       [[ -5.5850,  -4.7105,  -5.8037],\n",
       "                        [ -5.0838,  -4.7165,  -7.9166],\n",
       "                        [ -4.9731,  -5.3048,  -4.7580]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.0580,  -4.8034,  -4.9464],\n",
       "                        [ -6.6844,  -6.0721,  -4.9173],\n",
       "                        [ -5.1235,  -6.1430,  -4.8411]],\n",
       "              \n",
       "                       [[ -5.4078,  -5.7864,  -4.6640],\n",
       "                        [ -6.4800,  -6.3382,  -5.1955],\n",
       "                        [ -5.0759,  -4.6513,  -5.8223]],\n",
       "              \n",
       "                       [[ -5.8741,  -5.1930,  -6.1184],\n",
       "                        [ -5.9632,  -4.9854,  -5.5248],\n",
       "                        [ -5.4340,  -4.8756,  -6.1268]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7317,  -4.7876,  -4.6515],\n",
       "                        [ -4.6825,  -5.2984,  -6.1163],\n",
       "                        [ -5.4107,  -5.1975,  -8.0545]],\n",
       "              \n",
       "                       [[ -5.2834,  -5.6526,  -7.0465],\n",
       "                        [ -4.8033,  -5.4729,  -5.1557],\n",
       "                        [ -5.1154,  -5.3980,  -6.5179]],\n",
       "              \n",
       "                       [[ -4.6272,  -6.7603,  -5.9652],\n",
       "                        [ -7.2561,  -4.7363,  -5.3724],\n",
       "                        [ -4.8832,  -6.1377,  -5.4254]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.1932,  -5.1240,  -4.7613],\n",
       "                        [ -7.3618,  -4.9356,  -4.6646],\n",
       "                        [ -9.1949,  -4.9185,  -6.3190]],\n",
       "              \n",
       "                       [[ -5.7399,  -4.8507,  -5.5449],\n",
       "                        [ -5.1924,  -4.8358,  -5.1016],\n",
       "                        [ -4.6610,  -4.6812,  -4.7686]],\n",
       "              \n",
       "                       [[ -5.2705,  -4.6899,  -7.1359],\n",
       "                        [ -5.2371,  -4.7379,  -4.7493],\n",
       "                        [ -6.2951,  -4.8752,  -5.7799]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9011,  -5.4341,  -6.1519],\n",
       "                        [ -5.2461,  -5.0187,  -4.9425],\n",
       "                        [ -4.7894,  -4.9412,  -7.4545]],\n",
       "              \n",
       "                       [[ -6.6776,  -5.0606,  -4.9950],\n",
       "                        [ -4.7554,  -6.5076,  -5.5223],\n",
       "                        [ -4.7999,  -7.0382,  -5.1425]],\n",
       "              \n",
       "                       [[ -6.4810,  -6.1257,  -5.5495],\n",
       "                        [ -4.9374,  -6.0109,  -4.8740],\n",
       "                        [ -5.1312,  -5.0721,  -5.6891]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.5421,  -5.4475,  -4.9680],\n",
       "                        [ -5.6537,  -6.9608,  -6.1850],\n",
       "                        [ -5.8367,  -4.6858,  -5.8908]],\n",
       "              \n",
       "                       [[ -4.7354,  -5.8674,  -6.3676],\n",
       "                        [ -4.9714,  -5.2619,  -6.5081],\n",
       "                        [ -4.9468,  -5.1474,  -4.7506]],\n",
       "              \n",
       "                       [[ -5.0838,  -5.3120,  -6.4364],\n",
       "                        [ -5.3226,  -6.4487,  -5.7257],\n",
       "                        [ -6.4195,  -5.5895,  -4.8728]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_alphas_log',\n",
       "              tensor([[[[-3.1208, -2.7563, -3.7486],\n",
       "                        [-3.8965, -2.3548, -2.4956],\n",
       "                        [-3.7377, -2.4640, -3.2232]],\n",
       "              \n",
       "                       [[-2.9014, -3.9953, -3.4497],\n",
       "                        [-3.8640, -3.0927, -2.4998],\n",
       "                        [-2.6253, -2.4865, -2.2398]],\n",
       "              \n",
       "                       [[-3.0908, -2.4146, -3.9343],\n",
       "                        [-3.5985, -2.8794, -3.1899],\n",
       "                        [-2.1639, -3.1835, -2.4674]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3682, -3.1929, -3.2801],\n",
       "                        [-2.2721, -3.8645, -3.9398],\n",
       "                        [-2.9879, -3.7731, -2.4957]],\n",
       "              \n",
       "                       [[-2.8470, -2.3105, -3.8021],\n",
       "                        [-2.5435, -2.2728, -3.4867],\n",
       "                        [-2.9169, -2.0757, -3.0486]],\n",
       "              \n",
       "                       [[-2.3233, -3.4559, -3.2256],\n",
       "                        [-2.2036, -3.9219, -3.0986],\n",
       "                        [-2.9420, -2.3585, -3.8046]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1754, -2.0566, -3.6359],\n",
       "                        [-3.6927, -3.2862, -2.6869],\n",
       "                        [-3.5791, -3.3233, -3.6161]],\n",
       "              \n",
       "                       [[-3.2034, -3.0297, -2.7051],\n",
       "                        [-2.5706, -2.8884, -2.2364],\n",
       "                        [-2.1037, -3.6381, -3.1625]],\n",
       "              \n",
       "                       [[-3.7066, -3.3125, -3.1687],\n",
       "                        [-3.1239, -2.4540, -3.9694],\n",
       "                        [-2.4275, -3.4842, -3.5515]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.3355, -2.3924, -3.8762],\n",
       "                        [-3.2690, -2.8075, -2.1692],\n",
       "                        [-2.8498, -2.6340, -2.4757]],\n",
       "              \n",
       "                       [[-2.1258, -3.9112, -2.4498],\n",
       "                        [-3.6278, -3.6784, -3.4361],\n",
       "                        [-3.1734, -2.0465, -3.2119]],\n",
       "              \n",
       "                       [[-3.7677, -3.9241, -2.5258],\n",
       "                        [-2.7414, -2.0536, -2.7077],\n",
       "                        [-3.8235, -2.2494, -2.4314]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5014, -3.0658, -3.4985],\n",
       "                        [-2.7314, -3.8253, -3.3671],\n",
       "                        [-2.5513, -3.4363, -2.7036]],\n",
       "              \n",
       "                       [[-2.5428, -3.6467, -3.4415],\n",
       "                        [-2.8061, -2.9486, -2.2062],\n",
       "                        [-2.8026, -2.4836, -2.9947]],\n",
       "              \n",
       "                       [[-3.9244, -3.9050, -2.1187],\n",
       "                        [-3.3110, -3.2703, -3.0798],\n",
       "                        [-2.3001, -2.4495, -2.0953]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5645, -2.5936, -2.4790],\n",
       "                        [-2.6513, -3.4113, -2.9740],\n",
       "                        [-3.3577, -3.9606, -3.1418]],\n",
       "              \n",
       "                       [[-2.7975, -2.2998, -2.8023],\n",
       "                        [-2.3324, -2.8821, -3.2097],\n",
       "                        [-3.8507, -2.4488, -2.4988]],\n",
       "              \n",
       "                       [[-3.6760, -2.2862, -2.2226],\n",
       "                        [-3.6482, -2.4616, -3.3363],\n",
       "                        [-3.6237, -3.1775, -2.4673]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.5372, -2.7765, -2.7652],\n",
       "                        [-2.4836, -2.6969, -3.5783],\n",
       "                        [-3.6237, -3.0590, -3.9446]],\n",
       "              \n",
       "                       [[-3.2779, -2.1426, -2.9370],\n",
       "                        [-2.9242, -2.1070, -3.5358],\n",
       "                        [-3.7590, -2.1929, -3.6642]],\n",
       "              \n",
       "                       [[-3.2604, -3.3516, -2.1306],\n",
       "                        [-2.1995, -3.7089, -3.4965],\n",
       "                        [-3.7941, -2.7751, -2.5374]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.6517, -2.8730, -3.6893],\n",
       "                        [-3.6581, -3.7657, -2.9686],\n",
       "                        [-3.1837, -3.6331, -2.0719]],\n",
       "              \n",
       "                       [[-2.0032, -2.4179, -2.2813],\n",
       "                        [-3.1466, -2.4047, -3.1214],\n",
       "                        [-3.8901, -3.4469, -2.0390]],\n",
       "              \n",
       "                       [[-2.5345, -2.8868, -2.1386],\n",
       "                        [-3.2593, -3.2644, -2.2449],\n",
       "                        [-3.8276, -3.8468, -2.9239]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5266, -3.1675, -2.3135],\n",
       "                        [-3.8879, -2.2258, -2.8850],\n",
       "                        [-2.6335, -3.2377, -3.1881]],\n",
       "              \n",
       "                       [[-3.8447, -2.7766, -3.0112],\n",
       "                        [-3.4791, -3.0088, -3.5321],\n",
       "                        [-2.1507, -3.2181, -3.1322]],\n",
       "              \n",
       "                       [[-2.5166, -3.0865, -3.8249],\n",
       "                        [-2.2184, -2.6257, -3.2100],\n",
       "                        [-3.3021, -3.1101, -2.4990]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.0878, -2.8496, -2.9612],\n",
       "                        [-3.8138, -3.8751, -2.2066],\n",
       "                        [-2.8400, -2.7830, -3.5077]],\n",
       "              \n",
       "                       [[-3.2419, -2.2538, -2.5771],\n",
       "                        [-2.1442, -3.7542, -2.5197],\n",
       "                        [-2.7280, -2.3857, -3.3711]],\n",
       "              \n",
       "                       [[-3.6055, -2.6597, -2.8321],\n",
       "                        [-2.1913, -3.7560, -3.0916],\n",
       "                        [-3.0833, -2.4570, -2.8308]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5007, -3.1200, -2.7913],\n",
       "                        [-2.3740, -3.7332, -3.5897],\n",
       "                        [-3.3906, -2.1982, -3.5685]],\n",
       "              \n",
       "                       [[-2.7117, -2.2154, -3.9228],\n",
       "                        [-2.9140, -2.2561, -3.9724],\n",
       "                        [-2.5165, -3.6681, -2.8375]],\n",
       "              \n",
       "                       [[-3.9475, -3.1206, -2.4382],\n",
       "                        [-3.6749, -2.6256, -2.7378],\n",
       "                        [-2.8781, -3.7401, -3.3331]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2656, -2.4233, -3.3470],\n",
       "                        [-3.9943, -3.1019, -3.4108],\n",
       "                        [-2.3182, -2.2094, -3.1152]],\n",
       "              \n",
       "                       [[-3.2502, -3.4874, -2.9990],\n",
       "                        [-3.9277, -2.9806, -3.4410],\n",
       "                        [-2.5549, -2.5276, -3.0260]],\n",
       "              \n",
       "                       [[-2.4640, -3.6792, -2.2802],\n",
       "                        [-3.8788, -3.4409, -3.7543],\n",
       "                        [-2.9739, -2.7449, -2.5840]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.3.param_mus',\n",
       "              tensor([-0.0247, -0.0161, -0.0114, -0.0545, -0.0441,  0.0371, -0.0464,  0.0294,\n",
       "                      -0.0008, -0.0147,  0.0308, -0.0070, -0.0242, -0.0145,  0.0451, -0.0270,\n",
       "                       0.0504, -0.0330,  0.0052, -0.0263, -0.0461, -0.0056,  0.0507,  0.0085,\n",
       "                       0.0076,  0.0439, -0.0189,  0.0369,  0.0084,  0.0420,  0.0128,  0.0379,\n",
       "                      -0.0297,  0.0413,  0.0259,  0.0470, -0.0358, -0.0208,  0.0237,  0.0261,\n",
       "                       0.0004, -0.0455, -0.0450,  0.0178,  0.0462,  0.0565, -0.0233,  0.0362,\n",
       "                      -0.0050,  0.0535, -0.0252, -0.0276,  0.0260, -0.0487,  0.0129,  0.0404,\n",
       "                      -0.0017,  0.0002, -0.0322, -0.0017,  0.0003, -0.0446,  0.0136, -0.0410])),\n",
       "             ('module_list.0.posterior_params.3.param_std_log',\n",
       "              tensor([-4.9508, -5.1600, -4.7067, -6.2668, -6.0211, -5.9028, -4.6924, -5.1460,\n",
       "                      -5.0859, -5.2408, -4.8095, -7.1365, -5.4396, -5.8576, -5.3555, -4.8186,\n",
       "                      -5.5971, -5.6392, -4.8023, -9.8942, -4.8637, -5.9410, -5.1181, -5.4144,\n",
       "                      -4.8033, -4.6086, -5.2600, -5.8989, -8.6606, -4.7941, -5.4816, -6.0438,\n",
       "                      -4.6964, -5.4635, -5.9626, -4.9073, -6.1812, -6.3257, -4.7518, -7.6384,\n",
       "                      -5.0423, -5.8933, -5.6795, -5.5723, -5.4022, -4.9368, -4.6178, -6.4391,\n",
       "                      -7.6654, -5.8170, -5.2028, -4.6984, -6.6025, -7.1608, -5.6478, -5.8301,\n",
       "                      -8.4636, -6.7550, -5.5177, -6.4458, -5.0173, -5.0249, -5.1638, -6.9682])),\n",
       "             ('module_list.0.posterior_params.3.scale_alphas_log',\n",
       "              tensor([-3.8348, -3.2114, -3.4231, -3.7273, -2.6485, -2.0477, -3.3813, -2.3942,\n",
       "                      -2.1437, -3.0732, -3.1208, -3.7754, -2.1770, -3.4546, -2.0591, -2.1872,\n",
       "                      -3.8338, -2.4201, -2.0270, -3.3722, -2.6814, -2.6257, -3.0261, -3.7204,\n",
       "                      -2.8619, -2.3022, -3.9557, -2.0481, -2.1914, -2.2766, -3.5006, -2.7674,\n",
       "                      -2.6459, -3.9005, -2.1899, -2.1437, -3.6932, -2.9754, -2.9686, -2.5160,\n",
       "                      -2.4128, -3.1614, -3.3586, -3.1458, -3.9852, -3.3480, -2.6311, -3.9877,\n",
       "                      -3.4897, -3.3061, -3.4487, -2.5728, -3.9524, -3.9160, -3.2158, -2.5091,\n",
       "                      -2.4095, -2.5164, -3.1135, -3.4646, -2.0611, -3.9774, -3.7385, -3.8019])),\n",
       "             ('module_list.0.posterior_params.3.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.4.param_mus',\n",
       "              tensor([[-0.0060, -0.0038,  0.0059,  ...,  0.0055,  0.0056,  0.0112],\n",
       "                      [-0.0079,  0.0110,  0.0003,  ..., -0.0028,  0.0063,  0.0089],\n",
       "                      [-0.0015, -0.0005, -0.0153,  ..., -0.0079,  0.0070,  0.0004],\n",
       "                      ...,\n",
       "                      [-0.0138, -0.0050, -0.0028,  ..., -0.0167, -0.0055,  0.0021],\n",
       "                      [-0.0164,  0.0095,  0.0158,  ..., -0.0067, -0.0058, -0.0114],\n",
       "                      [ 0.0004,  0.0159,  0.0057,  ...,  0.0109, -0.0147,  0.0016]])),\n",
       "             ('module_list.0.posterior_params.4.param_std_log',\n",
       "              tensor([[-4.9756, -5.8793, -4.9216,  ..., -5.3952, -5.3355, -5.4162],\n",
       "                      [-5.7195, -5.1385, -4.7884,  ..., -6.9977, -5.3475, -5.5812],\n",
       "                      [-5.2810, -4.9176, -5.2894,  ..., -4.8890, -5.3043, -5.2011],\n",
       "                      ...,\n",
       "                      [-7.3917, -5.2957, -4.6272,  ..., -7.7839, -5.7845, -4.6136],\n",
       "                      [-4.9007, -5.6791, -5.0622,  ..., -8.2907, -4.9853, -4.6802],\n",
       "                      [-5.3296, -4.6666, -6.0255,  ..., -4.7482, -6.4359, -6.6661]])),\n",
       "             ('module_list.0.posterior_params.4.scale_alphas_log',\n",
       "              tensor([[-3.9412, -2.2401, -2.1336,  ..., -2.8340, -2.0098, -3.0041],\n",
       "                      [-3.8424, -3.8154, -2.0589,  ..., -3.8402, -2.2660, -2.0437],\n",
       "                      [-3.0144, -3.4008, -2.9408,  ..., -3.1575, -2.4630, -2.5550],\n",
       "                      ...,\n",
       "                      [-3.6887, -2.0952, -2.7619,  ..., -3.1953, -2.0440, -3.6054],\n",
       "                      [-3.7814, -3.0292, -2.1367,  ..., -2.3574, -2.4099, -3.5668],\n",
       "                      [-2.2732, -3.1055, -3.9327,  ..., -3.8411, -2.2908, -3.8868]])),\n",
       "             ('module_list.0.posterior_params.4.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.5.param_mus',\n",
       "              tensor([ 1.3917e-06,  1.4576e-02, -2.6537e-03,  3.6241e-03,  8.8199e-03,\n",
       "                      -4.2594e-03, -5.8750e-03, -1.4224e-02,  1.7093e-03, -1.6626e-02,\n",
       "                      -8.7674e-03, -6.6249e-04,  1.1945e-02, -7.4607e-03,  3.5004e-03,\n",
       "                       2.9062e-04,  1.5443e-02,  1.4859e-02, -8.4027e-04, -1.0798e-02,\n",
       "                      -1.0034e-02,  1.1881e-02,  9.1969e-03, -4.5546e-03,  9.8986e-03,\n",
       "                       1.1479e-02,  1.4816e-02,  1.4880e-04,  3.5551e-03, -7.0807e-03,\n",
       "                       6.7061e-03,  4.7266e-03, -9.7089e-03, -7.1940e-03,  7.2619e-04,\n",
       "                       9.2809e-03, -1.4593e-02, -1.3591e-02, -1.6470e-02,  1.4063e-02,\n",
       "                      -9.1353e-04, -3.2661e-03, -1.4228e-02, -2.4341e-03, -1.2841e-02,\n",
       "                       1.6272e-02,  7.2969e-04, -5.3828e-04,  9.9467e-03,  9.4742e-03,\n",
       "                       7.8785e-03,  8.5166e-03,  1.3222e-02,  8.9191e-03,  5.4819e-04,\n",
       "                       1.4297e-02, -5.2545e-03, -7.2711e-03,  6.5952e-04, -1.6730e-02,\n",
       "                       1.1633e-02, -5.6858e-04, -4.7100e-03, -1.2211e-02, -8.0731e-03,\n",
       "                       1.0279e-02, -9.7878e-03,  1.4347e-02,  1.6146e-02,  1.6533e-02,\n",
       "                       5.0773e-03, -8.0926e-06,  1.1499e-03,  8.6069e-03, -1.5657e-02,\n",
       "                       2.5551e-03, -1.0347e-02, -5.5322e-03,  6.3194e-04, -2.6397e-03,\n",
       "                       1.6151e-02, -5.1247e-03,  7.5796e-04,  1.0791e-02,  1.2136e-02,\n",
       "                      -6.8336e-03,  8.8692e-03, -4.9329e-03, -2.7250e-03, -6.5072e-03,\n",
       "                       4.7819e-03,  5.8093e-03,  2.1105e-03,  7.6752e-03, -6.7494e-04,\n",
       "                      -6.1659e-03, -6.9960e-03, -6.8731e-03,  1.4079e-02,  6.6005e-03,\n",
       "                       2.1725e-03,  3.5906e-03, -1.6101e-02, -1.3368e-02,  1.5433e-03,\n",
       "                       1.5355e-02,  6.8203e-03,  5.4357e-03, -6.9763e-03, -1.2410e-03,\n",
       "                       9.3939e-03, -1.0151e-03,  1.3439e-02, -6.1277e-03,  1.0773e-02,\n",
       "                      -3.1730e-03, -1.1496e-02,  7.5634e-03,  4.9156e-03, -5.2231e-03,\n",
       "                       6.6767e-04, -1.5855e-03,  9.0408e-03,  6.1271e-05,  1.0646e-02,\n",
       "                       2.8385e-04,  1.6445e-02,  8.5083e-03])),\n",
       "             ('module_list.0.posterior_params.5.param_std_log',\n",
       "              tensor([ -6.1301,  -6.3053,  -4.7569,  -4.8535,  -5.5086,  -6.2571,  -4.9596,\n",
       "                       -5.1803,  -9.1710,  -5.2503,  -4.7032,  -6.3647,  -4.9892,  -4.8991,\n",
       "                       -5.5498,  -4.8719,  -5.2564,  -6.3979,  -4.6770,  -5.0220,  -5.3810,\n",
       "                       -6.3140,  -5.8923,  -5.2650,  -4.9761,  -4.6328,  -4.6166,  -5.4437,\n",
       "                       -6.9506,  -8.3288,  -4.7537,  -5.3944,  -6.5924,  -5.2007,  -5.6800,\n",
       "                       -6.6248,  -4.7975,  -5.4612,  -6.0363,  -5.2273,  -4.8311,  -4.9170,\n",
       "                       -7.0548,  -4.7372,  -5.0017,  -5.8234,  -4.8280,  -5.9784,  -5.5531,\n",
       "                       -4.8025,  -5.2271,  -5.0813,  -4.8992,  -5.2294,  -4.7455,  -4.9664,\n",
       "                       -5.3673,  -4.9951,  -6.2463,  -5.6263,  -6.0417,  -5.3203,  -5.2607,\n",
       "                       -5.6038,  -5.1372,  -4.7812,  -9.2299,  -4.9424,  -5.9458,  -4.6662,\n",
       "                       -6.3344,  -5.0093,  -4.7124,  -4.7035,  -6.0073,  -6.9374, -10.0896,\n",
       "                       -5.3054,  -4.6996,  -6.5079,  -5.7761,  -4.6928,  -8.0134,  -5.6881,\n",
       "                       -5.2365,  -7.0051,  -5.1550,  -4.8573,  -6.8704,  -5.7208,  -6.4350,\n",
       "                       -6.2641,  -4.9658,  -5.9662,  -4.7389,  -5.8586,  -6.4300,  -7.3616,\n",
       "                       -5.1560,  -4.8765,  -5.2174,  -5.1795,  -4.7509,  -6.0089,  -4.9572,\n",
       "                       -5.0357,  -6.5988,  -4.6549,  -5.8021,  -5.8566,  -5.2058,  -6.4154,\n",
       "                       -6.4983,  -5.1042,  -7.4313,  -4.8408,  -5.1619,  -4.7916,  -5.1706,\n",
       "                       -5.6362,  -4.9764,  -4.7371,  -4.6643,  -4.6293,  -4.7894,  -5.4592,\n",
       "                       -4.6418,  -4.8033])),\n",
       "             ('module_list.0.posterior_params.5.scale_alphas_log',\n",
       "              tensor([-2.4306, -2.2903, -3.6280, -2.0664, -3.9830, -2.0650, -3.0199, -3.9249,\n",
       "                      -2.4829, -3.3871, -3.4510, -2.1563, -3.6882, -3.7823, -2.6647, -2.7932,\n",
       "                      -3.6408, -3.5198, -3.4117, -3.3658, -2.2965, -3.8272, -2.1687, -3.5843,\n",
       "                      -3.1820, -2.4904, -3.0998, -3.3045, -2.8369, -3.9646, -2.1372, -3.0637,\n",
       "                      -2.1170, -2.5102, -3.0699, -3.3785, -2.9198, -2.1314, -2.8533, -3.0354,\n",
       "                      -2.8678, -2.8004, -3.2019, -3.4330, -2.9017, -3.2934, -3.3927, -3.1566,\n",
       "                      -3.9698, -2.2223, -2.4634, -3.5020, -2.9290, -3.6592, -2.6679, -2.0644,\n",
       "                      -2.6583, -2.3873, -3.7120, -2.9279, -3.8128, -3.5404, -2.8089, -3.7370,\n",
       "                      -3.3619, -3.9554, -3.2154, -3.2334, -3.2777, -2.4485, -2.0038, -3.8139,\n",
       "                      -3.4262, -3.4084, -3.9413, -2.3644, -3.4584, -2.6866, -3.4744, -2.6733,\n",
       "                      -2.3477, -3.7812, -2.2835, -2.9558, -3.2714, -3.6735, -3.1556, -3.1640,\n",
       "                      -2.8820, -3.1243, -3.2482, -2.6631, -2.3087, -3.2976, -2.1635, -3.9299,\n",
       "                      -2.9423, -3.1138, -2.0352, -2.5459, -2.9323, -3.0463, -3.8173, -3.2842,\n",
       "                      -2.1008, -3.6207, -2.5263, -2.4122, -3.2815, -3.6080, -2.9052, -2.3396,\n",
       "                      -3.0947, -3.8459, -2.2397, -2.8293, -3.9033, -3.8290, -3.8715, -2.5682,\n",
       "                      -2.4280, -2.6951, -2.3212, -2.1949, -3.4253, -2.8357, -3.5357, -3.8741])),\n",
       "             ('module_list.0.posterior_params.5.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('module_list.0.posterior_params.6.param_mus',\n",
       "              tensor([[ 3.9227e-02,  6.8764e-02, -3.9786e-02,  ..., -7.2276e-02,\n",
       "                        3.9748e-03, -5.1731e-02],\n",
       "                      [ 7.8346e-02, -1.8090e-03,  7.6147e-06,  ..., -7.7946e-02,\n",
       "                        4.2434e-02,  6.5023e-02],\n",
       "                      [ 5.2894e-02,  3.2615e-02,  7.0440e-03,  ...,  8.0804e-02,\n",
       "                       -6.1565e-03,  4.6580e-03],\n",
       "                      ...,\n",
       "                      [-5.1605e-02,  4.2076e-02,  8.5599e-02,  ...,  6.9804e-02,\n",
       "                        2.9202e-02, -4.7371e-02],\n",
       "                      [-6.1415e-02, -1.1640e-02,  5.2282e-03,  ..., -8.0598e-02,\n",
       "                       -7.6587e-02,  8.1059e-02],\n",
       "                      [ 2.1192e-02, -6.5641e-02,  8.6442e-02,  ...,  7.8133e-02,\n",
       "                       -3.6499e-02, -4.3471e-02]])),\n",
       "             ('module_list.0.posterior_params.6.param_std_log',\n",
       "              tensor([[-5.0966, -5.4493, -6.4950,  ..., -7.1864, -5.3193, -4.8493],\n",
       "                      [-5.4764, -4.8478, -4.6153,  ..., -5.2323, -5.3591, -5.0230],\n",
       "                      [-7.2445, -5.4030, -5.8443,  ..., -4.9133, -4.6574, -5.2370],\n",
       "                      ...,\n",
       "                      [-5.3484, -5.1755, -5.4120,  ..., -4.6760, -7.3831, -7.9423],\n",
       "                      [-4.7803, -5.1935, -6.2579,  ..., -4.7575, -4.7360, -4.6253],\n",
       "                      [-4.6083, -5.0166, -5.0490,  ..., -6.3636, -5.9321, -4.9480]])),\n",
       "             ('module_list.0.posterior_params.6.scale_alphas_log',\n",
       "              tensor([[-3.6296, -2.5118, -3.2644,  ..., -3.8945, -2.5081, -2.1093],\n",
       "                      [-2.7061, -3.7425, -2.7283,  ..., -2.8242, -2.1006, -2.3789],\n",
       "                      [-2.0977, -3.9334, -3.8817,  ..., -3.4567, -2.3392, -2.5192],\n",
       "                      ...,\n",
       "                      [-3.5448, -2.6789, -2.3955,  ..., -2.5153, -3.1022, -2.6407],\n",
       "                      [-3.8205, -3.3679, -2.2138,  ..., -3.5941, -2.5858, -2.5143],\n",
       "                      [-3.7948, -2.0984, -2.1173,  ..., -2.2011, -3.7955, -2.3679]])),\n",
       "             ('module_list.0.posterior_params.6.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.7.param_mus',\n",
       "              tensor([-0.0733,  0.0529,  0.0067, -0.0068, -0.0484,  0.0613,  0.0566, -0.0554,\n",
       "                       0.0756,  0.0869])),\n",
       "             ('module_list.0.posterior_params.7.param_std_log',\n",
       "              tensor([-5.9055, -5.8104, -6.4917, -4.6170, -4.8353, -5.3310, -8.0676, -5.5411,\n",
       "                      -4.9011, -5.5787])),\n",
       "             ('module_list.0.posterior_params.7.scale_alphas_log',\n",
       "              tensor([-3.4337, -3.8663, -3.2812, -2.6804, -3.1560, -3.5765, -2.7891, -3.8486,\n",
       "                      -3.1032, -3.3602])),\n",
       "             ('module_list.0.posterior_params.7.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward делается по последнему сохраненному сэмплу. Заметим, что мы нигде не копируем данные, и модели не инкапсулируется. Поэтому, чтобы отвязать, их неободимо скопировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0562,  0.0925,  0.0410, -0.0008, -0.0394,  0.0506,  0.0586, -0.0280,\n",
      "          0.0820,  0.0733]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0562,  0.0925,  0.0410, -0.0008, -0.0394,  0.0506,  0.0586, -0.0280,\n",
      "          0.0820,  0.0733]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(bayes_model(torch.zeros_like(image)))\n",
    "#print(bayes_model(torch.zeros_like(image), sample = False))\n",
    "print(module(torch.zeros_like(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы импортируем несколько модулей для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.bayes.variational.trainer import VarBayesTrainer, VarTrainerParams, Beta_Scheduler_Plato, CallbackLossAccuracy #Сам тренер, Параметры тренера, Планировщик beta(коэффициент сооьношения между обычным лоссом и байесовским), и callback для метрики точности\n",
    "from src.methods.report.base import ReportChain #Это просто список callback\n",
    "from src.methods.report.variational import VarBaseReport #Этот модуль callback просто выводит каждый шаг данные от тренера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = Beta_Scheduler_Plato()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e956830790f4ce99d1d1a9a8f5ca03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4000],Loss:30378.220703125, KL Loss: 3037612.25. FitLoss: 2.0984816551208496,Accuracy:0.40277499999999994,Validation Loss:30348.34765625,Validation Accuracy:0.739, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [2/4000],Loss:30325.083984375, KL Loss: 3032387.5. FitLoss: 1.2057651281356812,Accuracy:0.7217124999999998,Validation Loss:30295.2578125,Validation Accuracy:0.805, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [3/4000],Loss:30272.353515625, KL Loss: 3027169.25. FitLoss: 0.662200927734375,Accuracy:0.7916750000000004,Validation Loss:30242.849609375,Validation Accuracy:0.848, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [4/4000],Loss:30219.98046875, KL Loss: 3021947.25. FitLoss: 0.5087894201278687,Accuracy:0.8374374999999997,Validation Loss:30190.494140625,Validation Accuracy:0.877, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [5/4000],Loss:30167.626953125, KL Loss: 3016721.5. FitLoss: 0.41347208619117737,Accuracy:0.8702749999999998,Validation Loss:30138.146484375,Validation Accuracy:0.914, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [6/4000],Loss:30115.2734375, KL Loss: 3011493.75. FitLoss: 0.33878737688064575,Accuracy:0.8984875000000008,Validation Loss:30085.806640625,Validation Accuracy:0.918, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [7/4000],Loss:30062.921875, KL Loss: 3006262.75. FitLoss: 0.2958531081676483,Accuracy:0.9110249999999999,Validation Loss:30033.45703125,Validation Accuracy:0.935, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [8/4000],Loss:30010.556640625, KL Loss: 3001029.75. FitLoss: 0.2623729109764099,Accuracy:0.9211499999999999,Validation Loss:29981.099609375,Validation Accuracy:0.936, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [9/4000],Loss:29958.19140625, KL Loss: 2995794.5. FitLoss: 0.24747121334075928,Accuracy:0.9272125000000001,Validation Loss:29928.703125,Validation Accuracy:0.939, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [10/4000],Loss:29905.798828125, KL Loss: 2990557.0. FitLoss: 0.22834369540214539,Accuracy:0.9321000000000002,Validation Loss:29876.314453125,Validation Accuracy:0.932, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [11/4000],Loss:29853.388671875, KL Loss: 2985317.5. FitLoss: 0.2158348113298416,Accuracy:0.9352125000000002,Validation Loss:29823.90234375,Validation Accuracy:0.942, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [12/4000],Loss:29800.955078125, KL Loss: 2980075.75. FitLoss: 0.20239192247390747,Accuracy:0.9411125,Validation Loss:29771.451171875,Validation Accuracy:0.947, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [13/4000],Loss:29748.494140625, KL Loss: 2974831.25. FitLoss: 0.18226109445095062,Accuracy:0.9468625000000002,Validation Loss:29718.9921875,Validation Accuracy:0.952, Prune parameters: 931.0/421642,Beta: 0.01\n",
      "Epoch [14/4000],Loss:29696.021484375, KL Loss: 2969585.0. FitLoss: 0.17153912782669067,Accuracy:0.9491124999999995,Validation Loss:29666.49609375,Validation Accuracy:0.955, Prune parameters: 2659.0/421642,Beta: 0.01\n",
      "Epoch [15/4000],Loss:29643.521484375, KL Loss: 2964336.0. FitLoss: 0.1614379584789276,Accuracy:0.9516999999999998,Validation Loss:29613.98828125,Validation Accuracy:0.96, Prune parameters: 4368.0/421642,Beta: 0.01\n",
      "Epoch [16/4000],Loss:29590.99609375, KL Loss: 2959084.75. FitLoss: 0.15055251121520996,Accuracy:0.9556624999999995,Validation Loss:29561.443359375,Validation Accuracy:0.962, Prune parameters: 6042.0/421642,Beta: 0.01\n",
      "Epoch [17/4000],Loss:29538.45703125, KL Loss: 2953831.25. FitLoss: 0.14397741854190826,Accuracy:0.9581499999999996,Validation Loss:29508.892578125,Validation Accuracy:0.96, Prune parameters: 7827.0/421642,Beta: 0.01\n",
      "Epoch [18/4000],Loss:29485.888671875, KL Loss: 2948575.5. FitLoss: 0.1350354254245758,Accuracy:0.9606000000000001,Validation Loss:29456.330078125,Validation Accuracy:0.967, Prune parameters: 9571.0/421642,Beta: 0.01\n",
      "Epoch [19/4000],Loss:29433.30078125, KL Loss: 2943317.25. FitLoss: 0.13122886419296265,Accuracy:0.9631374999999999,Validation Loss:29403.7265625,Validation Accuracy:0.966, Prune parameters: 11353.0/421642,Beta: 0.01\n",
      "Epoch [20/4000],Loss:29380.69140625, KL Loss: 2938056.25. FitLoss: 0.12770341336727142,Accuracy:0.9641499999999998,Validation Loss:29351.09765625,Validation Accuracy:0.969, Prune parameters: 13054.0/421642,Beta: 0.01\n",
      "Epoch [21/4000],Loss:29328.0546875, KL Loss: 2932793.5. FitLoss: 0.12049072980880737,Accuracy:0.9660874999999995,Validation Loss:29298.466796875,Validation Accuracy:0.964, Prune parameters: 14804.0/421642,Beta: 0.01\n",
      "Epoch [22/4000],Loss:29275.400390625, KL Loss: 2927528.25. FitLoss: 0.1227952092885971,Accuracy:0.9645374999999999,Validation Loss:29245.7890625,Validation Accuracy:0.971, Prune parameters: 16602.0/421642,Beta: 0.01\n",
      "Epoch [23/4000],Loss:29222.71875, KL Loss: 2922260.25. FitLoss: 0.11748604476451874,Accuracy:0.9659875,Validation Loss:29193.091796875,Validation Accuracy:0.969, Prune parameters: 18324.0/421642,Beta: 0.01\n",
      "Epoch [24/4000],Loss:29170.01171875, KL Loss: 2916990.0. FitLoss: 0.11107231676578522,Accuracy:0.9697499999999992,Validation Loss:29140.375,Validation Accuracy:0.973, Prune parameters: 20153.0/421642,Beta: 0.01\n",
      "Epoch [25/4000],Loss:29117.28125, KL Loss: 2911717.25. FitLoss: 0.10855767130851746,Accuracy:0.9689249999999996,Validation Loss:29087.6328125,Validation Accuracy:0.973, Prune parameters: 21819.0/421642,Beta: 0.01\n",
      "Epoch [26/4000],Loss:29064.52734375, KL Loss: 2906442.5. FitLoss: 0.10655663907527924,Accuracy:0.9705249999999996,Validation Loss:29034.876953125,Validation Accuracy:0.97, Prune parameters: 23507.0/421642,Beta: 0.01\n",
      "Epoch [27/4000],Loss:29011.75, KL Loss: 2901164.5. FitLoss: 0.10233186930418015,Accuracy:0.971175,Validation Loss:28982.0859375,Validation Accuracy:0.968, Prune parameters: 25319.0/421642,Beta: 0.01\n",
      "Epoch [28/4000],Loss:28958.943359375, KL Loss: 2895884.5. FitLoss: 0.09882570803165436,Accuracy:0.9717624999999999,Validation Loss:28929.265625,Validation Accuracy:0.973, Prune parameters: 27061.0/421642,Beta: 0.01\n",
      "Epoch [29/4000],Loss:28906.115234375, KL Loss: 2890602.25. FitLoss: 0.0954286977648735,Accuracy:0.9737249999999996,Validation Loss:28876.431640625,Validation Accuracy:0.972, Prune parameters: 28798.0/421642,Beta: 0.01\n",
      "Epoch [30/4000],Loss:28853.2578125, KL Loss: 2885317.0. FitLoss: 0.09129568189382553,Accuracy:0.9752499999999993,Validation Loss:28823.56640625,Validation Accuracy:0.968, Prune parameters: 30479.0/421642,Beta: 0.01\n",
      "Epoch [31/4000],Loss:28800.384765625, KL Loss: 2880029.5. FitLoss: 0.09037964791059494,Accuracy:0.9758124999999994,Validation Loss:28770.677734375,Validation Accuracy:0.971, Prune parameters: 32173.0/421642,Beta: 0.01\n",
      "Epoch [32/4000],Loss:28747.490234375, KL Loss: 2874739.5. FitLoss: 0.09441068023443222,Accuracy:0.9738374999999998,Validation Loss:28717.763671875,Validation Accuracy:0.975, Prune parameters: 33995.0/421642,Beta: 0.01\n",
      "Epoch [33/4000],Loss:28694.564453125, KL Loss: 2869447.0. FitLoss: 0.09343435615301132,Accuracy:0.9741874999999999,Validation Loss:28664.837890625,Validation Accuracy:0.975, Prune parameters: 35744.0/421642,Beta: 0.01\n",
      "Epoch [34/4000],Loss:28641.615234375, KL Loss: 2864152.5. FitLoss: 0.09113499522209167,Accuracy:0.9743249999999998,Validation Loss:28611.8828125,Validation Accuracy:0.972, Prune parameters: 37466.0/421642,Beta: 0.01\n",
      "Epoch [35/4000],Loss:28588.640625, KL Loss: 2858855.0. FitLoss: 0.09173312783241272,Accuracy:0.9738499999999993,Validation Loss:28558.908203125,Validation Accuracy:0.965, Prune parameters: 39196.0/421642,Beta: 0.01\n",
      "Epoch [36/4000],Loss:28535.6484375, KL Loss: 2853555.5. FitLoss: 0.09449390321969986,Accuracy:0.9733124999999996,Validation Loss:28505.8828125,Validation Accuracy:0.976, Prune parameters: 40975.0/421642,Beta: 0.01\n",
      "Epoch [37/4000],Loss:28482.623046875, KL Loss: 2848253.25. FitLoss: 0.09164391458034515,Accuracy:0.9751499999999995,Validation Loss:28452.84375,Validation Accuracy:0.978, Prune parameters: 42623.0/421642,Beta: 0.01\n",
      "Epoch [38/4000],Loss:28429.5625, KL Loss: 2842948.5. FitLoss: 0.07975348085165024,Accuracy:0.978925,Validation Loss:28399.78125,Validation Accuracy:0.975, Prune parameters: 44394.0/421642,Beta: 0.01\n",
      "Epoch [39/4000],Loss:28376.48828125, KL Loss: 2837641.0. FitLoss: 0.07840746641159058,Accuracy:0.9787499999999998,Validation Loss:28346.6875,Validation Accuracy:0.979, Prune parameters: 46129.0/421642,Beta: 0.01\n",
      "Epoch [40/4000],Loss:28323.384765625, KL Loss: 2832331.25. FitLoss: 0.07349709421396255,Accuracy:0.9803249999999999,Validation Loss:28293.587890625,Validation Accuracy:0.978, Prune parameters: 47807.0/421642,Beta: 0.01\n",
      "Epoch [41/4000],Loss:28270.263671875, KL Loss: 2827018.75. FitLoss: 0.07990501075983047,Accuracy:0.9786749999999996,Validation Loss:28240.4609375,Validation Accuracy:0.974, Prune parameters: 49508.0/421642,Beta: 0.01\n",
      "Epoch [42/4000],Loss:28217.126953125, KL Loss: 2821703.5. FitLoss: 0.08986964076757431,Accuracy:0.9749874999999998,Validation Loss:28187.314453125,Validation Accuracy:0.981, Prune parameters: 51224.0/421642,Beta: 0.01\n",
      "Epoch [43/4000],Loss:28163.94921875, KL Loss: 2816386.75. FitLoss: 0.08557368069887161,Accuracy:0.9764999999999995,Validation Loss:28134.13671875,Validation Accuracy:0.978, Prune parameters: 53033.0/421642,Beta: 0.01\n",
      "Epoch [44/4000],Loss:28110.75, KL Loss: 2811067.0. FitLoss: 0.07770152390003204,Accuracy:0.9784249999999999,Validation Loss:28080.921875,Validation Accuracy:0.981, Prune parameters: 54728.0/421642,Beta: 0.01\n",
      "Epoch [45/4000],Loss:28057.51953125, KL Loss: 2805744.5. FitLoss: 0.0722319632768631,Accuracy:0.9801124999999999,Validation Loss:28027.705078125,Validation Accuracy:0.977, Prune parameters: 56457.0/421642,Beta: 0.01\n",
      "Epoch [46/4000],Loss:28004.271484375, KL Loss: 2800420.0. FitLoss: 0.07332418113946915,Accuracy:0.9802499999999998,Validation Loss:27974.458984375,Validation Accuracy:0.966, Prune parameters: 58228.0/421642,Beta: 0.01\n",
      "Epoch [47/4000],Loss:27950.998046875, KL Loss: 2795092.5. FitLoss: 0.07552826404571533,Accuracy:0.9792749999999995,Validation Loss:27921.1796875,Validation Accuracy:0.973, Prune parameters: 59953.0/421642,Beta: 0.01\n",
      "Epoch [48/4000],Loss:27897.69921875, KL Loss: 2789762.75. FitLoss: 0.07095351815223694,Accuracy:0.9807374999999994,Validation Loss:27867.876953125,Validation Accuracy:0.969, Prune parameters: 61657.0/421642,Beta: 0.01\n",
      "Epoch [49/4000],Loss:27844.376953125, KL Loss: 2784430.5. FitLoss: 0.07122428715229034,Accuracy:0.9808124999999995,Validation Loss:27814.537109375,Validation Accuracy:0.968, Prune parameters: 63433.0/421642,Beta: 0.01\n",
      "Epoch [50/4000],Loss:27791.029296875, KL Loss: 2779095.75. FitLoss: 0.07156722992658615,Accuracy:0.9805499999999995,Validation Loss:27761.171875,Validation Accuracy:0.972, Prune parameters: 65128.0/421642,Beta: 0.01\n",
      "Epoch [51/4000],Loss:27737.654296875, KL Loss: 2773758.25. FitLoss: 0.07046020030975342,Accuracy:0.9812874999999994,Validation Loss:27707.779296875,Validation Accuracy:0.98, Prune parameters: 66887.0/421642,Beta: 0.01\n",
      "Epoch [52/4000],Loss:27684.25390625, KL Loss: 2768419.0. FitLoss: 0.06799817085266113,Accuracy:0.9819624999999996,Validation Loss:27654.376953125,Validation Accuracy:0.978, Prune parameters: 68676.0/421642,Beta: 0.01\n",
      "Epoch [53/4000],Loss:27630.833984375, KL Loss: 2763076.75. FitLoss: 0.06704048067331314,Accuracy:0.9822749999999998,Validation Loss:27600.953125,Validation Accuracy:0.972, Prune parameters: 70394.0/421642,Beta: 0.01\n",
      "Epoch [54/4000],Loss:27577.384765625, KL Loss: 2757732.0. FitLoss: 0.06473618745803833,Accuracy:0.9836374999999998,Validation Loss:27547.509765625,Validation Accuracy:0.972, Prune parameters: 72169.0/421642,Beta: 0.01\n",
      "Epoch [55/4000],Loss:27523.916015625, KL Loss: 2752385.0. FitLoss: 0.06645859777927399,Accuracy:0.9816874999999999,Validation Loss:27494.048828125,Validation Accuracy:0.97, Prune parameters: 73833.0/421642,Beta: 0.01\n",
      "Epoch [56/4000],Loss:27470.419921875, KL Loss: 2747035.25. FitLoss: 0.06619370728731155,Accuracy:0.9824999999999993,Validation Loss:27440.53515625,Validation Accuracy:0.978, Prune parameters: 75565.0/421642,Beta: 0.01\n",
      "Epoch [57/4000],Loss:27416.90234375, KL Loss: 2741683.5. FitLoss: 0.06999435275793076,Accuracy:0.9812124999999993,Validation Loss:27387.0,Validation Accuracy:0.971, Prune parameters: 77300.0/421642,Beta: 0.01\n",
      "Epoch [58/4000],Loss:27363.359375, KL Loss: 2736329.25. FitLoss: 0.0695229098200798,Accuracy:0.9805249999999995,Validation Loss:27333.46484375,Validation Accuracy:0.969, Prune parameters: 79046.0/421642,Beta: 0.01\n",
      "Epoch [59/4000],Loss:27309.79296875, KL Loss: 2730972.5. FitLoss: 0.07076722383499146,Accuracy:0.9799499999999994,Validation Loss:27279.888671875,Validation Accuracy:0.97, Prune parameters: 80794.0/421642,Beta: 0.01\n",
      "Epoch [60/4000],Loss:27256.19921875, KL Loss: 2725613.25. FitLoss: 0.06558584421873093,Accuracy:0.9824499999999994,Validation Loss:27226.3125,Validation Accuracy:0.969, Prune parameters: 82518.0/421642,Beta: 0.01\n",
      "Epoch [61/4000],Loss:27202.578125, KL Loss: 2720251.5. FitLoss: 0.06384836137294769,Accuracy:0.9826624999999997,Validation Loss:27172.658203125,Validation Accuracy:0.977, Prune parameters: 84248.0/421642,Beta: 0.01\n",
      "Epoch [62/4000],Loss:27148.9375, KL Loss: 2714887.5. FitLoss: 0.0643320232629776,Accuracy:0.9823124999999996,Validation Loss:27119.017578125,Validation Accuracy:0.976, Prune parameters: 85992.0/421642,Beta: 0.01\n",
      "Epoch [63/4000],Loss:27095.275390625, KL Loss: 2709521.0. FitLoss: 0.0655997022986412,Accuracy:0.9819125,Validation Loss:27065.416015625,Validation Accuracy:0.953, Prune parameters: 87652.0/421642,Beta: 0.01\n",
      "Epoch [64/4000],Loss:27041.58984375, KL Loss: 2704152.25. FitLoss: 0.07023201882839203,Accuracy:0.9807499999999999,Validation Loss:27011.703125,Validation Accuracy:0.965, Prune parameters: 89423.0/421642,Beta: 0.01\n",
      "Epoch [65/4000],Loss:26987.875, KL Loss: 2698781.0. FitLoss: 0.06537539511919022,Accuracy:0.9813374999999995,Validation Loss:26957.97265625,Validation Accuracy:0.97, Prune parameters: 91176.0/421642,Beta: 0.01\n",
      "Epoch [66/4000],Loss:26934.142578125, KL Loss: 2693407.5. FitLoss: 0.06833269447088242,Accuracy:0.9813499999999997,Validation Loss:26904.22265625,Validation Accuracy:0.966, Prune parameters: 92899.0/421642,Beta: 0.01\n",
      "Epoch [67/4000],Loss:26880.375, KL Loss: 2688032.0. FitLoss: 0.0618414506316185,Accuracy:0.9827124999999995,Validation Loss:26850.462890625,Validation Accuracy:0.966, Prune parameters: 94577.0/421642,Beta: 0.01\n",
      "Epoch [68/4000],Loss:26826.59375, KL Loss: 2682653.25. FitLoss: 0.06206901744008064,Accuracy:0.9826874999999994,Validation Loss:26796.701171875,Validation Accuracy:0.962, Prune parameters: 96351.0/421642,Beta: 0.01\n",
      "Epoch [69/4000],Loss:26772.78515625, KL Loss: 2677272.75. FitLoss: 0.05724219232797623,Accuracy:0.9841749999999996,Validation Loss:26742.884765625,Validation Accuracy:0.963, Prune parameters: 98002.0/421642,Beta: 0.01\n",
      "Epoch [70/4000],Loss:26718.962890625, KL Loss: 2671889.75. FitLoss: 0.06682039797306061,Accuracy:0.9815249999999999,Validation Loss:26689.078125,Validation Accuracy:0.963, Prune parameters: 99737.0/421642,Beta: 0.01\n",
      "Epoch [71/4000],Loss:26665.111328125, KL Loss: 2666504.75. FitLoss: 0.0649678185582161,Accuracy:0.982725,Validation Loss:26635.208984375,Validation Accuracy:0.97, Prune parameters: 101433.0/421642,Beta: 0.01\n",
      "Epoch [72/4000],Loss:26611.236328125, KL Loss: 2661117.25. FitLoss: 0.06424308568239212,Accuracy:0.9818749999999996,Validation Loss:26581.34765625,Validation Accuracy:0.963, Prune parameters: 103244.0/421642,Beta: 0.01\n",
      "Epoch [73/4000],Loss:26557.34375, KL Loss: 2655727.5. FitLoss: 0.06735879927873611,Accuracy:0.9807624999999994,Validation Loss:26527.4375,Validation Accuracy:0.974, Prune parameters: 105065.0/421642,Beta: 0.01\n",
      "Epoch [74/4000],Loss:26503.41796875, KL Loss: 2650335.75. FitLoss: 0.06226479634642601,Accuracy:0.9831749999999998,Validation Loss:26473.5078125,Validation Accuracy:0.976, Prune parameters: 106762.0/421642,Beta: 0.01\n",
      "Epoch [75/4000],Loss:26449.474609375, KL Loss: 2644941.5. FitLoss: 0.0604320652782917,Accuracy:0.9829374999999999,Validation Loss:26419.564453125,Validation Accuracy:0.976, Prune parameters: 108606.0/421642,Beta: 0.01\n",
      "Epoch [76/4000],Loss:26395.515625, KL Loss: 2639545.25. FitLoss: 0.06569893658161163,Accuracy:0.9814374999999996,Validation Loss:26365.62109375,Validation Accuracy:0.978, Prune parameters: 110447.0/421642,Beta: 0.01\n",
      "Epoch [77/4000],Loss:26341.5234375, KL Loss: 2634146.5. FitLoss: 0.062189530581235886,Accuracy:0.9833124999999999,Validation Loss:26311.634765625,Validation Accuracy:0.973, Prune parameters: 112161.0/421642,Beta: 0.01\n",
      "Epoch [78/4000],Loss:26287.515625, KL Loss: 2628745.5. FitLoss: 0.05939600244164467,Accuracy:0.9835624999999997,Validation Loss:26257.6171875,Validation Accuracy:0.975, Prune parameters: 113931.0/421642,Beta: 0.01\n",
      "Epoch [79/4000],Loss:26233.486328125, KL Loss: 2623342.5. FitLoss: 0.06066260114312172,Accuracy:0.9830249999999994,Validation Loss:26203.60546875,Validation Accuracy:0.976, Prune parameters: 115681.0/421642,Beta: 0.01\n",
      "Epoch [80/4000],Loss:26179.4375, KL Loss: 2617937.5. FitLoss: 0.06283959746360779,Accuracy:0.9823249999999997,Validation Loss:26149.576171875,Validation Accuracy:0.973, Prune parameters: 117475.0/421642,Beta: 0.01\n",
      "Epoch [81/4000],Loss:26125.3671875, KL Loss: 2612530.25. FitLoss: 0.06385204941034317,Accuracy:0.9818999999999999,Validation Loss:26095.501953125,Validation Accuracy:0.969, Prune parameters: 119242.0/421642,Beta: 0.01\n",
      "Epoch [82/4000],Loss:26071.2734375, KL Loss: 2607121.0. FitLoss: 0.06262434273958206,Accuracy:0.9827499999999999,Validation Loss:26041.42578125,Validation Accuracy:0.961, Prune parameters: 120981.0/421642,Beta: 0.01\n",
      "Epoch [83/4000],Loss:26017.15625, KL Loss: 2601709.75. FitLoss: 0.060344841331243515,Accuracy:0.9836749999999995,Validation Loss:25987.318359375,Validation Accuracy:0.962, Prune parameters: 122773.0/421642,Beta: 0.01\n",
      "Epoch [84/4000],Loss:25963.0234375, KL Loss: 2596296.0. FitLoss: 0.06057983636856079,Accuracy:0.9832374999999998,Validation Loss:25933.171875,Validation Accuracy:0.965, Prune parameters: 124534.0/421642,Beta: 0.01\n",
      "Epoch [85/4000],Loss:25908.86328125, KL Loss: 2590880.75. FitLoss: 0.058124370872974396,Accuracy:0.9831125000000001,Validation Loss:25879.033203125,Validation Accuracy:0.961, Prune parameters: 126241.0/421642,Beta: 0.01\n",
      "Epoch [86/4000],Loss:25854.689453125, KL Loss: 2585463.25. FitLoss: 0.059073306620121,Accuracy:0.9833999999999994,Validation Loss:25824.89453125,Validation Accuracy:0.967, Prune parameters: 127992.0/421642,Beta: 0.01\n",
      "Epoch [87/4000],Loss:25800.49609375, KL Loss: 2580043.5. FitLoss: 0.06172221153974533,Accuracy:0.9821874999999995,Validation Loss:25770.697265625,Validation Accuracy:0.972, Prune parameters: 129750.0/421642,Beta: 0.01\n",
      "Epoch [88/4000],Loss:25746.275390625, KL Loss: 2574622.25. FitLoss: 0.05758923292160034,Accuracy:0.9845624999999997,Validation Loss:25716.482421875,Validation Accuracy:0.969, Prune parameters: 131504.0/421642,Beta: 0.01\n",
      "Epoch [89/4000],Loss:25692.041015625, KL Loss: 2569198.75. FitLoss: 0.05809662491083145,Accuracy:0.9834624999999996,Validation Loss:25662.2421875,Validation Accuracy:0.971, Prune parameters: 133262.0/421642,Beta: 0.01\n",
      "Epoch [90/4000],Loss:25637.79296875, KL Loss: 2563773.25. FitLoss: 0.061419129371643066,Accuracy:0.9824874999999998,Validation Loss:25608.001953125,Validation Accuracy:0.975, Prune parameters: 134987.0/421642,Beta: 0.01\n",
      "Epoch [91/4000],Loss:25583.51953125, KL Loss: 2558346.25. FitLoss: 0.05894095078110695,Accuracy:0.9833624999999996,Validation Loss:25553.73046875,Validation Accuracy:0.973, Prune parameters: 136721.0/421642,Beta: 0.01\n",
      "Epoch [92/4000],Loss:25529.2265625, KL Loss: 2552917.25. FitLoss: 0.056850675493478775,Accuracy:0.9842624999999995,Validation Loss:25499.4375,Validation Accuracy:0.972, Prune parameters: 138515.0/421642,Beta: 0.01\n",
      "Epoch [93/4000],Loss:25474.91796875, KL Loss: 2547486.0. FitLoss: 0.05943433940410614,Accuracy:0.9832874999999994,Validation Loss:25445.162109375,Validation Accuracy:0.966, Prune parameters: 140298.0/421642,Beta: 0.01\n",
      "Epoch [94/4000],Loss:25420.58984375, KL Loss: 2542053.0. FitLoss: 0.060365624725818634,Accuracy:0.9829125,Validation Loss:25390.8828125,Validation Accuracy:0.965, Prune parameters: 142058.0/421642,Beta: 0.01\n",
      "Epoch [95/4000],Loss:25366.248046875, KL Loss: 2536618.5. FitLoss: 0.0629727765917778,Accuracy:0.9815874999999996,Validation Loss:25336.525390625,Validation Accuracy:0.973, Prune parameters: 143782.0/421642,Beta: 0.01\n",
      "Epoch [96/4000],Loss:25311.884765625, KL Loss: 2531182.5. FitLoss: 0.06161963567137718,Accuracy:0.9816499999999996,Validation Loss:25282.171875,Validation Accuracy:0.977, Prune parameters: 145556.0/421642,Beta: 0.01\n",
      "Epoch [97/4000],Loss:25257.505859375, KL Loss: 2525744.0. FitLoss: 0.0638391524553299,Accuracy:0.9806999999999991,Validation Loss:25227.82421875,Validation Accuracy:0.972, Prune parameters: 147312.0/421642,Beta: 0.01\n",
      "Epoch [98/4000],Loss:25203.111328125, KL Loss: 2520304.5. FitLoss: 0.06542447954416275,Accuracy:0.9809374999999996,Validation Loss:25173.43359375,Validation Accuracy:0.973, Prune parameters: 148994.0/421642,Beta: 0.01\n",
      "Epoch [99/4000],Loss:25148.69140625, KL Loss: 2514863.25. FitLoss: 0.06094282120466232,Accuracy:0.9819624999999995,Validation Loss:25119.017578125,Validation Accuracy:0.96, Prune parameters: 150742.0/421642,Beta: 0.01\n",
      "Epoch [100/4000],Loss:25094.255859375, KL Loss: 2509420.0. FitLoss: 0.057863008230924606,Accuracy:0.9833124999999997,Validation Loss:25064.60546875,Validation Accuracy:0.953, Prune parameters: 152515.0/421642,Beta: 0.01\n",
      "Epoch [101/4000],Loss:25039.810546875, KL Loss: 2503975.25. FitLoss: 0.05898052826523781,Accuracy:0.9834000000000002,Validation Loss:25010.177734375,Validation Accuracy:0.956, Prune parameters: 154246.0/421642,Beta: 0.01\n",
      "Epoch [102/4000],Loss:24985.353515625, KL Loss: 2498529.0. FitLoss: 0.0646294504404068,Accuracy:0.9805124999999993,Validation Loss:24955.734375,Validation Accuracy:0.96, Prune parameters: 155998.0/421642,Beta: 0.01\n",
      "Epoch [103/4000],Loss:24930.8828125, KL Loss: 2493081.25. FitLoss: 0.06901150196790695,Accuracy:0.9786624999999998,Validation Loss:24901.28515625,Validation Accuracy:0.956, Prune parameters: 157763.0/421642,Beta: 0.01\n",
      "Epoch [104/4000],Loss:24876.388671875, KL Loss: 2487632.0. FitLoss: 0.0696343332529068,Accuracy:0.9784249999999997,Validation Loss:24846.7734375,Validation Accuracy:0.955, Prune parameters: 159546.0/421642,Beta: 0.01\n",
      "Epoch [105/4000],Loss:24821.87890625, KL Loss: 2482181.25. FitLoss: 0.06695107370615005,Accuracy:0.9797374999999995,Validation Loss:24792.265625,Validation Accuracy:0.969, Prune parameters: 161294.0/421642,Beta: 0.01\n",
      "Epoch [106/4000],Loss:24767.353515625, KL Loss: 2476729.0. FitLoss: 0.06295425444841385,Accuracy:0.9813749999999996,Validation Loss:24737.755859375,Validation Accuracy:0.975, Prune parameters: 163122.0/421642,Beta: 0.01\n",
      "Epoch [107/4000],Loss:24712.8125, KL Loss: 2471275.0. FitLoss: 0.059667158871889114,Accuracy:0.9824374999999996,Validation Loss:24683.23046875,Validation Accuracy:0.968, Prune parameters: 164923.0/421642,Beta: 0.01\n",
      "Epoch [108/4000],Loss:24658.259765625, KL Loss: 2465820.0. FitLoss: 0.05921381711959839,Accuracy:0.9822625,Validation Loss:24628.716796875,Validation Accuracy:0.939, Prune parameters: 166581.0/421642,Beta: 0.01\n",
      "Epoch [109/4000],Loss:24603.6953125, KL Loss: 2460363.25. FitLoss: 0.061539482325315475,Accuracy:0.9819874999999995,Validation Loss:24574.140625,Validation Accuracy:0.947, Prune parameters: 168387.0/421642,Beta: 0.01\n",
      "Epoch [110/4000],Loss:24549.119140625, KL Loss: 2454905.75. FitLoss: 0.06265559792518616,Accuracy:0.9815749999999994,Validation Loss:24519.56640625,Validation Accuracy:0.968, Prune parameters: 170170.0/421642,Beta: 0.01\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=1000\n",
    "EPOCHS=4000\n",
    "LR = 1e-3 #5e-4\n",
    "# Split the training set into training and validation sets \n",
    "VAL_PERCENT = 0.2 # percentage of the data used for validation \n",
    "SAMPLES = 10\n",
    "BETA = 0.01 #5e-5 #0.01\n",
    "BETA_FAC = 5e-1\n",
    "PRUNE = 1.9#1.99, 2.1, 1.9\n",
    "PLATO_TOL = 20\n",
    "\n",
    "base_module = Classifier()\n",
    "var_module = LogUniformVarBayesModule(base_module)\n",
    "model = VarBayesModuleNet(base_module, nn.ModuleList([var_module]))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "#Первый лосс это обычный лосс на данные, второй лосс это лосс байесковской модели\n",
    "fit_loss = nn.CrossEntropyLoss() \n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "\n",
    "#Используем планировщик коэффицента пропорциональности между fit_loss и kl_loss\n",
    "beta = Beta_Scheduler_Plato(BETA, BETA_FAC, PLATO_TOL)\n",
    "beta_KL = Beta_Scheduler_Plato(beta.beta, 1 / BETA_FAC, PLATO_TOL, ref = beta, threshold=1e-4)\n",
    "\n",
    "#Данная функция будет выполнятся после каждого шага тренера, соответсвенно нам требуется сделать шаг планировщика и изменить соотвествующий коэффициент\n",
    "def post_train_step(trainer: VarTrainerParams, train_result: VarBayesTrainer.TrainResult):\n",
    "    beta.step(train_result.fit_loss)\n",
    "    beta_KL.step(train_result.dist_loss)\n",
    "    trainer.params.beta = float(beta)\n",
    "    \n",
    "#print(model.base_module.state_dict().keys())\n",
    "val_size    = int(VAL_PERCENT * len(train_dataset)) \n",
    "train_size  = len(train_dataset) - val_size \n",
    "\n",
    "t_dataset, v_dataset = torch.utils.data.random_split(train_dataset,  \n",
    "                                                        [train_size,  \n",
    "                                                            val_size]) \n",
    "\n",
    "# Create DataLoaders for the training and validation sets \n",
    "train_loader = torch.utils.data.DataLoader(t_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=True, \n",
    "                                        pin_memory=True) \n",
    "eval_loader = torch.utils.data.DataLoader(v_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=False, \n",
    "                                        pin_memory=True) \n",
    "\n",
    "model.to(device) \n",
    "train_params = VarTrainerParams(EPOCHS, optimizer,fit_loss, kl_loss, SAMPLES, PRUNE, BETA, {'accuracy': CallbackLossAccuracy()})\n",
    "#Если зотим сделать бету фиксированной, то нунжо убрать аргумент [post_train_step]\n",
    "#trainer = VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader, [post_train_step])\n",
    "trainer = VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader)\n",
    "trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('module_list.0.posterior_params.0.param_mus', tensor([[[[ 2.5841e-07, -1.2233e-02,  7.9962e-03],\n",
      "          [ 1.3414e-06,  4.4800e-03,  1.1717e-02],\n",
      "          [ 2.4174e-03,  6.1303e-06, -6.3872e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.4067e-06, -1.3908e-02, -2.3774e-05],\n",
      "          [-2.2695e-06,  1.2359e-03,  9.2660e-03],\n",
      "          [-9.2873e-07, -1.4729e-02,  3.6886e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7811e-02, -1.4421e-02,  1.6615e-02],\n",
      "          [-2.2942e-02, -3.1714e-05, -2.1503e-04],\n",
      "          [-8.1395e-08, -1.0686e-04, -6.5693e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5442e-03,  1.5579e-06, -2.7291e-04],\n",
      "          [-1.1265e-07, -1.4138e-06, -4.5947e-07],\n",
      "          [ 1.7760e-04, -2.5134e-02,  9.3481e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.5268e-03,  3.9635e-04,  3.5783e-06],\n",
      "          [ 1.2107e-06,  3.2627e-03,  8.3468e-03],\n",
      "          [ 7.4476e-06, -2.1339e-02,  2.7009e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5353e-02, -9.2420e-07, -3.7983e-06],\n",
      "          [-2.5550e-06, -2.7675e-05, -1.0869e-04],\n",
      "          [-1.4504e-06,  1.9404e-05, -8.4981e-07]]],\n",
      "\n",
      "\n",
      "        [[[-3.8399e-03, -2.5052e-07, -2.0034e-06],\n",
      "          [-5.5306e-04, -2.5338e-03, -1.2210e-05],\n",
      "          [ 9.5218e-04,  1.9900e-06, -4.4763e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4457e-06,  1.1123e-06, -1.1624e-02],\n",
      "          [ 6.8779e-06,  2.3516e-02, -1.7141e-02],\n",
      "          [ 9.7272e-03, -4.4036e-04,  1.3211e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7049e-06, -3.5580e-03, -6.5792e-03],\n",
      "          [-2.9534e-06,  1.3538e-03,  8.1825e-07],\n",
      "          [-1.4674e-06,  1.1792e-04, -6.9995e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8178e-03, -9.9942e-03,  5.7007e-03],\n",
      "          [-7.4708e-03, -7.0736e-04, -1.4455e-02],\n",
      "          [ 5.1561e-07, -3.7707e-07, -2.0521e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.1705e-06, -1.5740e-02, -3.5101e-03],\n",
      "          [ 3.7418e-06, -1.2803e-06, -8.0729e-04],\n",
      "          [-2.9114e-04,  2.0301e-02, -3.1997e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.9674e-07,  2.2417e-03,  1.1206e-03],\n",
      "          [-2.1884e-03,  2.2577e-06,  1.4350e-06],\n",
      "          [ 7.0208e-04,  1.0231e-06,  9.8961e-05]]],\n",
      "\n",
      "\n",
      "        [[[-8.4516e-05, -2.1553e-06, -2.3925e-06],\n",
      "          [ 6.9866e-03,  1.8799e-07, -2.4777e-02],\n",
      "          [-1.4826e-04,  3.4318e-08, -6.9202e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0188e-02, -2.1013e-02,  8.9118e-07],\n",
      "          [ 2.5531e-06,  2.6224e-03,  7.5206e-07],\n",
      "          [ 2.3221e-06,  3.5996e-06, -4.1197e-05]]],\n",
      "\n",
      "\n",
      "        [[[-5.9595e-03,  2.2925e-02, -1.1386e-05],\n",
      "          [ 3.4927e-07, -1.3098e-02, -3.2014e-05],\n",
      "          [-8.6633e-07, -3.9421e-04, -4.2186e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7765e-06,  5.4831e-07, -2.9066e-03],\n",
      "          [ 7.5810e-03, -2.6054e-06, -1.4417e-02],\n",
      "          [-2.5630e-04, -9.4736e-07, -5.7113e-07]]],\n",
      "\n",
      "\n",
      "        [[[-8.1127e-07, -1.3509e-06, -1.5762e-02],\n",
      "          [-3.7876e-07,  1.7251e-06,  2.4386e-04],\n",
      "          [-2.6539e-07, -6.0890e-03,  2.2171e-06]]],\n",
      "\n",
      "\n",
      "        [[[-8.8495e-04, -9.7259e-07,  4.4731e-07],\n",
      "          [-1.0542e-06,  2.3935e-02,  1.0181e-06],\n",
      "          [-1.2230e-06, -7.2804e-03,  1.1936e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.4825e-07,  2.1650e-04, -3.5296e-05],\n",
      "          [-1.1395e-06, -1.3727e-06,  1.9522e-05],\n",
      "          [-8.4116e-03,  3.8269e-05, -5.5530e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0988e-02,  6.4126e-05,  1.4931e-03],\n",
      "          [ 1.0168e-06, -1.2128e-02,  3.5826e-03],\n",
      "          [-1.3709e-02, -1.2379e-04,  1.0219e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.8645e-02, -8.1126e-07, -1.0590e-02],\n",
      "          [ 8.5649e-03, -2.0394e-03, -6.2270e-03],\n",
      "          [ 2.2023e-03,  7.5435e-06,  6.3066e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8194e-02, -1.1267e-04,  1.8598e-02],\n",
      "          [-6.1799e-05, -1.3620e-02, -1.5005e-03],\n",
      "          [-3.4143e-06,  1.6790e-06,  1.9621e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7392e-06,  3.0987e-03, -4.4467e-07],\n",
      "          [-1.8661e-02, -7.0661e-03, -1.0677e-03],\n",
      "          [ 2.1647e-07,  1.3368e-07, -1.1692e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9927e-07,  1.4092e-06, -5.2444e-04],\n",
      "          [-1.2161e-02,  6.1470e-04, -1.3498e-06],\n",
      "          [ 1.9385e-06,  1.8943e-06, -4.1283e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2883e-05,  1.8315e-06, -7.7233e-05],\n",
      "          [ 1.5017e-02, -4.2808e-03,  3.5370e-05],\n",
      "          [ 2.4729e-06,  2.1222e-06,  1.8174e-06]]],\n",
      "\n",
      "\n",
      "        [[[-3.0790e-04, -3.8316e-06, -4.7024e-03],\n",
      "          [-1.2708e-04,  4.7764e-07,  1.4075e-06],\n",
      "          [ 2.3562e-03, -4.8971e-08, -7.9573e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9270e-03, -6.5889e-03, -1.4460e-03],\n",
      "          [-1.7272e-07,  1.8683e-02, -1.5902e-02],\n",
      "          [ 9.5538e-06,  4.8826e-03, -1.1734e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3494e-02,  7.2270e-05, -2.4825e-02],\n",
      "          [-1.4074e-06,  1.5573e-02, -2.5925e-03],\n",
      "          [-1.8734e-06,  3.0182e-06,  2.4122e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2379e-04,  1.6725e-05,  1.8395e-03],\n",
      "          [-3.0169e-04,  1.2857e-03, -3.2004e-06],\n",
      "          [ 1.6853e-02, -4.6542e-03,  2.1320e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2230e-03,  2.6678e-04, -9.2836e-04],\n",
      "          [-3.9959e-03,  3.6144e-06, -3.1123e-03],\n",
      "          [-2.1747e-03, -1.9918e-05,  5.2954e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0836e-06, -4.0457e-03,  6.2489e-08],\n",
      "          [-2.3826e-02, -1.7704e-02, -1.1916e-06],\n",
      "          [ 6.5739e-04, -1.7009e-02,  6.4079e-06]]],\n",
      "\n",
      "\n",
      "        [[[-9.5706e-07,  8.3995e-03, -1.2415e-06],\n",
      "          [ 5.4498e-05,  5.2341e-04, -1.1777e-06],\n",
      "          [-2.6259e-04, -8.3315e-04,  1.1353e-06]]]], device='cuda:0')), ('module_list.0.posterior_params.0.param_std_log', tensor([[[[ -6.4947,  -4.8136,  -5.0328],\n",
      "          [ -7.6453,  -4.2656,  -4.3566],\n",
      "          [ -4.2898,  -7.6268,  -6.0105]]],\n",
      "\n",
      "\n",
      "        [[[ -4.1271,  -4.5163,  -5.1858],\n",
      "          [ -4.1565,  -4.2845,  -4.1073],\n",
      "          [ -7.4305,  -8.6512,  -5.8681]]],\n",
      "\n",
      "\n",
      "        [[[ -6.3825,  -4.2237,  -4.2113],\n",
      "          [ -4.4821,  -5.7181,  -4.1175],\n",
      "          [ -6.7994,  -4.3845,  -4.1148]]],\n",
      "\n",
      "\n",
      "        [[[ -4.6909,  -4.8016,  -4.0855],\n",
      "          [ -4.9422,  -4.6441,  -4.7017],\n",
      "          [ -4.9211,  -4.1100,  -5.1002]]],\n",
      "\n",
      "\n",
      "        [[[ -4.2920,  -4.3239,  -4.5325],\n",
      "          [ -5.1915,  -4.5259,  -4.0820],\n",
      "          [ -4.0948,  -4.6235,  -5.7959]]],\n",
      "\n",
      "\n",
      "        [[[ -4.3704,  -5.9859,  -4.4459],\n",
      "          [ -4.6160,  -5.7275,  -6.7973],\n",
      "          [ -4.3566,  -6.7673,  -4.7654]]],\n",
      "\n",
      "\n",
      "        [[[ -5.7650,  -4.1605,  -5.8985],\n",
      "          [ -5.1199,  -5.7967,  -4.9592],\n",
      "          [ -4.7941,  -4.1116,  -4.2244]]],\n",
      "\n",
      "\n",
      "        [[[ -5.1886,  -5.2568,  -7.7655],\n",
      "          [ -6.5778,  -6.2892,  -5.1249],\n",
      "          [ -4.5659,  -4.9816,  -6.0430]]],\n",
      "\n",
      "\n",
      "        [[[ -4.7287,  -4.1266,  -4.6495],\n",
      "          [ -4.4167,  -4.3834,  -6.1884],\n",
      "          [ -4.1874,  -4.2177,  -4.1857]]],\n",
      "\n",
      "\n",
      "        [[[ -4.5810,  -4.3147,  -6.1409],\n",
      "          [ -5.5924,  -4.0988,  -5.2937],\n",
      "          [ -7.8960,  -4.6583,  -4.3158]]],\n",
      "\n",
      "\n",
      "        [[[ -4.9624,  -4.5981,  -4.5308],\n",
      "          [ -4.4490,  -6.7644,  -5.1914],\n",
      "          [ -4.2664,  -4.2077,  -6.9489]]],\n",
      "\n",
      "\n",
      "        [[[ -4.1636,  -4.1361,  -7.8102],\n",
      "          [ -4.7175,  -5.1445,  -6.3258],\n",
      "          [ -4.1896,  -5.0145,  -6.3289]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0983,  -4.1674,  -4.2762],\n",
      "          [ -6.1255,  -4.2754,  -4.0955],\n",
      "          [ -5.3578,  -4.3699,  -4.4131]]],\n",
      "\n",
      "\n",
      "        [[[ -7.1214,  -5.0823,  -4.2594],\n",
      "          [ -4.4361,  -4.6151,  -5.8066],\n",
      "          [ -4.2009,  -5.0831,  -4.6804]]],\n",
      "\n",
      "\n",
      "        [[[ -4.5088,  -5.4152,  -5.1288],\n",
      "          [ -4.6035,  -4.7254,  -5.7152],\n",
      "          [ -5.0038,  -6.5429,  -4.0981]]],\n",
      "\n",
      "\n",
      "        [[[ -4.5363,  -4.8731,  -4.8805],\n",
      "          [ -4.7824,  -4.2325,  -4.0919],\n",
      "          [ -5.0284,  -8.2136,  -4.9477]]],\n",
      "\n",
      "\n",
      "        [[[ -4.4562,  -5.5288,  -4.2321],\n",
      "          [ -4.4242,  -4.4076,  -4.9019],\n",
      "          [ -4.3468,  -5.4421,  -4.8742]]],\n",
      "\n",
      "\n",
      "        [[[ -5.0770,  -4.2979,  -4.3266],\n",
      "          [ -4.5704,  -4.3644,  -6.2678],\n",
      "          [ -5.2841,  -5.3317,  -5.0125]]],\n",
      "\n",
      "\n",
      "        [[[ -4.9148,  -5.0182,  -4.4737],\n",
      "          [ -4.3254,  -5.3739,  -4.1148],\n",
      "          [ -6.0593,  -5.1290,  -5.1282]]],\n",
      "\n",
      "\n",
      "        [[[ -8.2877,  -6.0262,  -4.4019],\n",
      "          [ -7.9581,  -5.7533,  -5.4131],\n",
      "          [ -4.7670,  -4.6744,  -4.7482]]],\n",
      "\n",
      "\n",
      "        [[[ -4.3429,  -4.8270, -15.5712],\n",
      "          [ -4.8831,  -4.8744,  -4.5434],\n",
      "          [ -5.0165,  -4.6874,  -4.1868]]],\n",
      "\n",
      "\n",
      "        [[[ -5.6218,  -6.4461,  -5.8217],\n",
      "          [ -5.0565,  -6.0657,  -6.9629],\n",
      "          [ -5.2774,  -4.2602,  -4.8775]]],\n",
      "\n",
      "\n",
      "        [[[ -4.8660,  -4.1483,  -5.2323],\n",
      "          [ -4.9379,  -4.3428,  -4.9693],\n",
      "          [ -5.3985,  -5.2386,  -4.4587]]],\n",
      "\n",
      "\n",
      "        [[[ -4.2932,  -5.0413,  -4.3289],\n",
      "          [ -6.1493,  -9.1325,  -4.1244],\n",
      "          [ -4.5825,  -9.1810,  -5.7587]]],\n",
      "\n",
      "\n",
      "        [[[ -4.2070,  -4.2394,  -6.4879],\n",
      "          [ -4.1195,  -4.0842,  -4.6166],\n",
      "          [ -4.0841,  -4.3548,  -5.7479]]],\n",
      "\n",
      "\n",
      "        [[[ -4.1200,  -5.0215,  -7.1456],\n",
      "          [ -5.4086,  -4.7420,  -5.2495],\n",
      "          [ -4.7415,  -4.1130,  -4.8952]]],\n",
      "\n",
      "\n",
      "        [[[ -4.7114, -10.5682,  -4.2073],\n",
      "          [ -5.3579,  -5.6020,  -5.0559],\n",
      "          [ -4.1904,  -4.0829,  -4.9937]]],\n",
      "\n",
      "\n",
      "        [[[ -4.5668,  -5.0432,  -5.4627],\n",
      "          [ -4.6322,  -4.0996,  -5.2199],\n",
      "          [ -5.1886,  -6.1052,  -4.6022]]],\n",
      "\n",
      "\n",
      "        [[[ -5.1187,  -4.7148,  -4.2369],\n",
      "          [ -5.6662,  -4.5525,  -4.1182],\n",
      "          [ -5.1343,  -6.5005,  -6.3188]]],\n",
      "\n",
      "\n",
      "        [[[ -5.6133,  -5.2211,  -5.8710],\n",
      "          [ -4.8951,  -4.3601,  -6.2380],\n",
      "          [ -4.6509,  -5.0081,  -5.3717]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0941,  -5.6758,  -4.2624],\n",
      "          [ -4.4637,  -4.1345,  -4.1423],\n",
      "          [ -6.7226,  -4.0953,  -5.4928]]],\n",
      "\n",
      "\n",
      "        [[[ -4.3568,  -4.8428,  -4.4974],\n",
      "          [ -4.8351,  -4.4515,  -4.5175],\n",
      "          [ -7.0287,  -4.8522,  -5.2154]]]], device='cuda:0')), ('module_list.0.posterior_params.0.scale_alphas_log', tensor([[[[-1.5143, -1.6702, -1.7355],\n",
      "          [-3.0596, -2.6939, -2.9428],\n",
      "          [-2.4466, -1.9143, -3.3280]]],\n",
      "\n",
      "\n",
      "        [[[-1.4974, -2.7475, -1.5643],\n",
      "          [-2.2650, -3.0770, -1.7259],\n",
      "          [-2.7601, -1.6276, -2.0488]]],\n",
      "\n",
      "\n",
      "        [[[-1.5618, -3.4170, -3.0931],\n",
      "          [-2.6324, -2.2942, -2.6316],\n",
      "          [-2.6447, -1.6211, -2.7037]]],\n",
      "\n",
      "\n",
      "        [[[-2.0898, -1.9632, -1.9947],\n",
      "          [-2.2216, -2.3907, -1.6943],\n",
      "          [-2.3713, -2.6683, -2.9659]]],\n",
      "\n",
      "\n",
      "        [[[-2.6022, -3.4589, -2.5222],\n",
      "          [-2.1975, -3.2835, -2.5828],\n",
      "          [-2.2270, -3.0520, -1.4690]]],\n",
      "\n",
      "\n",
      "        [[[-3.3150, -2.0771, -2.9250],\n",
      "          [-3.0550, -2.3820, -3.0133],\n",
      "          [-3.1761, -1.6274, -2.2223]]],\n",
      "\n",
      "\n",
      "        [[[-2.3899, -1.7964, -2.1803],\n",
      "          [-2.1285, -1.5593, -2.1531],\n",
      "          [-1.7850, -2.3856, -2.8680]]],\n",
      "\n",
      "\n",
      "        [[[-3.1190, -1.9465, -2.2797],\n",
      "          [-2.1140, -2.4607, -2.2329],\n",
      "          [-2.1240, -3.3683, -2.0952]]],\n",
      "\n",
      "\n",
      "        [[[-2.0876, -2.2839, -1.9793],\n",
      "          [-1.5604, -2.5574, -2.0900],\n",
      "          [-3.1472, -2.9995, -2.8056]]],\n",
      "\n",
      "\n",
      "        [[[-2.0306, -2.5217, -2.0960],\n",
      "          [-1.4933, -2.5549, -2.9502],\n",
      "          [-1.6183, -2.3095, -2.3817]]],\n",
      "\n",
      "\n",
      "        [[[-2.9363, -1.4834, -1.5270],\n",
      "          [-2.4014, -3.3054, -1.7744],\n",
      "          [-2.7878, -2.5627, -1.7769]]],\n",
      "\n",
      "\n",
      "        [[[-1.8806, -3.1516, -3.2003],\n",
      "          [-3.2425, -2.7471, -1.9943],\n",
      "          [-1.6107, -2.3261, -2.6771]]],\n",
      "\n",
      "\n",
      "        [[[-2.5268, -2.9877, -3.0557],\n",
      "          [-1.7652, -2.8254, -2.0759],\n",
      "          [-2.9532, -1.7305, -2.2036]]],\n",
      "\n",
      "\n",
      "        [[[-2.3056, -1.7525, -2.1404],\n",
      "          [-2.2451, -2.9075, -2.9538],\n",
      "          [-1.8668, -1.9535, -2.6078]]],\n",
      "\n",
      "\n",
      "        [[[-2.8300, -1.4730, -1.4846],\n",
      "          [-2.6596, -2.3834, -2.1372],\n",
      "          [-2.8679, -3.0708, -2.3254]]],\n",
      "\n",
      "\n",
      "        [[[-2.3378, -2.3957, -2.5042],\n",
      "          [-2.7481, -1.7163, -2.8710],\n",
      "          [-2.0650, -2.7900, -2.9818]]],\n",
      "\n",
      "\n",
      "        [[[-2.7795, -1.7511, -2.0931],\n",
      "          [-2.6497, -3.1897, -2.5810],\n",
      "          [-2.4555, -1.9024, -2.7998]]],\n",
      "\n",
      "\n",
      "        [[[-1.8374, -3.3530, -1.5469],\n",
      "          [-3.1824, -1.6265, -2.4078],\n",
      "          [-2.5545, -2.3736, -1.9663]]],\n",
      "\n",
      "\n",
      "        [[[-2.9063, -2.8036, -3.3350],\n",
      "          [-1.6826, -1.4968, -2.4460],\n",
      "          [-2.0034, -3.0920, -3.2840]]],\n",
      "\n",
      "\n",
      "        [[[-2.7975, -1.8752, -2.4376],\n",
      "          [-3.3421, -2.4437, -2.1233],\n",
      "          [-3.3700, -3.4085, -2.2232]]],\n",
      "\n",
      "\n",
      "        [[[-2.0924, -1.7304, -3.0575],\n",
      "          [-1.9674, -2.4607, -1.5331],\n",
      "          [-1.4999, -2.7755, -1.8071]]],\n",
      "\n",
      "\n",
      "        [[[-2.8776, -2.8902, -3.1476],\n",
      "          [-3.3036, -2.6815, -1.5593],\n",
      "          [-2.0882, -2.2513, -2.9860]]],\n",
      "\n",
      "\n",
      "        [[[-3.4249, -2.8258, -3.2320],\n",
      "          [-3.1896, -2.3955, -2.8106],\n",
      "          [-2.4224, -2.8759, -3.3649]]],\n",
      "\n",
      "\n",
      "        [[[-2.7089, -2.2672, -2.4551],\n",
      "          [-3.1919, -1.5723, -1.9661],\n",
      "          [-1.4860, -3.1146, -2.6679]]],\n",
      "\n",
      "\n",
      "        [[[-2.8256, -3.0310, -1.4849],\n",
      "          [-3.3486, -1.8318, -2.7723],\n",
      "          [-1.7415, -3.0374, -3.2885]]],\n",
      "\n",
      "\n",
      "        [[[-3.1892, -1.7211, -1.5851],\n",
      "          [-2.1683, -3.3811, -1.5784],\n",
      "          [-1.6685, -2.2583, -2.2286]]],\n",
      "\n",
      "\n",
      "        [[[-3.3414, -2.4805, -2.9179],\n",
      "          [-2.0798, -2.9344, -2.4395],\n",
      "          [-1.4954, -3.1694, -1.5002]]],\n",
      "\n",
      "\n",
      "        [[[-2.7612, -2.9043, -2.8418],\n",
      "          [-3.1497, -3.2447, -2.4384],\n",
      "          [-2.8824, -1.6642, -2.3667]]],\n",
      "\n",
      "\n",
      "        [[[-3.1605, -2.4096, -1.9485],\n",
      "          [-3.2840, -3.2157, -3.1445],\n",
      "          [-1.4726, -2.7458, -3.1156]]],\n",
      "\n",
      "\n",
      "        [[[-2.7008, -3.2307, -2.2640],\n",
      "          [-1.6348, -3.2305, -2.9108],\n",
      "          [-3.1003, -3.2952, -3.1832]]],\n",
      "\n",
      "\n",
      "        [[[-2.5660, -2.9847, -3.2215],\n",
      "          [-1.8051, -2.0058, -3.1018],\n",
      "          [-2.5875, -3.0386, -2.3712]]],\n",
      "\n",
      "\n",
      "        [[[-3.1834, -2.9611, -2.0927],\n",
      "          [-3.3368, -1.7620, -1.9541],\n",
      "          [-1.4729, -2.2604, -2.0798]]]], device='cuda:0')), ('module_list.0.posterior_params.0.scale_mus', tensor([[[[1.0269, 0.9694, 1.0311],\n",
      "          [1.0307, 1.0373, 1.0341],\n",
      "          [1.0365, 1.0281, 0.9645]]],\n",
      "\n",
      "\n",
      "        [[[0.9904, 0.9765, 0.9691],\n",
      "          [1.0151, 1.0259, 1.0329],\n",
      "          [0.9768, 0.9720, 1.0311]]],\n",
      "\n",
      "\n",
      "        [[[0.9863, 1.0056, 1.0144],\n",
      "          [0.9950, 0.9846, 0.9838],\n",
      "          [0.9951, 1.0037, 0.9984]]],\n",
      "\n",
      "\n",
      "        [[[1.0159, 1.0116, 0.9952],\n",
      "          [0.9874, 1.0132, 1.0107],\n",
      "          [1.0137, 0.9843, 1.0191]]],\n",
      "\n",
      "\n",
      "        [[[0.9799, 1.0295, 1.0302],\n",
      "          [1.0241, 1.0315, 1.0303],\n",
      "          [1.0321, 0.9681, 0.9668]]],\n",
      "\n",
      "\n",
      "        [[[1.0217, 0.9944, 1.0049],\n",
      "          [1.0251, 0.9798, 0.9885],\n",
      "          [0.9753, 0.9983, 0.9853]]],\n",
      "\n",
      "\n",
      "        [[[1.0066, 0.9913, 0.9846],\n",
      "          [0.9834, 0.9795, 1.0019],\n",
      "          [1.0194, 1.0222, 0.9876]]],\n",
      "\n",
      "\n",
      "        [[[1.0082, 0.9737, 0.9861],\n",
      "          [0.9856, 1.0284, 0.9868],\n",
      "          [1.0183, 0.9771, 1.0054]]],\n",
      "\n",
      "\n",
      "        [[[1.0094, 0.9846, 0.9925],\n",
      "          [1.0189, 1.0228, 1.0164],\n",
      "          [0.9807, 1.0179, 0.9843]]],\n",
      "\n",
      "\n",
      "        [[[1.0071, 1.0019, 0.9965],\n",
      "          [0.9820, 0.9870, 1.0060],\n",
      "          [1.0079, 0.9859, 0.9896]]],\n",
      "\n",
      "\n",
      "        [[[0.9789, 0.9969, 1.0275],\n",
      "          [1.0108, 0.9912, 1.0173],\n",
      "          [0.9852, 1.0015, 0.9922]]],\n",
      "\n",
      "\n",
      "        [[[0.9760, 1.0308, 1.0305],\n",
      "          [0.9720, 1.0300, 0.9725],\n",
      "          [1.0265, 0.9736, 1.0274]]],\n",
      "\n",
      "\n",
      "        [[[1.0265, 0.9799, 1.0158],\n",
      "          [0.9771, 1.0237, 1.0269],\n",
      "          [1.0279, 1.0140, 1.0076]]],\n",
      "\n",
      "\n",
      "        [[[1.0010, 1.0056, 0.9842],\n",
      "          [0.9920, 0.9991, 0.9928],\n",
      "          [0.9992, 1.0038, 0.9923]]],\n",
      "\n",
      "\n",
      "        [[[1.0110, 0.9873, 0.9846],\n",
      "          [1.0054, 1.0092, 1.0050],\n",
      "          [0.9830, 1.0042, 0.9647]]],\n",
      "\n",
      "\n",
      "        [[[1.0136, 0.9857, 0.9887],\n",
      "          [1.0156, 1.0216, 0.9826],\n",
      "          [0.9864, 0.9831, 1.0163]]],\n",
      "\n",
      "\n",
      "        [[[0.9921, 0.9832, 0.9744],\n",
      "          [0.9764, 1.0138, 1.0180],\n",
      "          [1.0202, 1.0028, 0.9850]]],\n",
      "\n",
      "\n",
      "        [[[1.0107, 1.0088, 1.0114],\n",
      "          [1.0201, 1.0244, 1.0188],\n",
      "          [0.9774, 0.9740, 1.0262]]],\n",
      "\n",
      "\n",
      "        [[[1.0236, 1.0251, 0.9975],\n",
      "          [1.0202, 1.0279, 1.0188],\n",
      "          [0.9834, 1.0248, 0.9820]]],\n",
      "\n",
      "\n",
      "        [[[1.0192, 1.0241, 1.0304],\n",
      "          [0.9925, 0.9776, 1.0284],\n",
      "          [1.0112, 0.9871, 1.0255]]],\n",
      "\n",
      "\n",
      "        [[[0.9762, 0.9823, 1.0176],\n",
      "          [1.0266, 0.9788, 1.0107],\n",
      "          [1.0300, 1.0104, 0.9913]]],\n",
      "\n",
      "\n",
      "        [[[1.0173, 1.0005, 0.9950],\n",
      "          [0.9788, 1.0021, 1.0083],\n",
      "          [1.0015, 0.9950, 0.9905]]],\n",
      "\n",
      "\n",
      "        [[[1.0101, 0.9859, 1.0154],\n",
      "          [1.0214, 1.0222, 1.0234],\n",
      "          [1.0007, 0.9947, 0.9925]]],\n",
      "\n",
      "\n",
      "        [[[0.9949, 1.0172, 0.9748],\n",
      "          [0.9949, 1.0160, 1.0184],\n",
      "          [0.9832, 1.0065, 0.9915]]],\n",
      "\n",
      "\n",
      "        [[[1.0329, 1.0101, 1.0228],\n",
      "          [1.0340, 0.9822, 1.0091],\n",
      "          [1.0298, 1.0237, 1.0266]]],\n",
      "\n",
      "\n",
      "        [[[1.0203, 0.9899, 0.9721],\n",
      "          [0.9840, 1.0242, 0.9922],\n",
      "          [1.0333, 1.0284, 0.9901]]],\n",
      "\n",
      "\n",
      "        [[[1.0250, 0.9782, 0.9833],\n",
      "          [0.9770, 1.0258, 0.9771],\n",
      "          [1.0246, 1.0265, 0.9745]]],\n",
      "\n",
      "\n",
      "        [[[1.0381, 1.0374, 0.9642],\n",
      "          [0.9673, 1.0384, 0.9650],\n",
      "          [1.0361, 1.0324, 1.0299]]],\n",
      "\n",
      "\n",
      "        [[[1.0122, 1.0125, 1.0112],\n",
      "          [0.9871, 1.0137, 0.9879],\n",
      "          [1.0212, 0.9799, 1.0128]]],\n",
      "\n",
      "\n",
      "        [[[1.0111, 0.9944, 0.9751],\n",
      "          [0.9862, 1.0183, 0.9730],\n",
      "          [1.0060, 0.9898, 1.0304]]],\n",
      "\n",
      "\n",
      "        [[[0.9881, 1.0018, 0.9942],\n",
      "          [0.9853, 0.9705, 1.0131],\n",
      "          [1.0165, 0.9918, 0.9935]]],\n",
      "\n",
      "\n",
      "        [[[1.0210, 1.0198, 0.9967],\n",
      "          [1.0219, 1.0114, 0.9959],\n",
      "          [0.9846, 0.9829, 0.9869]]]], device='cuda:0')), ('module_list.0.posterior_params.1.param_mus', tensor([ 1.1550e-06,  4.7274e-07, -6.2620e-06,  6.5583e-03,  8.1219e-03,\n",
      "         3.6230e-04, -1.5061e-02,  7.7570e-06, -8.9144e-04,  2.1388e-07,\n",
      "        -3.5672e-03, -5.9058e-05,  1.2210e-02, -2.3283e-02, -1.5512e-02,\n",
      "        -2.2575e-02,  1.2710e-03,  3.0569e-06,  1.9752e-06,  2.5718e-06,\n",
      "        -1.5768e-06,  4.8040e-06,  3.7901e-04,  1.9328e-06,  2.0451e-04,\n",
      "         3.9062e-05,  7.7367e-09,  1.3911e-02,  2.6251e-04,  1.7829e-06,\n",
      "        -6.4918e-03, -1.0056e-02], device='cuda:0')), ('module_list.0.posterior_params.1.param_std_log', tensor([-4.1593, -4.3317, -6.0343, -4.8871, -5.3405, -5.8841, -4.1936, -4.3391,\n",
      "        -4.6150, -4.9606, -4.2102, -4.1023, -4.1343, -4.7892, -4.2105, -4.0998,\n",
      "        -4.1669, -4.1276, -4.3750, -4.3629, -4.5065, -4.7476, -4.9526, -4.6440,\n",
      "        -4.1418, -6.4263, -4.3648, -5.2927, -4.6181, -4.1051, -4.2543, -4.5189],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.1.scale_alphas_log', tensor([-1.9959, -2.0880, -3.3180, -2.8506, -1.7171, -3.3408, -1.5161, -3.4499,\n",
      "        -3.1400, -2.0602, -1.7883, -2.5354, -1.5036, -3.2240, -2.9984, -1.8829,\n",
      "        -2.1218, -2.6661, -2.5252, -1.8825, -2.0705, -2.3608, -2.0346, -1.5672,\n",
      "        -1.7009, -2.9427, -2.2079, -1.8316, -2.0547, -2.1299, -2.1954, -2.4297],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.1.scale_mus', tensor([0.9674, 0.9881, 0.9913, 0.9863, 1.0129, 1.0082, 0.9792, 1.0000, 0.9785,\n",
      "        0.9954, 0.9983, 0.9726, 0.9922, 0.9975, 1.0125, 0.9851, 1.0132, 0.9798,\n",
      "        0.9809, 0.9752, 0.9723, 0.9887, 1.0132, 1.0030, 1.0055, 0.9933, 0.9998,\n",
      "        1.0000, 0.9792, 0.9748, 1.0028, 0.9838], device='cuda:0')), ('module_list.0.posterior_params.2.param_mus', tensor([[[[-1.5895e-06,  3.0069e-07, -1.0353e-06],\n",
      "          [-1.0632e-06,  4.2397e-07,  1.1708e-07],\n",
      "          [-1.0479e-06,  1.8781e-08, -1.0691e-06]],\n",
      "\n",
      "         [[-1.7970e-06, -3.6943e-07, -3.5270e-07],\n",
      "          [ 2.6234e-07, -1.5053e-07, -4.3719e-10],\n",
      "          [-1.0900e-07, -1.1772e-07, -1.3156e-07]],\n",
      "\n",
      "         [[-3.1881e-07,  3.1596e-07,  3.0193e-07],\n",
      "          [-5.1184e-07, -1.0289e-05, -1.8825e-07],\n",
      "          [-1.7217e-07,  8.4086e-07, -8.7788e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6474e-07,  2.3668e-07, -1.3876e-07],\n",
      "          [ 6.5383e-08,  1.1551e-06, -8.5503e-08],\n",
      "          [ 1.3757e-07,  1.4441e-09, -1.4863e-07]],\n",
      "\n",
      "         [[-5.3876e-08,  1.4688e-07,  3.8505e-08],\n",
      "          [ 7.1429e-08,  3.1808e-07, -1.8541e-08],\n",
      "          [-4.4602e-07,  3.9563e-07, -3.2244e-08]],\n",
      "\n",
      "         [[ 5.9270e-07, -1.5097e-06,  8.2276e-07],\n",
      "          [ 1.7497e-06,  9.4856e-07,  2.7302e-06],\n",
      "          [-1.1974e-08,  1.9542e-07, -2.0261e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6518e-06,  3.2413e-07,  8.2712e-07],\n",
      "          [ 2.1557e-07, -3.6300e-07, -7.7495e-07],\n",
      "          [ 4.8890e-07, -2.1358e-07, -2.7405e-06]],\n",
      "\n",
      "         [[ 4.4793e-08,  3.5072e-07,  5.6150e-07],\n",
      "          [ 2.1818e-06,  1.9201e-08,  2.6875e-07],\n",
      "          [ 4.9720e-08,  5.7665e-06,  8.7268e-08]],\n",
      "\n",
      "         [[-2.8880e-07,  2.7698e-07, -4.7568e-08],\n",
      "          [-2.7191e-07, -3.8970e-07, -6.3534e-08],\n",
      "          [-3.9971e-07, -8.9112e-08,  7.0740e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3219e-06,  7.9511e-07, -7.9785e-06],\n",
      "          [ 7.6809e-07,  3.8573e-07, -1.3559e-07],\n",
      "          [ 9.6683e-07, -2.5674e-07,  1.2407e-06]],\n",
      "\n",
      "         [[ 4.2459e-07, -1.5197e-06,  8.7352e-08],\n",
      "          [ 1.2380e-06,  4.1063e-07,  1.1793e-06],\n",
      "          [ 1.1059e-06,  7.4497e-07,  4.7749e-07]],\n",
      "\n",
      "         [[-2.6952e-07, -5.3448e-07,  2.1005e-07],\n",
      "          [-1.1082e-06,  8.8718e-07, -9.9881e-08],\n",
      "          [-5.1297e-07, -2.8078e-07,  4.5264e-07]]],\n",
      "\n",
      "\n",
      "        [[[-4.3678e-07, -1.1083e-06, -7.5110e-07],\n",
      "          [-3.8313e-07, -3.6403e-07, -5.9122e-07],\n",
      "          [-1.5308e-06,  2.3551e-07, -1.6088e-07]],\n",
      "\n",
      "         [[-2.2147e-06, -1.0290e-06, -2.3009e-06],\n",
      "          [-2.9296e-06, -7.7655e-07,  2.3380e-06],\n",
      "          [-1.1487e-06, -3.4383e-07, -7.4392e-07]],\n",
      "\n",
      "         [[ 3.7448e-07,  4.7154e-07,  1.3823e-07],\n",
      "          [-5.0974e-07, -2.2867e-07,  3.5526e-07],\n",
      "          [-2.8299e-07,  1.1956e-05, -2.5504e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8560e-07, -1.2021e-06, -1.4964e-07],\n",
      "          [ 1.6091e-07,  5.1963e-07,  1.5821e-07],\n",
      "          [-3.1158e-07,  1.7032e-07,  2.9512e-07]],\n",
      "\n",
      "         [[-1.8056e-07, -6.6259e-08, -6.8801e-07],\n",
      "          [-2.3034e-07, -3.0153e-08, -1.3869e-06],\n",
      "          [ 2.3993e-07, -3.3705e-07, -7.3268e-07]],\n",
      "\n",
      "         [[ 3.4847e-07,  3.4395e-08, -1.4016e-06],\n",
      "          [ 1.3074e-07,  8.3181e-07, -2.3831e-07],\n",
      "          [-1.2170e-06, -2.0974e-08, -4.9376e-07]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.2393e-07,  7.5510e-07,  1.7252e-07],\n",
      "          [ 4.3854e-07,  2.3878e-07,  1.5533e-06],\n",
      "          [ 9.2922e-07,  1.3853e-07,  6.1897e-07]],\n",
      "\n",
      "         [[ 2.1000e-07,  7.1220e-07, -8.0132e-07],\n",
      "          [ 1.3094e-06, -1.0071e-06, -1.4660e-07],\n",
      "          [-4.9619e-08, -3.1004e-06,  8.7277e-07]],\n",
      "\n",
      "         [[ 6.5123e-08, -1.1416e-07,  5.9335e-08],\n",
      "          [ 6.6849e-07, -1.6460e-07,  2.4077e-07],\n",
      "          [ 7.8931e-08, -1.0635e-07, -3.8229e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0494e-07, -4.4100e-07, -2.7253e-07],\n",
      "          [-2.2379e-07, -5.2714e-07, -1.1531e-08],\n",
      "          [ 7.9407e-07,  5.3108e-07,  1.2248e-06]],\n",
      "\n",
      "         [[ 2.9926e-07,  2.2954e-07, -5.3736e-08],\n",
      "          [-8.5010e-07, -1.2845e-08, -1.9762e-07],\n",
      "          [ 1.8816e-07, -3.4850e-07, -1.9287e-07]],\n",
      "\n",
      "         [[ 3.5081e-07,  4.6032e-07, -8.3947e-07],\n",
      "          [ 9.8442e-07,  2.7021e-07, -1.5595e-07],\n",
      "          [ 1.0478e-06,  5.6294e-07, -3.3945e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6445e-08,  8.8183e-07,  3.7462e-07],\n",
      "          [ 4.4209e-07,  3.8997e-07,  1.5134e-06],\n",
      "          [-8.7750e-07,  3.1085e-07,  5.8364e-07]],\n",
      "\n",
      "         [[-1.4427e-08,  1.7696e-07,  2.0621e-07],\n",
      "          [-2.8510e-07, -6.1702e-07, -5.1615e-07],\n",
      "          [-5.0328e-07,  2.3500e-08,  3.6084e-07]],\n",
      "\n",
      "         [[-1.5693e-07, -4.8504e-07,  2.4960e-07],\n",
      "          [ 1.4423e-07,  3.3649e-06,  5.3069e-07],\n",
      "          [ 4.2593e-07, -1.1391e-06,  8.6017e-07]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9853e-07,  3.0671e-07,  5.6652e-06],\n",
      "          [-1.0219e-06,  4.8225e-06,  2.1662e-06],\n",
      "          [-4.0638e-07, -3.1099e-07, -1.1460e-07]],\n",
      "\n",
      "         [[-5.1648e-07,  1.1006e-07, -6.5007e-07],\n",
      "          [-5.6266e-08,  2.3041e-08, -5.5865e-07],\n",
      "          [ 3.8550e-08,  1.6126e-06, -2.3776e-07]],\n",
      "\n",
      "         [[ 3.4279e-07, -1.3584e-07,  2.9724e-07],\n",
      "          [-4.1838e-07, -8.3003e-08,  3.4051e-07],\n",
      "          [-5.2079e-07, -3.1470e-07, -7.6979e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1091e-06, -2.4814e-07, -1.3688e-06],\n",
      "          [ 6.2042e-08, -4.9970e-07, -7.7271e-08],\n",
      "          [ 7.0370e-07, -3.9886e-07, -4.5787e-07]],\n",
      "\n",
      "         [[-4.5686e-07,  3.8654e-07, -1.5878e-07],\n",
      "          [ 1.1717e-07, -7.6118e-08,  8.3957e-07],\n",
      "          [ 4.0807e-07, -2.5120e-07, -1.3197e-07]],\n",
      "\n",
      "         [[ 6.3085e-07,  2.3866e-07,  2.5275e-07],\n",
      "          [-2.7498e-08,  1.1581e-07,  2.0936e-07],\n",
      "          [-3.7705e-07,  2.1668e-06,  2.0308e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6670e-07, -3.1232e-07, -5.9156e-08],\n",
      "          [ 3.2850e-07,  4.0916e-07,  3.4502e-06],\n",
      "          [-2.3883e-06,  4.0099e-07,  2.5098e-07]],\n",
      "\n",
      "         [[ 6.9067e-08,  1.5044e-07, -1.7478e-07],\n",
      "          [-1.5452e-07, -8.0860e-07, -2.5402e-07],\n",
      "          [-1.9175e-07, -9.2206e-08, -4.6353e-07]],\n",
      "\n",
      "         [[ 4.2045e-07, -2.0603e-07, -5.3511e-07],\n",
      "          [ 4.6721e-08, -3.0942e-06, -4.7221e-07],\n",
      "          [-1.7576e-07, -7.1284e-07, -3.7647e-07]]]], device='cuda:0')), ('module_list.0.posterior_params.2.param_std_log', tensor([[[[-6.5890, -6.3248, -4.2001],\n",
      "          [-4.4853, -5.6661, -4.2658],\n",
      "          [-4.7315, -4.6523, -4.2705]],\n",
      "\n",
      "         [[-4.9140, -4.6685, -4.1060],\n",
      "          [-4.5979, -4.3367, -5.1337],\n",
      "          [-4.5705, -4.2887, -6.1359]],\n",
      "\n",
      "         [[-4.3663, -6.4064, -4.0824],\n",
      "          [-4.2380, -5.3166, -5.0618],\n",
      "          [-5.0412, -4.6756, -4.2025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.8154, -4.6372, -4.1100],\n",
      "          [-6.0635, -7.0058, -6.1157],\n",
      "          [-5.1309, -4.7105, -5.1222]],\n",
      "\n",
      "         [[-4.3893, -4.7472, -4.6416],\n",
      "          [-5.4763, -5.7922, -4.4296],\n",
      "          [-5.6737, -4.3552, -4.6320]],\n",
      "\n",
      "         [[-4.7445, -5.3910, -5.6141],\n",
      "          [-5.6867, -5.4272, -4.2943],\n",
      "          [-4.1893, -5.4943, -5.5207]]],\n",
      "\n",
      "\n",
      "        [[[-4.9895, -4.2902, -7.1863],\n",
      "          [-5.1400, -4.1525, -4.6151],\n",
      "          [-5.1633, -4.1205, -4.5670]],\n",
      "\n",
      "         [[-4.4017, -8.6900, -4.1762],\n",
      "          [-4.7537, -4.9603, -4.3402],\n",
      "          [-6.6264, -9.5298, -4.8126]],\n",
      "\n",
      "         [[-4.2459, -6.2183, -5.3111],\n",
      "          [-5.0906, -5.1635, -4.1602],\n",
      "          [-5.4708, -4.2228, -5.9979]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7297, -4.9450, -4.1168],\n",
      "          [-5.2267, -4.2769, -5.1146],\n",
      "          [-5.4860, -4.4138, -5.1908]],\n",
      "\n",
      "         [[-4.1059, -4.2602, -5.3324],\n",
      "          [-4.1246, -4.3648, -5.3433],\n",
      "          [-4.9279, -4.5776, -4.1924]],\n",
      "\n",
      "         [[-5.0657, -5.8347, -4.1183],\n",
      "          [-4.0762, -5.7430, -5.6106],\n",
      "          [-4.2195, -6.2510, -4.9298]]],\n",
      "\n",
      "\n",
      "        [[[-4.0939, -5.2511, -5.1759],\n",
      "          [-4.3015, -5.0527, -4.4217],\n",
      "          [-5.5738, -4.1981, -6.0245]],\n",
      "\n",
      "         [[-4.7491, -6.7971, -5.1523],\n",
      "          [-4.6635, -6.4692, -5.8278],\n",
      "          [-4.1019, -5.0103, -5.2205]],\n",
      "\n",
      "         [[-4.2303, -7.5290, -4.2249],\n",
      "          [-4.5017, -4.3475, -5.3617],\n",
      "          [-4.7791, -4.9418, -4.2008]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.1967, -5.6204, -5.3884],\n",
      "          [-4.2053, -4.3802, -5.0183],\n",
      "          [-4.6764, -4.1643, -4.1793]],\n",
      "\n",
      "         [[-5.9145, -5.4538, -4.7985],\n",
      "          [-4.3181, -5.2849, -5.2292],\n",
      "          [-4.4458, -4.4068, -4.1099]],\n",
      "\n",
      "         [[-4.8473, -4.7101, -5.3092],\n",
      "          [-5.3163, -5.6945, -4.5449],\n",
      "          [-4.0769, -4.7520, -5.3711]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.1085, -4.6366, -4.4832],\n",
      "          [-4.5079, -6.9968, -4.2626],\n",
      "          [-4.6224, -5.8424, -4.8314]],\n",
      "\n",
      "         [[-4.9858, -4.2272, -5.4539],\n",
      "          [-6.7818, -4.1048, -5.0170],\n",
      "          [-6.0654, -5.1898, -4.8668]],\n",
      "\n",
      "         [[-4.3708, -5.7923, -4.5193],\n",
      "          [-5.9892, -4.5415, -5.1675],\n",
      "          [-4.2166, -4.5677, -4.6772]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1362, -4.4363, -4.2799],\n",
      "          [-4.1543, -5.5358, -4.2531],\n",
      "          [-4.2231, -5.7460, -5.5312]],\n",
      "\n",
      "         [[-5.5447, -4.9171, -5.6421],\n",
      "          [-6.8079, -5.7413, -4.7678],\n",
      "          [-5.9305, -4.1311, -9.8447]],\n",
      "\n",
      "         [[-6.5626, -8.1611, -6.4684],\n",
      "          [-5.0019, -5.7471, -4.2666],\n",
      "          [-4.3501, -5.5868, -5.2413]]],\n",
      "\n",
      "\n",
      "        [[[-6.4085, -4.3217, -4.4249],\n",
      "          [-4.2690, -5.2052, -4.5134],\n",
      "          [-4.4690, -5.1753, -4.2262]],\n",
      "\n",
      "         [[-4.6327, -5.6117, -5.1182],\n",
      "          [-4.8379, -5.1353, -5.2613],\n",
      "          [-4.2172, -6.7396, -4.5858]],\n",
      "\n",
      "         [[-4.2163, -4.5718, -4.7340],\n",
      "          [-7.2768, -4.6184, -5.1894],\n",
      "          [-4.3884, -5.1769, -6.0240]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.3540, -4.0876, -5.3067],\n",
      "          [-4.5091, -4.3834, -4.1994],\n",
      "          [-4.1305, -5.5996, -4.6195]],\n",
      "\n",
      "         [[-4.2421, -4.7490, -6.7896],\n",
      "          [-4.8791, -5.3958, -4.6455],\n",
      "          [-4.6527, -4.5696, -4.9342]],\n",
      "\n",
      "         [[-5.5782, -4.9756, -4.1937],\n",
      "          [-5.0094, -4.2196, -7.1123],\n",
      "          [-6.3730, -6.5725, -5.0658]]],\n",
      "\n",
      "\n",
      "        [[[-4.0770, -6.0930, -4.7330],\n",
      "          [-5.2536, -5.7684, -4.1731],\n",
      "          [-4.9365, -4.5163, -4.8961]],\n",
      "\n",
      "         [[-4.1084, -5.2812, -4.8491],\n",
      "          [-4.5249, -5.2921, -4.7213],\n",
      "          [-4.4597, -4.1702, -5.9216]],\n",
      "\n",
      "         [[-4.6472, -4.4557, -7.2130],\n",
      "          [-7.5295, -6.2885, -4.2154],\n",
      "          [-4.5591, -4.4380, -4.5613]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.4212, -4.3814, -6.2654],\n",
      "          [-5.2409, -4.9268, -4.3706],\n",
      "          [-4.2094, -5.0594, -4.7448]],\n",
      "\n",
      "         [[-4.1042, -4.4071, -4.1265],\n",
      "          [-4.1616, -4.1580, -4.2280],\n",
      "          [-4.5427, -4.3313, -4.4009]],\n",
      "\n",
      "         [[-5.4502, -4.6675, -5.7618],\n",
      "          [-6.0163, -4.5448, -4.5029],\n",
      "          [-4.2505, -5.1605, -4.9706]]]], device='cuda:0')), ('module_list.0.posterior_params.2.scale_alphas_log', tensor([[[[-2.9027, -3.1765, -1.8186],\n",
      "          [-2.0010, -2.1367, -2.8437],\n",
      "          [-2.0727, -2.0095, -2.2420]],\n",
      "\n",
      "         [[-3.2733, -1.6348, -1.7445],\n",
      "          [-2.8132, -3.1815, -2.0431],\n",
      "          [-1.9943, -2.1886, -1.8663]],\n",
      "\n",
      "         [[-2.3995, -1.4811, -1.6496],\n",
      "          [-2.0029, -2.0383, -1.6856],\n",
      "          [-2.1883, -3.0176, -2.0423]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4137, -2.6287, -2.0827],\n",
      "          [-2.0580, -2.5595, -1.8611],\n",
      "          [-3.2885, -2.2321, -1.4986]],\n",
      "\n",
      "         [[-1.8708, -2.7482, -3.4150],\n",
      "          [-1.8256, -2.6590, -3.3792],\n",
      "          [-1.9272, -1.9146, -2.9028]],\n",
      "\n",
      "         [[-1.4950, -3.0938, -2.2738],\n",
      "          [-3.0456, -2.3813, -2.3133],\n",
      "          [-3.3432, -1.4709, -3.2521]]],\n",
      "\n",
      "\n",
      "        [[[-2.0798, -2.2833, -3.0442],\n",
      "          [-2.8234, -2.3432, -3.2192],\n",
      "          [-3.1337, -2.3670, -2.7544]],\n",
      "\n",
      "         [[-3.3680, -1.7232, -3.3753],\n",
      "          [-2.4777, -2.7981, -1.7649],\n",
      "          [-2.8648, -2.8095, -2.6137]],\n",
      "\n",
      "         [[-2.2355, -2.8331, -1.6104],\n",
      "          [-3.2719, -3.1793, -2.7915],\n",
      "          [-1.9414, -2.9227, -3.0779]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8682, -2.3126, -1.9213],\n",
      "          [-2.8627, -3.2399, -1.7122],\n",
      "          [-1.8666, -2.7817, -1.8911]],\n",
      "\n",
      "         [[-2.5635, -1.9620, -3.3148],\n",
      "          [-1.6758, -3.2333, -3.3801],\n",
      "          [-2.9123, -1.6472, -3.0173]],\n",
      "\n",
      "         [[-2.6704, -2.1980, -2.7254],\n",
      "          [-2.1655, -2.1764, -2.6433],\n",
      "          [-2.3406, -3.2941, -1.6926]]],\n",
      "\n",
      "\n",
      "        [[[-1.9834, -2.1860, -3.4417],\n",
      "          [-3.1744, -1.8720, -2.0006],\n",
      "          [-2.6756, -2.0601, -3.0397]],\n",
      "\n",
      "         [[-2.6550, -2.7163, -2.5833],\n",
      "          [-2.6113, -3.3631, -3.1318],\n",
      "          [-2.7233, -2.1933, -2.2543]],\n",
      "\n",
      "         [[-2.9365, -2.9629, -3.0840],\n",
      "          [-2.7588, -3.0139, -2.9350],\n",
      "          [-2.5523, -1.6324, -3.2073]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7703, -3.1818, -3.3893],\n",
      "          [-2.4395, -2.1524, -3.3657],\n",
      "          [-2.0656, -2.3280, -2.8312]],\n",
      "\n",
      "         [[-2.1194, -3.4132, -2.0629],\n",
      "          [-2.0176, -2.6345, -3.1633],\n",
      "          [-3.3234, -2.0473, -1.7857]],\n",
      "\n",
      "         [[-1.6341, -1.9836, -2.8559],\n",
      "          [-2.0917, -2.3373, -2.4369],\n",
      "          [-2.4107, -3.3237, -1.8982]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.0919, -2.0308, -2.8131],\n",
      "          [-3.3092, -1.5351, -1.5684],\n",
      "          [-1.5192, -1.7451, -3.3497]],\n",
      "\n",
      "         [[-3.0697, -1.6451, -3.3215],\n",
      "          [-3.2596, -2.3897, -1.6913],\n",
      "          [-2.5563, -3.0545, -3.2820]],\n",
      "\n",
      "         [[-2.6075, -1.9977, -2.6795],\n",
      "          [-1.4739, -1.7542, -3.0725],\n",
      "          [-2.6733, -2.4163, -1.6912]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1445, -1.8961, -3.2182],\n",
      "          [-3.3740, -1.8673, -1.7777],\n",
      "          [-2.1306, -2.7517, -2.2103]],\n",
      "\n",
      "         [[-3.3742, -1.8693, -2.8180],\n",
      "          [-2.4707, -3.3560, -2.5173],\n",
      "          [-3.1282, -2.2164, -2.0457]],\n",
      "\n",
      "         [[-2.0540, -2.8550, -3.3660],\n",
      "          [-1.7791, -2.5949, -2.4194],\n",
      "          [-2.2373, -1.6468, -1.6768]]],\n",
      "\n",
      "\n",
      "        [[[-2.9449, -2.0436, -2.9840],\n",
      "          [-2.9414, -3.1276, -3.1406],\n",
      "          [-2.1657, -3.4221, -2.3664]],\n",
      "\n",
      "         [[-2.5326, -2.4150, -2.0522],\n",
      "          [-2.0702, -1.9128, -3.1835],\n",
      "          [-2.6952, -3.2303, -3.1654]],\n",
      "\n",
      "         [[-1.9809, -1.5246, -3.3886],\n",
      "          [-1.8245, -3.2746, -3.1702],\n",
      "          [-1.8541, -3.2559, -1.9116]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6581, -2.0739, -2.2248],\n",
      "          [-3.0379, -1.5303, -2.0161],\n",
      "          [-3.1879, -2.5360, -3.1005]],\n",
      "\n",
      "         [[-2.4607, -1.4696, -2.9895],\n",
      "          [-1.6676, -2.1962, -3.1573],\n",
      "          [-1.9870, -2.0105, -1.8804]],\n",
      "\n",
      "         [[-1.4711, -1.6702, -2.5683],\n",
      "          [-1.6911, -2.4352, -3.3607],\n",
      "          [-2.5179, -2.9967, -2.1629]]],\n",
      "\n",
      "\n",
      "        [[[-2.5507, -2.4328, -2.8459],\n",
      "          [-2.6406, -1.9164, -2.5868],\n",
      "          [-2.5266, -1.7563, -2.3590]],\n",
      "\n",
      "         [[-3.2493, -3.4597, -3.1626],\n",
      "          [-1.6325, -2.7686, -2.3004],\n",
      "          [-3.3834, -1.5570, -2.4527]],\n",
      "\n",
      "         [[-1.7849, -2.6773, -2.5766],\n",
      "          [-2.0843, -2.9883, -3.0129],\n",
      "          [-2.7736, -3.3909, -1.6421]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8356, -1.7361, -2.7961],\n",
      "          [-2.4395, -2.0150, -3.4110],\n",
      "          [-2.8148, -1.8766, -2.5169]],\n",
      "\n",
      "         [[-3.0109, -1.9607, -2.5613],\n",
      "          [-2.2352, -3.1708, -3.3421],\n",
      "          [-2.4779, -2.5896, -1.9093]],\n",
      "\n",
      "         [[-1.8677, -3.1321, -1.9809],\n",
      "          [-1.8500, -2.6939, -1.9791],\n",
      "          [-3.3189, -2.6765, -1.7129]]]], device='cuda:0')), ('module_list.0.posterior_params.2.scale_mus', tensor([[[[0.9897, 1.0103, 0.9944],\n",
      "          [1.0175, 0.9941, 0.9962],\n",
      "          [1.0164, 0.9977, 1.0117]],\n",
      "\n",
      "         [[1.0046, 1.0119, 0.9939],\n",
      "          [1.0110, 1.0038, 1.0130],\n",
      "          [1.0062, 1.0076, 0.9892]],\n",
      "\n",
      "         [[0.9808, 1.0192, 0.9826],\n",
      "          [1.0066, 1.0097, 0.9880],\n",
      "          [1.0123, 1.0148, 0.9941]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.9881, 0.9800, 1.0129],\n",
      "          [0.9838, 0.9922, 1.0120],\n",
      "          [1.0162, 1.0112, 1.0195]],\n",
      "\n",
      "         [[0.9974, 1.0031, 0.9995],\n",
      "          [0.9983, 1.0055, 0.9988],\n",
      "          [1.0002, 1.0003, 1.0006]],\n",
      "\n",
      "         [[1.0203, 0.9965, 1.0024],\n",
      "          [0.9839, 1.0113, 1.0019],\n",
      "          [1.0082, 0.9901, 0.9897]]],\n",
      "\n",
      "\n",
      "        [[[0.9844, 1.0189, 0.9838],\n",
      "          [1.0216, 0.9760, 0.9838],\n",
      "          [0.9788, 1.0203, 1.0135]],\n",
      "\n",
      "         [[1.0195, 0.9874, 0.9842],\n",
      "          [0.9908, 1.0173, 0.9921],\n",
      "          [1.0100, 1.0012, 0.9856]],\n",
      "\n",
      "         [[1.0174, 1.0155, 1.0060],\n",
      "          [1.0124, 0.9852, 0.9888],\n",
      "          [1.0132, 1.0040, 0.9858]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.0147, 0.9999, 0.9829],\n",
      "          [0.9966, 1.0054, 0.9861],\n",
      "          [0.9957, 1.0046, 1.0185]],\n",
      "\n",
      "         [[1.0060, 0.9986, 1.0127],\n",
      "          [0.9985, 1.0136, 0.9935],\n",
      "          [0.9994, 0.9994, 0.9981]],\n",
      "\n",
      "         [[0.9777, 1.0217, 0.9893],\n",
      "          [0.9967, 1.0179, 0.9841],\n",
      "          [0.9774, 1.0205, 0.9841]]],\n",
      "\n",
      "\n",
      "        [[[1.0154, 1.0081, 1.0005],\n",
      "          [1.0029, 0.9929, 1.0163],\n",
      "          [1.0087, 1.0186, 1.0185]],\n",
      "\n",
      "         [[0.9867, 1.0052, 0.9821],\n",
      "          [0.9944, 1.0207, 1.0075],\n",
      "          [1.0149, 1.0173, 1.0181]],\n",
      "\n",
      "         [[1.0164, 0.9814, 1.0197],\n",
      "          [0.9821, 0.9791, 0.9886],\n",
      "          [1.0174, 0.9980, 0.9947]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.9838, 1.0138, 0.9810],\n",
      "          [0.9965, 1.0206, 1.0234],\n",
      "          [1.0082, 0.9891, 1.0153]],\n",
      "\n",
      "         [[0.9922, 0.9956, 1.0047],\n",
      "          [1.0025, 0.9968, 1.0039],\n",
      "          [0.9898, 0.9940, 1.0049]],\n",
      "\n",
      "         [[0.9790, 0.9778, 0.9907],\n",
      "          [0.9810, 1.0041, 0.9932],\n",
      "          [1.0060, 0.9924, 1.0140]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.0093, 1.0010, 0.9822],\n",
      "          [0.9759, 1.0058, 1.0075],\n",
      "          [1.0087, 0.9791, 0.9748]],\n",
      "\n",
      "         [[1.0128, 0.9938, 1.0089],\n",
      "          [0.9962, 1.0106, 0.9859],\n",
      "          [1.0194, 1.0038, 0.9881]],\n",
      "\n",
      "         [[0.9892, 0.9820, 1.0019],\n",
      "          [0.9780, 0.9838, 1.0220],\n",
      "          [0.9821, 1.0201, 1.0182]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.9830, 0.9795, 1.0053],\n",
      "          [0.9781, 1.0216, 0.9915],\n",
      "          [0.9966, 0.9893, 1.0097]],\n",
      "\n",
      "         [[0.9930, 0.9970, 0.9881],\n",
      "          [0.9997, 0.9955, 1.0010],\n",
      "          [0.9942, 0.9869, 1.0049]],\n",
      "\n",
      "         [[1.0058, 0.9871, 0.9836],\n",
      "          [0.9785, 0.9782, 1.0226],\n",
      "          [1.0043, 0.9920, 0.9961]]],\n",
      "\n",
      "\n",
      "        [[[0.9947, 1.0083, 0.9990],\n",
      "          [0.9947, 1.0020, 0.9884],\n",
      "          [0.9898, 0.9891, 1.0073]],\n",
      "\n",
      "         [[1.0009, 0.9997, 0.9996],\n",
      "          [1.0232, 0.9879, 1.0152],\n",
      "          [0.9932, 1.0150, 0.9861]],\n",
      "\n",
      "         [[1.0124, 1.0123, 1.0149],\n",
      "          [1.0133, 1.0033, 1.0046],\n",
      "          [0.9872, 0.9930, 0.9893]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.0116, 0.9825, 1.0033],\n",
      "          [0.9879, 1.0033, 0.9976],\n",
      "          [0.9887, 1.0227, 0.9983]],\n",
      "\n",
      "         [[0.9955, 0.9934, 1.0007],\n",
      "          [0.9903, 1.0100, 1.0038],\n",
      "          [0.9941, 1.0010, 0.9992]],\n",
      "\n",
      "         [[0.9898, 0.9856, 0.9894],\n",
      "          [0.9997, 0.9950, 1.0048],\n",
      "          [1.0052, 1.0010, 0.9992]]],\n",
      "\n",
      "\n",
      "        [[[1.0133, 0.9882, 1.0111],\n",
      "          [1.0068, 0.9844, 0.9902],\n",
      "          [1.0043, 0.9829, 1.0007]],\n",
      "\n",
      "         [[0.9943, 1.0057, 1.0127],\n",
      "          [1.0141, 0.9862, 0.9934],\n",
      "          [1.0028, 1.0058, 0.9996]],\n",
      "\n",
      "         [[1.0149, 1.0095, 0.9892],\n",
      "          [1.0114, 0.9890, 1.0103],\n",
      "          [0.9934, 0.9983, 0.9991]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.9871, 0.9834, 0.9985],\n",
      "          [1.0117, 0.9924, 0.9962],\n",
      "          [0.9776, 0.9846, 0.9884]],\n",
      "\n",
      "         [[0.9948, 0.9972, 0.9969],\n",
      "          [0.9985, 0.9999, 0.9991],\n",
      "          [1.0040, 0.9948, 0.9947]],\n",
      "\n",
      "         [[1.0148, 1.0132, 0.9871],\n",
      "          [0.9876, 1.0054, 1.0129],\n",
      "          [1.0071, 0.9981, 0.9849]]]], device='cuda:0')), ('module_list.0.posterior_params.3.param_mus', tensor([-1.3675e-05,  3.6191e-05, -2.8626e-05,  1.3600e-05,  5.8396e-06,\n",
      "         1.2092e-04,  1.7517e-05,  6.1901e-07, -1.4434e-05,  6.1941e-05,\n",
      "         5.3204e-05, -2.2353e-05, -1.9727e-05,  5.1075e-05,  3.6460e-06,\n",
      "         3.4245e-05, -1.7955e-05,  1.1759e-05,  8.5117e-06,  6.4907e-06,\n",
      "        -3.4984e-06,  1.3426e-05, -2.0614e-05, -6.7045e-06,  2.0095e-07,\n",
      "        -2.9300e-05, -7.6743e-06,  3.7508e-05, -1.6321e-05,  2.1065e-05,\n",
      "         1.4926e-05,  4.1130e-05,  8.9225e-05,  3.2987e-05, -6.4706e-05,\n",
      "         3.3843e-05,  5.3134e-06,  3.5223e-05,  1.5761e-05, -1.1158e-05,\n",
      "         6.3431e-05, -5.9516e-05,  1.9982e-05, -1.2703e-06,  7.5484e-05,\n",
      "         1.6941e-05,  1.8051e-04,  3.0665e-05,  5.6479e-05, -4.6766e-05,\n",
      "         4.3595e-05, -3.8435e-05, -3.7263e-05, -1.3595e-04, -5.2845e-05,\n",
      "        -6.0033e-06, -1.3097e-05, -7.8922e-06,  7.0953e-07,  2.2126e-06,\n",
      "        -1.1941e-05,  1.9430e-05,  4.0778e-06,  2.2884e-05], device='cuda:0')), ('module_list.0.posterior_params.3.param_std_log', tensor([-4.6329, -4.7048, -4.8204, -5.1808, -4.2200, -4.1367, -4.4752, -4.2638,\n",
      "        -4.2800, -5.9466, -6.1655, -4.8182, -6.4267, -6.7604, -4.3847, -4.7129,\n",
      "        -6.6825, -4.2083, -5.0966, -4.0812, -4.3230, -9.0457, -5.3733, -4.4808,\n",
      "        -6.1630, -5.1324, -4.2157, -4.1638, -5.4418, -4.3873, -4.5671, -4.4069,\n",
      "        -5.0601, -4.4625, -4.2045, -4.5176, -4.1274, -4.5064, -4.4529, -4.5499,\n",
      "        -4.3959, -4.9638, -4.3302, -8.3069, -4.6865, -4.8943, -4.1730, -4.1640,\n",
      "        -4.5224, -4.6641, -4.9044, -4.6127, -4.1384, -4.6067, -4.6450, -4.4136,\n",
      "        -4.2111, -4.2415, -5.1994, -5.1779, -5.9756, -6.9464, -4.1643, -5.0457],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.3.scale_alphas_log', tensor([-2.9016, -1.9239, -1.6896, -1.5281, -2.9227, -2.0680, -1.8946, -1.6426,\n",
      "        -2.3780, -2.6794, -1.5340, -2.9062, -1.9918, -1.8627, -2.4514, -2.6900,\n",
      "        -2.7655, -3.3402, -2.5627, -1.9509, -2.0325, -1.5763, -3.0221, -3.3830,\n",
      "        -2.4564, -2.1571, -2.5340, -2.1054, -2.0292, -2.2108, -2.6625, -2.7619,\n",
      "        -1.5064, -1.5517, -1.6856, -2.8830, -1.8870, -3.1858, -2.4289, -1.7730,\n",
      "        -1.6051, -2.7785, -2.2097, -2.3171, -2.0395, -2.8545, -2.8967, -1.7947,\n",
      "        -3.1318, -2.5243, -1.9748, -1.4684, -2.4934, -3.0428, -2.1706, -3.3056,\n",
      "        -1.8300, -2.3662, -2.3089, -1.8573, -2.2349, -2.5968, -1.7866, -2.9300],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.3.scale_mus', tensor([0.9914, 1.0041, 0.9891, 1.0042, 1.0124, 1.0077, 0.9936, 1.0182, 0.9918,\n",
      "        1.0263, 0.9857, 0.9776, 0.9814, 0.9861, 0.9824, 0.9917, 1.0066, 0.9891,\n",
      "        0.9841, 0.9908, 0.9972, 0.9988, 0.9968, 1.0058, 0.9922, 1.0162, 0.9980,\n",
      "        0.9885, 0.9973, 1.0338, 0.9980, 0.9979, 0.9924, 0.9909, 1.0169, 1.0072,\n",
      "        1.0091, 1.0006, 1.0089, 0.9946, 1.0084, 1.0003, 1.0040, 0.9883, 1.0057,\n",
      "        1.0047, 1.0123, 0.9891, 0.9828, 0.9954, 0.9914, 0.9788, 1.0039, 0.9879,\n",
      "        1.0015, 1.0166, 0.9976, 0.9812, 1.0096, 0.9968, 1.0084, 1.0122, 1.0169,\n",
      "        1.0144], device='cuda:0')), ('module_list.0.posterior_params.4.param_mus', tensor([[ 7.7214e-07,  6.4135e-07, -3.5022e-08,  ...,  4.4236e-07,\n",
      "          5.7630e-07,  4.4649e-07],\n",
      "        [ 8.9819e-07,  1.0495e-06,  5.8324e-07,  ...,  2.0223e-07,\n",
      "          1.2570e-07, -2.3573e-07],\n",
      "        [-8.2865e-07,  1.2426e-06, -8.8034e-07,  ...,  2.9729e-07,\n",
      "          1.7603e-07,  1.0326e-07],\n",
      "        ...,\n",
      "        [ 2.8484e-07,  5.6520e-07,  7.1044e-07,  ...,  3.4535e-07,\n",
      "          2.7041e-07, -1.0691e-07],\n",
      "        [ 4.3289e-07,  1.1174e-06,  4.8300e-07,  ..., -3.0016e-07,\n",
      "          1.3107e-06, -4.2176e-07],\n",
      "        [-8.7451e-07, -1.5636e-06, -5.5524e-07,  ..., -1.9713e-08,\n",
      "         -4.4409e-08, -9.6311e-08]], device='cuda:0')), ('module_list.0.posterior_params.4.param_std_log', tensor([[-4.8102, -4.3481, -4.5148,  ..., -5.7909, -4.1275, -6.8039],\n",
      "        [-4.9555, -4.3504, -4.1693,  ..., -4.1622, -4.6549, -4.2014],\n",
      "        [-4.1751, -4.9333, -6.2750,  ..., -4.7329, -4.3478, -4.5356],\n",
      "        ...,\n",
      "        [-5.3807, -5.8564, -4.4367,  ..., -5.0838, -6.4157, -6.4450],\n",
      "        [-4.3783, -5.8415, -4.3810,  ..., -6.1343, -4.1599, -4.3801],\n",
      "        [-7.2108, -4.2671, -7.7434,  ..., -6.2028, -4.6343, -5.0981]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.4.scale_alphas_log', tensor([[-2.8528, -2.3756, -3.3441,  ..., -1.4779, -1.6322, -2.9854],\n",
      "        [-1.9694, -1.6667, -1.8622,  ..., -2.5192, -3.4126, -2.7231],\n",
      "        [-2.8640, -1.9590, -2.1168,  ..., -2.8486, -1.6212, -1.6197],\n",
      "        ...,\n",
      "        [-2.7906, -2.5162, -2.3845,  ..., -2.2912, -1.6506, -3.3543],\n",
      "        [-3.3989, -2.6947, -2.4611,  ..., -2.0967, -2.7224, -3.3147],\n",
      "        [-1.4934, -2.2239, -3.0375,  ..., -2.9213, -2.4150, -3.4128]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.4.scale_mus', tensor([[1.0050, 0.9971, 1.0083,  ..., 1.0111, 0.9970, 0.9974],\n",
      "        [1.0120, 1.0088, 0.9865,  ..., 1.0043, 1.0038, 0.9992],\n",
      "        [1.0065, 0.9929, 0.9841,  ..., 0.9833, 1.0105, 0.9926],\n",
      "        ...,\n",
      "        [0.9885, 0.9916, 0.9901,  ..., 0.9946, 0.9923, 1.0069],\n",
      "        [0.9899, 1.0102, 0.9875,  ..., 1.0137, 1.0016, 1.0026],\n",
      "        [0.9992, 0.9861, 1.0185,  ..., 0.9928, 1.0147, 0.9984]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.5.param_mus', tensor([ 1.0126e-04, -3.0732e-05,  1.5005e-04, -1.3251e-05,  3.1156e-05,\n",
      "        -3.1162e-04,  1.1707e-05, -3.8285e-05, -6.0643e-05, -5.2154e-05,\n",
      "         3.5783e-06,  3.0618e-05, -1.0358e-04,  9.0169e-05, -4.5457e-05,\n",
      "        -2.7410e-04, -4.4688e-05,  1.1500e-05,  3.1372e-06,  2.3341e-05,\n",
      "         3.8841e-05, -2.8488e-05, -2.3813e-04,  3.3488e-05,  4.6640e-05,\n",
      "         7.1639e-06, -1.3089e-04,  2.8863e-05, -2.1503e-05,  1.2085e-04,\n",
      "         3.9436e-05,  3.8132e-05, -9.7394e-05, -3.8975e-05,  1.0530e-04,\n",
      "         7.0130e-05, -1.3494e-04,  2.3243e-05,  7.5965e-05, -7.1859e-05,\n",
      "        -1.3304e-04,  6.2286e-05, -6.2110e-05,  3.4751e-05, -1.4015e-05,\n",
      "         1.3210e-04, -4.8236e-05,  6.6013e-05,  2.1965e-05, -1.3317e-05,\n",
      "         1.7659e-05,  2.4720e-04,  5.6599e-05,  6.9831e-05,  3.6818e-05,\n",
      "        -5.4295e-05,  8.1837e-05,  1.4124e-04,  3.1197e-05,  2.9947e-06,\n",
      "        -2.4051e-04,  4.4384e-05, -6.4361e-05,  2.5019e-05,  2.7385e-05,\n",
      "         5.4480e-05,  4.1333e-05,  8.3446e-05,  1.1698e-04, -1.3213e-04,\n",
      "        -4.2699e-05, -5.5693e-05, -1.3834e-04,  4.8278e-05,  8.8281e-06,\n",
      "         1.2911e-04,  2.3370e-05, -3.8703e-06, -1.7124e-04, -1.1162e-05,\n",
      "         1.2662e-04,  8.0303e-05, -7.3462e-05, -2.9224e-05,  8.2819e-05,\n",
      "         1.0725e-04,  5.1070e-05, -1.4058e-05,  6.0345e-05,  1.8120e-06,\n",
      "         1.8212e-04,  1.8808e-05, -7.8314e-05, -1.5819e-05,  1.6749e-05,\n",
      "        -1.0087e-04, -1.1775e-04,  6.0418e-05, -1.4325e-04, -1.0287e-04,\n",
      "         8.3538e-05,  1.6551e-05,  2.6679e-05,  2.2021e-05,  1.2118e-04,\n",
      "        -5.6805e-06, -5.1861e-05, -1.2939e-05,  4.7907e-05,  5.1091e-05,\n",
      "        -6.8882e-05, -5.8546e-05, -1.3051e-04, -5.1336e-05, -9.8631e-05,\n",
      "        -2.7002e-05, -2.3968e-05,  1.5682e-04, -1.5217e-05, -1.6092e-04,\n",
      "         2.0477e-05,  5.7489e-05,  2.8222e-04, -8.6123e-05, -1.8131e-05,\n",
      "         3.0935e-05, -6.6018e-05, -4.4375e-05], device='cuda:0')), ('module_list.0.posterior_params.5.param_std_log', tensor([-4.6252, -4.7416, -7.0787, -8.7415, -5.3575, -5.2833, -4.7366, -6.3542,\n",
      "        -4.8557, -6.1012, -4.3770, -4.7718, -6.0773, -4.8643, -4.7288, -4.6637,\n",
      "        -5.2612, -4.1396, -5.4804, -4.4581, -8.0171, -4.4094, -4.9519, -4.0911,\n",
      "        -4.3617, -4.8610, -6.3570, -4.8475, -6.5148, -4.8297, -4.6059, -4.1451,\n",
      "        -4.9506, -4.1181, -6.4814, -4.3216, -4.4425, -4.9607, -7.5173, -4.3134,\n",
      "        -4.6068, -4.1120, -6.2206, -4.2715, -4.4058, -4.1391, -5.5679, -4.5191,\n",
      "        -5.2667, -5.7917, -4.6578, -4.8200, -4.3735, -5.7690, -4.1738, -4.8715,\n",
      "        -4.2083, -4.5068, -5.6779, -4.5627, -5.6629, -5.0279, -5.1459, -8.4292,\n",
      "        -7.8994, -5.7681, -4.1163, -5.4181, -4.1041, -4.8459, -4.6583, -4.1869,\n",
      "        -5.6251, -4.1555, -5.8078, -5.2061, -4.8658, -5.0538, -4.1063, -4.5862,\n",
      "        -4.2972, -4.8337, -5.5609, -5.1165, -4.2063, -7.8278, -4.6987, -7.6644,\n",
      "        -5.8072, -4.6641, -4.5253, -4.7158, -5.0862, -4.9425, -5.1011, -5.3184,\n",
      "        -4.2736, -5.0045, -4.7809, -4.3939, -4.5215, -5.0803, -4.2563, -9.5756,\n",
      "        -8.0862, -9.1523, -5.1018, -4.2555, -6.9762, -4.1255, -4.9667, -7.7900,\n",
      "        -8.0893, -4.2488, -6.8200, -4.3719, -4.4819, -4.2120, -4.8147, -4.2613,\n",
      "        -4.3823, -8.1299, -4.1724, -7.5255, -5.7071, -6.9015, -4.5191, -4.8045],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.5.scale_alphas_log', tensor([-1.8258, -2.8037, -2.3154, -2.5535, -2.4260, -3.2006, -3.2061, -2.4725,\n",
      "        -1.6093, -2.5312, -2.1329, -2.2615, -2.7024, -2.4028, -1.4727, -2.7177,\n",
      "        -2.0055, -2.8505, -3.1376, -3.0867, -2.1756, -2.2197, -3.3985, -3.4323,\n",
      "        -2.9009, -2.1536, -1.4856, -1.9881, -2.9202, -1.5835, -2.1354, -1.7681,\n",
      "        -3.4036, -3.3131, -2.9370, -1.8758, -2.1885, -2.0978, -2.5003, -1.7644,\n",
      "        -2.8572, -2.7915, -2.7250, -2.1611, -3.0477, -3.2371, -1.5148, -1.5486,\n",
      "        -1.4769, -1.8454, -1.9769, -2.3484, -1.5881, -2.4532, -1.8776, -2.2279,\n",
      "        -3.3724, -2.6801, -1.5402, -3.2540, -3.4385, -2.3128, -3.0979, -1.4822,\n",
      "        -1.5370, -2.1676, -2.4254, -2.2733, -2.3382, -3.2384, -2.5028, -3.0731,\n",
      "        -3.0505, -2.9951, -3.3269, -3.3321, -2.2167, -3.4510, -2.1434, -2.6928,\n",
      "        -2.2668, -2.9750, -1.6458, -2.5225, -1.6759, -3.3780, -3.1134, -2.9890,\n",
      "        -3.1368, -2.7823, -3.3227, -2.8655, -3.2959, -1.9201, -2.1885, -3.0100,\n",
      "        -2.8227, -2.5815, -3.1384, -1.4715, -3.0460, -3.2832, -2.9988, -1.9474,\n",
      "        -2.1300, -3.1837, -3.3593, -2.3948, -2.3995, -2.4306, -1.8495, -2.8879,\n",
      "        -2.3656, -1.9714, -2.0148, -3.0182, -3.4135, -2.9672, -1.6794, -2.2252,\n",
      "        -2.8059, -1.8527, -2.3326, -1.8732, -1.8646, -2.6823, -3.2207, -3.0711],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.5.scale_mus', tensor([0.9966, 1.0018, 1.0171, 0.9840, 1.0243, 0.9820, 0.9978, 0.9839, 1.0247,\n",
      "        0.9964, 0.9772, 0.9805, 1.0006, 0.9892, 1.0089, 1.0108, 1.0089, 1.0086,\n",
      "        1.0179, 0.9772, 0.9955, 0.9582, 1.0199, 0.9919, 1.0065, 1.0193, 0.9998,\n",
      "        1.0132, 1.0151, 0.9879, 0.9956, 0.9870, 1.0043, 1.0602, 0.9978, 0.9688,\n",
      "        0.9977, 1.0089, 1.0004, 0.9920, 1.0249, 1.0322, 1.0159, 1.0333, 1.0048,\n",
      "        0.9916, 0.9883, 0.9725, 0.9902, 1.0037, 0.9904, 0.9821, 0.9497, 1.0127,\n",
      "        0.9723, 1.0165, 0.9992, 1.0515, 0.9752, 1.0041, 1.0005, 1.0017, 0.9927,\n",
      "        1.0174, 1.0081, 1.0002, 1.0008, 1.0202, 0.9728, 0.9805, 1.0041, 1.0524,\n",
      "        0.9945, 0.9791, 0.9945, 0.9886, 1.0314, 0.9905, 1.0140, 0.9556, 0.9997,\n",
      "        1.0148, 1.0035, 1.0124, 1.0203, 1.0040, 1.0240, 1.0112, 0.9894, 0.9845,\n",
      "        0.9847, 1.0253, 0.9798, 1.0110, 1.0090, 1.0178, 1.0147, 1.0022, 1.0200,\n",
      "        1.0122, 0.9956, 1.0105, 1.0046, 1.0102, 1.0152, 1.0189, 0.9958, 0.9959,\n",
      "        0.9817, 1.0151, 0.9883, 1.0125, 1.0058, 1.0168, 1.0149, 0.9910, 1.0131,\n",
      "        0.9894, 1.0053, 1.0352, 1.0159, 0.9858, 0.9567, 1.0043, 1.0134, 1.0092,\n",
      "        1.0003, 0.9996], device='cuda:0')), ('module_list.0.posterior_params.6.param_mus', tensor([[-4.4623e-05, -4.2848e-06, -1.3377e-06,  ..., -1.3500e-06,\n",
      "         -7.3083e-06, -3.6073e-05],\n",
      "        [ 4.5588e-05,  4.2054e-05,  5.4489e-06,  ...,  1.4135e-05,\n",
      "          1.3749e-04,  3.6736e-05],\n",
      "        [ 9.2180e-06,  8.7745e-06,  8.5275e-07,  ..., -9.4198e-07,\n",
      "          1.1030e-05,  4.4352e-06],\n",
      "        ...,\n",
      "        [ 8.0495e-06,  9.1625e-06,  4.5206e-06,  ...,  2.8083e-06,\n",
      "         -2.4002e-06, -1.1862e-06],\n",
      "        [-2.3887e-07, -1.3081e-05,  3.0694e-06,  ..., -2.4738e-05,\n",
      "         -1.0163e-06, -2.0965e-06],\n",
      "        [ 1.4343e-07,  1.0473e-05, -7.7101e-06,  ...,  1.5385e-06,\n",
      "         -2.5420e-05,  4.1828e-06]], device='cuda:0')), ('module_list.0.posterior_params.6.param_std_log', tensor([[-4.1813, -4.4268, -4.6795,  ..., -4.2055, -4.8927, -4.1284],\n",
      "        [-4.4651, -4.3323, -4.2909,  ..., -6.2008, -5.7658, -4.8787],\n",
      "        [-5.3534, -5.4736, -4.0873,  ..., -4.3633, -5.3206, -5.3694],\n",
      "        ...,\n",
      "        [-5.1401, -4.0772, -4.3220,  ..., -5.2889, -4.0800, -4.4325],\n",
      "        [-5.3501, -4.9262, -4.6256,  ..., -4.2371, -5.1621, -4.1631],\n",
      "        [-4.6956, -5.2086, -4.6908,  ..., -8.0793, -6.1039, -5.2715]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.6.scale_alphas_log', tensor([[-2.9681, -2.9959, -1.9126,  ..., -2.0726, -3.3883, -2.8816],\n",
      "        [-2.6644, -3.1065, -3.1406,  ..., -1.4957, -1.7779, -2.0162],\n",
      "        [-2.4882, -2.7269, -3.2243,  ..., -2.2977, -2.0736, -1.8672],\n",
      "        ...,\n",
      "        [-2.1892, -2.0337, -2.5144,  ..., -2.5039, -2.4651, -1.9543],\n",
      "        [-1.6062, -3.1331, -3.2969,  ..., -2.7061, -3.1160, -2.2386],\n",
      "        [-2.2411, -1.9841, -1.9708,  ..., -2.2110, -2.2385, -2.7110]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.6.scale_mus', tensor([[1.0064, 0.9998, 0.9989,  ..., 0.9959, 0.9961, 0.9966],\n",
      "        [0.9844, 0.9935, 0.9934,  ..., 1.0124, 1.0021, 1.0163],\n",
      "        [1.0114, 1.0115, 0.9850,  ..., 0.9863, 0.9913, 1.0208],\n",
      "        ...,\n",
      "        [0.9898, 1.0150, 0.9852,  ..., 0.9891, 1.0003, 1.0191],\n",
      "        [0.9919, 1.0006, 1.0130,  ..., 0.9978, 1.0142, 0.9978],\n",
      "        [1.0035, 1.0058, 1.0115,  ..., 1.0091, 1.0037, 1.0011]],\n",
      "       device='cuda:0')), ('module_list.0.posterior_params.7.param_mus', tensor([-0.0019,  0.0134,  0.0008, -0.0007, -0.0009, -0.0078, -0.0081,  0.0014,\n",
      "        -0.0005,  0.0020], device='cuda:0')), ('module_list.0.posterior_params.7.param_std_log', tensor([-5.3637, -4.3256, -5.3654, -5.4082, -4.2301, -4.4158, -5.8792, -4.1335,\n",
      "        -4.1724, -4.6708], device='cuda:0')), ('module_list.0.posterior_params.7.scale_alphas_log', tensor([-1.8752, -2.6005, -3.3077, -3.1848, -3.1316, -2.2628, -2.7549, -1.4825,\n",
      "        -2.6679, -3.3542], device='cuda:0')), ('module_list.0.posterior_params.7.scale_mus', tensor([1.0652, 1.1322, 1.0039, 0.9870, 0.9223, 1.1191, 1.2574, 0.8067, 0.8125,\n",
      "        0.9759], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_module.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_bayes.pt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(409356., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.prune({'threshold': 1.9})\n",
    "print(model.prune_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47343., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.prune([{'threshold': -2.2}])\n",
    "print(model.prune_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = Classifier()\n",
    "var_module = LogUniformVarBayesModule(module)\n",
    "model = VarBayesModuleNet(module, nn.ModuleList([var_module]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('module_list.0.posterior_params.0.param_mus',\n",
       "              tensor([[[[-0.2737, -0.0213, -0.1784],\n",
       "                        [-0.0449,  0.1339,  0.2884],\n",
       "                        [ 0.1757,  0.2454,  0.0318]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2829,  0.1125,  0.2672],\n",
       "                        [-0.0329,  0.1954,  0.2326],\n",
       "                        [-0.0857, -0.2534,  0.0893]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1525,  0.0669, -0.2533],\n",
       "                        [-0.1758,  0.1672,  0.1206],\n",
       "                        [ 0.0153,  0.1936, -0.3305]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0107,  0.3182,  0.2102],\n",
       "                        [-0.1029,  0.3132, -0.2125],\n",
       "                        [-0.2650,  0.0061,  0.2422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1922,  0.1445, -0.1445],\n",
       "                        [-0.1862, -0.1703,  0.1814],\n",
       "                        [-0.3061, -0.1629,  0.1818]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2469, -0.2962, -0.1922],\n",
       "                        [-0.1502, -0.0190, -0.1009],\n",
       "                        [ 0.1418,  0.0435, -0.2017]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2999,  0.2396,  0.0861],\n",
       "                        [-0.1399,  0.0275, -0.3024],\n",
       "                        [-0.1098, -0.1394, -0.2101]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0273,  0.2970, -0.2747],\n",
       "                        [ 0.1127,  0.2224,  0.0496],\n",
       "                        [-0.2127,  0.1349, -0.2917]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0222,  0.2411,  0.0425],\n",
       "                        [ 0.0817,  0.1037,  0.2716],\n",
       "                        [ 0.0878, -0.2382, -0.0517]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0719,  0.1895,  0.1076],\n",
       "                        [-0.1426, -0.1827,  0.3090],\n",
       "                        [-0.1734,  0.0608, -0.1394]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2088,  0.1865,  0.1586],\n",
       "                        [-0.1817, -0.1410, -0.1049],\n",
       "                        [-0.1832, -0.3061, -0.3109]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2269,  0.1814, -0.3188],\n",
       "                        [ 0.2725, -0.0902, -0.2374],\n",
       "                        [-0.1628, -0.2985, -0.0739]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2382, -0.0886,  0.2284],\n",
       "                        [ 0.0932, -0.0300,  0.1199],\n",
       "                        [-0.3036,  0.0679,  0.3242]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2995, -0.0269,  0.2335],\n",
       "                        [-0.2868,  0.1297,  0.2263],\n",
       "                        [-0.1365,  0.0827, -0.1368]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2408, -0.1476,  0.1649],\n",
       "                        [ 0.1636, -0.0114, -0.1543],\n",
       "                        [ 0.1516,  0.2401, -0.3093]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0533,  0.1382,  0.0024],\n",
       "                        [-0.1546,  0.2536, -0.2555],\n",
       "                        [-0.1677, -0.0555,  0.0449]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2179,  0.0416,  0.1664],\n",
       "                        [ 0.1895,  0.1240, -0.2714],\n",
       "                        [-0.0561, -0.2904,  0.1815]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0931, -0.2447, -0.1122],\n",
       "                        [ 0.2836, -0.3144,  0.2693],\n",
       "                        [ 0.0475,  0.0702,  0.2088]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2935, -0.0657,  0.2059],\n",
       "                        [-0.2644,  0.2140,  0.0178],\n",
       "                        [-0.0679, -0.2655, -0.0174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1912, -0.0838, -0.1078],\n",
       "                        [ 0.2290,  0.2124, -0.2783],\n",
       "                        [-0.0186,  0.2010, -0.1156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2628, -0.2447,  0.0938],\n",
       "                        [-0.1858, -0.2919, -0.2134],\n",
       "                        [ 0.2410, -0.0449,  0.1174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3145, -0.2647,  0.2348],\n",
       "                        [ 0.1423, -0.1619, -0.1704],\n",
       "                        [ 0.3221, -0.1983, -0.0801]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0133, -0.3084,  0.1228],\n",
       "                        [ 0.1514,  0.0796, -0.1055],\n",
       "                        [ 0.2269,  0.1001, -0.2295]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1243,  0.1812,  0.0307],\n",
       "                        [ 0.2902,  0.2480, -0.0722],\n",
       "                        [-0.1125,  0.2348,  0.0912]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2855,  0.0356,  0.2712],\n",
       "                        [ 0.3197, -0.0580,  0.0020],\n",
       "                        [-0.2933, -0.1005,  0.2072]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1050, -0.2946,  0.0811],\n",
       "                        [-0.0863,  0.2160, -0.2627],\n",
       "                        [-0.1286,  0.0596, -0.1345]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0546, -0.0362,  0.0594],\n",
       "                        [ 0.0646,  0.1745, -0.0352],\n",
       "                        [-0.1120, -0.0474,  0.0383]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1332, -0.2500, -0.1542],\n",
       "                        [-0.2412, -0.3166, -0.0210],\n",
       "                        [ 0.1060,  0.1158,  0.0057]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2678, -0.2166,  0.0712],\n",
       "                        [-0.0535,  0.1413,  0.2406],\n",
       "                        [-0.2855, -0.3059, -0.2075]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2055, -0.2482,  0.1404],\n",
       "                        [-0.2513, -0.1904,  0.1103],\n",
       "                        [-0.2845,  0.0184,  0.2082]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0582,  0.2715,  0.1728],\n",
       "                        [-0.1080,  0.1155,  0.1371],\n",
       "                        [ 0.2162, -0.0247, -0.2244]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1486,  0.0659,  0.1559],\n",
       "                        [-0.2081,  0.0449,  0.3216],\n",
       "                        [ 0.2564,  0.2344, -0.0866]]]])),\n",
       "             ('module_list.0.posterior_params.0.param_std_log',\n",
       "              tensor([[[[-7.6443, -6.8122, -6.2178],\n",
       "                        [-4.6537, -8.1042, -5.0853],\n",
       "                        [-6.9559, -4.9253, -4.6574]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.9750, -6.1978, -5.7079],\n",
       "                        [-5.8540, -7.7156, -6.2078],\n",
       "                        [-4.9556, -5.0383, -6.1048]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7616, -5.4980, -4.7636],\n",
       "                        [-4.9685, -8.0552, -6.3784],\n",
       "                        [-4.9320, -6.9730, -6.1062]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8593, -5.2212, -4.8359],\n",
       "                        [-4.9786, -7.6505, -5.0176],\n",
       "                        [-5.6760, -5.2133, -5.7229]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.5549, -5.6953, -7.5045],\n",
       "                        [-4.8243, -5.2325, -8.2682],\n",
       "                        [-4.7497, -5.2409, -6.0584]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.2319, -5.1681, -5.0143],\n",
       "                        [-4.6465, -4.7084, -6.2273],\n",
       "                        [-4.7883, -5.2719, -4.9517]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0582, -5.2466, -5.4416],\n",
       "                        [-5.1359, -5.2855, -5.4410],\n",
       "                        [-5.7903, -4.6311, -5.1965]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9802, -4.6867, -5.9103],\n",
       "                        [-4.9393, -7.2178, -5.2489],\n",
       "                        [-4.6243, -5.9567, -5.4351]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6969, -5.5580, -5.1405],\n",
       "                        [-4.7906, -5.6145, -7.0589],\n",
       "                        [-5.0275, -4.7744, -5.2552]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.2480, -6.9430, -4.8825],\n",
       "                        [-5.6597, -6.6762, -4.9689],\n",
       "                        [-5.1752, -4.9931, -5.0197]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6701, -4.8942, -5.5445],\n",
       "                        [-5.9894, -5.5842, -4.8125],\n",
       "                        [-5.2390, -4.8248, -6.3544]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0899, -6.3075, -5.0728],\n",
       "                        [-4.7244, -4.7276, -5.5322],\n",
       "                        [-6.5785, -5.2176, -8.2081]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.8461, -6.0238, -5.0947],\n",
       "                        [-4.7004, -4.7245, -4.9359],\n",
       "                        [-5.4876, -4.8804, -5.2382]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7568, -4.7962, -4.8076],\n",
       "                        [-4.8334, -4.6812, -4.8790],\n",
       "                        [-5.2112, -4.6500, -5.2285]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1571, -5.5234, -5.3730],\n",
       "                        [-6.3554, -4.7353, -5.0411],\n",
       "                        [-4.7423, -5.0554, -5.8877]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.4057, -5.4768, -5.8319],\n",
       "                        [-4.8379, -4.8591, -7.9367],\n",
       "                        [-6.0085, -4.6697, -5.8908]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7667, -5.2830, -4.8108],\n",
       "                        [-4.7277, -5.0035, -4.8743],\n",
       "                        [-4.7109, -7.0394, -4.8987]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5578, -5.4441, -4.7811],\n",
       "                        [-4.6132, -5.0880, -4.7208],\n",
       "                        [-5.2930, -4.7753, -5.3517]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0392, -6.9003, -6.4838],\n",
       "                        [-6.2912, -4.9652, -6.3513],\n",
       "                        [-5.4759, -4.9867, -5.3265]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.6965, -5.1672, -4.6054],\n",
       "                        [-5.8090, -4.9806, -5.4375],\n",
       "                        [-5.2273, -5.3135, -5.2484]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8862, -4.9312, -5.9119],\n",
       "                        [-5.3062, -5.0569, -4.6850],\n",
       "                        [-5.4883, -6.1027, -5.0738]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.3343, -6.1922, -6.2508],\n",
       "                        [-5.0133, -4.8441, -6.0976],\n",
       "                        [-7.5900, -5.7515, -4.6156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5193, -6.1760, -5.7592],\n",
       "                        [-5.5590, -4.8624, -5.6229],\n",
       "                        [-4.9285, -4.8645, -5.8739]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6902, -5.6837, -4.9300],\n",
       "                        [-5.4640, -6.1872, -5.1738],\n",
       "                        [-4.6249, -4.7705, -4.9058]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1386, -4.6787, -4.8687],\n",
       "                        [-4.7995, -6.2731, -5.5295],\n",
       "                        [-7.9139, -5.6268, -4.8398]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4830, -5.1139, -5.3729],\n",
       "                        [-4.6113, -5.2906, -5.0130],\n",
       "                        [-5.5503, -4.9968, -4.6078]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.3845, -6.3526, -5.5192],\n",
       "                        [-6.8718, -5.3505, -5.9623],\n",
       "                        [-5.2600, -5.0851, -5.2559]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.5084, -6.8383, -6.7434],\n",
       "                        [-5.1087, -5.0522, -5.0362],\n",
       "                        [-4.8434, -4.6105, -5.9471]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0541, -6.8497, -5.4263],\n",
       "                        [-5.1009, -4.6458, -5.4793],\n",
       "                        [-5.4213, -4.9003, -4.8682]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4279, -8.2878, -5.5914],\n",
       "                        [-5.8017, -5.5931, -4.8151],\n",
       "                        [-4.7875, -5.1253, -4.8293]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6792, -5.2176, -6.3633],\n",
       "                        [-6.5483, -4.7496, -5.1030],\n",
       "                        [-4.7008, -4.6548, -4.8405]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9131, -5.5380, -5.7411],\n",
       "                        [-8.2987, -4.6276, -5.5294],\n",
       "                        [-5.5955, -4.9558, -8.0978]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_alphas_log',\n",
       "              tensor([[[[-3.9730, -3.8184, -2.7370],\n",
       "                        [-2.8423, -3.3155, -3.7674],\n",
       "                        [-2.8688, -3.4832, -3.3337]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4496, -3.1676, -2.3279],\n",
       "                        [-2.5704, -2.6994, -2.5631],\n",
       "                        [-2.3078, -3.7059, -3.1989]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3379, -3.3761, -2.0345],\n",
       "                        [-3.8821, -2.3943, -3.7338],\n",
       "                        [-3.1945, -2.8338, -3.7807]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3331, -3.7250, -3.6263],\n",
       "                        [-3.3903, -2.8828, -3.6775],\n",
       "                        [-3.0060, -2.4066, -2.8119]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3633, -2.0377, -2.0332],\n",
       "                        [-3.5051, -3.9339, -3.9972],\n",
       "                        [-2.8213, -2.7204, -2.4167]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4371, -3.7661, -2.8416],\n",
       "                        [-2.1897, -2.4125, -2.5461],\n",
       "                        [-3.4732, -3.3259, -2.3366]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2825, -3.0099, -2.5968],\n",
       "                        [-3.0321, -3.8588, -3.2249],\n",
       "                        [-3.7188, -3.9843, -3.5802]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8530, -3.9986, -3.0276],\n",
       "                        [-2.0767, -3.6595, -2.9175],\n",
       "                        [-3.2203, -2.1420, -3.6336]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5784, -2.8119, -2.3119],\n",
       "                        [-3.2846, -3.0844, -2.5892],\n",
       "                        [-3.3545, -2.3341, -3.3552]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5695, -2.5832, -2.3026],\n",
       "                        [-3.3705, -3.8097, -3.8492],\n",
       "                        [-2.4600, -2.2967, -3.7054]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3626, -3.4220, -3.9690],\n",
       "                        [-2.0460, -2.1348, -3.8663],\n",
       "                        [-2.3202, -3.0671, -2.3580]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1191, -3.4663, -3.9155],\n",
       "                        [-2.9626, -2.6909, -2.0241],\n",
       "                        [-3.6772, -2.0887, -2.8112]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5335, -2.2046, -3.8070],\n",
       "                        [-2.0733, -3.4714, -3.3680],\n",
       "                        [-2.0920, -3.3321, -3.0712]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9456, -3.9397, -2.3680],\n",
       "                        [-2.0659, -3.5653, -2.3071],\n",
       "                        [-3.2517, -3.4542, -2.0715]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2097, -3.9403, -2.1460],\n",
       "                        [-3.0559, -3.4030, -2.5687],\n",
       "                        [-3.4692, -2.5501, -3.5228]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8775, -3.4609, -3.5841],\n",
       "                        [-3.2468, -3.9733, -3.9215],\n",
       "                        [-3.4708, -3.8749, -3.1619]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4536, -3.0306, -3.1692],\n",
       "                        [-2.9309, -2.0621, -2.1662],\n",
       "                        [-2.1606, -2.5014, -2.8317]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8540, -3.1003, -2.3888],\n",
       "                        [-2.9370, -2.7015, -3.5162],\n",
       "                        [-2.7293, -2.3345, -3.2506]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4800, -3.4780, -2.7654],\n",
       "                        [-2.0434, -2.3557, -2.0213],\n",
       "                        [-2.2703, -2.0352, -3.7971]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9834, -3.0913, -2.8502],\n",
       "                        [-2.8904, -2.8264, -3.4881],\n",
       "                        [-3.3516, -3.2357, -2.9829]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1380, -3.2730, -3.5269],\n",
       "                        [-2.6177, -3.5875, -3.6728],\n",
       "                        [-2.7636, -3.6273, -3.2167]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4872, -3.5043, -2.3076],\n",
       "                        [-2.8557, -3.3450, -2.6795],\n",
       "                        [-2.7737, -2.7499, -3.3472]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2195, -2.7689, -2.0130],\n",
       "                        [-3.5297, -3.6577, -2.2098],\n",
       "                        [-2.0077, -3.4508, -3.4853]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1046, -3.8315, -3.3988],\n",
       "                        [-2.0476, -3.0053, -3.8965],\n",
       "                        [-2.1855, -2.1632, -2.1847]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9850, -2.6428, -2.9310],\n",
       "                        [-2.1326, -3.2657, -2.4740],\n",
       "                        [-3.1584, -2.4350, -3.3533]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9450, -2.5128, -3.1556],\n",
       "                        [-3.2801, -3.5410, -2.8983],\n",
       "                        [-2.5519, -3.2341, -2.8721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8494, -3.8954, -3.0426],\n",
       "                        [-3.2585, -3.2226, -3.6094],\n",
       "                        [-3.2983, -3.4633, -3.9118]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4175, -2.1018, -2.3832],\n",
       "                        [-2.6769, -2.5597, -3.1847],\n",
       "                        [-3.8278, -2.5293, -3.5093]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6108, -3.0801, -2.6812],\n",
       "                        [-2.7818, -3.4267, -3.2687],\n",
       "                        [-2.1624, -2.1442, -2.5664]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5382, -2.5531, -3.3821],\n",
       "                        [-2.7202, -3.1200, -3.5994],\n",
       "                        [-3.7090, -3.5544, -3.7490]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9206, -2.9339, -2.6854],\n",
       "                        [-2.8685, -3.9728, -2.4037],\n",
       "                        [-3.7632, -2.0636, -2.3169]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5363, -2.2065, -3.9187],\n",
       "                        [-2.5296, -2.8139, -2.1778],\n",
       "                        [-3.0076, -2.6238, -3.4175]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.1.param_mus',\n",
       "              tensor([-0.0917,  0.2394,  0.0686, -0.2604, -0.0798,  0.2396, -0.0338,  0.2310,\n",
       "                       0.0511, -0.0118,  0.1305,  0.2870,  0.1377,  0.0071, -0.0213, -0.0859,\n",
       "                       0.1393, -0.0984, -0.1080,  0.1917,  0.1436, -0.2344,  0.0637, -0.2897,\n",
       "                      -0.2618, -0.2384, -0.1295,  0.1794, -0.0685, -0.0023, -0.2036, -0.0473])),\n",
       "             ('module_list.0.posterior_params.1.param_std_log',\n",
       "              tensor([-5.6001, -5.0561, -7.3938, -4.6664, -5.3911, -4.6895, -5.8183, -4.6080,\n",
       "                      -4.9778, -5.0134, -5.1747, -6.2682, -5.6235, -4.6147, -4.6179, -5.5958,\n",
       "                      -7.3049, -5.8125, -5.3669, -6.1171, -5.4824, -4.6084, -4.8485, -5.1090,\n",
       "                      -4.6260, -4.8618, -4.6064, -5.7304, -4.9281, -6.2759, -6.1592, -4.6723])),\n",
       "             ('module_list.0.posterior_params.1.scale_alphas_log',\n",
       "              tensor([-3.8439, -3.2271, -3.3951, -2.1596, -3.5587, -3.3096, -3.8678, -3.2271,\n",
       "                      -3.7286, -2.2776, -3.4039, -2.1131, -3.8562, -2.1256, -2.6956, -2.0418,\n",
       "                      -3.5359, -3.6205, -3.8657, -2.2383, -2.6532, -2.0978, -2.3008, -3.0798,\n",
       "                      -3.8545, -2.1004, -2.2579, -3.7659, -2.8519, -2.2167, -2.4384, -3.4444])),\n",
       "             ('module_list.0.posterior_params.1.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.2.param_mus',\n",
       "              tensor([[[[-0.0196,  0.0454,  0.0391],\n",
       "                        [ 0.0089,  0.0444,  0.0319],\n",
       "                        [ 0.0151, -0.0048, -0.0067]],\n",
       "              \n",
       "                       [[ 0.0389,  0.0052, -0.0038],\n",
       "                        [ 0.0210, -0.0377,  0.0379],\n",
       "                        [-0.0082, -0.0270,  0.0123]],\n",
       "              \n",
       "                       [[-0.0195, -0.0450, -0.0348],\n",
       "                        [-0.0266,  0.0158,  0.0558],\n",
       "                        [ 0.0572, -0.0150, -0.0562]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0117, -0.0527,  0.0530],\n",
       "                        [-0.0441, -0.0011,  0.0099],\n",
       "                        [ 0.0460, -0.0206,  0.0311]],\n",
       "              \n",
       "                       [[ 0.0086, -0.0104,  0.0082],\n",
       "                        [-0.0060,  0.0010,  0.0508],\n",
       "                        [ 0.0234, -0.0204, -0.0198]],\n",
       "              \n",
       "                       [[ 0.0014,  0.0375, -0.0589],\n",
       "                        [-0.0500, -0.0523, -0.0287],\n",
       "                        [-0.0491,  0.0049,  0.0422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0086, -0.0462,  0.0437],\n",
       "                        [-0.0584, -0.0168, -0.0261],\n",
       "                        [-0.0548, -0.0186, -0.0516]],\n",
       "              \n",
       "                       [[ 0.0359, -0.0341,  0.0119],\n",
       "                        [-0.0516, -0.0310, -0.0073],\n",
       "                        [-0.0050,  0.0106,  0.0388]],\n",
       "              \n",
       "                       [[ 0.0335,  0.0242, -0.0266],\n",
       "                        [-0.0136,  0.0261,  0.0277],\n",
       "                        [-0.0235, -0.0340, -0.0570]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0397, -0.0346,  0.0134],\n",
       "                        [-0.0087,  0.0414,  0.0012],\n",
       "                        [-0.0219,  0.0087,  0.0025]],\n",
       "              \n",
       "                       [[-0.0426,  0.0360, -0.0347],\n",
       "                        [-0.0527, -0.0319,  0.0490],\n",
       "                        [ 0.0425,  0.0571,  0.0575]],\n",
       "              \n",
       "                       [[ 0.0446,  0.0385,  0.0485],\n",
       "                        [ 0.0124,  0.0016, -0.0074],\n",
       "                        [ 0.0091, -0.0570, -0.0402]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0326, -0.0093, -0.0427],\n",
       "                        [-0.0027, -0.0183,  0.0407],\n",
       "                        [ 0.0067,  0.0192, -0.0295]],\n",
       "              \n",
       "                       [[ 0.0398, -0.0258, -0.0529],\n",
       "                        [ 0.0533, -0.0561,  0.0226],\n",
       "                        [-0.0508, -0.0089, -0.0217]],\n",
       "              \n",
       "                       [[-0.0574,  0.0053,  0.0086],\n",
       "                        [ 0.0176, -0.0122,  0.0389],\n",
       "                        [ 0.0315, -0.0262,  0.0497]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0496,  0.0429, -0.0389],\n",
       "                        [ 0.0564,  0.0134, -0.0487],\n",
       "                        [ 0.0151, -0.0558, -0.0526]],\n",
       "              \n",
       "                       [[ 0.0041,  0.0085,  0.0242],\n",
       "                        [-0.0357,  0.0532, -0.0053],\n",
       "                        [ 0.0320,  0.0389, -0.0084]],\n",
       "              \n",
       "                       [[-0.0232, -0.0328, -0.0265],\n",
       "                        [ 0.0073,  0.0322,  0.0154],\n",
       "                        [ 0.0334, -0.0364, -0.0399]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0362, -0.0152, -0.0356],\n",
       "                        [-0.0227,  0.0356,  0.0551],\n",
       "                        [ 0.0449,  0.0479,  0.0460]],\n",
       "              \n",
       "                       [[ 0.0109, -0.0216,  0.0328],\n",
       "                        [ 0.0278,  0.0500, -0.0082],\n",
       "                        [ 0.0543, -0.0203,  0.0153]],\n",
       "              \n",
       "                       [[ 0.0102,  0.0585, -0.0482],\n",
       "                        [ 0.0470,  0.0210,  0.0068],\n",
       "                        [ 0.0122,  0.0472, -0.0473]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0350,  0.0331,  0.0211],\n",
       "                        [ 0.0469,  0.0194, -0.0124],\n",
       "                        [ 0.0085,  0.0097,  0.0335]],\n",
       "              \n",
       "                       [[-0.0213, -0.0421,  0.0169],\n",
       "                        [ 0.0271,  0.0084, -0.0281],\n",
       "                        [-0.0009,  0.0395,  0.0552]],\n",
       "              \n",
       "                       [[-0.0405,  0.0506,  0.0431],\n",
       "                        [ 0.0378,  0.0429,  0.0452],\n",
       "                        [ 0.0226,  0.0213, -0.0085]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0589, -0.0413,  0.0375],\n",
       "                        [-0.0113,  0.0128, -0.0504],\n",
       "                        [ 0.0348,  0.0297, -0.0023]],\n",
       "              \n",
       "                       [[ 0.0142, -0.0146,  0.0395],\n",
       "                        [-0.0279,  0.0025, -0.0369],\n",
       "                        [-0.0193,  0.0065,  0.0184]],\n",
       "              \n",
       "                       [[ 0.0535, -0.0271,  0.0205],\n",
       "                        [ 0.0521,  0.0121,  0.0178],\n",
       "                        [-0.0015, -0.0246,  0.0102]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0374,  0.0082,  0.0361],\n",
       "                        [-0.0384, -0.0128,  0.0242],\n",
       "                        [ 0.0210,  0.0459, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0085,  0.0549, -0.0122],\n",
       "                        [ 0.0470, -0.0425,  0.0118],\n",
       "                        [-0.0259, -0.0331,  0.0163]],\n",
       "              \n",
       "                       [[-0.0175,  0.0018,  0.0136],\n",
       "                        [ 0.0412, -0.0085, -0.0292],\n",
       "                        [ 0.0508, -0.0501,  0.0192]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0055, -0.0442, -0.0088],\n",
       "                        [-0.0253, -0.0387, -0.0068],\n",
       "                        [-0.0327,  0.0401,  0.0176]],\n",
       "              \n",
       "                       [[-0.0053, -0.0276,  0.0089],\n",
       "                        [ 0.0546,  0.0484, -0.0486],\n",
       "                        [ 0.0030,  0.0041, -0.0256]],\n",
       "              \n",
       "                       [[ 0.0418,  0.0024, -0.0539],\n",
       "                        [ 0.0261, -0.0357, -0.0540],\n",
       "                        [ 0.0082, -0.0161,  0.0249]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0420, -0.0219, -0.0447],\n",
       "                        [-0.0553, -0.0467, -0.0041],\n",
       "                        [-0.0133, -0.0239,  0.0284]],\n",
       "              \n",
       "                       [[-0.0090,  0.0331,  0.0218],\n",
       "                        [-0.0550, -0.0575, -0.0531],\n",
       "                        [ 0.0528, -0.0313,  0.0230]],\n",
       "              \n",
       "                       [[-0.0138,  0.0412, -0.0435],\n",
       "                        [ 0.0420, -0.0355,  0.0162],\n",
       "                        [ 0.0510,  0.0107,  0.0575]]]])),\n",
       "             ('module_list.0.posterior_params.2.param_std_log',\n",
       "              tensor([[[[ -4.8953,  -5.0285,  -6.2216],\n",
       "                        [ -4.9035,  -8.6040,  -6.4262],\n",
       "                        [ -5.3935,  -6.4831,  -5.3591]],\n",
       "              \n",
       "                       [[ -5.5549,  -5.1110,  -4.7856],\n",
       "                        [ -5.0981,  -4.8755,  -5.7412],\n",
       "                        [ -5.6913,  -5.1175,  -5.4186]],\n",
       "              \n",
       "                       [[ -7.5934,  -4.9929,  -4.8682],\n",
       "                        [ -6.5329,  -6.7392,  -5.7023],\n",
       "                        [ -4.6655,  -6.5716,  -5.0604]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.6578,  -4.9114,  -5.8949],\n",
       "                        [ -5.4794,  -5.1367,  -5.2141],\n",
       "                        [ -7.1503,  -5.0723,  -6.8911]],\n",
       "              \n",
       "                       [[ -7.7260,  -4.7098,  -4.7194],\n",
       "                        [ -4.8400,  -5.9135,  -5.9438],\n",
       "                        [ -4.6816,  -5.5583,  -4.6564]],\n",
       "              \n",
       "                       [[ -5.4169,  -4.8717,  -4.7754],\n",
       "                        [ -5.1123,  -4.8388,  -5.6561],\n",
       "                        [ -5.6101,  -5.9402,  -5.5524]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3646,  -6.1044,  -4.8309],\n",
       "                        [ -4.9290,  -6.4702,  -4.7857],\n",
       "                        [ -4.7454,  -6.7668,  -4.7657]],\n",
       "              \n",
       "                       [[ -5.3774,  -6.1290,  -5.3385],\n",
       "                        [ -8.1817,  -5.3416,  -4.6654],\n",
       "                        [ -6.9278,  -5.2007,  -5.8790]],\n",
       "              \n",
       "                       [[ -6.2015,  -4.7918,  -7.0114],\n",
       "                        [ -6.6029,  -4.9880,  -5.1994],\n",
       "                        [ -4.7158,  -4.6187,  -4.7050]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -7.0537,  -5.3076,  -5.5863],\n",
       "                        [ -5.8178,  -5.1174,  -5.0456],\n",
       "                        [ -5.3676,  -5.2478,  -5.6625]],\n",
       "              \n",
       "                       [[ -5.3646,  -6.0331,  -4.8292],\n",
       "                        [ -5.1204,  -5.0109,  -5.4891],\n",
       "                        [ -6.4985,  -4.7923,  -4.8494]],\n",
       "              \n",
       "                       [[ -5.2417,  -5.3264,  -4.9075],\n",
       "                        [ -4.6669,  -5.7886,  -5.0299],\n",
       "                        [ -4.8249,  -4.7134,  -5.8615]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.3013,  -5.6837,  -6.1340],\n",
       "                        [ -4.8347,  -6.8893,  -6.6270],\n",
       "                        [ -5.4885,  -6.7957,  -4.8725]],\n",
       "              \n",
       "                       [[ -4.7680,  -7.2965,  -6.8039],\n",
       "                        [ -7.3785,  -4.9002,  -5.0066],\n",
       "                        [ -4.6913,  -5.5690,  -4.6084]],\n",
       "              \n",
       "                       [[ -4.8951,  -7.2483,  -4.8205],\n",
       "                        [ -5.4375,  -5.4348,  -5.8624],\n",
       "                        [ -5.6269,  -4.8600,  -8.1621]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.9090,  -5.1043,  -6.6300],\n",
       "                        [ -4.9572,  -5.2812,  -4.9467],\n",
       "                        [ -6.9966,  -5.9345,  -5.1252]],\n",
       "              \n",
       "                       [[ -4.6989,  -4.8439,  -5.2943],\n",
       "                        [ -5.1051,  -5.7968,  -5.8932],\n",
       "                        [-10.1077,  -4.7491,  -8.4951]],\n",
       "              \n",
       "                       [[ -5.6271,  -5.8009,  -5.6112],\n",
       "                        [ -5.6509,  -4.7704,  -6.9457],\n",
       "                        [ -6.5300,  -5.8772,  -6.3974]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ -6.2656,  -6.2033,  -4.9923],\n",
       "                        [ -4.8826,  -8.2525,  -5.1309],\n",
       "                        [ -4.8151,  -5.6355,  -5.0209]],\n",
       "              \n",
       "                       [[ -6.3848,  -6.0805,  -7.8335],\n",
       "                        [ -4.8021,  -5.2011,  -4.9359],\n",
       "                        [ -5.2328,  -6.5811,  -4.6836]],\n",
       "              \n",
       "                       [[ -4.6560,  -4.6885, -11.7446],\n",
       "                        [ -6.5880,  -4.7699,  -5.2749],\n",
       "                        [ -5.6483,  -4.7934,  -6.8433]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.2342,  -5.2849,  -6.0316],\n",
       "                        [ -5.3714,  -4.7595,  -5.4207],\n",
       "                        [ -6.7571,  -9.9357,  -7.0918]],\n",
       "              \n",
       "                       [[ -7.8484,  -7.9049,  -4.8852],\n",
       "                        [ -8.5928,  -6.9321,  -4.7064],\n",
       "                        [ -4.6875,  -4.8348,  -5.5023]],\n",
       "              \n",
       "                       [[ -4.7033,  -4.6839,  -5.3626],\n",
       "                        [ -5.8149,  -4.6163,  -4.7024],\n",
       "                        [ -5.2816,  -5.4297,  -4.8385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7027,  -4.6516,  -5.3516],\n",
       "                        [ -5.2600,  -4.8881,  -5.0138],\n",
       "                        [ -5.9239,  -5.4689,  -4.6260]],\n",
       "              \n",
       "                       [[ -4.9607,  -5.8558,  -5.9619],\n",
       "                        [ -5.1053,  -7.0853,  -5.5569],\n",
       "                        [ -4.6085,  -6.3642,  -4.8830]],\n",
       "              \n",
       "                       [[ -5.5688,  -4.9501,  -6.1348],\n",
       "                        [ -6.3153,  -5.5237,  -4.7659],\n",
       "                        [ -4.6286,  -5.5474,  -6.4980]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.5645,  -4.6941,  -5.2743],\n",
       "                        [ -5.4054,  -4.9133,  -6.4651],\n",
       "                        [ -7.0040,  -4.9656,  -7.0266]],\n",
       "              \n",
       "                       [[ -5.2028,  -5.1697,  -4.7442],\n",
       "                        [ -4.8667,  -5.2562,  -6.2058],\n",
       "                        [ -7.5951,  -4.6418,  -4.9033]],\n",
       "              \n",
       "                       [[ -4.6518,  -5.0600,  -5.0147],\n",
       "                        [ -6.5606,  -5.0663,  -5.1944],\n",
       "                        [ -7.4739,  -4.6704,  -4.6449]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.6330,  -6.6073,  -5.0135],\n",
       "                        [ -4.9958,  -4.8325,  -4.6252],\n",
       "                        [ -4.9012,  -6.2909,  -6.0797]],\n",
       "              \n",
       "                       [[ -4.8079,  -7.8986,  -5.3821],\n",
       "                        [ -5.9537,  -7.2645,  -5.7079],\n",
       "                        [ -4.7860,  -5.0177,  -5.3445]],\n",
       "              \n",
       "                       [[ -4.9210,  -5.5095,  -4.9153],\n",
       "                        [ -9.2945,  -5.2109,  -5.0991],\n",
       "                        [ -4.6786,  -4.8999,  -4.7837]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.0940,  -6.4246,  -6.0016],\n",
       "                        [ -5.9106,  -4.6236,  -9.3768],\n",
       "                        [ -4.8565,  -4.6549,  -4.8105]],\n",
       "              \n",
       "                       [[ -5.0449,  -5.1650,  -4.6892],\n",
       "                        [ -5.7240,  -5.5601,  -4.7530],\n",
       "                        [ -4.6144,  -5.6058,  -7.4718]],\n",
       "              \n",
       "                       [[ -6.1598,  -4.6782,  -5.3052],\n",
       "                        [ -5.1732,  -5.6023,  -5.3645],\n",
       "                        [ -5.2507,  -5.4567,  -4.8220]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_alphas_log',\n",
       "              tensor([[[[-2.9031, -3.5752, -3.1913],\n",
       "                        [-2.2432, -3.7676, -3.9219],\n",
       "                        [-2.2315, -3.3817, -3.0104]],\n",
       "              \n",
       "                       [[-3.4620, -2.1322, -2.3796],\n",
       "                        [-3.2906, -3.9242, -2.4920],\n",
       "                        [-2.6064, -2.2625, -3.8039]],\n",
       "              \n",
       "                       [[-3.0305, -3.3771, -3.4199],\n",
       "                        [-2.7889, -2.9304, -3.7615],\n",
       "                        [-2.1174, -2.1470, -3.9918]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2688, -2.4659, -3.1240],\n",
       "                        [-3.7692, -3.6450, -3.6797],\n",
       "                        [-3.3195, -2.8639, -2.6135]],\n",
       "              \n",
       "                       [[-2.1157, -2.3645, -3.2899],\n",
       "                        [-3.4988, -3.0115, -2.7938],\n",
       "                        [-3.8293, -3.2961, -2.8436]],\n",
       "              \n",
       "                       [[-3.9779, -2.0617, -3.1237],\n",
       "                        [-3.9790, -2.6218, -2.4551],\n",
       "                        [-3.5406, -3.1608, -3.2890]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6755, -2.0339, -3.6471],\n",
       "                        [-3.1715, -3.2779, -2.7492],\n",
       "                        [-2.6883, -3.9882, -3.6644]],\n",
       "              \n",
       "                       [[-2.4057, -2.0133, -2.1821],\n",
       "                        [-2.7596, -2.0538, -2.6359],\n",
       "                        [-3.5137, -3.3185, -3.5885]],\n",
       "              \n",
       "                       [[-3.0351, -2.9763, -2.0979],\n",
       "                        [-3.3766, -3.9956, -2.0556],\n",
       "                        [-2.8010, -3.5787, -3.6768]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.9227, -3.6770, -3.7636],\n",
       "                        [-3.2002, -2.1039, -2.2279],\n",
       "                        [-3.7049, -2.7865, -2.1264]],\n",
       "              \n",
       "                       [[-3.0326, -2.2067, -2.2916],\n",
       "                        [-2.1105, -3.7049, -2.5112],\n",
       "                        [-3.1940, -2.1001, -3.4853]],\n",
       "              \n",
       "                       [[-2.8792, -3.0937, -2.7589],\n",
       "                        [-2.6047, -2.2957, -3.1234],\n",
       "                        [-3.8853, -2.5147, -2.4693]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4313, -3.4454, -2.5228],\n",
       "                        [-2.2018, -3.2355, -2.3762],\n",
       "                        [-3.8663, -3.0295, -3.5700]],\n",
       "              \n",
       "                       [[-3.5861, -2.0395, -2.0020],\n",
       "                        [-2.1038, -3.2346, -2.7971],\n",
       "                        [-2.3657, -2.5616, -3.5310]],\n",
       "              \n",
       "                       [[-3.3006, -3.3535, -3.3189],\n",
       "                        [-3.1244, -3.3003, -3.5692],\n",
       "                        [-2.7795, -2.1361, -2.3262]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.1123, -3.5558, -2.4190],\n",
       "                        [-2.8286, -2.1191, -2.5490],\n",
       "                        [-2.3278, -2.8362, -3.7079]],\n",
       "              \n",
       "                       [[-2.0250, -2.0361, -2.2242],\n",
       "                        [-3.5920, -2.1569, -3.2739],\n",
       "                        [-2.3617, -3.3745, -2.4369]],\n",
       "              \n",
       "                       [[-3.4996, -2.8253, -2.5848],\n",
       "                        [-3.4868, -3.3970, -3.3454],\n",
       "                        [-3.3596, -3.8827, -3.4139]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.1325, -2.0101, -2.3009],\n",
       "                        [-3.3946, -3.7420, -2.2947],\n",
       "                        [-2.8810, -3.1959, -2.4976]],\n",
       "              \n",
       "                       [[-3.0886, -3.6569, -2.8172],\n",
       "                        [-3.7599, -3.9197, -2.1939],\n",
       "                        [-3.7000, -2.5793, -3.5384]],\n",
       "              \n",
       "                       [[-2.8714, -2.3903, -2.9222],\n",
       "                        [-2.1279, -3.4309, -2.6593],\n",
       "                        [-3.9820, -2.9647, -3.0653]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4074, -3.5453, -2.9808],\n",
       "                        [-2.2863, -3.9489, -2.0954],\n",
       "                        [-3.8373, -3.9608, -3.8983]],\n",
       "              \n",
       "                       [[-3.3889, -2.3294, -3.8718],\n",
       "                        [-2.4368, -2.1073, -2.8512],\n",
       "                        [-3.6483, -3.7381, -3.0208]],\n",
       "              \n",
       "                       [[-2.0715, -3.7128, -2.4285],\n",
       "                        [-3.7453, -2.5793, -3.9045],\n",
       "                        [-2.2144, -2.8838, -3.2419]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8225, -2.4760, -2.3612],\n",
       "                        [-3.4040, -2.1312, -3.9279],\n",
       "                        [-3.2219, -3.0139, -2.9078]],\n",
       "              \n",
       "                       [[-3.9570, -3.6798, -3.8169],\n",
       "                        [-2.9281, -3.5607, -2.0121],\n",
       "                        [-2.0334, -3.3228, -3.2737]],\n",
       "              \n",
       "                       [[-3.0264, -2.6413, -2.7952],\n",
       "                        [-2.6720, -2.2991, -3.6808],\n",
       "                        [-2.9856, -3.2928, -3.7279]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2259, -2.7306, -3.2844],\n",
       "                        [-3.2082, -2.3142, -3.7642],\n",
       "                        [-2.4837, -2.9002, -2.0545]],\n",
       "              \n",
       "                       [[-3.8918, -3.5356, -2.0444],\n",
       "                        [-2.3271, -2.4968, -3.9083],\n",
       "                        [-2.4074, -2.6570, -2.4153]],\n",
       "              \n",
       "                       [[-2.0498, -3.5175, -2.1168],\n",
       "                        [-3.9951, -2.7050, -2.6350],\n",
       "                        [-2.7071, -2.6911, -3.2756]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4691, -2.6418, -3.3070],\n",
       "                        [-2.0403, -3.3388, -3.3410],\n",
       "                        [-3.4311, -2.3567, -2.7274]],\n",
       "              \n",
       "                       [[-2.9643, -3.1868, -2.6083],\n",
       "                        [-3.9008, -2.3488, -2.8015],\n",
       "                        [-3.6829, -3.6533, -3.1903]],\n",
       "              \n",
       "                       [[-3.1084, -2.5719, -3.7105],\n",
       "                        [-2.5479, -3.8481, -2.2664],\n",
       "                        [-2.6867, -2.7838, -3.6353]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0250, -2.3754, -2.1942],\n",
       "                        [-2.2754, -2.2488, -2.5304],\n",
       "                        [-3.6430, -2.9638, -3.1415]],\n",
       "              \n",
       "                       [[-3.1872, -2.3818, -3.4090],\n",
       "                        [-3.5182, -3.5750, -3.3125],\n",
       "                        [-2.8591, -2.2255, -3.4907]],\n",
       "              \n",
       "                       [[-2.1073, -3.1520, -3.7595],\n",
       "                        [-2.5730, -2.0243, -3.1251],\n",
       "                        [-3.6950, -3.2891, -3.7837]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.3.param_mus',\n",
       "              tensor([-0.0347, -0.0540, -0.0008,  0.0293, -0.0292,  0.0349, -0.0176,  0.0116,\n",
       "                       0.0173,  0.0239,  0.0535,  0.0285,  0.0451, -0.0420,  0.0108, -0.0409,\n",
       "                       0.0453, -0.0289, -0.0493, -0.0556, -0.0361, -0.0034, -0.0584,  0.0529,\n",
       "                       0.0162, -0.0444,  0.0243,  0.0210, -0.0163,  0.0040,  0.0075, -0.0225,\n",
       "                      -0.0476,  0.0339,  0.0409, -0.0459,  0.0447,  0.0547,  0.0345, -0.0486,\n",
       "                       0.0053, -0.0136,  0.0179, -0.0266,  0.0421, -0.0030, -0.0182, -0.0482,\n",
       "                      -0.0340, -0.0338,  0.0125, -0.0354,  0.0531, -0.0226, -0.0371, -0.0432,\n",
       "                       0.0315,  0.0339, -0.0145,  0.0430,  0.0406,  0.0375, -0.0415, -0.0373])),\n",
       "             ('module_list.0.posterior_params.3.param_std_log',\n",
       "              tensor([-5.4569, -4.6801, -4.7204, -5.3099, -5.5642, -7.9669, -5.1158, -5.7351,\n",
       "                      -4.8519, -5.2321, -6.6220, -5.4749, -5.7233, -5.7436, -4.8307, -5.3099,\n",
       "                      -5.5596, -6.0521, -5.2583, -4.7860, -4.8898, -5.6637, -4.7467, -4.6643,\n",
       "                      -5.3782, -6.6473, -4.6510, -5.2890, -4.7336, -4.6367, -4.8326, -7.7491,\n",
       "                      -5.7414, -5.3058, -5.7958, -4.8864, -4.6670, -5.3566, -6.6464, -6.9234,\n",
       "                      -6.2836, -4.6365, -7.2882, -6.8838, -4.6835, -5.1239, -7.1621, -5.2982,\n",
       "                      -5.1323, -6.3269, -5.4452, -6.2584, -6.0409, -5.0412, -4.7253, -4.7920,\n",
       "                      -4.8736, -4.7333, -4.9122, -4.8091, -6.4931, -5.7098, -8.9380, -4.7787])),\n",
       "             ('module_list.0.posterior_params.3.scale_alphas_log',\n",
       "              tensor([-2.0096, -3.1070, -2.4744, -2.8249, -2.1330, -2.1949, -3.7866, -3.2097,\n",
       "                      -3.8550, -3.1583, -3.0586, -2.9922, -2.6323, -2.1886, -2.5555, -2.2712,\n",
       "                      -2.9222, -2.3903, -2.9189, -2.6913, -2.1877, -2.3527, -2.1297, -3.1475,\n",
       "                      -2.6098, -2.0891, -3.4339, -2.4926, -3.6903, -2.8732, -2.1957, -3.5118,\n",
       "                      -2.2983, -3.3832, -3.4829, -2.7464, -3.3553, -3.5355, -2.4428, -3.0015,\n",
       "                      -2.7173, -2.5134, -3.9719, -2.8202, -2.6662, -3.1703, -2.6489, -2.1131,\n",
       "                      -2.0383, -3.8398, -2.6632, -2.2751, -2.4046, -2.9891, -2.8446, -3.0018,\n",
       "                      -2.0600, -3.5996, -3.0579, -2.5789, -3.7129, -2.4109, -2.5351, -3.2553])),\n",
       "             ('module_list.0.posterior_params.3.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.4.param_mus',\n",
       "              tensor([[ 0.0009,  0.0158,  0.0126,  ..., -0.0105, -0.0025, -0.0128],\n",
       "                      [ 0.0080, -0.0029, -0.0087,  ...,  0.0028, -0.0101,  0.0126],\n",
       "                      [ 0.0150, -0.0064, -0.0075,  ..., -0.0084, -0.0034, -0.0038],\n",
       "                      ...,\n",
       "                      [-0.0002, -0.0109,  0.0178,  ..., -0.0034, -0.0082, -0.0020],\n",
       "                      [-0.0095,  0.0160, -0.0090,  ..., -0.0084,  0.0039,  0.0121],\n",
       "                      [-0.0176, -0.0070,  0.0146,  ..., -0.0085,  0.0145, -0.0063]])),\n",
       "             ('module_list.0.posterior_params.4.param_std_log',\n",
       "              tensor([[-5.0882, -5.6143, -5.0647,  ..., -5.6104, -4.6591, -4.9445],\n",
       "                      [-4.6745, -5.9688, -5.0048,  ..., -6.3473, -4.6243, -6.2210],\n",
       "                      [-4.7615, -7.7854, -5.7147,  ..., -7.3079, -5.9162, -5.9307],\n",
       "                      ...,\n",
       "                      [-6.7976, -5.2108, -5.6782,  ..., -5.2774, -5.6684, -6.0092],\n",
       "                      [-6.6351, -4.8296, -5.0264,  ..., -7.7251, -5.2107, -4.8150],\n",
       "                      [-7.3702, -8.7021, -4.7729,  ..., -4.8881, -4.7526, -5.0925]])),\n",
       "             ('module_list.0.posterior_params.4.scale_alphas_log',\n",
       "              tensor([[-2.3414, -2.7704, -3.4864,  ..., -2.1757, -3.9189, -2.2035],\n",
       "                      [-2.3410, -2.2061, -3.1260,  ..., -3.4673, -2.0878, -3.4667],\n",
       "                      [-3.9802, -2.7468, -2.0136,  ..., -2.2748, -3.8034, -2.2377],\n",
       "                      ...,\n",
       "                      [-2.4080, -2.7311, -2.1504,  ..., -3.6135, -2.4462, -2.0026],\n",
       "                      [-3.4683, -2.5169, -2.6618,  ..., -2.9077, -2.7889, -2.0861],\n",
       "                      [-2.1884, -3.1091, -3.6772,  ..., -2.2174, -2.0252, -2.5327]])),\n",
       "             ('module_list.0.posterior_params.4.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.5.param_mus',\n",
       "              tensor([-0.0112,  0.0141,  0.0014,  0.0127, -0.0057, -0.0123, -0.0136,  0.0164,\n",
       "                       0.0140,  0.0152,  0.0077,  0.0159, -0.0018, -0.0005,  0.0025,  0.0036,\n",
       "                       0.0174, -0.0110,  0.0078, -0.0102,  0.0028,  0.0009,  0.0105,  0.0106,\n",
       "                       0.0002, -0.0018,  0.0092, -0.0014, -0.0002,  0.0019,  0.0001,  0.0019,\n",
       "                      -0.0122,  0.0073, -0.0102, -0.0153, -0.0162,  0.0075,  0.0051,  0.0153,\n",
       "                       0.0129, -0.0160, -0.0173, -0.0098, -0.0150,  0.0157, -0.0045,  0.0022,\n",
       "                      -0.0135,  0.0099,  0.0101,  0.0171,  0.0014, -0.0172,  0.0025, -0.0021,\n",
       "                       0.0169,  0.0017,  0.0117, -0.0016,  0.0121, -0.0066, -0.0090, -0.0044,\n",
       "                      -0.0091,  0.0011, -0.0143,  0.0033, -0.0132, -0.0091, -0.0091, -0.0157,\n",
       "                       0.0127,  0.0111, -0.0166,  0.0143,  0.0017, -0.0061, -0.0174,  0.0098,\n",
       "                       0.0034, -0.0063,  0.0041, -0.0007, -0.0088, -0.0068, -0.0123, -0.0048,\n",
       "                       0.0054, -0.0105, -0.0157,  0.0175, -0.0124,  0.0101,  0.0101,  0.0164,\n",
       "                       0.0117, -0.0088, -0.0032,  0.0164,  0.0047,  0.0089, -0.0158, -0.0005,\n",
       "                       0.0097, -0.0070,  0.0082,  0.0131, -0.0131, -0.0050,  0.0024, -0.0050,\n",
       "                       0.0152,  0.0010, -0.0035, -0.0169,  0.0012, -0.0119, -0.0085, -0.0127,\n",
       "                       0.0139,  0.0060,  0.0050, -0.0074, -0.0137,  0.0144,  0.0127, -0.0140])),\n",
       "             ('module_list.0.posterior_params.5.param_std_log',\n",
       "              tensor([ -8.5058,  -4.9983,  -4.7748,  -6.4515,  -8.2332, -10.5456,  -5.4021,\n",
       "                       -8.7938,  -6.3761,  -5.5005,  -7.5101,  -5.7537,  -4.8349,  -6.5463,\n",
       "                       -4.9158,  -6.0935,  -7.2662,  -5.4875,  -5.6636,  -4.8700,  -4.7151,\n",
       "                       -4.7584,  -4.8736,  -5.3312,  -4.9649,  -4.9046,  -4.9326,  -7.3845,\n",
       "                       -6.0946,  -5.0042,  -4.9009,  -4.6594,  -5.4126,  -4.7578,  -5.2708,\n",
       "                       -7.4743,  -5.6484,  -5.0898,  -5.7023,  -5.2178,  -6.5615,  -7.9420,\n",
       "                       -5.2271,  -5.7446,  -5.1716,  -5.5231,  -5.2031,  -6.4824,  -4.7606,\n",
       "                       -5.7502,  -5.2827,  -6.0781,  -5.8726,  -5.0141,  -4.9438,  -8.0827,\n",
       "                       -5.3131,  -5.7115,  -4.7213,  -4.6253,  -4.7276,  -4.6258,  -5.1091,\n",
       "                       -5.2092,  -5.5085,  -5.6953,  -4.6783,  -4.9021,  -4.7901,  -4.9724,\n",
       "                       -5.9262,  -6.1041,  -5.0713,  -4.6735,  -6.4833,  -5.2216,  -5.1605,\n",
       "                       -4.9854,  -5.7718,  -6.8357,  -4.9983,  -6.0955,  -5.8611,  -5.9829,\n",
       "                       -4.8589,  -5.1603,  -6.4991,  -5.6061,  -5.8304,  -5.4435,  -4.6777,\n",
       "                       -4.7764,  -5.0857,  -4.9599,  -4.7925,  -4.8101,  -4.6988,  -4.6460,\n",
       "                       -5.2655,  -6.4285,  -5.7866,  -5.3847,  -5.1084,  -5.3568,  -5.4592,\n",
       "                       -5.4557,  -7.1196,  -4.6417,  -6.3491,  -4.9110,  -5.1545,  -4.8412,\n",
       "                       -5.2638,  -6.0338,  -4.9269,  -7.4436,  -5.8754,  -4.9944,  -5.3159,\n",
       "                       -5.9607,  -6.5675,  -6.2111,  -5.1559,  -7.5439,  -4.7024,  -5.7944,\n",
       "                       -4.7159,  -5.0060])),\n",
       "             ('module_list.0.posterior_params.5.scale_alphas_log',\n",
       "              tensor([-2.9711, -2.3029, -3.2661, -3.8841, -3.9730, -2.9972, -3.0801, -2.8908,\n",
       "                      -3.2214, -2.5367, -3.7855, -3.5761, -3.2829, -2.4807, -3.7627, -3.3901,\n",
       "                      -3.2457, -2.9323, -3.2918, -3.2453, -3.4675, -2.9678, -3.9310, -2.9987,\n",
       "                      -2.2035, -2.3976, -3.5818, -3.1568, -2.2656, -3.4460, -3.9424, -3.2561,\n",
       "                      -2.0742, -3.8532, -3.1280, -2.8851, -2.0143, -2.0730, -2.5920, -3.7779,\n",
       "                      -2.5698, -3.7920, -3.6548, -2.3358, -3.9477, -3.6476, -3.8149, -2.5764,\n",
       "                      -2.8168, -3.6043, -3.2515, -3.9662, -3.3422, -2.4601, -2.8934, -2.9427,\n",
       "                      -3.4763, -2.3204, -2.2301, -2.4737, -3.8858, -3.7568, -3.4567, -3.1788,\n",
       "                      -2.4339, -2.0268, -2.8586, -3.4026, -2.9261, -2.2214, -3.0145, -3.9870,\n",
       "                      -2.0210, -3.2889, -2.6818, -2.6525, -2.6215, -2.5191, -3.3091, -2.5133,\n",
       "                      -2.1772, -2.7749, -3.2064, -2.7597, -2.0681, -2.4307, -2.3182, -3.3219,\n",
       "                      -3.7947, -3.7979, -2.5180, -2.9864, -2.1951, -3.9902, -2.8577, -3.3741,\n",
       "                      -3.5462, -3.3496, -2.4838, -2.2125, -3.5979, -2.9471, -3.3925, -3.8978,\n",
       "                      -3.0267, -2.5021, -2.3832, -3.2529, -2.6711, -3.8071, -3.5777, -3.3519,\n",
       "                      -2.8422, -2.2266, -2.3704, -2.8740, -2.7499, -2.9441, -2.7132, -3.9846,\n",
       "                      -2.8880, -3.0201, -3.8964, -2.4971, -3.7383, -2.5198, -2.3017, -3.7625])),\n",
       "             ('module_list.0.posterior_params.5.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('module_list.0.posterior_params.6.param_mus',\n",
       "              tensor([[ 0.0861,  0.0572,  0.0623,  ...,  0.0349, -0.0029,  0.0783],\n",
       "                      [ 0.0663, -0.0496, -0.0471,  ...,  0.0246, -0.0090,  0.0290],\n",
       "                      [ 0.0787, -0.0569, -0.0074,  ...,  0.0223,  0.0753,  0.0849],\n",
       "                      ...,\n",
       "                      [-0.0752, -0.0523,  0.0439,  ..., -0.0768, -0.0083, -0.0679],\n",
       "                      [-0.0070, -0.0547, -0.0404,  ...,  0.0185, -0.0464, -0.0533],\n",
       "                      [-0.0087, -0.0757, -0.0331,  ...,  0.0254, -0.0312,  0.0815]])),\n",
       "             ('module_list.0.posterior_params.6.param_std_log',\n",
       "              tensor([[-5.2017, -7.5709, -4.9455,  ..., -5.7424, -5.2740, -7.6515],\n",
       "                      [-5.7487, -5.2041, -5.0962,  ..., -6.7837, -5.8445, -6.4197],\n",
       "                      [-5.0128, -4.9754, -5.1209,  ..., -5.3098, -6.3397, -8.8992],\n",
       "                      ...,\n",
       "                      [-6.1798, -5.0020, -5.8882,  ..., -4.7352, -8.7045, -4.7601],\n",
       "                      [-6.9533, -5.3401, -4.6249,  ..., -4.6350, -4.9398, -4.7976],\n",
       "                      [-5.3153, -4.6354, -5.0823,  ..., -5.2240, -5.2665, -4.6325]])),\n",
       "             ('module_list.0.posterior_params.6.scale_alphas_log',\n",
       "              tensor([[-3.4896, -2.3144, -3.2581,  ..., -2.1586, -3.0065, -2.2661],\n",
       "                      [-2.4441, -2.0589, -2.5914,  ..., -3.1640, -3.8862, -2.6127],\n",
       "                      [-2.4363, -2.7432, -2.3645,  ..., -2.4624, -2.6623, -2.2037],\n",
       "                      ...,\n",
       "                      [-3.5581, -3.5343, -3.9614,  ..., -3.5155, -3.0719, -3.5733],\n",
       "                      [-3.6154, -3.6500, -2.4728,  ..., -2.0083, -3.4753, -2.4960],\n",
       "                      [-3.1972, -3.5865, -2.2273,  ..., -3.9335, -3.2613, -3.5673]])),\n",
       "             ('module_list.0.posterior_params.6.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.7.param_mus',\n",
       "              tensor([ 0.0045,  0.0808, -0.0811,  0.0353,  0.0298, -0.0510, -0.0097,  0.0499,\n",
       "                       0.0105, -0.0429])),\n",
       "             ('module_list.0.posterior_params.7.param_std_log',\n",
       "              tensor([-5.2095, -5.1445, -5.7701, -4.7362, -6.1606, -5.0685, -5.4482, -5.0233,\n",
       "                      -5.1172, -4.9747])),\n",
       "             ('module_list.0.posterior_params.7.scale_alphas_log',\n",
       "              tensor([-2.7219, -3.5050, -3.6166, -2.6818, -2.5404, -2.2111, -2.9576, -3.6258,\n",
       "                      -2.4424, -2.8427])),\n",
       "             ('module_list.0.posterior_params.7.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_bayes.pt'))\n",
    "image1, label1 = test_dataset[10]\n",
    "image2, label2 = test_dataset[11]\n",
    "model(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:16906.90234375, KL Loss: 1690681.375, FitLoss: 0.09073139727115631, Accuracy 0.98, Prune parameters: 221821.0/421642\n"
     ]
    }
   ],
   "source": [
    "val_loss = 0.0\n",
    "val_acc = 0.0\n",
    "PRUNE = 1.0\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,  \n",
    "                                         batch_size=BATCH_SIZE,  \n",
    "                                         shuffle=False, \n",
    "                                         pin_memory=True) \n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "trainer.params.prune_threshold = PRUNE\n",
    "test_result = trainer.eval(model, test_loader)\n",
    "acc = test_result.custom_losses['val_accuracy']\n",
    "print(f'Loss:{test_result.val_loss}, KL Loss: {test_result.dist_loss}, FitLoss: {test_result.fit_loss}, Accuracy {acc}, Prune parameters: {test_result.cnt_prune_parameters}/{test_result.cnt_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device=device)\n",
    "model.prune({'threshold': 1.0})\n",
    "model.set_map_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 4.2992e-03, -5.4342e-01, -0.0000e+00],\n",
      "          [ 3.9089e-01, -0.0000e+00, -0.0000e+00],\n",
      "          [ 8.2518e-01,  3.0815e-01, -2.3478e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8153e-02,  0.0000e+00, -0.0000e+00],\n",
      "          [ 4.4879e-01,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.4131e+00, -7.5729e-01, -0.0000e+00],\n",
      "          [ 2.0788e-01,  4.6619e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  2.6288e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  9.8380e-01,  3.4592e-01],\n",
      "          [-0.0000e+00,  4.0430e-01,  0.0000e+00],\n",
      "          [-8.4115e-01, -3.8792e-01, -1.5979e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0565e-01,  0.0000e+00,  2.3229e-01],\n",
      "          [ 0.0000e+00,  6.6020e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -3.2411e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00,  3.8068e-01,  0.0000e+00],\n",
      "          [-1.7023e-03,  7.2274e-01,  1.6451e-01],\n",
      "          [-2.6313e-01,  0.0000e+00, -8.0280e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  7.1311e-01, -0.0000e+00],\n",
      "          [ 7.3480e-01,  0.0000e+00, -6.3528e-01],\n",
      "          [ 1.7638e-02, -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8662e-01,  4.1352e-01,  7.5745e-01],\n",
      "          [ 3.4204e-03, -2.4012e-03,  1.9629e-01],\n",
      "          [-0.0000e+00, -1.8996e+00, -5.4733e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7047e-01, -0.0000e+00, -4.2426e-02],\n",
      "          [-0.0000e+00,  8.9670e-01,  8.5076e-01],\n",
      "          [-4.0429e-01,  5.5609e-01, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  1.1400e-01],\n",
      "          [ 0.0000e+00,  4.4838e-01, -0.0000e+00],\n",
      "          [ 4.5566e-02, -0.0000e+00, -1.9310e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.7405e-02,  2.3569e-01, -0.0000e+00],\n",
      "          [ 4.6704e-01,  8.9131e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -1.1183e-02, -6.1903e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 5.3916e-02,  1.3328e-02, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4441e-01,  0.0000e+00, -2.3364e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  7.9347e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6268e-01,  0.0000e+00, -0.0000e+00],\n",
      "          [ 6.3382e-01,  3.4143e-01, -0.0000e+00],\n",
      "          [-0.0000e+00, -3.0772e-01, -8.3751e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0354e-01,  0.0000e+00, -0.0000e+00],\n",
      "          [ 4.2287e-01,  0.0000e+00,  3.6846e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.1328e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0544e-01, -1.0880e+00, -1.3626e+00],\n",
      "          [ 0.0000e+00,  4.4564e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  6.4581e-01,  3.5768e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  3.1633e-01, -6.6071e-01],\n",
      "          [ 0.0000e+00,  2.3753e-01, -0.0000e+00],\n",
      "          [ 3.6975e-01, -5.6517e-03, -6.6312e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.1901e-01,  6.4522e-02,  2.1885e-01],\n",
      "          [-0.0000e+00,  6.1452e-01,  4.0866e-01],\n",
      "          [-1.2748e-01,  5.6207e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.3363e-01, -0.0000e+00, -0.0000e+00],\n",
      "          [ 2.1696e-01,  0.0000e+00,  6.1144e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.8670e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  6.6921e-01,  3.2235e-01],\n",
      "          [-0.0000e+00,  4.6664e-01,  1.8888e-01],\n",
      "          [-5.4447e-01, -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.0248e-01, -0.0000e+00,  1.2330e-01],\n",
      "          [-0.0000e+00,  0.0000e+00,  6.1526e-01],\n",
      "          [-1.3471e-01,  3.3910e-01,  2.8420e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  2.2249e-01,  0.0000e+00],\n",
      "          [ 1.4262e-01,  8.8915e-01,  0.0000e+00],\n",
      "          [-0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1939e+00, -4.6484e-01, -0.0000e+00],\n",
      "          [-8.6274e-01,  1.4272e-01,  0.0000e+00],\n",
      "          [ 1.0309e-01,  4.9730e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1762e-01, -1.4468e-01, -0.0000e+00],\n",
      "          [ 3.6268e-01,  5.3481e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  5.2241e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00,  0.0000e+00,  1.2648e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.5915e-01],\n",
      "          [-0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3550e-02,  0.0000e+00,  6.7948e-02],\n",
      "          [ 5.6981e-01,  0.0000e+00,  4.5842e-01],\n",
      "          [ 2.9938e-02,  1.7861e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  3.6278e-01, -2.5424e-01],\n",
      "          [ 9.4070e-01,  0.0000e+00, -2.1502e-02],\n",
      "          [ 9.6985e-03,  6.5121e-02, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  9.1819e-02],\n",
      "          [ 0.0000e+00, -0.0000e+00, -3.3740e-01],\n",
      "          [-0.0000e+00, -0.0000e+00, -2.1633e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3137e-02, -0.0000e+00, -0.0000e+00],\n",
      "          [ 5.4615e-01,  2.9908e-01, -0.0000e+00],\n",
      "          [ 9.4902e-01,  2.2312e-01, -3.2910e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6456e-02, -3.2759e-01, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.7491e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -1.7607e-01, -7.8085e-02],\n",
      "          [-0.0000e+00,  1.0843e+00,  0.0000e+00],\n",
      "          [-7.0030e-02,  0.0000e+00,  1.0573e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  9.0907e-01],\n",
      "          [-1.3929e-01, -2.4492e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00]]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.base_module.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = test_dataset[100]\n",
    "plt.imshow(image.permute(1, 2, 0), cmap=\"gray\")\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2.1405], device='cuda:0'),\n",
       "indices=tensor([5], device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(model(image.cuda()).data, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
