{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sasha/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier(nn.Module): \n",
    "    def __init__(self, classes: int = 10): \n",
    "        super().__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) \n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        #self.dropout1 = nn.Dropout2d(0.25) \n",
    "        #self.dropout2 = nn.Dropout2d(0.5) \n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128) \n",
    "        self.fc2 = nn.Linear(128, classes) \n",
    "  \n",
    "    def forward(self, x): \n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        #x = self.dropout1(x) \n",
    "        x = self.pool(F.relu(self.conv2(x))) \n",
    "        #x = self.dropout2(x) \n",
    "        x = x.view(-1, 64 * 7 * 7) \n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.fc2(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.bayes.variational.distribution import LogUniformVarDist\n",
    "from src.methods.bayes.variational.net_distribution import VarBayesModuleNetDistribution\n",
    "from src.methods.bayes.base.net_distribution import BaseNetDistributionPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogUniformVarDist(param_mus: torch.Size([2]), param_std_log: torch.Size([2]), scale_mus: torch.Size([2]), scale_alphas_log: torch.Size([2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = nn.Parameter(torch.tensor([0.0, 1.0]))\n",
    "LogUniformVarDist.from_parameter(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.bayes.variational.net import LogUniformVarBayesModule, VarBayesModuleNet\n",
    "from src.methods.bayes.variational.optimization import LogUniformVarKLLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayes_model = BayesModule(module)\n",
    "var_module = LogUniformVarBayesModule(module)\n",
    "bayes_model = VarBayesModuleNet(module, nn.ModuleList([var_module]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VarBayesModuleNet(\n",
      "  (module_list): ModuleList(\n",
      "    (0): LogUniformVarBayesModule(\n",
      "      (posterior_params): ParameterList(\n",
      "          (0): Object of type: ParameterDict\n",
      "          (1): Object of type: ParameterDict\n",
      "          (2): Object of type: ParameterDict\n",
      "          (3): Object of type: ParameterDict\n",
      "          (4): Object of type: ParameterDict\n",
      "          (5): Object of type: ParameterDict\n",
      "          (6): Object of type: ParameterDict\n",
      "          (7): Object of type: ParameterDict\n",
      "        (0): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "        )\n",
      "        (1): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        )\n",
      "        (2): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "        )\n",
      "        (3): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        )\n",
      "        (4): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "        )\n",
      "        (5): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 128]\n",
      "        )\n",
      "        (6): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "        )\n",
      "        (7): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 10]\n",
      "        )\n",
      "      )\n",
      "      (prior_params): ParameterList()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(bayes_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i, p in enumerate(bayes_model.parameters()):\n",
    "    cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0, 2.], [3, 0]])\n",
    "b =  torch.tensor([1., 1.])\n",
    "a_s = a.to_sparse()\n",
    "print(a_s @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(bayes_model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1.weight': None,\n",
       " 'conv1.bias': None,\n",
       " 'conv2.weight': None,\n",
       " 'conv2.bias': None,\n",
       " 'fc1.weight': None,\n",
       " 'fc1.bias': None,\n",
       " 'fc2.weight': None,\n",
       " 'fc2.bias': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_model.prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = test_dataset[10]\n",
    "y = bayes_model(torch.ones_like(image))\n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "bayes_model.prior\n",
    "out = y.sum() + kl_loss(bayes_model.weights, bayes_model.posterior, bayes_model.prior)\n",
    "optimizer.zero_grad() \n",
    "out.backward() \n",
    "optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_distributon = VarBayesModuleNetDistribution(bayes_model.base_module, bayes_model.posterior)\n",
    "net_distributon_pruner = BaseNetDistributionPruner(net_distributon)\n",
    "net_distributon.set_map_params()\n",
    "net_distributon_pruner.prune(-2.2)\n",
    "#get basic model for evaluation\n",
    "eval_model = net_distributon.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.0242, -0.0590, -0.0548],\n",
      "          [-0.0238, -0.0273,  0.0524],\n",
      "          [ 0.1173, -0.0952,  0.1695]]],\n",
      "\n",
      "\n",
      "        [[[-0.1079, -0.1807, -0.1969],\n",
      "          [-0.0410,  0.0735, -0.0119],\n",
      "          [ 0.0757, -0.1481, -0.2216]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0326,  0.0025, -0.0676],\n",
      "          [-0.0131, -0.0667, -0.0575],\n",
      "          [-0.0197,  0.1946, -0.0525]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0803, -0.0287, -0.0999],\n",
      "          [ 0.1838,  0.1064,  0.1259],\n",
      "          [-0.0364,  0.0209, -0.0017]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0730, -0.0113,  0.0363],\n",
      "          [-0.0491,  0.0027, -0.1039],\n",
      "          [ 0.1076,  0.1462,  0.0888]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2284, -0.2176, -0.0731],\n",
      "          [ 0.1149,  0.0250,  0.0368],\n",
      "          [-0.0170,  0.2151,  0.1945]]],\n",
      "\n",
      "\n",
      "        [[[-0.0327, -0.0320, -0.1460],\n",
      "          [-0.0803,  0.0557,  0.2258],\n",
      "          [ 0.0038, -0.1255, -0.0011]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1912, -0.0171, -0.2159],\n",
      "          [ 0.0557, -0.0454,  0.0071],\n",
      "          [-0.1780,  0.0052,  0.0430]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0841, -0.0563,  0.0091],\n",
      "          [-0.0724,  0.1936,  0.1108],\n",
      "          [-0.0765,  0.1326, -0.0550]]],\n",
      "\n",
      "\n",
      "        [[[-0.1768, -0.1140,  0.0785],\n",
      "          [-0.0065, -0.1844,  0.1698],\n",
      "          [ 0.2036, -0.1282, -0.2184]]],\n",
      "\n",
      "\n",
      "        [[[-0.0937,  0.1081,  0.0293],\n",
      "          [-0.2242, -0.0733,  0.0986],\n",
      "          [ 0.1244,  0.1416,  0.0728]]],\n",
      "\n",
      "\n",
      "        [[[-0.0809,  0.1329,  0.1518],\n",
      "          [ 0.0789,  0.0865,  0.0559],\n",
      "          [-0.0627, -0.1042,  0.0136]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0017,  0.0353,  0.0150],\n",
      "          [ 0.0778, -0.0780, -0.1008],\n",
      "          [-0.1351, -0.1918, -0.0434]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0331,  0.1497, -0.0039],\n",
      "          [ 0.0060,  0.2028,  0.0026],\n",
      "          [ 0.1737,  0.0326, -0.0350]]],\n",
      "\n",
      "\n",
      "        [[[-0.1576, -0.0638, -0.1346],\n",
      "          [-0.0241,  0.1157, -0.0587],\n",
      "          [ 0.0915,  0.0167, -0.0192]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0578,  0.0385, -0.2091],\n",
      "          [-0.0299,  0.0126, -0.0171],\n",
      "          [ 0.1214, -0.1630, -0.0182]]],\n",
      "\n",
      "\n",
      "        [[[-0.0546, -0.2115, -0.0042],\n",
      "          [-0.0279,  0.0855,  0.0015],\n",
      "          [ 0.0607, -0.0086, -0.0560]]],\n",
      "\n",
      "\n",
      "        [[[-0.2279,  0.0167, -0.2231],\n",
      "          [ 0.0770,  0.0606, -0.0237],\n",
      "          [ 0.0884,  0.2276,  0.0381]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2262,  0.0023, -0.1826],\n",
      "          [ 0.0188,  0.0474,  0.0348],\n",
      "          [-0.0710, -0.0052,  0.1496]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2077,  0.0968,  0.0769],\n",
      "          [-0.0783, -0.0183,  0.0804],\n",
      "          [ 0.1965, -0.0785, -0.0245]]],\n",
      "\n",
      "\n",
      "        [[[-0.0077,  0.0844, -0.0633],\n",
      "          [ 0.1366,  0.1737,  0.1639],\n",
      "          [-0.1667, -0.0784, -0.2274]]],\n",
      "\n",
      "\n",
      "        [[[-0.0686, -0.0955,  0.0912],\n",
      "          [-0.1483,  0.0991, -0.2160],\n",
      "          [-0.0616, -0.0612, -0.1309]]],\n",
      "\n",
      "\n",
      "        [[[-0.1812, -0.1984, -0.0617],\n",
      "          [ 0.0699, -0.0553, -0.0253],\n",
      "          [-0.0778, -0.1414, -0.2005]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0837, -0.1898,  0.1646],\n",
      "          [ 0.0834, -0.0295, -0.0707],\n",
      "          [ 0.1952,  0.1248,  0.1731]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1781, -0.2138, -0.1188],\n",
      "          [-0.1437,  0.0565, -0.0685],\n",
      "          [ 0.1552, -0.1207,  0.0710]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1732,  0.0959, -0.1183],\n",
      "          [ 0.0014,  0.0951, -0.0476],\n",
      "          [ 0.0601, -0.1951,  0.0481]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0443,  0.0297, -0.1668],\n",
      "          [ 0.0884, -0.0011, -0.1235],\n",
      "          [ 0.0114, -0.0982, -0.2148]]],\n",
      "\n",
      "\n",
      "        [[[-0.0835,  0.1184,  0.0025],\n",
      "          [ 0.1604,  0.1037,  0.1257],\n",
      "          [ 0.2201, -0.0031, -0.0815]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0083,  0.1466,  0.2316],\n",
      "          [-0.0782, -0.0391, -0.1011],\n",
      "          [ 0.1990,  0.0272,  0.1943]]],\n",
      "\n",
      "\n",
      "        [[[-0.1941, -0.1597, -0.2142],\n",
      "          [ 0.0350, -0.0573, -0.1396],\n",
      "          [-0.1558,  0.1714,  0.0201]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0916, -0.0315, -0.0610],\n",
      "          [-0.0031, -0.0765, -0.0436],\n",
      "          [ 0.0346, -0.0301,  0.1009]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1808, -0.2127, -0.1757],\n",
      "          [-0.0737, -0.1432,  0.0248],\n",
      "          [-0.2173, -0.0939,  0.0089]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(eval_model.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('module_list.0.posterior_params.0.param_mus',\n",
       "              tensor([[[[-0.0242, -0.0590, -0.0548],\n",
       "                        [-0.0238, -0.0273,  0.0524],\n",
       "                        [ 0.1173, -0.0952,  0.1695]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1079, -0.1807, -0.1969],\n",
       "                        [-0.0410,  0.0735, -0.0119],\n",
       "                        [ 0.0757, -0.1481, -0.2216]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0326,  0.0025, -0.0676],\n",
       "                        [-0.0131, -0.0667, -0.0575],\n",
       "                        [-0.0197,  0.1946, -0.0525]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0803, -0.0287, -0.0999],\n",
       "                        [ 0.1838,  0.1064,  0.1259],\n",
       "                        [-0.0364,  0.0209, -0.0017]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0730, -0.0113,  0.0363],\n",
       "                        [-0.0491,  0.0027, -0.1039],\n",
       "                        [ 0.1076,  0.1462,  0.0888]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2284, -0.2176, -0.0731],\n",
       "                        [ 0.1149,  0.0250,  0.0368],\n",
       "                        [-0.0170,  0.2151,  0.1945]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0327, -0.0320, -0.1460],\n",
       "                        [-0.0803,  0.0557,  0.2258],\n",
       "                        [ 0.0038, -0.1255, -0.0011]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1912, -0.0171, -0.2159],\n",
       "                        [ 0.0557, -0.0454,  0.0071],\n",
       "                        [-0.1780,  0.0052,  0.0430]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0841, -0.0563,  0.0091],\n",
       "                        [-0.0724,  0.1936,  0.1108],\n",
       "                        [-0.0765,  0.1326, -0.0550]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1768, -0.1140,  0.0785],\n",
       "                        [-0.0065, -0.1844,  0.1698],\n",
       "                        [ 0.2036, -0.1282, -0.2184]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0937,  0.1081,  0.0293],\n",
       "                        [-0.2242, -0.0733,  0.0986],\n",
       "                        [ 0.1244,  0.1416,  0.0728]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0809,  0.1329,  0.1518],\n",
       "                        [ 0.0789,  0.0865,  0.0559],\n",
       "                        [-0.0627, -0.1042,  0.0136]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0017,  0.0353,  0.0150],\n",
       "                        [ 0.0778, -0.0780, -0.1008],\n",
       "                        [-0.1351, -0.1918, -0.0434]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0331,  0.1497, -0.0039],\n",
       "                        [ 0.0060,  0.2028,  0.0026],\n",
       "                        [ 0.1737,  0.0326, -0.0350]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1576, -0.0638, -0.1346],\n",
       "                        [-0.0241,  0.1157, -0.0587],\n",
       "                        [ 0.0915,  0.0167, -0.0192]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0578,  0.0385, -0.2091],\n",
       "                        [-0.0299,  0.0126, -0.0171],\n",
       "                        [ 0.1214, -0.1630, -0.0182]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0546, -0.2115, -0.0042],\n",
       "                        [-0.0279,  0.0855,  0.0015],\n",
       "                        [ 0.0607, -0.0086, -0.0560]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2279,  0.0167, -0.2231],\n",
       "                        [ 0.0770,  0.0606, -0.0237],\n",
       "                        [ 0.0884,  0.2276,  0.0381]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2262,  0.0023, -0.1826],\n",
       "                        [ 0.0188,  0.0474,  0.0348],\n",
       "                        [-0.0710, -0.0052,  0.1496]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2077,  0.0968,  0.0769],\n",
       "                        [-0.0783, -0.0183,  0.0804],\n",
       "                        [ 0.1965, -0.0785, -0.0245]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0077,  0.0844, -0.0633],\n",
       "                        [ 0.1366,  0.1737,  0.1639],\n",
       "                        [-0.1667, -0.0784, -0.2274]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0686, -0.0955,  0.0912],\n",
       "                        [-0.1483,  0.0991, -0.2160],\n",
       "                        [-0.0616, -0.0612, -0.1309]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1812, -0.1984, -0.0617],\n",
       "                        [ 0.0699, -0.0553, -0.0253],\n",
       "                        [-0.0778, -0.1414, -0.2005]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0837, -0.1898,  0.1646],\n",
       "                        [ 0.0834, -0.0295, -0.0707],\n",
       "                        [ 0.1952,  0.1248,  0.1731]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1781, -0.2138, -0.1188],\n",
       "                        [-0.1437,  0.0565, -0.0685],\n",
       "                        [ 0.1552, -0.1207,  0.0710]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1732,  0.0959, -0.1183],\n",
       "                        [ 0.0014,  0.0951, -0.0476],\n",
       "                        [ 0.0601, -0.1951,  0.0481]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0443,  0.0297, -0.1668],\n",
       "                        [ 0.0884, -0.0011, -0.1235],\n",
       "                        [ 0.0114, -0.0982, -0.2148]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0835,  0.1184,  0.0025],\n",
       "                        [ 0.1604,  0.1037,  0.1257],\n",
       "                        [ 0.2201, -0.0031, -0.0815]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0083,  0.1466,  0.2316],\n",
       "                        [-0.0782, -0.0391, -0.1011],\n",
       "                        [ 0.1990,  0.0272,  0.1943]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1941, -0.1597, -0.2142],\n",
       "                        [ 0.0350, -0.0573, -0.1396],\n",
       "                        [-0.1558,  0.1714,  0.0201]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0916, -0.0315, -0.0610],\n",
       "                        [-0.0031, -0.0765, -0.0436],\n",
       "                        [ 0.0346, -0.0301,  0.1009]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1808, -0.2127, -0.1757],\n",
       "                        [-0.0737, -0.1432,  0.0248],\n",
       "                        [-0.2173, -0.0939,  0.0089]]]])),\n",
       "             ('module_list.0.posterior_params.0.param_std_log',\n",
       "              tensor([[[[-4.6948, -6.6982, -4.9078],\n",
       "                        [-4.5448, -4.6972, -5.3485],\n",
       "                        [-5.9185, -4.8625, -5.7384]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.9966, -5.2167, -4.5172],\n",
       "                        [-4.7898, -4.8278, -8.1093],\n",
       "                        [-5.4935, -4.8456, -6.5915]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.2167, -4.9010, -5.8534],\n",
       "                        [-5.2012, -5.2527, -6.3644],\n",
       "                        [-4.7241, -4.6016, -4.9011]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7929, -4.6695, -4.5699],\n",
       "                        [-4.6266, -4.8374, -4.5503],\n",
       "                        [-4.7482, -5.0994, -5.4962]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0915, -5.0931, -5.4336],\n",
       "                        [-5.5121, -4.8930, -4.7077],\n",
       "                        [-5.8518, -5.3425, -5.3202]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7253, -4.8678, -8.1381],\n",
       "                        [-4.9845, -4.8897, -4.6614],\n",
       "                        [-5.1148, -5.6913, -4.5134]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.4124, -4.6069, -4.6163],\n",
       "                        [-4.7889, -4.6302, -4.5445],\n",
       "                        [-7.3645, -5.5767, -9.6875]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5822, -4.9812, -5.0012],\n",
       "                        [-5.5734, -5.0382, -4.6572],\n",
       "                        [-4.6436, -4.9465, -4.9866]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.6709, -5.7624, -5.4986],\n",
       "                        [-5.5840, -5.3101, -5.3511],\n",
       "                        [-5.5163, -5.8435, -4.6970]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6610, -5.5517, -4.7898],\n",
       "                        [-7.3700, -4.8614, -4.6162],\n",
       "                        [-4.8113, -5.0112, -5.8599]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1055, -4.6530, -4.5198],\n",
       "                        [-5.5741, -4.5083, -4.6232],\n",
       "                        [-4.5580, -7.1244, -5.3255]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7974, -4.5752, -5.1309],\n",
       "                        [-5.0613, -5.2168, -5.6367],\n",
       "                        [-4.5335, -5.8672, -5.7320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.2508, -5.1829, -5.2588],\n",
       "                        [-4.5323, -4.5324, -5.5526],\n",
       "                        [-5.0976, -4.9525, -5.3801]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7358, -4.7794, -6.2832],\n",
       "                        [-5.8387, -5.7460, -4.6199],\n",
       "                        [-5.7388, -4.6168, -5.2082]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6110, -7.3231, -5.2631],\n",
       "                        [-4.7704, -7.4566, -7.0914],\n",
       "                        [-6.4019, -5.3604, -4.5101]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0274, -5.7887, -5.3695],\n",
       "                        [-5.2984, -5.4268, -5.3807],\n",
       "                        [-6.6492, -4.9058, -5.9912]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.2869, -5.0658, -6.6944],\n",
       "                        [-4.8021, -4.7659, -5.0457],\n",
       "                        [-4.5254, -4.9072, -4.7691]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1072, -4.5126, -6.9205],\n",
       "                        [-7.2312, -6.0357, -4.9434],\n",
       "                        [-5.8425, -5.8011, -6.6572]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6017, -7.0950, -4.7288],\n",
       "                        [-5.0837, -5.0076, -4.8599],\n",
       "                        [-4.8932, -5.2993, -7.1005]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0865, -6.8230, -7.3988],\n",
       "                        [-5.0311, -6.8726, -4.6263],\n",
       "                        [-4.6748, -6.1102, -4.6278]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0524, -4.5554, -6.4664],\n",
       "                        [-5.2811, -5.4605, -7.2217],\n",
       "                        [-5.4769, -4.7483, -4.8038]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.2155, -4.8328, -5.8391],\n",
       "                        [-4.9348, -5.5655, -4.5172],\n",
       "                        [-5.4284, -5.6883, -5.2067]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6109, -4.9042, -5.5657],\n",
       "                        [-6.2078, -4.7449, -5.2510],\n",
       "                        [-4.8180, -5.4252, -5.6232]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5148, -5.6138, -5.0603],\n",
       "                        [-5.4398, -4.5060, -5.5740],\n",
       "                        [-5.5591, -5.7289, -4.6606]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5777, -5.9767, -4.7374],\n",
       "                        [-4.5777, -6.7465, -5.0135],\n",
       "                        [-4.9469, -4.7403, -4.7969]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.3945, -4.8958, -5.7981],\n",
       "                        [-6.0693, -5.4600, -4.5970],\n",
       "                        [-8.4901, -5.6858, -5.4706]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9696, -5.7327, -4.5306],\n",
       "                        [-5.2280, -6.3003, -7.6783],\n",
       "                        [-6.5668, -5.4665, -4.6462]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6187, -5.6168, -4.8436],\n",
       "                        [-4.6501, -4.8100, -6.8012],\n",
       "                        [-4.6272, -5.6021, -5.7383]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.3196, -7.6217, -5.8873],\n",
       "                        [-6.0669, -6.8977, -4.6564],\n",
       "                        [-4.6215, -4.6971, -6.5408]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5443, -6.1846, -7.3408],\n",
       "                        [-5.0217, -5.5628, -6.6559],\n",
       "                        [-5.9232, -5.5818, -4.9753]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8458, -4.6169, -4.7797],\n",
       "                        [-4.7002, -4.5778, -4.5995],\n",
       "                        [-4.7872, -5.4067, -4.8928]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7505, -5.2802, -9.0885],\n",
       "                        [-4.6295, -6.1010, -5.0751],\n",
       "                        [-4.7578, -5.8410, -6.0650]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_alphas_log',\n",
       "              tensor([[[[-2.1656, -2.8313, -3.1897],\n",
       "                        [-3.7559, -1.9414, -2.7531],\n",
       "                        [-2.5209, -3.7635, -2.6003]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3190, -2.6896, -2.7055],\n",
       "                        [-3.5347, -3.0708, -3.2343],\n",
       "                        [-3.5211, -2.6336, -2.2161]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5861, -2.9408, -3.5877],\n",
       "                        [-2.2992, -3.2803, -2.8852],\n",
       "                        [-3.8348, -3.8868, -3.6372]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4799, -2.7986, -3.2390],\n",
       "                        [-2.7369, -2.6498, -3.1071],\n",
       "                        [-3.7187, -2.5780, -3.6896]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7298, -3.5546, -2.2203],\n",
       "                        [-2.5847, -2.8220, -2.0417],\n",
       "                        [-2.6505, -3.6031, -3.8399]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1033, -3.1616, -2.6150],\n",
       "                        [-3.4758, -3.4801, -2.9160],\n",
       "                        [-3.2757, -3.5604, -1.9848]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8851, -2.1242, -3.0794],\n",
       "                        [-2.0779, -2.9997, -2.2112],\n",
       "                        [-3.6805, -3.2975, -3.8258]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6261, -2.0192, -3.5873],\n",
       "                        [-2.3763, -3.1825, -2.9759],\n",
       "                        [-2.6604, -3.1916, -3.0677]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4376, -1.9332, -2.1672],\n",
       "                        [-2.4401, -2.5056, -2.3208],\n",
       "                        [-3.3240, -2.0323, -2.5760]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8836, -3.8119, -2.9310],\n",
       "                        [-3.1352, -2.4914, -3.5200],\n",
       "                        [-3.2275, -3.1431, -2.9105]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0748, -1.9777, -2.3372],\n",
       "                        [-2.5128, -3.2950, -2.8525],\n",
       "                        [-3.8248, -3.0538, -2.5222]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8780, -1.9247, -2.4913],\n",
       "                        [-3.6901, -2.7369, -3.3810],\n",
       "                        [-2.2850, -2.5693, -2.5503]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7855, -2.3487, -3.5889],\n",
       "                        [-3.3511, -1.9445, -3.6633],\n",
       "                        [-3.5055, -2.4002, -2.9843]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8816, -3.0363, -2.6254],\n",
       "                        [-3.3271, -2.1409, -2.1695],\n",
       "                        [-3.6061, -2.5542, -3.8429]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3104, -3.1800, -2.8282],\n",
       "                        [-3.3821, -2.7332, -2.8195],\n",
       "                        [-2.8376, -2.7737, -2.5196]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8592, -3.2943, -3.4896],\n",
       "                        [-2.1154, -3.5231, -2.4944],\n",
       "                        [-2.4879, -3.1572, -3.0778]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4483, -3.3814, -3.1043],\n",
       "                        [-3.7298, -2.4274, -2.6944],\n",
       "                        [-2.5796, -2.1398, -3.8099]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3650, -2.8860, -3.4535],\n",
       "                        [-3.5046, -2.4781, -3.5875],\n",
       "                        [-3.2580, -3.2620, -2.4070]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6891, -2.1009, -2.2811],\n",
       "                        [-3.7421, -2.7268, -2.6971],\n",
       "                        [-2.2592, -2.6918, -3.1943]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.7352, -2.3382, -3.6163],\n",
       "                        [-2.4535, -2.8781, -2.0608],\n",
       "                        [-3.5351, -3.6502, -2.8834]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1263, -2.7150, -2.0665],\n",
       "                        [-2.2057, -3.8134, -1.9617],\n",
       "                        [-2.8084, -2.8408, -2.5782]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9472, -2.6228, -3.0317],\n",
       "                        [-3.1226, -2.7266, -2.5557],\n",
       "                        [-3.5313, -3.3001, -3.6282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5222, -3.3412, -3.2102],\n",
       "                        [-2.0757, -2.9891, -3.0093],\n",
       "                        [-3.0459, -2.2922, -2.7981]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3598, -3.3712, -3.6771],\n",
       "                        [-3.7664, -3.0120, -2.6183],\n",
       "                        [-2.3780, -2.0181, -2.9821]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0907, -3.8479, -2.6108],\n",
       "                        [-2.2947, -3.4294, -1.9833],\n",
       "                        [-2.1941, -3.3391, -2.2643]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1374, -3.2276, -3.3194],\n",
       "                        [-3.4144, -2.4596, -2.4564],\n",
       "                        [-3.5332, -2.5259, -3.4062]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8431, -3.6818, -2.1979],\n",
       "                        [-2.4032, -2.7068, -3.6511],\n",
       "                        [-1.9606, -2.7038, -2.9645]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8544, -1.9028, -3.6254],\n",
       "                        [-1.9382, -1.9560, -1.9926],\n",
       "                        [-3.2548, -3.1683, -3.5432]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3266, -2.6634, -3.4826],\n",
       "                        [-2.5871, -3.3503, -2.8560],\n",
       "                        [-2.3734, -2.5351, -2.4837]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8825, -3.0880, -2.4741],\n",
       "                        [-3.5321, -2.7679, -1.9088],\n",
       "                        [-3.2670, -3.2943, -3.0703]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8578, -2.2743, -2.2106],\n",
       "                        [-2.3908, -3.6898, -3.1190],\n",
       "                        [-3.5460, -2.0194, -3.8228]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4631, -3.5400, -3.7418],\n",
       "                        [-2.9146, -2.6512, -2.8175],\n",
       "                        [-3.0022, -2.8488, -2.0239]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.1.param_mus',\n",
       "              tensor([ 0.0722,  0.0733, -0.0899, -0.0104, -0.0211,  0.1457,  0.0728, -0.0882,\n",
       "                       0.0640,  0.0281, -0.0071,  0.0527, -0.1161,  0.0291,  0.0930, -0.0535,\n",
       "                      -0.1640, -0.1894,  0.0269,  0.0336, -0.0577,  0.0333, -0.0280,  0.0455,\n",
       "                       0.0229,  0.0950,  0.0414,  0.1834, -0.0817,  0.0017, -0.1367,  0.0178])),\n",
       "             ('module_list.0.posterior_params.1.param_std_log',\n",
       "              tensor([-4.5823, -5.0120, -5.0417, -6.6590, -5.0081, -5.4865, -4.5533, -4.6962,\n",
       "                      -4.7273, -4.8152, -5.5687, -4.8656, -5.4522, -4.7463, -4.5594, -5.9201,\n",
       "                      -4.6876, -4.6390, -4.6326, -5.7309, -4.6031, -5.1134, -5.4573, -5.4753,\n",
       "                      -6.2204, -6.1383, -5.0558, -5.6006, -4.6324, -5.2742, -4.5533, -4.8260])),\n",
       "             ('module_list.0.posterior_params.1.scale_alphas_log',\n",
       "              tensor([-3.3316, -3.3183, -2.5636, -3.2293, -2.9645, -2.7708, -3.3117, -2.0624,\n",
       "                      -3.5219, -3.7738, -2.9745, -2.0179, -2.2853, -2.0825, -3.2267, -2.5397,\n",
       "                      -3.4405, -3.0472, -3.3088, -3.2413, -2.3815, -3.5919, -2.8555, -3.2838,\n",
       "                      -2.4840, -3.3480, -3.6027, -2.5144, -2.4284, -2.1805, -2.4025, -3.7845])),\n",
       "             ('module_list.0.posterior_params.1.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.2.param_mus',\n",
       "              tensor([[[[-0.0543, -0.0528,  0.0679],\n",
       "                        [-0.0684, -0.0938,  0.0494],\n",
       "                        [-0.0958,  0.0731,  0.0531]],\n",
       "              \n",
       "                       [[ 0.0599, -0.0720,  0.0913],\n",
       "                        [ 0.0974,  0.0507, -0.0890],\n",
       "                        [-0.0578,  0.0982, -0.0413]],\n",
       "              \n",
       "                       [[-0.0974,  0.0717,  0.0957],\n",
       "                        [-0.0933, -0.0523,  0.0643],\n",
       "                        [ 0.0715, -0.0411, -0.0665]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0577,  0.0465, -0.0569],\n",
       "                        [ 0.0435, -0.0551,  0.0709],\n",
       "                        [-0.0774, -0.0596,  0.0883]],\n",
       "              \n",
       "                       [[ 0.0522,  0.0591, -0.0852],\n",
       "                        [ 0.0887, -0.0418,  0.0784],\n",
       "                        [ 0.0690, -0.0972, -0.0847]],\n",
       "              \n",
       "                       [[-0.0480, -0.0417,  0.0512],\n",
       "                        [-0.0565, -0.0928,  0.0767],\n",
       "                        [-0.0563, -0.0830, -0.0900]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0602, -0.0877,  0.0564],\n",
       "                        [ 0.0417, -0.0958, -0.0685],\n",
       "                        [ 0.0800,  0.0897,  0.0672]],\n",
       "              \n",
       "                       [[ 0.0951, -0.0689,  0.0852],\n",
       "                        [-0.0988,  0.0862,  0.0682],\n",
       "                        [ 0.0908, -0.0698, -0.0579]],\n",
       "              \n",
       "                       [[ 0.0860,  0.0721,  0.0938],\n",
       "                        [-0.0541,  0.0635, -0.0419],\n",
       "                        [-0.0461,  0.0643,  0.0789]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0451,  0.0967, -0.0724],\n",
       "                        [ 0.0978,  0.0777,  0.0635],\n",
       "                        [-0.0768,  0.0717,  0.0448]],\n",
       "              \n",
       "                       [[ 0.0908, -0.0564,  0.0842],\n",
       "                        [-0.0515, -0.0420,  0.0599],\n",
       "                        [-0.0605, -0.0961, -0.0698]],\n",
       "              \n",
       "                       [[ 0.0629, -0.0717, -0.0515],\n",
       "                        [ 0.0945,  0.0652,  0.0999],\n",
       "                        [ 0.0488,  0.0475,  0.0729]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0534, -0.0945,  0.0601],\n",
       "                        [ 0.0621,  0.0809,  0.0791],\n",
       "                        [-0.0445, -0.0447, -0.0711]],\n",
       "              \n",
       "                       [[-0.0918, -0.0803,  0.0963],\n",
       "                        [-0.0557, -0.0629, -0.0601],\n",
       "                        [-0.0452,  0.0753, -0.0893]],\n",
       "              \n",
       "                       [[ 0.0950,  0.0754, -0.0453],\n",
       "                        [-0.0646,  0.0778,  0.0770],\n",
       "                        [-0.0980, -0.0947, -0.0624]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0751,  0.0825,  0.0661],\n",
       "                        [ 0.0470, -0.0618, -0.0616],\n",
       "                        [-0.0905,  0.0754, -0.0875]],\n",
       "              \n",
       "                       [[ 0.0906, -0.0864, -0.0666],\n",
       "                        [-0.0440, -0.0586, -0.0743],\n",
       "                        [ 0.0851,  0.0531,  0.0748]],\n",
       "              \n",
       "                       [[-0.0608, -0.0798, -0.0740],\n",
       "                        [ 0.0456,  0.0657, -0.0829],\n",
       "                        [-0.0756,  0.0951,  0.0535]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0911,  0.0729,  0.0648],\n",
       "                        [-0.0674, -0.0551,  0.0938],\n",
       "                        [ 0.0445,  0.0811, -0.0910]],\n",
       "              \n",
       "                       [[ 0.0560,  0.0862, -0.0442],\n",
       "                        [ 0.0870, -0.0954, -0.0500],\n",
       "                        [-0.0630,  0.0816, -0.0712]],\n",
       "              \n",
       "                       [[-0.0716, -0.0906,  0.0993],\n",
       "                        [ 0.0558, -0.0453,  0.0997],\n",
       "                        [-0.0952, -0.0723, -0.0735]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0443, -0.0896, -0.0576],\n",
       "                        [-0.0863,  0.0443,  0.0895],\n",
       "                        [-0.0411, -0.0682,  0.0722]],\n",
       "              \n",
       "                       [[-0.0622, -0.0811,  0.0447],\n",
       "                        [ 0.0866, -0.0504,  0.0928],\n",
       "                        [-0.0714,  0.0483,  0.0623]],\n",
       "              \n",
       "                       [[-0.0457,  0.0445, -0.0953],\n",
       "                        [ 0.0566, -0.0637, -0.0671],\n",
       "                        [ 0.0782, -0.0922,  0.0769]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0715,  0.0802,  0.0974],\n",
       "                        [ 0.0613,  0.0974, -0.0922],\n",
       "                        [ 0.0996, -0.0448,  0.0747]],\n",
       "              \n",
       "                       [[-0.0822, -0.0657, -0.0548],\n",
       "                        [ 0.0887,  0.0497,  0.0930],\n",
       "                        [-0.0617, -0.0936, -0.0940]],\n",
       "              \n",
       "                       [[-0.0568, -0.0634,  0.0568],\n",
       "                        [-0.0863, -0.0872,  0.0700],\n",
       "                        [ 0.0760,  0.0525, -0.0994]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0816, -0.0997,  0.0805],\n",
       "                        [-0.0627,  0.0690,  0.0928],\n",
       "                        [ 0.0783,  0.0609, -0.0511]],\n",
       "              \n",
       "                       [[-0.0542,  0.0690,  0.0771],\n",
       "                        [-0.0476,  0.0888, -0.0874],\n",
       "                        [ 0.0885, -0.0581,  0.0724]],\n",
       "              \n",
       "                       [[ 0.0876, -0.0466, -0.0848],\n",
       "                        [-0.0764,  0.0742, -0.0892],\n",
       "                        [ 0.0499,  0.0903,  0.0756]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0924,  0.0755, -0.0453],\n",
       "                        [ 0.0411,  0.0730,  0.0772],\n",
       "                        [-0.0491,  0.0868, -0.0686]],\n",
       "              \n",
       "                       [[-0.0687,  0.0520, -0.0664],\n",
       "                        [-0.0575,  0.0473,  0.0887],\n",
       "                        [-0.0667, -0.0861,  0.0510]],\n",
       "              \n",
       "                       [[-0.0819, -0.0580, -0.0564],\n",
       "                        [ 0.0731, -0.0582,  0.0533],\n",
       "                        [ 0.0994,  0.0793,  0.0497]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0816,  0.0763,  0.0938],\n",
       "                        [-0.0963,  0.0525,  0.0794],\n",
       "                        [ 0.0931,  0.0867,  0.0789]],\n",
       "              \n",
       "                       [[ 0.0954,  0.0709, -0.0437],\n",
       "                        [ 0.0694,  0.0757, -0.0606],\n",
       "                        [ 0.0964,  0.0817, -0.0982]],\n",
       "              \n",
       "                       [[ 0.0498, -0.0625, -0.0953],\n",
       "                        [-0.0914,  0.0557, -0.0933],\n",
       "                        [-0.0554, -0.0831,  0.0578]]]])),\n",
       "             ('module_list.0.posterior_params.2.param_std_log',\n",
       "              tensor([[[[ -7.8482,  -5.5446,  -4.9488],\n",
       "                        [ -5.5632,  -4.6945, -10.0113],\n",
       "                        [ -5.7864,  -5.5138,  -4.8230]],\n",
       "              \n",
       "                       [[ -4.7062,  -6.2943,  -5.8556],\n",
       "                        [ -7.0677,  -4.5561,  -4.7093],\n",
       "                        [ -4.9335,  -6.1419,  -5.0247]],\n",
       "              \n",
       "                       [[ -6.2807,  -6.6489,  -7.1646],\n",
       "                        [ -5.3482,  -4.6501,  -4.5973],\n",
       "                        [ -4.5629,  -6.8174,  -6.1606]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.6966,  -5.4463,  -5.8728],\n",
       "                        [ -4.7907,  -4.8927,  -4.5239],\n",
       "                        [ -6.9427,  -5.8416,  -4.6146]],\n",
       "              \n",
       "                       [[ -4.5538,  -6.1857,  -6.5273],\n",
       "                        [ -4.5373,  -4.9213,  -4.7717],\n",
       "                        [ -4.5929,  -5.5642,  -4.6867]],\n",
       "              \n",
       "                       [[ -5.9398,  -8.4648,  -5.9121],\n",
       "                        [ -8.8938,  -4.5657,  -5.0359],\n",
       "                        [ -4.5285,  -6.4324,  -5.2730]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9499,  -5.0614,  -4.6895],\n",
       "                        [ -4.6775,  -4.8833,  -5.1666],\n",
       "                        [ -4.6959,  -4.5708,  -8.2176]],\n",
       "              \n",
       "                       [[ -5.4450,  -6.0871,  -4.8775],\n",
       "                        [ -6.1970,  -4.6406, -11.6967],\n",
       "                        [ -4.8615,  -7.3687,  -7.0940]],\n",
       "              \n",
       "                       [[ -6.0608,  -4.5088,  -5.1569],\n",
       "                        [ -4.5296,  -4.7435,  -5.9496],\n",
       "                        [ -4.7558,  -4.9714,  -4.5841]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.7187,  -5.3306,  -5.2697],\n",
       "                        [ -4.9694,  -6.7508,  -5.1481],\n",
       "                        [ -4.7786,  -5.1283,  -5.8924]],\n",
       "              \n",
       "                       [[ -4.6811,  -4.6916,  -5.9435],\n",
       "                        [ -4.7535,  -7.2105,  -4.8157],\n",
       "                        [ -6.1415,  -4.9037,  -4.9599]],\n",
       "              \n",
       "                       [[ -5.9500,  -5.5154,  -8.7608],\n",
       "                        [ -8.3636,  -5.5323,  -5.0985],\n",
       "                        [ -5.8177,  -4.5361,  -7.2734]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6436,  -4.6930,  -4.5155],\n",
       "                        [ -5.4273,  -6.1869,  -4.6422],\n",
       "                        [ -4.6453,  -6.3473,  -4.5497]],\n",
       "              \n",
       "                       [[ -6.2151,  -6.7176,  -4.5527],\n",
       "                        [ -5.1828,  -5.1079,  -5.5149],\n",
       "                        [ -5.7413,  -6.2438,  -4.7074]],\n",
       "              \n",
       "                       [[ -5.0253,  -5.0069,  -5.1433],\n",
       "                        [ -5.2101,  -5.7092,  -6.1678],\n",
       "                        [ -5.6070,  -6.4209,  -4.8505]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -6.2180,  -5.6369,  -5.3354],\n",
       "                        [ -5.4139,  -6.4043,  -7.1416],\n",
       "                        [ -5.0444,  -5.3227,  -4.6195]],\n",
       "              \n",
       "                       [[ -4.7779,  -9.0784,  -4.7232],\n",
       "                        [ -5.0804,  -4.5211,  -5.0767],\n",
       "                        [ -4.7795,  -6.1748,  -5.3843]],\n",
       "              \n",
       "                       [[ -8.6068,  -5.1375,  -5.8896],\n",
       "                        [ -5.0830,  -5.9639,  -7.0651],\n",
       "                        [ -4.6582,  -6.6854,  -5.8238]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ -4.8694,  -5.6045,  -6.6212],\n",
       "                        [ -5.2665,  -4.5291,  -6.2978],\n",
       "                        [ -5.2571,  -6.3740,  -6.3940]],\n",
       "              \n",
       "                       [[ -4.9734,  -6.2658,  -4.8627],\n",
       "                        [ -6.0921,  -5.4122,  -7.2943],\n",
       "                        [ -4.9997,  -4.8688,  -5.2375]],\n",
       "              \n",
       "                       [[ -4.7778,  -4.6657,  -5.3108],\n",
       "                        [ -5.8216,  -4.8369,  -5.8292],\n",
       "                        [ -7.8927,  -6.4024,  -6.3432]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.1343,  -5.7357,  -5.4967],\n",
       "                        [ -5.5267,  -6.9923,  -5.3164],\n",
       "                        [ -4.6949,  -6.4456,  -4.5778]],\n",
       "              \n",
       "                       [[ -8.2982,  -5.4327,  -7.0845],\n",
       "                        [ -4.8825,  -4.9547,  -7.0068],\n",
       "                        [ -6.3262,  -4.8699,  -9.8431]],\n",
       "              \n",
       "                       [[ -7.1396,  -4.9343,  -4.9280],\n",
       "                        [ -5.5623,  -7.9643,  -7.1118],\n",
       "                        [ -6.8246,  -4.9429,  -5.5829]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.5470,  -4.5272,  -5.5862],\n",
       "                        [ -4.6309,  -4.7179,  -5.2435],\n",
       "                        [ -4.5726,  -4.8010,  -5.4668]],\n",
       "              \n",
       "                       [[ -4.8401,  -4.5447,  -4.5188],\n",
       "                        [ -5.9191,  -6.1594,  -7.0846],\n",
       "                        [ -4.8668,  -4.9145,  -4.6296]],\n",
       "              \n",
       "                       [[ -4.5854,  -5.0998,  -5.9532],\n",
       "                        [ -4.9372,  -4.7409,  -4.5725],\n",
       "                        [ -5.2167,  -6.2000,  -5.0313]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.8783,  -5.0521,  -4.7305],\n",
       "                        [ -5.7161,  -5.7156,  -5.4134],\n",
       "                        [ -5.5599,  -5.3641,  -5.8688]],\n",
       "              \n",
       "                       [[ -6.2995,  -6.1377,  -4.5377],\n",
       "                        [ -5.6938,  -6.4026,  -5.5412],\n",
       "                        [ -4.8534,  -7.1053,  -7.5992]],\n",
       "              \n",
       "                       [[ -4.8176,  -6.9332,  -6.2554],\n",
       "                        [ -6.2990,  -4.9760,  -4.5203],\n",
       "                        [ -5.6118,  -4.9666,  -6.3976]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6314,  -5.1782,  -5.1955],\n",
       "                        [ -5.3849,  -4.9848,  -5.8803],\n",
       "                        [ -4.8543,  -4.8410,  -4.7884]],\n",
       "              \n",
       "                       [[ -4.9707,  -6.0176,  -5.1651],\n",
       "                        [ -4.7002,  -6.3830,  -4.5349],\n",
       "                        [ -6.4150,  -4.6113,  -5.2856]],\n",
       "              \n",
       "                       [[ -4.8682,  -6.2621,  -5.4253],\n",
       "                        [ -8.9318,  -4.7626,  -5.2880],\n",
       "                        [ -6.7121,  -4.6663,  -4.6246]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.4061,  -5.9112,  -5.0756],\n",
       "                        [ -4.8783,  -4.6552,  -6.5308],\n",
       "                        [ -5.0075,  -5.2413,  -7.3721]],\n",
       "              \n",
       "                       [[ -4.7490,  -5.2898,  -6.3604],\n",
       "                        [ -4.5390,  -5.2630,  -4.6799],\n",
       "                        [ -5.1411,  -4.7650,  -4.7565]],\n",
       "              \n",
       "                       [[ -4.8305,  -4.8108,  -6.5429],\n",
       "                        [ -4.5151,  -4.9174,  -4.6999],\n",
       "                        [ -4.8407,  -5.2677,  -4.7082]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_alphas_log',\n",
       "              tensor([[[[-3.2974, -2.9047, -3.8543],\n",
       "                        [-2.3534, -2.7284, -3.3108],\n",
       "                        [-3.1750, -2.5670, -2.3381]],\n",
       "              \n",
       "                       [[-3.2396, -3.4470, -2.5506],\n",
       "                        [-2.8152, -2.6822, -2.0510],\n",
       "                        [-2.8307, -2.0754, -3.6764]],\n",
       "              \n",
       "                       [[-3.8447, -3.8946, -2.7938],\n",
       "                        [-3.2933, -2.3266, -3.3125],\n",
       "                        [-2.6497, -2.1425, -3.5924]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.1848, -2.4136, -2.7363],\n",
       "                        [-3.4512, -2.9425, -3.6024],\n",
       "                        [-2.5968, -2.0690, -2.4901]],\n",
       "              \n",
       "                       [[-3.5309, -2.3699, -2.2785],\n",
       "                        [-1.9482, -3.6439, -3.8919],\n",
       "                        [-2.6244, -3.4054, -2.5393]],\n",
       "              \n",
       "                       [[-2.0936, -2.3871, -3.1719],\n",
       "                        [-1.9758, -3.7558, -2.5794],\n",
       "                        [-3.2790, -3.0774, -3.1541]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6034, -2.2505, -2.3866],\n",
       "                        [-3.0623, -3.6860, -2.2276],\n",
       "                        [-2.4239, -2.4506, -3.5861]],\n",
       "              \n",
       "                       [[-3.0405, -2.7337, -3.2777],\n",
       "                        [-3.4820, -2.2742, -3.3801],\n",
       "                        [-2.4183, -2.9151, -3.8524]],\n",
       "              \n",
       "                       [[-2.3363, -3.8824, -3.4994],\n",
       "                        [-2.2119, -3.8686, -2.2530],\n",
       "                        [-2.4764, -3.4693, -2.2571]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.6981, -3.8845, -3.8419],\n",
       "                        [-3.1510, -3.5511, -2.0669],\n",
       "                        [-3.1578, -2.5096, -3.1502]],\n",
       "              \n",
       "                       [[-3.4301, -3.8343, -2.6439],\n",
       "                        [-1.9183, -2.6477, -2.6708],\n",
       "                        [-3.6084, -2.9211, -2.9176]],\n",
       "              \n",
       "                       [[-3.1087, -3.4006, -2.3918],\n",
       "                        [-2.5101, -2.4441, -2.9148],\n",
       "                        [-2.7065, -1.9141, -2.9141]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6588, -2.5818, -2.9064],\n",
       "                        [-2.6051, -2.7940, -2.7249],\n",
       "                        [-3.2562, -3.2963, -3.1645]],\n",
       "              \n",
       "                       [[-2.4670, -3.5128, -2.9415],\n",
       "                        [-2.0714, -2.8873, -2.7841],\n",
       "                        [-2.8853, -2.9690, -1.9670]],\n",
       "              \n",
       "                       [[-2.1023, -2.8246, -3.4848],\n",
       "                        [-2.7842, -3.3190, -2.8133],\n",
       "                        [-3.6649, -3.6256, -3.8919]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.0871, -2.9683, -3.0094],\n",
       "                        [-2.1089, -2.5902, -2.5222],\n",
       "                        [-2.2616, -2.2460, -2.9923]],\n",
       "              \n",
       "                       [[-2.7944, -3.5476, -3.0203],\n",
       "                        [-3.7799, -2.4137, -2.2978],\n",
       "                        [-3.1904, -2.4651, -2.2475]],\n",
       "              \n",
       "                       [[-3.2122, -2.7808, -3.4037],\n",
       "                        [-2.4360, -3.8299, -2.7257],\n",
       "                        [-2.9773, -1.9743, -2.6542]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.4126, -3.0179, -2.2798],\n",
       "                        [-3.6954, -3.3032, -2.3929],\n",
       "                        [-2.7975, -3.5901, -2.4594]],\n",
       "              \n",
       "                       [[-2.6177, -3.7952, -2.7770],\n",
       "                        [-3.0024, -3.6926, -2.9551],\n",
       "                        [-2.2676, -3.3726, -3.4931]],\n",
       "              \n",
       "                       [[-3.1263, -2.7758, -2.6888],\n",
       "                        [-3.1989, -2.7270, -3.7907],\n",
       "                        [-2.4193, -3.6149, -1.9035]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.4055, -3.1308, -3.1690],\n",
       "                        [-2.3890, -1.9199, -3.7651],\n",
       "                        [-3.0442, -3.0790, -3.4259]],\n",
       "              \n",
       "                       [[-2.2687, -2.6848, -2.6269],\n",
       "                        [-2.7907, -2.3756, -3.1159],\n",
       "                        [-3.6137, -3.6144, -2.5043]],\n",
       "              \n",
       "                       [[-2.2209, -3.8760, -3.7623],\n",
       "                        [-3.0063, -3.1466, -2.0529],\n",
       "                        [-2.1533, -2.2931, -3.8953]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2547, -3.4762, -3.1113],\n",
       "                        [-3.6711, -3.0991, -2.2952],\n",
       "                        [-2.0947, -2.7076, -3.3536]],\n",
       "              \n",
       "                       [[-3.1393, -2.4551, -3.8737],\n",
       "                        [-3.1898, -3.3853, -3.0046],\n",
       "                        [-2.5017, -2.5049, -2.6958]],\n",
       "              \n",
       "                       [[-2.9313, -2.6121, -2.9859],\n",
       "                        [-3.0009, -2.2647, -3.4889],\n",
       "                        [-3.2916, -2.3375, -3.0539]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.6121, -3.1852, -2.4452],\n",
       "                        [-1.9730, -3.5932, -2.7319],\n",
       "                        [-2.5346, -2.9089, -2.8310]],\n",
       "              \n",
       "                       [[-2.1459, -2.5999, -3.8913],\n",
       "                        [-2.4562, -3.3154, -2.7265],\n",
       "                        [-2.6393, -3.2717, -3.3998]],\n",
       "              \n",
       "                       [[-3.6633, -2.1542, -3.0159],\n",
       "                        [-2.7407, -3.8723, -3.6903],\n",
       "                        [-3.4797, -3.0115, -2.2283]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9422, -3.3802, -2.2317],\n",
       "                        [-3.5915, -2.7868, -3.4850],\n",
       "                        [-3.3586, -1.9073, -3.4935]],\n",
       "              \n",
       "                       [[-2.3720, -2.3331, -2.8196],\n",
       "                        [-3.7759, -2.6659, -2.7876],\n",
       "                        [-2.4592, -3.4411, -2.8243]],\n",
       "              \n",
       "                       [[-2.2779, -1.9580, -2.7823],\n",
       "                        [-3.2104, -2.7004, -3.2093],\n",
       "                        [-2.5119, -3.6620, -2.8820]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3303, -3.4739, -3.5278],\n",
       "                        [-2.1379, -3.3382, -1.9354],\n",
       "                        [-3.2526, -3.5956, -3.6753]],\n",
       "              \n",
       "                       [[-3.3129, -2.1374, -3.5231],\n",
       "                        [-2.4335, -2.3653, -3.1095],\n",
       "                        [-2.7764, -3.5714, -2.3968]],\n",
       "              \n",
       "                       [[-2.9843, -3.3058, -3.1824],\n",
       "                        [-2.3156, -2.1707, -2.2711],\n",
       "                        [-3.4930, -2.5220, -3.0450]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.3.param_mus',\n",
       "              tensor([-0.0975, -0.0970,  0.0845,  0.0428, -0.0750, -0.0479,  0.0428,  0.0571,\n",
       "                      -0.0993,  0.0844,  0.0475,  0.0529, -0.0723,  0.0565, -0.0454, -0.0439,\n",
       "                       0.0965,  0.0449, -0.0653, -0.0740,  0.0604,  0.0993,  0.0656,  0.0825,\n",
       "                      -0.0926, -0.0909,  0.0856,  0.0656, -0.0605, -0.0902,  0.0490,  0.0763,\n",
       "                      -0.0661,  0.0634,  0.0529,  0.0509,  0.0833, -0.0764,  0.0833, -0.0414,\n",
       "                       0.0443,  0.0979,  0.0849, -0.0989,  0.0518, -0.0644,  0.0823, -0.0422,\n",
       "                      -0.0424,  0.0814,  0.0494,  0.0875, -0.0600, -0.0699, -0.0468, -0.0554,\n",
       "                       0.0768,  0.0960, -0.0637,  0.0747, -0.0720,  0.0525,  0.0958, -0.0599])),\n",
       "             ('module_list.0.posterior_params.3.param_std_log',\n",
       "              tensor([-5.2171, -6.1672, -5.3787, -4.6509, -4.5339, -5.0559, -4.5283, -4.9851,\n",
       "                      -5.4101, -5.9530, -6.2740, -4.9355, -5.0441, -4.6699, -5.1972, -5.3986,\n",
       "                      -5.1593, -5.2402, -5.1183, -5.1291, -4.7448, -5.6040, -4.5557, -4.5792,\n",
       "                      -5.0848, -5.3902, -5.2814, -4.5864, -4.9080, -4.7587, -4.7928, -5.8545,\n",
       "                      -4.6741, -5.0513, -5.6447, -5.1321, -4.7404, -6.9569, -4.6387, -6.1318,\n",
       "                      -7.2692, -6.6240, -4.7472, -4.6294, -9.1428, -6.0488, -4.6530, -4.8919,\n",
       "                      -6.2818, -5.0811, -8.6813, -5.2949, -4.5741, -6.2511, -5.1095, -4.5525,\n",
       "                      -6.2224, -5.7657, -5.0969, -6.4636, -5.2114, -5.7074, -4.5862, -4.5279])),\n",
       "             ('module_list.0.posterior_params.3.scale_alphas_log',\n",
       "              tensor([-2.9667, -2.3115, -2.5292, -3.4824, -3.4569, -2.1628, -2.6692, -3.8506,\n",
       "                      -3.2947, -2.2228, -2.4568, -3.6055, -3.7198, -3.3077, -3.5781, -2.1138,\n",
       "                      -2.5315, -2.7309, -1.9950, -2.9499, -2.8111, -3.7727, -2.0560, -2.2723,\n",
       "                      -3.5129, -2.4914, -3.1700, -2.9405, -3.8902, -2.4770, -2.5732, -3.3456,\n",
       "                      -3.2356, -2.6484, -2.5982, -2.1873, -2.2878, -2.3157, -2.1212, -2.1365,\n",
       "                      -3.4705, -3.1546, -3.3279, -1.9482, -2.4941, -3.1363, -2.4512, -3.0149,\n",
       "                      -3.6714, -2.4241, -2.9396, -3.3239, -2.9290, -3.3640, -3.6241, -3.2853,\n",
       "                      -3.8815, -3.7306, -3.4897, -3.1178, -2.5035, -2.5990, -2.0653, -2.2198])),\n",
       "             ('module_list.0.posterior_params.3.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.4.param_mus',\n",
       "              tensor([[-0.0906, -0.0838, -0.0829,  ..., -0.0923, -0.0896,  0.0903],\n",
       "                      [ 0.0931, -0.0968,  0.0992,  ..., -0.0843, -0.0935,  0.0945],\n",
       "                      [-0.0861,  0.0877, -0.0906,  ...,  0.0948, -0.0887, -0.0911],\n",
       "                      ...,\n",
       "                      [ 0.0954, -0.0956, -0.0896,  ..., -0.0835,  0.0898, -0.0885],\n",
       "                      [ 0.0863,  0.0850,  0.0943,  ..., -0.0826, -0.0872, -0.0964],\n",
       "                      [ 0.0942,  0.0997, -0.0854,  ...,  0.0881,  0.0952,  0.0947]])),\n",
       "             ('module_list.0.posterior_params.4.param_std_log',\n",
       "              tensor([[-9.0770, -4.5493, -5.1618,  ..., -5.0888, -4.6293, -4.6190],\n",
       "                      [-4.7482, -5.3741, -4.9844,  ..., -5.2524, -6.0780, -5.8287],\n",
       "                      [-4.5179, -4.6243, -4.7461,  ..., -5.1522, -6.1432, -4.9598],\n",
       "                      ...,\n",
       "                      [-4.6115, -5.8856, -4.7179,  ..., -5.5802, -7.8000, -4.7182],\n",
       "                      [-4.6128, -6.6361, -4.9886,  ..., -7.4180, -4.5932, -5.7579],\n",
       "                      [-5.7266, -5.3227, -9.8273,  ..., -5.9020, -4.5586, -4.6548]])),\n",
       "             ('module_list.0.posterior_params.4.scale_alphas_log',\n",
       "              tensor([[-2.6925, -2.4106, -3.3986,  ..., -3.1691, -3.8465, -2.5782],\n",
       "                      [-2.8585, -3.2163, -2.4394,  ..., -2.2901, -3.2663, -2.4731],\n",
       "                      [-2.6929, -2.5564, -1.9852,  ..., -2.9302, -2.5985, -3.4513],\n",
       "                      ...,\n",
       "                      [-3.8364, -3.6861, -2.4803,  ..., -3.4810, -2.6650, -2.8532],\n",
       "                      [-2.8845, -3.1365, -2.1303,  ..., -2.1259, -2.3350, -2.8756],\n",
       "                      [-3.1230, -3.5729, -3.5671,  ..., -3.7631, -3.1399, -3.0781]])),\n",
       "             ('module_list.0.posterior_params.4.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.5.param_mus',\n",
       "              tensor([ 0.0842, -0.0960,  0.0947,  0.0915, -0.0983, -0.0938,  0.0874,  0.0989,\n",
       "                       0.0915,  0.0921,  0.0945, -0.0947, -0.0984,  0.0989, -0.0869, -0.0882,\n",
       "                       0.0973,  0.0914, -0.0881, -0.0947, -0.0990, -0.0869,  0.0925, -0.0972,\n",
       "                      -0.0845, -0.0858, -0.0871,  0.0914,  0.0947, -0.0955,  0.0857, -0.0843,\n",
       "                      -0.0947,  0.0870,  0.0911,  0.0903,  0.0832,  0.0844, -0.0997,  0.0842,\n",
       "                       0.0844, -0.0947, -0.0907, -0.0993,  0.0932,  0.0885,  0.0992,  0.0887,\n",
       "                       0.0982,  0.0876, -0.0906, -0.0924, -0.0944,  0.0904, -0.0849, -0.0960,\n",
       "                      -0.0982,  0.0871,  0.0857, -0.0858,  0.0840,  0.0872,  0.0875,  0.0965,\n",
       "                      -0.0831,  0.0851,  0.0947,  0.0935, -0.0920, -0.0986, -0.0829, -0.0989,\n",
       "                      -0.0824,  0.0854,  0.0994,  0.0912, -0.0866, -0.0958, -0.0971, -0.0894,\n",
       "                       0.0890, -0.0909, -0.0850,  0.0940,  0.0912, -0.0917,  0.0827,  0.0992,\n",
       "                       0.0859, -0.0919,  0.0989, -0.0971, -0.0869,  0.0997, -0.0824,  0.0920,\n",
       "                       0.0849, -0.0859, -0.0827,  0.0887, -0.0960,  0.0882,  0.0842, -0.0959,\n",
       "                       0.0931, -0.0980,  0.0875, -0.0888, -0.0973,  0.0968, -0.0946,  0.0943,\n",
       "                       0.0884,  0.0953, -0.0850, -0.0843, -0.0980, -0.0860, -0.0893, -0.0836,\n",
       "                      -0.0981, -0.0990, -0.0938, -0.0957,  0.0989, -0.0978,  0.0860,  0.0943])),\n",
       "             ('module_list.0.posterior_params.5.param_std_log',\n",
       "              tensor([ -5.7212,  -6.1508,  -4.5853,  -6.1894,  -4.7802,  -8.7901,  -5.2844,\n",
       "                       -4.5828,  -6.1033,  -4.9352,  -5.6516,  -4.7308,  -4.8552,  -5.7930,\n",
       "                       -5.4178,  -5.3955,  -5.0510,  -5.5755,  -8.6750,  -4.6968,  -5.0317,\n",
       "                       -7.0757,  -6.6151,  -5.5651,  -6.8987,  -4.7680,  -4.9640,  -5.1297,\n",
       "                       -5.3771,  -4.5066,  -5.1009,  -5.0633,  -4.8453,  -5.0673,  -6.3397,\n",
       "                       -6.0146,  -6.1190,  -4.6762,  -6.1135, -10.2706,  -4.5572,  -4.9949,\n",
       "                       -4.5320,  -4.6093,  -5.2380,  -4.6725,  -5.4686,  -4.5993,  -4.6588,\n",
       "                       -6.7573,  -4.6371,  -5.4331,  -5.3677,  -4.6910,  -5.1759,  -4.8373,\n",
       "                       -4.6801,  -6.3156,  -5.4423,  -5.9787,  -5.4375,  -5.3991,  -5.0945,\n",
       "                       -5.2291,  -5.1571,  -5.3673,  -6.4595,  -5.2973,  -8.3900,  -5.1131,\n",
       "                       -5.5663,  -4.5281,  -4.5712,  -5.9223,  -6.4504,  -4.5073,  -5.2971,\n",
       "                       -4.5174,  -4.5943,  -5.5641,  -7.8441,  -5.0459,  -5.2224,  -6.0845,\n",
       "                       -5.0189,  -6.4432,  -5.4145,  -4.6463,  -4.5753,  -4.9188,  -5.3023,\n",
       "                       -6.9867,  -5.6441,  -4.5254,  -5.0890,  -4.8886,  -4.6017,  -6.2958,\n",
       "                       -5.1794,  -6.1721,  -5.4811,  -4.5665,  -5.3905,  -5.0272,  -5.5994,\n",
       "                       -4.5507,  -4.5497,  -6.1250,  -5.0331,  -4.9789,  -7.1492,  -4.5120,\n",
       "                       -4.9481,  -4.7204,  -6.1890,  -5.8712,  -6.8163,  -5.3611,  -4.6504,\n",
       "                       -5.1954,  -5.4728,  -5.4914,  -5.9632,  -5.9729,  -4.6815,  -5.9720,\n",
       "                       -4.5500,  -5.6235])),\n",
       "             ('module_list.0.posterior_params.5.scale_alphas_log',\n",
       "              tensor([-3.1923, -2.9273, -2.7650, -2.5600, -2.9223, -3.4540, -2.6792, -3.1903,\n",
       "                      -3.5709, -1.9912, -2.0004, -2.2731, -3.3678, -3.7959, -3.0546, -3.5400,\n",
       "                      -3.2552, -3.2338, -3.8930, -1.9994, -3.5409, -3.1403, -3.7834, -2.5321,\n",
       "                      -3.8102, -2.6589, -2.5909, -2.2048, -3.3756, -3.2359, -2.9401, -2.2528,\n",
       "                      -2.9806, -3.1752, -2.0854, -3.8801, -3.8991, -2.7386, -3.2199, -2.4706,\n",
       "                      -2.9669, -3.5006, -2.3806, -2.9463, -3.7690, -3.6657, -2.5666, -2.6568,\n",
       "                      -3.6526, -2.1501, -3.5521, -2.8616, -3.6516, -3.8184, -3.4175, -2.6631,\n",
       "                      -3.1170, -1.9269, -2.7893, -3.4202, -3.7974, -3.5206, -3.7557, -3.4895,\n",
       "                      -2.7749, -2.1429, -2.3027, -3.2076, -2.1608, -2.9632, -2.2020, -2.8751,\n",
       "                      -2.4773, -3.7438, -2.5550, -2.5436, -2.9800, -2.7027, -1.9697, -3.2501,\n",
       "                      -2.1490, -2.4912, -2.7526, -3.7811, -2.4931, -2.4713, -2.6154, -1.9483,\n",
       "                      -2.8704, -2.3009, -2.0250, -2.5590, -3.6786, -3.8803, -2.3531, -2.2901,\n",
       "                      -2.1482, -2.0499, -2.9905, -2.9947, -2.0996, -1.9504, -3.3845, -3.2747,\n",
       "                      -2.8978, -2.3467, -2.1211, -3.4990, -3.5909, -3.6310, -3.2823, -3.2281,\n",
       "                      -2.7796, -2.0713, -2.7927, -2.9913, -3.1183, -2.2519, -2.8750, -3.5338,\n",
       "                      -3.8796, -2.2120, -3.6245, -2.5215, -3.8441, -2.2621, -2.3612, -2.9266])),\n",
       "             ('module_list.0.posterior_params.5.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('module_list.0.posterior_params.6.param_mus',\n",
       "              tensor([[ 0.0389, -0.0511, -0.0580,  ...,  0.0491, -0.0475, -0.0465],\n",
       "                      [-0.0484,  0.0485,  0.0407,  ..., -0.0881, -0.0954,  0.0446],\n",
       "                      [-0.0935,  0.0888,  0.0633,  ..., -0.0929,  0.0961, -0.0650],\n",
       "                      ...,\n",
       "                      [-0.0955, -0.0420, -0.0676,  ...,  0.0218,  0.0822,  0.0425],\n",
       "                      [ 0.0122,  0.0192,  0.0692,  ...,  0.0435,  0.0512,  0.0182],\n",
       "                      [-0.0559, -0.0984, -0.0871,  ...,  0.0164, -0.0732, -0.0519]])),\n",
       "             ('module_list.0.posterior_params.6.param_std_log',\n",
       "              tensor([[-4.9676, -6.5269, -5.3594,  ..., -5.4614, -5.3342, -4.8485],\n",
       "                      [-5.4030, -4.5170, -5.4515,  ..., -5.2194, -4.6959, -4.6491],\n",
       "                      [-5.0029, -4.9895, -6.4804,  ..., -4.7361, -4.9224, -5.3589],\n",
       "                      ...,\n",
       "                      [-5.4832, -6.2456, -6.0005,  ..., -5.6552, -5.0081, -4.9574],\n",
       "                      [-7.4754, -5.1637, -4.7861,  ..., -5.2114, -4.5501, -5.0992],\n",
       "                      [-4.9423, -5.5591, -8.3432,  ..., -6.0531, -5.0218, -5.0620]])),\n",
       "             ('module_list.0.posterior_params.6.scale_alphas_log',\n",
       "              tensor([[-2.3897, -3.8291, -3.2094,  ..., -2.0571, -3.3160, -3.7339],\n",
       "                      [-1.9342, -3.1010, -2.0428,  ..., -2.7818, -3.8913, -3.7423],\n",
       "                      [-1.9629, -2.7612, -2.0519,  ..., -2.6547, -3.0411, -3.2980],\n",
       "                      ...,\n",
       "                      [-1.9756, -2.1950, -3.8114,  ..., -2.9087, -3.3558, -2.8456],\n",
       "                      [-3.5745, -2.1296, -2.5913,  ..., -2.1163, -3.1350, -1.9151],\n",
       "                      [-2.1335, -2.8678, -3.0901,  ..., -2.7281, -2.6702, -3.4782]])),\n",
       "             ('module_list.0.posterior_params.6.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.7.param_mus',\n",
       "              tensor([-0.0149, -0.0698, -0.0975,  0.0988, -0.0179,  0.0420,  0.0281,  0.0993,\n",
       "                       0.0383, -0.0719])),\n",
       "             ('module_list.0.posterior_params.7.param_std_log',\n",
       "              tensor([-4.5862, -5.3847, -9.6135, -5.2890, -5.8250, -5.7961, -4.5619, -4.7953,\n",
       "                      -5.0516, -4.7084])),\n",
       "             ('module_list.0.posterior_params.7.scale_alphas_log',\n",
       "              tensor([-2.2857, -3.0481, -2.7567, -3.6157, -2.0071, -3.0056, -3.2564, -2.5474,\n",
       "                      -2.5068, -3.3515])),\n",
       "             ('module_list.0.posterior_params.7.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2608, -0.3241,  0.5980, -0.1901, -0.0699,  0.2316, -0.0549,  0.1312,\n",
      "          0.1061, -0.1890]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.2608, -0.3241,  0.5980, -0.1901, -0.0699,  0.2316, -0.0549,  0.1312,\n",
      "          0.1061, -0.1890]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(bayes_model(torch.zeros_like(image)))\n",
    "#print(bayes_model(torch.zeros_like(image), sample = False))\n",
    "print(module(torch.zeros_like(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.bayes.variational.trainer import VarBayesTrainer, VarTrainerParams, Beta_Scheduler_Plato, CallbackLossAccuracy\n",
    "from src.methods.report.base import ReportChain\n",
    "from src.methods.report.variational import VarBaseReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = Beta_Scheduler_Plato()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.], requires_grad=True)\n",
      "tensor([1., 4.], grad_fn=<PowBackward0>)\n",
      "Parameter containing:\n",
      "tensor([1., 4.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 4.], requires_grad=True)\n",
      "tensor([1., 2.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2.], requires_grad=True)\n",
    "print(x)\n",
    "y = x ** 2\n",
    "print(y)\n",
    "z = nn.Parameter(y)\n",
    "l = z.sum()\n",
    "print(z)\n",
    "l.backward()\n",
    "print(z)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a1d50bd474435da848e1115dada8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4000],Loss:30388.533203125, KL Loss: 3038630.5. FitLoss: 2.2275853157043457,Accuracy:0.29327499999999995,Validation Loss:30373.6484375,Validation Accuracy:0.678, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [2/4000],Loss:30362.033203125, KL Loss: 3036015.5. FitLoss: 1.8791234493255615,Accuracy:0.6103875,Validation Loss:30347.0,Validation Accuracy:0.749, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [3/4000],Loss:30335.34765625, KL Loss: 3033404.0. FitLoss: 1.3084180355072021,Accuracy:0.7105250000000002,Validation Loss:30320.306640625,Validation Accuracy:0.79, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [4/4000],Loss:30308.806640625, KL Loss: 3030795.0. FitLoss: 0.8586298823356628,Accuracy:0.7572124999999998,Validation Loss:30293.892578125,Validation Accuracy:0.822, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [5/4000],Loss:30282.494140625, KL Loss: 3028185.0. FitLoss: 0.6446530222892761,Accuracy:0.79875,Validation Loss:30267.6484375,Validation Accuracy:0.856, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [6/4000],Loss:30256.255859375, KL Loss: 3025573.75. FitLoss: 0.5207279324531555,Accuracy:0.8390374999999999,Validation Loss:30241.455078125,Validation Accuracy:0.887, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [7/4000],Loss:30230.0703125, KL Loss: 3022961.25. FitLoss: 0.45843014121055603,Accuracy:0.8613499999999996,Validation Loss:30215.279296875,Validation Accuracy:0.898, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [8/4000],Loss:30203.888671875, KL Loss: 3020347.75. FitLoss: 0.4110206067562103,Accuracy:0.8785624999999999,Validation Loss:30189.115234375,Validation Accuracy:0.898, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [9/4000],Loss:30177.70703125, KL Loss: 3017733.5. FitLoss: 0.37214502692222595,Accuracy:0.8903250000000001,Validation Loss:30162.9375,Validation Accuracy:0.909, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [10/4000],Loss:30151.53125, KL Loss: 3015118.75. FitLoss: 0.34520089626312256,Accuracy:0.8952125000000001,Validation Loss:30136.787109375,Validation Accuracy:0.911, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [11/4000],Loss:30125.365234375, KL Loss: 3012503.5. FitLoss: 0.33180153369903564,Accuracy:0.9003249999999999,Validation Loss:30110.609375,Validation Accuracy:0.915, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [12/4000],Loss:30099.185546875, KL Loss: 3009887.5. FitLoss: 0.30967241525650024,Accuracy:0.9083874999999999,Validation Loss:30084.423828125,Validation Accuracy:0.923, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [13/4000],Loss:30073.0, KL Loss: 3007271.5. FitLoss: 0.28643131256103516,Accuracy:0.915025,Validation Loss:30058.240234375,Validation Accuracy:0.928, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [14/4000],Loss:30046.8125, KL Loss: 3004654.25. FitLoss: 0.2667480707168579,Accuracy:0.9215874999999997,Validation Loss:30032.05078125,Validation Accuracy:0.936, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [15/4000],Loss:30020.623046875, KL Loss: 3002037.0. FitLoss: 0.2574038505554199,Accuracy:0.9242624999999999,Validation Loss:30005.865234375,Validation Accuracy:0.94, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [16/4000],Loss:29994.44140625, KL Loss: 2999418.75. FitLoss: 0.25246167182922363,Accuracy:0.9254000000000001,Validation Loss:29979.6796875,Validation Accuracy:0.934, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [17/4000],Loss:29968.2421875, KL Loss: 2996800.0. FitLoss: 0.24007132649421692,Accuracy:0.9284750000000006,Validation Loss:29953.474609375,Validation Accuracy:0.939, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [18/4000],Loss:29942.037109375, KL Loss: 2994181.0. FitLoss: 0.22655482590198517,Accuracy:0.9323625000000005,Validation Loss:29927.267578125,Validation Accuracy:0.944, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [19/4000],Loss:29915.828125, KL Loss: 2991561.5. FitLoss: 0.21444743871688843,Accuracy:0.9377249999999995,Validation Loss:29901.056640625,Validation Accuracy:0.946, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [20/4000],Loss:29889.62109375, KL Loss: 2988941.5. FitLoss: 0.208227276802063,Accuracy:0.9384625000000009,Validation Loss:29874.841796875,Validation Accuracy:0.948, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [21/4000],Loss:29863.40625, KL Loss: 2986320.5. FitLoss: 0.19876790046691895,Accuracy:0.9425875000000001,Validation Loss:29848.62890625,Validation Accuracy:0.949, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [22/4000],Loss:29837.18359375, KL Loss: 2983699.25. FitLoss: 0.19031289219856262,Accuracy:0.9437250000000008,Validation Loss:29822.41015625,Validation Accuracy:0.95, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [23/4000],Loss:29810.955078125, KL Loss: 2981077.25. FitLoss: 0.17936469614505768,Accuracy:0.9485500000000002,Validation Loss:29796.189453125,Validation Accuracy:0.948, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [24/4000],Loss:29784.72265625, KL Loss: 2978455.25. FitLoss: 0.17361953854560852,Accuracy:0.9503249999999998,Validation Loss:29769.939453125,Validation Accuracy:0.955, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [25/4000],Loss:29758.486328125, KL Loss: 2975832.0. FitLoss: 0.16827048361301422,Accuracy:0.9507250000000003,Validation Loss:29743.701171875,Validation Accuracy:0.957, Prune parameters: 42.0/421642,Beta: 0.01\n",
      "Epoch [26/4000],Loss:29732.240234375, KL Loss: 2973208.0. FitLoss: 0.16126152873039246,Accuracy:0.9529375000000003,Validation Loss:29717.455078125,Validation Accuracy:0.955, Prune parameters: 876.0/421642,Beta: 0.01\n",
      "Epoch [27/4000],Loss:29706.0, KL Loss: 2970584.0. FitLoss: 0.15826207399368286,Accuracy:0.9541000000000001,Validation Loss:29691.224609375,Validation Accuracy:0.954, Prune parameters: 1734.0/421642,Beta: 0.01\n",
      "Epoch [28/4000],Loss:29679.75, KL Loss: 2967959.25. FitLoss: 0.15649574995040894,Accuracy:0.9552999999999997,Validation Loss:29664.953125,Validation Accuracy:0.957, Prune parameters: 2608.0/421642,Beta: 0.01\n",
      "Epoch [29/4000],Loss:29653.484375, KL Loss: 2965334.0. FitLoss: 0.14700277149677277,Accuracy:0.9588000000000003,Validation Loss:29638.701171875,Validation Accuracy:0.958, Prune parameters: 3458.0/421642,Beta: 0.01\n",
      "Epoch [30/4000],Loss:29627.23046875, KL Loss: 2962708.0. FitLoss: 0.15105584263801575,Accuracy:0.9563249999999999,Validation Loss:29612.4375,Validation Accuracy:0.953, Prune parameters: 4277.0/421642,Beta: 0.01\n",
      "Epoch [31/4000],Loss:11045.3740234375, KL Loss: 2960169.5. FitLoss: 0.14394958317279816,Accuracy:0.95745,Validation Loss:231.30218505859375,Validation Accuracy:0.957, Prune parameters: 5019.0/421642,Beta: 7.8125e-05\n",
      "Epoch [32/4000],Loss:57.701194763183594, KL Loss: 2958529.25. FitLoss: 0.1361711323261261,Accuracy:0.9602000000000002,Validation Loss:1.0256388187408447,Validation Accuracy:0.965, Prune parameters: 5368.0/421642,Beta: 3.0517578125e-07\n",
      "Epoch [33/4000],Loss:0.36700019240379333, KL Loss: 2957793.5. FitLoss: 0.12722349166870117,Accuracy:0.9625875,Validation Loss:0.22565598785877228,Validation Accuracy:0.963, Prune parameters: 5518.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [34/4000],Loss:3.7152371406555176, KL Loss: 2957471.5. FitLoss: 0.1192188560962677,Accuracy:0.9652999999999998,Validation Loss:28.98661994934082,Validation Accuracy:0.957, Prune parameters: 5587.0/421642,Beta: 9.765625e-06\n",
      "Epoch [35/4000],Loss:920.6548461914062, KL Loss: 2957329.25. FitLoss: 0.10884420573711395,Accuracy:0.9667499999999999,Validation Loss:7393.27197265625,Validation Accuracy:0.971, Prune parameters: 5616.0/421642,Beta: 0.0025\n",
      "Epoch [36/4000],Loss:176453.90625, KL Loss: 2956825.75. FitLoss: 0.09943719953298569,Accuracy:0.9710874999999992,Validation Loss:472782.0,Validation Accuracy:0.968, Prune parameters: 6370.0/421642,Beta: 0.16\n",
      "Epoch [37/4000],Loss:472244.875, KL Loss: 2951529.5. FitLoss: 0.1259719878435135,Accuracy:0.9699499999999999,Validation Loss:471497.53125,Validation Accuracy:0.968, Prune parameters: 9049.0/421642,Beta: 0.16\n",
      "Epoch [38/4000],Loss:470892.8125, KL Loss: 2943078.5. FitLoss: 0.2939794957637787,Accuracy:0.9490625000000005,Validation Loss:470123.375,Validation Accuracy:0.953, Prune parameters: 11881.0/421642,Beta: 0.16\n",
      "Epoch [39/4000],Loss:344940.53125, KL Loss: 2934697.0. FitLoss: 0.5040359497070312,Accuracy:0.9107499999999998,Validation Loss:29305.126953125,Validation Accuracy:0.917, Prune parameters: 14387.0/421642,Beta: 0.01\n",
      "Epoch [40/4000],Loss:7296.35986328125, KL Loss: 2928309.75. FitLoss: 0.4580549895763397,Accuracy:0.8913125,Validation Loss:114.616455078125,Validation Accuracy:0.927, Prune parameters: 15785.0/421642,Beta: 3.90625e-05\n",
      "Epoch [41/4000],Loss:28.80313491821289, KL Loss: 2925234.25. FitLoss: 0.34160250425338745,Accuracy:0.9023625000000001,Validation Loss:0.7166392207145691,Validation Accuracy:0.92, Prune parameters: 16399.0/421642,Beta: 1.52587890625e-07\n",
      "Epoch [42/4000],Loss:0.413056343793869, KL Loss: 2923890.0. FitLoss: 0.2805963456630707,Accuracy:0.9161375000000002,Validation Loss:0.2733204662799835,Validation Accuracy:0.936, Prune parameters: 16675.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [43/4000],Loss:0.30257201194763184, KL Loss: 2923303.25. FitLoss: 0.23984506726264954,Accuracy:0.9265625,Validation Loss:0.3050957918167114,Validation Accuracy:0.943, Prune parameters: 16805.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [44/4000],Loss:0.3248003423213959, KL Loss: 2923047.5. FitLoss: 0.21329496800899506,Accuracy:0.934225,Validation Loss:0.2894931137561798,Validation Accuracy:0.947, Prune parameters: 16850.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [45/4000],Loss:0.3014732003211975, KL Loss: 2922936.5. FitLoss: 0.18997205793857574,Accuracy:0.9407999999999994,Validation Loss:0.2724011540412903,Validation Accuracy:0.946, Prune parameters: 16868.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [46/4000],Loss:0.28248339891433716, KL Loss: 2922888.5. FitLoss: 0.17098402976989746,Accuracy:0.9466874999999997,Validation Loss:0.25615638494491577,Validation Accuracy:0.953, Prune parameters: 16883.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [47/4000],Loss:0.2692745625972748, KL Loss: 2922867.75. FitLoss: 0.15777599811553955,Accuracy:0.9511875,Validation Loss:0.2448996603488922,Validation Accuracy:0.953, Prune parameters: 16890.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [48/4000],Loss:0.2549935579299927, KL Loss: 2922858.75. FitLoss: 0.1434953659772873,Accuracy:0.9547500000000003,Validation Loss:0.2279542088508606,Validation Accuracy:0.959, Prune parameters: 16893.0/421642,Beta: 3.814697265625e-08\n",
      "Epoch [49/4000],Loss:0.24379628896713257, KL Loss: 2922855.75. FitLoss: 0.13229817152023315,Accuracy:0.9594250000000001,Validation Loss:0.2286282479763031,Validation Accuracy:0.955, Prune parameters: 16893.0/421642,Beta: 3.814697265625e-08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m train_params \u001b[38;5;241m=\u001b[39m VarTrainerParams(EPOCHS, optimizer,fit_loss, kl_loss, SAMPLES, PRUNE, BETA, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: CallbackLossAccuracy()})\n\u001b[1;32m     49\u001b[0m trainer \u001b[38;5;241m=\u001b[39m VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader, [post_train_step])\n\u001b[0;32m---> 50\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(model)\n",
      "File \u001b[0;32m~/BMM/project/src/methods/bayes/variational/trainer.py:131\u001b[0m, in \u001b[0;36mVarBayesTrainer.train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    129\u001b[0m train_fit_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (objects, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset): \n\u001b[0;32m--> 131\u001b[0m     train_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(model, objects, labels)\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__post_train_step(train_output)\n\u001b[1;32m    133\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(train_output\u001b[38;5;241m.\u001b[39mtotal_loss\u001b[38;5;241m.\u001b[39mitem())   \n",
      "File \u001b[0;32m~/BMM/project/src/methods/bayes/variational/trainer.py:194\u001b[0m, in \u001b[0;36mVarBayesTrainer.train_step\u001b[0;34m(self, model, objects, labels)\u001b[0m\n\u001b[1;32m    192\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(objects)\n\u001b[1;32m    193\u001b[0m fit_loss_total \u001b[38;5;241m=\u001b[39m fit_loss_total \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mfit_loss(outputs, labels)  \n\u001b[0;32m--> 194\u001b[0m dist_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mdist_loss(param_sample_list, model\u001b[38;5;241m.\u001b[39mposterior, model\u001b[38;5;241m.\u001b[39mprior))\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mcallback_losses \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m custom_loss \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mcallback_losses\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/BMM/project/src/methods/bayes/variational/optimization.py:28\u001b[0m, in \u001b[0;36mLogUniformVarKLLoss.forward\u001b[0;34m(self, param_sample_list, posterior, prior)\u001b[0m\n\u001b[1;32m     25\u001b[0m KL_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m posterior\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     27\u001b[0m     KL_w_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mtorch\u001b[38;5;241m.\u001b[39mexp(dist\u001b[38;5;241m.\u001b[39mparam_std_log)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m---> 28\u001b[0m                           torch\u001b[38;5;241m.\u001b[39mexp(dist\u001b[38;5;241m.\u001b[39mparam_std_log)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m dist\u001b[38;5;241m.\u001b[39mparam_mus \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m     KL_w \u001b[38;5;241m=\u001b[39m KL_w  \u001b[38;5;241m+\u001b[39m KL_w_element\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mKL_z \u001b[38;5;241m+\u001b[39m KL_w\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:34\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m(f):\n\u001b[1;32m     32\u001b[0m     assigned \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=1000\n",
    "EPOCHS=4000\n",
    "LR = 5e-4 #5e-4\n",
    "# Split the training set into training and validation sets \n",
    "VAL_PERCENT = 0.2 # percentage of the data used for validation \n",
    "SAMPLES = 10\n",
    "BETA = 0.01 #5e-5\n",
    "BETA_FAC = 5e-1\n",
    "PRUNE = 1.9#1.99, 2.1\n",
    "PLATO_TOL = 20\n",
    "\n",
    "base_module = Classifier()\n",
    "var_module = LogUniformVarBayesModule(base_module)\n",
    "model = VarBayesModuleNet(base_module, nn.ModuleList([var_module]))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "fit_loss = nn.CrossEntropyLoss() \n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "\n",
    "beta = Beta_Scheduler_Plato(BETA, BETA_FAC, PLATO_TOL)\n",
    "beta_KL = Beta_Scheduler_Plato(beta.beta, 1 / BETA_FAC, PLATO_TOL, ref = beta, threshold=1e-4)\n",
    "def post_train_step(trainer: VarTrainerParams, train_result: VarBayesTrainer.TrainResult):\n",
    "    beta.step(train_result.fit_loss)\n",
    "    beta_KL.step(train_result.dist_loss)\n",
    "    trainer.params.beta = float(beta)\n",
    "    \n",
    "#print(model.base_module.state_dict().keys())\n",
    "val_size    = int(VAL_PERCENT * len(train_dataset)) \n",
    "train_size  = len(train_dataset) - val_size \n",
    "#   \n",
    "t_dataset, v_dataset = torch.utils.data.random_split(train_dataset,  \n",
    "                                                        [train_size,  \n",
    "                                                            val_size]) \n",
    "\n",
    "# Create DataLoaders for the training and validation sets \n",
    "train_loader = torch.utils.data.DataLoader(t_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=True, \n",
    "                                        pin_memory=True) \n",
    "eval_loader = torch.utils.data.DataLoader(v_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=False, \n",
    "                                        pin_memory=True) \n",
    "\n",
    "model.to(device) \n",
    "train_params = VarTrainerParams(EPOCHS, optimizer,fit_loss, kl_loss, SAMPLES, PRUNE, BETA, {'accuracy': CallbackLossAccuracy()})\n",
    "trainer = VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader, [post_train_step])\n",
    "trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_module.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_bayes.pt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(409356., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.prune({'threshold': 1.9})\n",
    "print(model.prune_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47343., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.prune([{'threshold': -2.2}])\n",
    "print(model.prune_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = Classifier()\n",
    "var_module = LogUniformVarBayesModule(module)\n",
    "model = VarBayesModuleNet(module, nn.ModuleList([var_module]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('module_list.0.posterior_params.0.param_mus',\n",
       "              tensor([[[[-0.2737, -0.0213, -0.1784],\n",
       "                        [-0.0449,  0.1339,  0.2884],\n",
       "                        [ 0.1757,  0.2454,  0.0318]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2829,  0.1125,  0.2672],\n",
       "                        [-0.0329,  0.1954,  0.2326],\n",
       "                        [-0.0857, -0.2534,  0.0893]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1525,  0.0669, -0.2533],\n",
       "                        [-0.1758,  0.1672,  0.1206],\n",
       "                        [ 0.0153,  0.1936, -0.3305]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0107,  0.3182,  0.2102],\n",
       "                        [-0.1029,  0.3132, -0.2125],\n",
       "                        [-0.2650,  0.0061,  0.2422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1922,  0.1445, -0.1445],\n",
       "                        [-0.1862, -0.1703,  0.1814],\n",
       "                        [-0.3061, -0.1629,  0.1818]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2469, -0.2962, -0.1922],\n",
       "                        [-0.1502, -0.0190, -0.1009],\n",
       "                        [ 0.1418,  0.0435, -0.2017]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2999,  0.2396,  0.0861],\n",
       "                        [-0.1399,  0.0275, -0.3024],\n",
       "                        [-0.1098, -0.1394, -0.2101]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0273,  0.2970, -0.2747],\n",
       "                        [ 0.1127,  0.2224,  0.0496],\n",
       "                        [-0.2127,  0.1349, -0.2917]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0222,  0.2411,  0.0425],\n",
       "                        [ 0.0817,  0.1037,  0.2716],\n",
       "                        [ 0.0878, -0.2382, -0.0517]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0719,  0.1895,  0.1076],\n",
       "                        [-0.1426, -0.1827,  0.3090],\n",
       "                        [-0.1734,  0.0608, -0.1394]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2088,  0.1865,  0.1586],\n",
       "                        [-0.1817, -0.1410, -0.1049],\n",
       "                        [-0.1832, -0.3061, -0.3109]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2269,  0.1814, -0.3188],\n",
       "                        [ 0.2725, -0.0902, -0.2374],\n",
       "                        [-0.1628, -0.2985, -0.0739]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2382, -0.0886,  0.2284],\n",
       "                        [ 0.0932, -0.0300,  0.1199],\n",
       "                        [-0.3036,  0.0679,  0.3242]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2995, -0.0269,  0.2335],\n",
       "                        [-0.2868,  0.1297,  0.2263],\n",
       "                        [-0.1365,  0.0827, -0.1368]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2408, -0.1476,  0.1649],\n",
       "                        [ 0.1636, -0.0114, -0.1543],\n",
       "                        [ 0.1516,  0.2401, -0.3093]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0533,  0.1382,  0.0024],\n",
       "                        [-0.1546,  0.2536, -0.2555],\n",
       "                        [-0.1677, -0.0555,  0.0449]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2179,  0.0416,  0.1664],\n",
       "                        [ 0.1895,  0.1240, -0.2714],\n",
       "                        [-0.0561, -0.2904,  0.1815]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0931, -0.2447, -0.1122],\n",
       "                        [ 0.2836, -0.3144,  0.2693],\n",
       "                        [ 0.0475,  0.0702,  0.2088]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2935, -0.0657,  0.2059],\n",
       "                        [-0.2644,  0.2140,  0.0178],\n",
       "                        [-0.0679, -0.2655, -0.0174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1912, -0.0838, -0.1078],\n",
       "                        [ 0.2290,  0.2124, -0.2783],\n",
       "                        [-0.0186,  0.2010, -0.1156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2628, -0.2447,  0.0938],\n",
       "                        [-0.1858, -0.2919, -0.2134],\n",
       "                        [ 0.2410, -0.0449,  0.1174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3145, -0.2647,  0.2348],\n",
       "                        [ 0.1423, -0.1619, -0.1704],\n",
       "                        [ 0.3221, -0.1983, -0.0801]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0133, -0.3084,  0.1228],\n",
       "                        [ 0.1514,  0.0796, -0.1055],\n",
       "                        [ 0.2269,  0.1001, -0.2295]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1243,  0.1812,  0.0307],\n",
       "                        [ 0.2902,  0.2480, -0.0722],\n",
       "                        [-0.1125,  0.2348,  0.0912]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2855,  0.0356,  0.2712],\n",
       "                        [ 0.3197, -0.0580,  0.0020],\n",
       "                        [-0.2933, -0.1005,  0.2072]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1050, -0.2946,  0.0811],\n",
       "                        [-0.0863,  0.2160, -0.2627],\n",
       "                        [-0.1286,  0.0596, -0.1345]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0546, -0.0362,  0.0594],\n",
       "                        [ 0.0646,  0.1745, -0.0352],\n",
       "                        [-0.1120, -0.0474,  0.0383]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1332, -0.2500, -0.1542],\n",
       "                        [-0.2412, -0.3166, -0.0210],\n",
       "                        [ 0.1060,  0.1158,  0.0057]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2678, -0.2166,  0.0712],\n",
       "                        [-0.0535,  0.1413,  0.2406],\n",
       "                        [-0.2855, -0.3059, -0.2075]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2055, -0.2482,  0.1404],\n",
       "                        [-0.2513, -0.1904,  0.1103],\n",
       "                        [-0.2845,  0.0184,  0.2082]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0582,  0.2715,  0.1728],\n",
       "                        [-0.1080,  0.1155,  0.1371],\n",
       "                        [ 0.2162, -0.0247, -0.2244]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1486,  0.0659,  0.1559],\n",
       "                        [-0.2081,  0.0449,  0.3216],\n",
       "                        [ 0.2564,  0.2344, -0.0866]]]])),\n",
       "             ('module_list.0.posterior_params.0.param_std_log',\n",
       "              tensor([[[[-7.6443, -6.8122, -6.2178],\n",
       "                        [-4.6537, -8.1042, -5.0853],\n",
       "                        [-6.9559, -4.9253, -4.6574]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.9750, -6.1978, -5.7079],\n",
       "                        [-5.8540, -7.7156, -6.2078],\n",
       "                        [-4.9556, -5.0383, -6.1048]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7616, -5.4980, -4.7636],\n",
       "                        [-4.9685, -8.0552, -6.3784],\n",
       "                        [-4.9320, -6.9730, -6.1062]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8593, -5.2212, -4.8359],\n",
       "                        [-4.9786, -7.6505, -5.0176],\n",
       "                        [-5.6760, -5.2133, -5.7229]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.5549, -5.6953, -7.5045],\n",
       "                        [-4.8243, -5.2325, -8.2682],\n",
       "                        [-4.7497, -5.2409, -6.0584]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.2319, -5.1681, -5.0143],\n",
       "                        [-4.6465, -4.7084, -6.2273],\n",
       "                        [-4.7883, -5.2719, -4.9517]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0582, -5.2466, -5.4416],\n",
       "                        [-5.1359, -5.2855, -5.4410],\n",
       "                        [-5.7903, -4.6311, -5.1965]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9802, -4.6867, -5.9103],\n",
       "                        [-4.9393, -7.2178, -5.2489],\n",
       "                        [-4.6243, -5.9567, -5.4351]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6969, -5.5580, -5.1405],\n",
       "                        [-4.7906, -5.6145, -7.0589],\n",
       "                        [-5.0275, -4.7744, -5.2552]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.2480, -6.9430, -4.8825],\n",
       "                        [-5.6597, -6.6762, -4.9689],\n",
       "                        [-5.1752, -4.9931, -5.0197]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6701, -4.8942, -5.5445],\n",
       "                        [-5.9894, -5.5842, -4.8125],\n",
       "                        [-5.2390, -4.8248, -6.3544]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0899, -6.3075, -5.0728],\n",
       "                        [-4.7244, -4.7276, -5.5322],\n",
       "                        [-6.5785, -5.2176, -8.2081]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.8461, -6.0238, -5.0947],\n",
       "                        [-4.7004, -4.7245, -4.9359],\n",
       "                        [-5.4876, -4.8804, -5.2382]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7568, -4.7962, -4.8076],\n",
       "                        [-4.8334, -4.6812, -4.8790],\n",
       "                        [-5.2112, -4.6500, -5.2285]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1571, -5.5234, -5.3730],\n",
       "                        [-6.3554, -4.7353, -5.0411],\n",
       "                        [-4.7423, -5.0554, -5.8877]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.4057, -5.4768, -5.8319],\n",
       "                        [-4.8379, -4.8591, -7.9367],\n",
       "                        [-6.0085, -4.6697, -5.8908]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7667, -5.2830, -4.8108],\n",
       "                        [-4.7277, -5.0035, -4.8743],\n",
       "                        [-4.7109, -7.0394, -4.8987]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5578, -5.4441, -4.7811],\n",
       "                        [-4.6132, -5.0880, -4.7208],\n",
       "                        [-5.2930, -4.7753, -5.3517]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0392, -6.9003, -6.4838],\n",
       "                        [-6.2912, -4.9652, -6.3513],\n",
       "                        [-5.4759, -4.9867, -5.3265]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.6965, -5.1672, -4.6054],\n",
       "                        [-5.8090, -4.9806, -5.4375],\n",
       "                        [-5.2273, -5.3135, -5.2484]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8862, -4.9312, -5.9119],\n",
       "                        [-5.3062, -5.0569, -4.6850],\n",
       "                        [-5.4883, -6.1027, -5.0738]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.3343, -6.1922, -6.2508],\n",
       "                        [-5.0133, -4.8441, -6.0976],\n",
       "                        [-7.5900, -5.7515, -4.6156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5193, -6.1760, -5.7592],\n",
       "                        [-5.5590, -4.8624, -5.6229],\n",
       "                        [-4.9285, -4.8645, -5.8739]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6902, -5.6837, -4.9300],\n",
       "                        [-5.4640, -6.1872, -5.1738],\n",
       "                        [-4.6249, -4.7705, -4.9058]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1386, -4.6787, -4.8687],\n",
       "                        [-4.7995, -6.2731, -5.5295],\n",
       "                        [-7.9139, -5.6268, -4.8398]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4830, -5.1139, -5.3729],\n",
       "                        [-4.6113, -5.2906, -5.0130],\n",
       "                        [-5.5503, -4.9968, -4.6078]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.3845, -6.3526, -5.5192],\n",
       "                        [-6.8718, -5.3505, -5.9623],\n",
       "                        [-5.2600, -5.0851, -5.2559]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.5084, -6.8383, -6.7434],\n",
       "                        [-5.1087, -5.0522, -5.0362],\n",
       "                        [-4.8434, -4.6105, -5.9471]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0541, -6.8497, -5.4263],\n",
       "                        [-5.1009, -4.6458, -5.4793],\n",
       "                        [-5.4213, -4.9003, -4.8682]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4279, -8.2878, -5.5914],\n",
       "                        [-5.8017, -5.5931, -4.8151],\n",
       "                        [-4.7875, -5.1253, -4.8293]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6792, -5.2176, -6.3633],\n",
       "                        [-6.5483, -4.7496, -5.1030],\n",
       "                        [-4.7008, -4.6548, -4.8405]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9131, -5.5380, -5.7411],\n",
       "                        [-8.2987, -4.6276, -5.5294],\n",
       "                        [-5.5955, -4.9558, -8.0978]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_alphas_log',\n",
       "              tensor([[[[-3.9730, -3.8184, -2.7370],\n",
       "                        [-2.8423, -3.3155, -3.7674],\n",
       "                        [-2.8688, -3.4832, -3.3337]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4496, -3.1676, -2.3279],\n",
       "                        [-2.5704, -2.6994, -2.5631],\n",
       "                        [-2.3078, -3.7059, -3.1989]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3379, -3.3761, -2.0345],\n",
       "                        [-3.8821, -2.3943, -3.7338],\n",
       "                        [-3.1945, -2.8338, -3.7807]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3331, -3.7250, -3.6263],\n",
       "                        [-3.3903, -2.8828, -3.6775],\n",
       "                        [-3.0060, -2.4066, -2.8119]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3633, -2.0377, -2.0332],\n",
       "                        [-3.5051, -3.9339, -3.9972],\n",
       "                        [-2.8213, -2.7204, -2.4167]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4371, -3.7661, -2.8416],\n",
       "                        [-2.1897, -2.4125, -2.5461],\n",
       "                        [-3.4732, -3.3259, -2.3366]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2825, -3.0099, -2.5968],\n",
       "                        [-3.0321, -3.8588, -3.2249],\n",
       "                        [-3.7188, -3.9843, -3.5802]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8530, -3.9986, -3.0276],\n",
       "                        [-2.0767, -3.6595, -2.9175],\n",
       "                        [-3.2203, -2.1420, -3.6336]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5784, -2.8119, -2.3119],\n",
       "                        [-3.2846, -3.0844, -2.5892],\n",
       "                        [-3.3545, -2.3341, -3.3552]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5695, -2.5832, -2.3026],\n",
       "                        [-3.3705, -3.8097, -3.8492],\n",
       "                        [-2.4600, -2.2967, -3.7054]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3626, -3.4220, -3.9690],\n",
       "                        [-2.0460, -2.1348, -3.8663],\n",
       "                        [-2.3202, -3.0671, -2.3580]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1191, -3.4663, -3.9155],\n",
       "                        [-2.9626, -2.6909, -2.0241],\n",
       "                        [-3.6772, -2.0887, -2.8112]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5335, -2.2046, -3.8070],\n",
       "                        [-2.0733, -3.4714, -3.3680],\n",
       "                        [-2.0920, -3.3321, -3.0712]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9456, -3.9397, -2.3680],\n",
       "                        [-2.0659, -3.5653, -2.3071],\n",
       "                        [-3.2517, -3.4542, -2.0715]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2097, -3.9403, -2.1460],\n",
       "                        [-3.0559, -3.4030, -2.5687],\n",
       "                        [-3.4692, -2.5501, -3.5228]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8775, -3.4609, -3.5841],\n",
       "                        [-3.2468, -3.9733, -3.9215],\n",
       "                        [-3.4708, -3.8749, -3.1619]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4536, -3.0306, -3.1692],\n",
       "                        [-2.9309, -2.0621, -2.1662],\n",
       "                        [-2.1606, -2.5014, -2.8317]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8540, -3.1003, -2.3888],\n",
       "                        [-2.9370, -2.7015, -3.5162],\n",
       "                        [-2.7293, -2.3345, -3.2506]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4800, -3.4780, -2.7654],\n",
       "                        [-2.0434, -2.3557, -2.0213],\n",
       "                        [-2.2703, -2.0352, -3.7971]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9834, -3.0913, -2.8502],\n",
       "                        [-2.8904, -2.8264, -3.4881],\n",
       "                        [-3.3516, -3.2357, -2.9829]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1380, -3.2730, -3.5269],\n",
       "                        [-2.6177, -3.5875, -3.6728],\n",
       "                        [-2.7636, -3.6273, -3.2167]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4872, -3.5043, -2.3076],\n",
       "                        [-2.8557, -3.3450, -2.6795],\n",
       "                        [-2.7737, -2.7499, -3.3472]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2195, -2.7689, -2.0130],\n",
       "                        [-3.5297, -3.6577, -2.2098],\n",
       "                        [-2.0077, -3.4508, -3.4853]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1046, -3.8315, -3.3988],\n",
       "                        [-2.0476, -3.0053, -3.8965],\n",
       "                        [-2.1855, -2.1632, -2.1847]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9850, -2.6428, -2.9310],\n",
       "                        [-2.1326, -3.2657, -2.4740],\n",
       "                        [-3.1584, -2.4350, -3.3533]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9450, -2.5128, -3.1556],\n",
       "                        [-3.2801, -3.5410, -2.8983],\n",
       "                        [-2.5519, -3.2341, -2.8721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8494, -3.8954, -3.0426],\n",
       "                        [-3.2585, -3.2226, -3.6094],\n",
       "                        [-3.2983, -3.4633, -3.9118]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4175, -2.1018, -2.3832],\n",
       "                        [-2.6769, -2.5597, -3.1847],\n",
       "                        [-3.8278, -2.5293, -3.5093]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6108, -3.0801, -2.6812],\n",
       "                        [-2.7818, -3.4267, -3.2687],\n",
       "                        [-2.1624, -2.1442, -2.5664]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5382, -2.5531, -3.3821],\n",
       "                        [-2.7202, -3.1200, -3.5994],\n",
       "                        [-3.7090, -3.5544, -3.7490]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9206, -2.9339, -2.6854],\n",
       "                        [-2.8685, -3.9728, -2.4037],\n",
       "                        [-3.7632, -2.0636, -2.3169]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5363, -2.2065, -3.9187],\n",
       "                        [-2.5296, -2.8139, -2.1778],\n",
       "                        [-3.0076, -2.6238, -3.4175]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.1.param_mus',\n",
       "              tensor([-0.0917,  0.2394,  0.0686, -0.2604, -0.0798,  0.2396, -0.0338,  0.2310,\n",
       "                       0.0511, -0.0118,  0.1305,  0.2870,  0.1377,  0.0071, -0.0213, -0.0859,\n",
       "                       0.1393, -0.0984, -0.1080,  0.1917,  0.1436, -0.2344,  0.0637, -0.2897,\n",
       "                      -0.2618, -0.2384, -0.1295,  0.1794, -0.0685, -0.0023, -0.2036, -0.0473])),\n",
       "             ('module_list.0.posterior_params.1.param_std_log',\n",
       "              tensor([-5.6001, -5.0561, -7.3938, -4.6664, -5.3911, -4.6895, -5.8183, -4.6080,\n",
       "                      -4.9778, -5.0134, -5.1747, -6.2682, -5.6235, -4.6147, -4.6179, -5.5958,\n",
       "                      -7.3049, -5.8125, -5.3669, -6.1171, -5.4824, -4.6084, -4.8485, -5.1090,\n",
       "                      -4.6260, -4.8618, -4.6064, -5.7304, -4.9281, -6.2759, -6.1592, -4.6723])),\n",
       "             ('module_list.0.posterior_params.1.scale_alphas_log',\n",
       "              tensor([-3.8439, -3.2271, -3.3951, -2.1596, -3.5587, -3.3096, -3.8678, -3.2271,\n",
       "                      -3.7286, -2.2776, -3.4039, -2.1131, -3.8562, -2.1256, -2.6956, -2.0418,\n",
       "                      -3.5359, -3.6205, -3.8657, -2.2383, -2.6532, -2.0978, -2.3008, -3.0798,\n",
       "                      -3.8545, -2.1004, -2.2579, -3.7659, -2.8519, -2.2167, -2.4384, -3.4444])),\n",
       "             ('module_list.0.posterior_params.1.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.2.param_mus',\n",
       "              tensor([[[[-0.0196,  0.0454,  0.0391],\n",
       "                        [ 0.0089,  0.0444,  0.0319],\n",
       "                        [ 0.0151, -0.0048, -0.0067]],\n",
       "              \n",
       "                       [[ 0.0389,  0.0052, -0.0038],\n",
       "                        [ 0.0210, -0.0377,  0.0379],\n",
       "                        [-0.0082, -0.0270,  0.0123]],\n",
       "              \n",
       "                       [[-0.0195, -0.0450, -0.0348],\n",
       "                        [-0.0266,  0.0158,  0.0558],\n",
       "                        [ 0.0572, -0.0150, -0.0562]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0117, -0.0527,  0.0530],\n",
       "                        [-0.0441, -0.0011,  0.0099],\n",
       "                        [ 0.0460, -0.0206,  0.0311]],\n",
       "              \n",
       "                       [[ 0.0086, -0.0104,  0.0082],\n",
       "                        [-0.0060,  0.0010,  0.0508],\n",
       "                        [ 0.0234, -0.0204, -0.0198]],\n",
       "              \n",
       "                       [[ 0.0014,  0.0375, -0.0589],\n",
       "                        [-0.0500, -0.0523, -0.0287],\n",
       "                        [-0.0491,  0.0049,  0.0422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0086, -0.0462,  0.0437],\n",
       "                        [-0.0584, -0.0168, -0.0261],\n",
       "                        [-0.0548, -0.0186, -0.0516]],\n",
       "              \n",
       "                       [[ 0.0359, -0.0341,  0.0119],\n",
       "                        [-0.0516, -0.0310, -0.0073],\n",
       "                        [-0.0050,  0.0106,  0.0388]],\n",
       "              \n",
       "                       [[ 0.0335,  0.0242, -0.0266],\n",
       "                        [-0.0136,  0.0261,  0.0277],\n",
       "                        [-0.0235, -0.0340, -0.0570]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0397, -0.0346,  0.0134],\n",
       "                        [-0.0087,  0.0414,  0.0012],\n",
       "                        [-0.0219,  0.0087,  0.0025]],\n",
       "              \n",
       "                       [[-0.0426,  0.0360, -0.0347],\n",
       "                        [-0.0527, -0.0319,  0.0490],\n",
       "                        [ 0.0425,  0.0571,  0.0575]],\n",
       "              \n",
       "                       [[ 0.0446,  0.0385,  0.0485],\n",
       "                        [ 0.0124,  0.0016, -0.0074],\n",
       "                        [ 0.0091, -0.0570, -0.0402]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0326, -0.0093, -0.0427],\n",
       "                        [-0.0027, -0.0183,  0.0407],\n",
       "                        [ 0.0067,  0.0192, -0.0295]],\n",
       "              \n",
       "                       [[ 0.0398, -0.0258, -0.0529],\n",
       "                        [ 0.0533, -0.0561,  0.0226],\n",
       "                        [-0.0508, -0.0089, -0.0217]],\n",
       "              \n",
       "                       [[-0.0574,  0.0053,  0.0086],\n",
       "                        [ 0.0176, -0.0122,  0.0389],\n",
       "                        [ 0.0315, -0.0262,  0.0497]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0496,  0.0429, -0.0389],\n",
       "                        [ 0.0564,  0.0134, -0.0487],\n",
       "                        [ 0.0151, -0.0558, -0.0526]],\n",
       "              \n",
       "                       [[ 0.0041,  0.0085,  0.0242],\n",
       "                        [-0.0357,  0.0532, -0.0053],\n",
       "                        [ 0.0320,  0.0389, -0.0084]],\n",
       "              \n",
       "                       [[-0.0232, -0.0328, -0.0265],\n",
       "                        [ 0.0073,  0.0322,  0.0154],\n",
       "                        [ 0.0334, -0.0364, -0.0399]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0362, -0.0152, -0.0356],\n",
       "                        [-0.0227,  0.0356,  0.0551],\n",
       "                        [ 0.0449,  0.0479,  0.0460]],\n",
       "              \n",
       "                       [[ 0.0109, -0.0216,  0.0328],\n",
       "                        [ 0.0278,  0.0500, -0.0082],\n",
       "                        [ 0.0543, -0.0203,  0.0153]],\n",
       "              \n",
       "                       [[ 0.0102,  0.0585, -0.0482],\n",
       "                        [ 0.0470,  0.0210,  0.0068],\n",
       "                        [ 0.0122,  0.0472, -0.0473]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0350,  0.0331,  0.0211],\n",
       "                        [ 0.0469,  0.0194, -0.0124],\n",
       "                        [ 0.0085,  0.0097,  0.0335]],\n",
       "              \n",
       "                       [[-0.0213, -0.0421,  0.0169],\n",
       "                        [ 0.0271,  0.0084, -0.0281],\n",
       "                        [-0.0009,  0.0395,  0.0552]],\n",
       "              \n",
       "                       [[-0.0405,  0.0506,  0.0431],\n",
       "                        [ 0.0378,  0.0429,  0.0452],\n",
       "                        [ 0.0226,  0.0213, -0.0085]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0589, -0.0413,  0.0375],\n",
       "                        [-0.0113,  0.0128, -0.0504],\n",
       "                        [ 0.0348,  0.0297, -0.0023]],\n",
       "              \n",
       "                       [[ 0.0142, -0.0146,  0.0395],\n",
       "                        [-0.0279,  0.0025, -0.0369],\n",
       "                        [-0.0193,  0.0065,  0.0184]],\n",
       "              \n",
       "                       [[ 0.0535, -0.0271,  0.0205],\n",
       "                        [ 0.0521,  0.0121,  0.0178],\n",
       "                        [-0.0015, -0.0246,  0.0102]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0374,  0.0082,  0.0361],\n",
       "                        [-0.0384, -0.0128,  0.0242],\n",
       "                        [ 0.0210,  0.0459, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0085,  0.0549, -0.0122],\n",
       "                        [ 0.0470, -0.0425,  0.0118],\n",
       "                        [-0.0259, -0.0331,  0.0163]],\n",
       "              \n",
       "                       [[-0.0175,  0.0018,  0.0136],\n",
       "                        [ 0.0412, -0.0085, -0.0292],\n",
       "                        [ 0.0508, -0.0501,  0.0192]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0055, -0.0442, -0.0088],\n",
       "                        [-0.0253, -0.0387, -0.0068],\n",
       "                        [-0.0327,  0.0401,  0.0176]],\n",
       "              \n",
       "                       [[-0.0053, -0.0276,  0.0089],\n",
       "                        [ 0.0546,  0.0484, -0.0486],\n",
       "                        [ 0.0030,  0.0041, -0.0256]],\n",
       "              \n",
       "                       [[ 0.0418,  0.0024, -0.0539],\n",
       "                        [ 0.0261, -0.0357, -0.0540],\n",
       "                        [ 0.0082, -0.0161,  0.0249]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0420, -0.0219, -0.0447],\n",
       "                        [-0.0553, -0.0467, -0.0041],\n",
       "                        [-0.0133, -0.0239,  0.0284]],\n",
       "              \n",
       "                       [[-0.0090,  0.0331,  0.0218],\n",
       "                        [-0.0550, -0.0575, -0.0531],\n",
       "                        [ 0.0528, -0.0313,  0.0230]],\n",
       "              \n",
       "                       [[-0.0138,  0.0412, -0.0435],\n",
       "                        [ 0.0420, -0.0355,  0.0162],\n",
       "                        [ 0.0510,  0.0107,  0.0575]]]])),\n",
       "             ('module_list.0.posterior_params.2.param_std_log',\n",
       "              tensor([[[[ -4.8953,  -5.0285,  -6.2216],\n",
       "                        [ -4.9035,  -8.6040,  -6.4262],\n",
       "                        [ -5.3935,  -6.4831,  -5.3591]],\n",
       "              \n",
       "                       [[ -5.5549,  -5.1110,  -4.7856],\n",
       "                        [ -5.0981,  -4.8755,  -5.7412],\n",
       "                        [ -5.6913,  -5.1175,  -5.4186]],\n",
       "              \n",
       "                       [[ -7.5934,  -4.9929,  -4.8682],\n",
       "                        [ -6.5329,  -6.7392,  -5.7023],\n",
       "                        [ -4.6655,  -6.5716,  -5.0604]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.6578,  -4.9114,  -5.8949],\n",
       "                        [ -5.4794,  -5.1367,  -5.2141],\n",
       "                        [ -7.1503,  -5.0723,  -6.8911]],\n",
       "              \n",
       "                       [[ -7.7260,  -4.7098,  -4.7194],\n",
       "                        [ -4.8400,  -5.9135,  -5.9438],\n",
       "                        [ -4.6816,  -5.5583,  -4.6564]],\n",
       "              \n",
       "                       [[ -5.4169,  -4.8717,  -4.7754],\n",
       "                        [ -5.1123,  -4.8388,  -5.6561],\n",
       "                        [ -5.6101,  -5.9402,  -5.5524]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3646,  -6.1044,  -4.8309],\n",
       "                        [ -4.9290,  -6.4702,  -4.7857],\n",
       "                        [ -4.7454,  -6.7668,  -4.7657]],\n",
       "              \n",
       "                       [[ -5.3774,  -6.1290,  -5.3385],\n",
       "                        [ -8.1817,  -5.3416,  -4.6654],\n",
       "                        [ -6.9278,  -5.2007,  -5.8790]],\n",
       "              \n",
       "                       [[ -6.2015,  -4.7918,  -7.0114],\n",
       "                        [ -6.6029,  -4.9880,  -5.1994],\n",
       "                        [ -4.7158,  -4.6187,  -4.7050]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -7.0537,  -5.3076,  -5.5863],\n",
       "                        [ -5.8178,  -5.1174,  -5.0456],\n",
       "                        [ -5.3676,  -5.2478,  -5.6625]],\n",
       "              \n",
       "                       [[ -5.3646,  -6.0331,  -4.8292],\n",
       "                        [ -5.1204,  -5.0109,  -5.4891],\n",
       "                        [ -6.4985,  -4.7923,  -4.8494]],\n",
       "              \n",
       "                       [[ -5.2417,  -5.3264,  -4.9075],\n",
       "                        [ -4.6669,  -5.7886,  -5.0299],\n",
       "                        [ -4.8249,  -4.7134,  -5.8615]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.3013,  -5.6837,  -6.1340],\n",
       "                        [ -4.8347,  -6.8893,  -6.6270],\n",
       "                        [ -5.4885,  -6.7957,  -4.8725]],\n",
       "              \n",
       "                       [[ -4.7680,  -7.2965,  -6.8039],\n",
       "                        [ -7.3785,  -4.9002,  -5.0066],\n",
       "                        [ -4.6913,  -5.5690,  -4.6084]],\n",
       "              \n",
       "                       [[ -4.8951,  -7.2483,  -4.8205],\n",
       "                        [ -5.4375,  -5.4348,  -5.8624],\n",
       "                        [ -5.6269,  -4.8600,  -8.1621]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.9090,  -5.1043,  -6.6300],\n",
       "                        [ -4.9572,  -5.2812,  -4.9467],\n",
       "                        [ -6.9966,  -5.9345,  -5.1252]],\n",
       "              \n",
       "                       [[ -4.6989,  -4.8439,  -5.2943],\n",
       "                        [ -5.1051,  -5.7968,  -5.8932],\n",
       "                        [-10.1077,  -4.7491,  -8.4951]],\n",
       "              \n",
       "                       [[ -5.6271,  -5.8009,  -5.6112],\n",
       "                        [ -5.6509,  -4.7704,  -6.9457],\n",
       "                        [ -6.5300,  -5.8772,  -6.3974]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ -6.2656,  -6.2033,  -4.9923],\n",
       "                        [ -4.8826,  -8.2525,  -5.1309],\n",
       "                        [ -4.8151,  -5.6355,  -5.0209]],\n",
       "              \n",
       "                       [[ -6.3848,  -6.0805,  -7.8335],\n",
       "                        [ -4.8021,  -5.2011,  -4.9359],\n",
       "                        [ -5.2328,  -6.5811,  -4.6836]],\n",
       "              \n",
       "                       [[ -4.6560,  -4.6885, -11.7446],\n",
       "                        [ -6.5880,  -4.7699,  -5.2749],\n",
       "                        [ -5.6483,  -4.7934,  -6.8433]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.2342,  -5.2849,  -6.0316],\n",
       "                        [ -5.3714,  -4.7595,  -5.4207],\n",
       "                        [ -6.7571,  -9.9357,  -7.0918]],\n",
       "              \n",
       "                       [[ -7.8484,  -7.9049,  -4.8852],\n",
       "                        [ -8.5928,  -6.9321,  -4.7064],\n",
       "                        [ -4.6875,  -4.8348,  -5.5023]],\n",
       "              \n",
       "                       [[ -4.7033,  -4.6839,  -5.3626],\n",
       "                        [ -5.8149,  -4.6163,  -4.7024],\n",
       "                        [ -5.2816,  -5.4297,  -4.8385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7027,  -4.6516,  -5.3516],\n",
       "                        [ -5.2600,  -4.8881,  -5.0138],\n",
       "                        [ -5.9239,  -5.4689,  -4.6260]],\n",
       "              \n",
       "                       [[ -4.9607,  -5.8558,  -5.9619],\n",
       "                        [ -5.1053,  -7.0853,  -5.5569],\n",
       "                        [ -4.6085,  -6.3642,  -4.8830]],\n",
       "              \n",
       "                       [[ -5.5688,  -4.9501,  -6.1348],\n",
       "                        [ -6.3153,  -5.5237,  -4.7659],\n",
       "                        [ -4.6286,  -5.5474,  -6.4980]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.5645,  -4.6941,  -5.2743],\n",
       "                        [ -5.4054,  -4.9133,  -6.4651],\n",
       "                        [ -7.0040,  -4.9656,  -7.0266]],\n",
       "              \n",
       "                       [[ -5.2028,  -5.1697,  -4.7442],\n",
       "                        [ -4.8667,  -5.2562,  -6.2058],\n",
       "                        [ -7.5951,  -4.6418,  -4.9033]],\n",
       "              \n",
       "                       [[ -4.6518,  -5.0600,  -5.0147],\n",
       "                        [ -6.5606,  -5.0663,  -5.1944],\n",
       "                        [ -7.4739,  -4.6704,  -4.6449]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.6330,  -6.6073,  -5.0135],\n",
       "                        [ -4.9958,  -4.8325,  -4.6252],\n",
       "                        [ -4.9012,  -6.2909,  -6.0797]],\n",
       "              \n",
       "                       [[ -4.8079,  -7.8986,  -5.3821],\n",
       "                        [ -5.9537,  -7.2645,  -5.7079],\n",
       "                        [ -4.7860,  -5.0177,  -5.3445]],\n",
       "              \n",
       "                       [[ -4.9210,  -5.5095,  -4.9153],\n",
       "                        [ -9.2945,  -5.2109,  -5.0991],\n",
       "                        [ -4.6786,  -4.8999,  -4.7837]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.0940,  -6.4246,  -6.0016],\n",
       "                        [ -5.9106,  -4.6236,  -9.3768],\n",
       "                        [ -4.8565,  -4.6549,  -4.8105]],\n",
       "              \n",
       "                       [[ -5.0449,  -5.1650,  -4.6892],\n",
       "                        [ -5.7240,  -5.5601,  -4.7530],\n",
       "                        [ -4.6144,  -5.6058,  -7.4718]],\n",
       "              \n",
       "                       [[ -6.1598,  -4.6782,  -5.3052],\n",
       "                        [ -5.1732,  -5.6023,  -5.3645],\n",
       "                        [ -5.2507,  -5.4567,  -4.8220]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_alphas_log',\n",
       "              tensor([[[[-2.9031, -3.5752, -3.1913],\n",
       "                        [-2.2432, -3.7676, -3.9219],\n",
       "                        [-2.2315, -3.3817, -3.0104]],\n",
       "              \n",
       "                       [[-3.4620, -2.1322, -2.3796],\n",
       "                        [-3.2906, -3.9242, -2.4920],\n",
       "                        [-2.6064, -2.2625, -3.8039]],\n",
       "              \n",
       "                       [[-3.0305, -3.3771, -3.4199],\n",
       "                        [-2.7889, -2.9304, -3.7615],\n",
       "                        [-2.1174, -2.1470, -3.9918]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2688, -2.4659, -3.1240],\n",
       "                        [-3.7692, -3.6450, -3.6797],\n",
       "                        [-3.3195, -2.8639, -2.6135]],\n",
       "              \n",
       "                       [[-2.1157, -2.3645, -3.2899],\n",
       "                        [-3.4988, -3.0115, -2.7938],\n",
       "                        [-3.8293, -3.2961, -2.8436]],\n",
       "              \n",
       "                       [[-3.9779, -2.0617, -3.1237],\n",
       "                        [-3.9790, -2.6218, -2.4551],\n",
       "                        [-3.5406, -3.1608, -3.2890]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6755, -2.0339, -3.6471],\n",
       "                        [-3.1715, -3.2779, -2.7492],\n",
       "                        [-2.6883, -3.9882, -3.6644]],\n",
       "              \n",
       "                       [[-2.4057, -2.0133, -2.1821],\n",
       "                        [-2.7596, -2.0538, -2.6359],\n",
       "                        [-3.5137, -3.3185, -3.5885]],\n",
       "              \n",
       "                       [[-3.0351, -2.9763, -2.0979],\n",
       "                        [-3.3766, -3.9956, -2.0556],\n",
       "                        [-2.8010, -3.5787, -3.6768]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.9227, -3.6770, -3.7636],\n",
       "                        [-3.2002, -2.1039, -2.2279],\n",
       "                        [-3.7049, -2.7865, -2.1264]],\n",
       "              \n",
       "                       [[-3.0326, -2.2067, -2.2916],\n",
       "                        [-2.1105, -3.7049, -2.5112],\n",
       "                        [-3.1940, -2.1001, -3.4853]],\n",
       "              \n",
       "                       [[-2.8792, -3.0937, -2.7589],\n",
       "                        [-2.6047, -2.2957, -3.1234],\n",
       "                        [-3.8853, -2.5147, -2.4693]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4313, -3.4454, -2.5228],\n",
       "                        [-2.2018, -3.2355, -2.3762],\n",
       "                        [-3.8663, -3.0295, -3.5700]],\n",
       "              \n",
       "                       [[-3.5861, -2.0395, -2.0020],\n",
       "                        [-2.1038, -3.2346, -2.7971],\n",
       "                        [-2.3657, -2.5616, -3.5310]],\n",
       "              \n",
       "                       [[-3.3006, -3.3535, -3.3189],\n",
       "                        [-3.1244, -3.3003, -3.5692],\n",
       "                        [-2.7795, -2.1361, -2.3262]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.1123, -3.5558, -2.4190],\n",
       "                        [-2.8286, -2.1191, -2.5490],\n",
       "                        [-2.3278, -2.8362, -3.7079]],\n",
       "              \n",
       "                       [[-2.0250, -2.0361, -2.2242],\n",
       "                        [-3.5920, -2.1569, -3.2739],\n",
       "                        [-2.3617, -3.3745, -2.4369]],\n",
       "              \n",
       "                       [[-3.4996, -2.8253, -2.5848],\n",
       "                        [-3.4868, -3.3970, -3.3454],\n",
       "                        [-3.3596, -3.8827, -3.4139]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.1325, -2.0101, -2.3009],\n",
       "                        [-3.3946, -3.7420, -2.2947],\n",
       "                        [-2.8810, -3.1959, -2.4976]],\n",
       "              \n",
       "                       [[-3.0886, -3.6569, -2.8172],\n",
       "                        [-3.7599, -3.9197, -2.1939],\n",
       "                        [-3.7000, -2.5793, -3.5384]],\n",
       "              \n",
       "                       [[-2.8714, -2.3903, -2.9222],\n",
       "                        [-2.1279, -3.4309, -2.6593],\n",
       "                        [-3.9820, -2.9647, -3.0653]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4074, -3.5453, -2.9808],\n",
       "                        [-2.2863, -3.9489, -2.0954],\n",
       "                        [-3.8373, -3.9608, -3.8983]],\n",
       "              \n",
       "                       [[-3.3889, -2.3294, -3.8718],\n",
       "                        [-2.4368, -2.1073, -2.8512],\n",
       "                        [-3.6483, -3.7381, -3.0208]],\n",
       "              \n",
       "                       [[-2.0715, -3.7128, -2.4285],\n",
       "                        [-3.7453, -2.5793, -3.9045],\n",
       "                        [-2.2144, -2.8838, -3.2419]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8225, -2.4760, -2.3612],\n",
       "                        [-3.4040, -2.1312, -3.9279],\n",
       "                        [-3.2219, -3.0139, -2.9078]],\n",
       "              \n",
       "                       [[-3.9570, -3.6798, -3.8169],\n",
       "                        [-2.9281, -3.5607, -2.0121],\n",
       "                        [-2.0334, -3.3228, -3.2737]],\n",
       "              \n",
       "                       [[-3.0264, -2.6413, -2.7952],\n",
       "                        [-2.6720, -2.2991, -3.6808],\n",
       "                        [-2.9856, -3.2928, -3.7279]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2259, -2.7306, -3.2844],\n",
       "                        [-3.2082, -2.3142, -3.7642],\n",
       "                        [-2.4837, -2.9002, -2.0545]],\n",
       "              \n",
       "                       [[-3.8918, -3.5356, -2.0444],\n",
       "                        [-2.3271, -2.4968, -3.9083],\n",
       "                        [-2.4074, -2.6570, -2.4153]],\n",
       "              \n",
       "                       [[-2.0498, -3.5175, -2.1168],\n",
       "                        [-3.9951, -2.7050, -2.6350],\n",
       "                        [-2.7071, -2.6911, -3.2756]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4691, -2.6418, -3.3070],\n",
       "                        [-2.0403, -3.3388, -3.3410],\n",
       "                        [-3.4311, -2.3567, -2.7274]],\n",
       "              \n",
       "                       [[-2.9643, -3.1868, -2.6083],\n",
       "                        [-3.9008, -2.3488, -2.8015],\n",
       "                        [-3.6829, -3.6533, -3.1903]],\n",
       "              \n",
       "                       [[-3.1084, -2.5719, -3.7105],\n",
       "                        [-2.5479, -3.8481, -2.2664],\n",
       "                        [-2.6867, -2.7838, -3.6353]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0250, -2.3754, -2.1942],\n",
       "                        [-2.2754, -2.2488, -2.5304],\n",
       "                        [-3.6430, -2.9638, -3.1415]],\n",
       "              \n",
       "                       [[-3.1872, -2.3818, -3.4090],\n",
       "                        [-3.5182, -3.5750, -3.3125],\n",
       "                        [-2.8591, -2.2255, -3.4907]],\n",
       "              \n",
       "                       [[-2.1073, -3.1520, -3.7595],\n",
       "                        [-2.5730, -2.0243, -3.1251],\n",
       "                        [-3.6950, -3.2891, -3.7837]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.3.param_mus',\n",
       "              tensor([-0.0347, -0.0540, -0.0008,  0.0293, -0.0292,  0.0349, -0.0176,  0.0116,\n",
       "                       0.0173,  0.0239,  0.0535,  0.0285,  0.0451, -0.0420,  0.0108, -0.0409,\n",
       "                       0.0453, -0.0289, -0.0493, -0.0556, -0.0361, -0.0034, -0.0584,  0.0529,\n",
       "                       0.0162, -0.0444,  0.0243,  0.0210, -0.0163,  0.0040,  0.0075, -0.0225,\n",
       "                      -0.0476,  0.0339,  0.0409, -0.0459,  0.0447,  0.0547,  0.0345, -0.0486,\n",
       "                       0.0053, -0.0136,  0.0179, -0.0266,  0.0421, -0.0030, -0.0182, -0.0482,\n",
       "                      -0.0340, -0.0338,  0.0125, -0.0354,  0.0531, -0.0226, -0.0371, -0.0432,\n",
       "                       0.0315,  0.0339, -0.0145,  0.0430,  0.0406,  0.0375, -0.0415, -0.0373])),\n",
       "             ('module_list.0.posterior_params.3.param_std_log',\n",
       "              tensor([-5.4569, -4.6801, -4.7204, -5.3099, -5.5642, -7.9669, -5.1158, -5.7351,\n",
       "                      -4.8519, -5.2321, -6.6220, -5.4749, -5.7233, -5.7436, -4.8307, -5.3099,\n",
       "                      -5.5596, -6.0521, -5.2583, -4.7860, -4.8898, -5.6637, -4.7467, -4.6643,\n",
       "                      -5.3782, -6.6473, -4.6510, -5.2890, -4.7336, -4.6367, -4.8326, -7.7491,\n",
       "                      -5.7414, -5.3058, -5.7958, -4.8864, -4.6670, -5.3566, -6.6464, -6.9234,\n",
       "                      -6.2836, -4.6365, -7.2882, -6.8838, -4.6835, -5.1239, -7.1621, -5.2982,\n",
       "                      -5.1323, -6.3269, -5.4452, -6.2584, -6.0409, -5.0412, -4.7253, -4.7920,\n",
       "                      -4.8736, -4.7333, -4.9122, -4.8091, -6.4931, -5.7098, -8.9380, -4.7787])),\n",
       "             ('module_list.0.posterior_params.3.scale_alphas_log',\n",
       "              tensor([-2.0096, -3.1070, -2.4744, -2.8249, -2.1330, -2.1949, -3.7866, -3.2097,\n",
       "                      -3.8550, -3.1583, -3.0586, -2.9922, -2.6323, -2.1886, -2.5555, -2.2712,\n",
       "                      -2.9222, -2.3903, -2.9189, -2.6913, -2.1877, -2.3527, -2.1297, -3.1475,\n",
       "                      -2.6098, -2.0891, -3.4339, -2.4926, -3.6903, -2.8732, -2.1957, -3.5118,\n",
       "                      -2.2983, -3.3832, -3.4829, -2.7464, -3.3553, -3.5355, -2.4428, -3.0015,\n",
       "                      -2.7173, -2.5134, -3.9719, -2.8202, -2.6662, -3.1703, -2.6489, -2.1131,\n",
       "                      -2.0383, -3.8398, -2.6632, -2.2751, -2.4046, -2.9891, -2.8446, -3.0018,\n",
       "                      -2.0600, -3.5996, -3.0579, -2.5789, -3.7129, -2.4109, -2.5351, -3.2553])),\n",
       "             ('module_list.0.posterior_params.3.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.4.param_mus',\n",
       "              tensor([[ 0.0009,  0.0158,  0.0126,  ..., -0.0105, -0.0025, -0.0128],\n",
       "                      [ 0.0080, -0.0029, -0.0087,  ...,  0.0028, -0.0101,  0.0126],\n",
       "                      [ 0.0150, -0.0064, -0.0075,  ..., -0.0084, -0.0034, -0.0038],\n",
       "                      ...,\n",
       "                      [-0.0002, -0.0109,  0.0178,  ..., -0.0034, -0.0082, -0.0020],\n",
       "                      [-0.0095,  0.0160, -0.0090,  ..., -0.0084,  0.0039,  0.0121],\n",
       "                      [-0.0176, -0.0070,  0.0146,  ..., -0.0085,  0.0145, -0.0063]])),\n",
       "             ('module_list.0.posterior_params.4.param_std_log',\n",
       "              tensor([[-5.0882, -5.6143, -5.0647,  ..., -5.6104, -4.6591, -4.9445],\n",
       "                      [-4.6745, -5.9688, -5.0048,  ..., -6.3473, -4.6243, -6.2210],\n",
       "                      [-4.7615, -7.7854, -5.7147,  ..., -7.3079, -5.9162, -5.9307],\n",
       "                      ...,\n",
       "                      [-6.7976, -5.2108, -5.6782,  ..., -5.2774, -5.6684, -6.0092],\n",
       "                      [-6.6351, -4.8296, -5.0264,  ..., -7.7251, -5.2107, -4.8150],\n",
       "                      [-7.3702, -8.7021, -4.7729,  ..., -4.8881, -4.7526, -5.0925]])),\n",
       "             ('module_list.0.posterior_params.4.scale_alphas_log',\n",
       "              tensor([[-2.3414, -2.7704, -3.4864,  ..., -2.1757, -3.9189, -2.2035],\n",
       "                      [-2.3410, -2.2061, -3.1260,  ..., -3.4673, -2.0878, -3.4667],\n",
       "                      [-3.9802, -2.7468, -2.0136,  ..., -2.2748, -3.8034, -2.2377],\n",
       "                      ...,\n",
       "                      [-2.4080, -2.7311, -2.1504,  ..., -3.6135, -2.4462, -2.0026],\n",
       "                      [-3.4683, -2.5169, -2.6618,  ..., -2.9077, -2.7889, -2.0861],\n",
       "                      [-2.1884, -3.1091, -3.6772,  ..., -2.2174, -2.0252, -2.5327]])),\n",
       "             ('module_list.0.posterior_params.4.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.5.param_mus',\n",
       "              tensor([-0.0112,  0.0141,  0.0014,  0.0127, -0.0057, -0.0123, -0.0136,  0.0164,\n",
       "                       0.0140,  0.0152,  0.0077,  0.0159, -0.0018, -0.0005,  0.0025,  0.0036,\n",
       "                       0.0174, -0.0110,  0.0078, -0.0102,  0.0028,  0.0009,  0.0105,  0.0106,\n",
       "                       0.0002, -0.0018,  0.0092, -0.0014, -0.0002,  0.0019,  0.0001,  0.0019,\n",
       "                      -0.0122,  0.0073, -0.0102, -0.0153, -0.0162,  0.0075,  0.0051,  0.0153,\n",
       "                       0.0129, -0.0160, -0.0173, -0.0098, -0.0150,  0.0157, -0.0045,  0.0022,\n",
       "                      -0.0135,  0.0099,  0.0101,  0.0171,  0.0014, -0.0172,  0.0025, -0.0021,\n",
       "                       0.0169,  0.0017,  0.0117, -0.0016,  0.0121, -0.0066, -0.0090, -0.0044,\n",
       "                      -0.0091,  0.0011, -0.0143,  0.0033, -0.0132, -0.0091, -0.0091, -0.0157,\n",
       "                       0.0127,  0.0111, -0.0166,  0.0143,  0.0017, -0.0061, -0.0174,  0.0098,\n",
       "                       0.0034, -0.0063,  0.0041, -0.0007, -0.0088, -0.0068, -0.0123, -0.0048,\n",
       "                       0.0054, -0.0105, -0.0157,  0.0175, -0.0124,  0.0101,  0.0101,  0.0164,\n",
       "                       0.0117, -0.0088, -0.0032,  0.0164,  0.0047,  0.0089, -0.0158, -0.0005,\n",
       "                       0.0097, -0.0070,  0.0082,  0.0131, -0.0131, -0.0050,  0.0024, -0.0050,\n",
       "                       0.0152,  0.0010, -0.0035, -0.0169,  0.0012, -0.0119, -0.0085, -0.0127,\n",
       "                       0.0139,  0.0060,  0.0050, -0.0074, -0.0137,  0.0144,  0.0127, -0.0140])),\n",
       "             ('module_list.0.posterior_params.5.param_std_log',\n",
       "              tensor([ -8.5058,  -4.9983,  -4.7748,  -6.4515,  -8.2332, -10.5456,  -5.4021,\n",
       "                       -8.7938,  -6.3761,  -5.5005,  -7.5101,  -5.7537,  -4.8349,  -6.5463,\n",
       "                       -4.9158,  -6.0935,  -7.2662,  -5.4875,  -5.6636,  -4.8700,  -4.7151,\n",
       "                       -4.7584,  -4.8736,  -5.3312,  -4.9649,  -4.9046,  -4.9326,  -7.3845,\n",
       "                       -6.0946,  -5.0042,  -4.9009,  -4.6594,  -5.4126,  -4.7578,  -5.2708,\n",
       "                       -7.4743,  -5.6484,  -5.0898,  -5.7023,  -5.2178,  -6.5615,  -7.9420,\n",
       "                       -5.2271,  -5.7446,  -5.1716,  -5.5231,  -5.2031,  -6.4824,  -4.7606,\n",
       "                       -5.7502,  -5.2827,  -6.0781,  -5.8726,  -5.0141,  -4.9438,  -8.0827,\n",
       "                       -5.3131,  -5.7115,  -4.7213,  -4.6253,  -4.7276,  -4.6258,  -5.1091,\n",
       "                       -5.2092,  -5.5085,  -5.6953,  -4.6783,  -4.9021,  -4.7901,  -4.9724,\n",
       "                       -5.9262,  -6.1041,  -5.0713,  -4.6735,  -6.4833,  -5.2216,  -5.1605,\n",
       "                       -4.9854,  -5.7718,  -6.8357,  -4.9983,  -6.0955,  -5.8611,  -5.9829,\n",
       "                       -4.8589,  -5.1603,  -6.4991,  -5.6061,  -5.8304,  -5.4435,  -4.6777,\n",
       "                       -4.7764,  -5.0857,  -4.9599,  -4.7925,  -4.8101,  -4.6988,  -4.6460,\n",
       "                       -5.2655,  -6.4285,  -5.7866,  -5.3847,  -5.1084,  -5.3568,  -5.4592,\n",
       "                       -5.4557,  -7.1196,  -4.6417,  -6.3491,  -4.9110,  -5.1545,  -4.8412,\n",
       "                       -5.2638,  -6.0338,  -4.9269,  -7.4436,  -5.8754,  -4.9944,  -5.3159,\n",
       "                       -5.9607,  -6.5675,  -6.2111,  -5.1559,  -7.5439,  -4.7024,  -5.7944,\n",
       "                       -4.7159,  -5.0060])),\n",
       "             ('module_list.0.posterior_params.5.scale_alphas_log',\n",
       "              tensor([-2.9711, -2.3029, -3.2661, -3.8841, -3.9730, -2.9972, -3.0801, -2.8908,\n",
       "                      -3.2214, -2.5367, -3.7855, -3.5761, -3.2829, -2.4807, -3.7627, -3.3901,\n",
       "                      -3.2457, -2.9323, -3.2918, -3.2453, -3.4675, -2.9678, -3.9310, -2.9987,\n",
       "                      -2.2035, -2.3976, -3.5818, -3.1568, -2.2656, -3.4460, -3.9424, -3.2561,\n",
       "                      -2.0742, -3.8532, -3.1280, -2.8851, -2.0143, -2.0730, -2.5920, -3.7779,\n",
       "                      -2.5698, -3.7920, -3.6548, -2.3358, -3.9477, -3.6476, -3.8149, -2.5764,\n",
       "                      -2.8168, -3.6043, -3.2515, -3.9662, -3.3422, -2.4601, -2.8934, -2.9427,\n",
       "                      -3.4763, -2.3204, -2.2301, -2.4737, -3.8858, -3.7568, -3.4567, -3.1788,\n",
       "                      -2.4339, -2.0268, -2.8586, -3.4026, -2.9261, -2.2214, -3.0145, -3.9870,\n",
       "                      -2.0210, -3.2889, -2.6818, -2.6525, -2.6215, -2.5191, -3.3091, -2.5133,\n",
       "                      -2.1772, -2.7749, -3.2064, -2.7597, -2.0681, -2.4307, -2.3182, -3.3219,\n",
       "                      -3.7947, -3.7979, -2.5180, -2.9864, -2.1951, -3.9902, -2.8577, -3.3741,\n",
       "                      -3.5462, -3.3496, -2.4838, -2.2125, -3.5979, -2.9471, -3.3925, -3.8978,\n",
       "                      -3.0267, -2.5021, -2.3832, -3.2529, -2.6711, -3.8071, -3.5777, -3.3519,\n",
       "                      -2.8422, -2.2266, -2.3704, -2.8740, -2.7499, -2.9441, -2.7132, -3.9846,\n",
       "                      -2.8880, -3.0201, -3.8964, -2.4971, -3.7383, -2.5198, -2.3017, -3.7625])),\n",
       "             ('module_list.0.posterior_params.5.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('module_list.0.posterior_params.6.param_mus',\n",
       "              tensor([[ 0.0861,  0.0572,  0.0623,  ...,  0.0349, -0.0029,  0.0783],\n",
       "                      [ 0.0663, -0.0496, -0.0471,  ...,  0.0246, -0.0090,  0.0290],\n",
       "                      [ 0.0787, -0.0569, -0.0074,  ...,  0.0223,  0.0753,  0.0849],\n",
       "                      ...,\n",
       "                      [-0.0752, -0.0523,  0.0439,  ..., -0.0768, -0.0083, -0.0679],\n",
       "                      [-0.0070, -0.0547, -0.0404,  ...,  0.0185, -0.0464, -0.0533],\n",
       "                      [-0.0087, -0.0757, -0.0331,  ...,  0.0254, -0.0312,  0.0815]])),\n",
       "             ('module_list.0.posterior_params.6.param_std_log',\n",
       "              tensor([[-5.2017, -7.5709, -4.9455,  ..., -5.7424, -5.2740, -7.6515],\n",
       "                      [-5.7487, -5.2041, -5.0962,  ..., -6.7837, -5.8445, -6.4197],\n",
       "                      [-5.0128, -4.9754, -5.1209,  ..., -5.3098, -6.3397, -8.8992],\n",
       "                      ...,\n",
       "                      [-6.1798, -5.0020, -5.8882,  ..., -4.7352, -8.7045, -4.7601],\n",
       "                      [-6.9533, -5.3401, -4.6249,  ..., -4.6350, -4.9398, -4.7976],\n",
       "                      [-5.3153, -4.6354, -5.0823,  ..., -5.2240, -5.2665, -4.6325]])),\n",
       "             ('module_list.0.posterior_params.6.scale_alphas_log',\n",
       "              tensor([[-3.4896, -2.3144, -3.2581,  ..., -2.1586, -3.0065, -2.2661],\n",
       "                      [-2.4441, -2.0589, -2.5914,  ..., -3.1640, -3.8862, -2.6127],\n",
       "                      [-2.4363, -2.7432, -2.3645,  ..., -2.4624, -2.6623, -2.2037],\n",
       "                      ...,\n",
       "                      [-3.5581, -3.5343, -3.9614,  ..., -3.5155, -3.0719, -3.5733],\n",
       "                      [-3.6154, -3.6500, -2.4728,  ..., -2.0083, -3.4753, -2.4960],\n",
       "                      [-3.1972, -3.5865, -2.2273,  ..., -3.9335, -3.2613, -3.5673]])),\n",
       "             ('module_list.0.posterior_params.6.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.7.param_mus',\n",
       "              tensor([ 0.0045,  0.0808, -0.0811,  0.0353,  0.0298, -0.0510, -0.0097,  0.0499,\n",
       "                       0.0105, -0.0429])),\n",
       "             ('module_list.0.posterior_params.7.param_std_log',\n",
       "              tensor([-5.2095, -5.1445, -5.7701, -4.7362, -6.1606, -5.0685, -5.4482, -5.0233,\n",
       "                      -5.1172, -4.9747])),\n",
       "             ('module_list.0.posterior_params.7.scale_alphas_log',\n",
       "              tensor([-2.7219, -3.5050, -3.6166, -2.6818, -2.5404, -2.2111, -2.9576, -3.6258,\n",
       "                      -2.4424, -2.8427])),\n",
       "             ('module_list.0.posterior_params.7.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_bayes.pt'))\n",
    "image1, label1 = test_dataset[10]\n",
    "image2, label2 = test_dataset[11]\n",
    "model(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:16906.90234375, KL Loss: 1690681.375, FitLoss: 0.09073139727115631, Accuracy 0.98, Prune parameters: 221821.0/421642\n"
     ]
    }
   ],
   "source": [
    "val_loss = 0.0\n",
    "val_acc = 0.0\n",
    "PRUNE = 1.0\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,  \n",
    "                                         batch_size=BATCH_SIZE,  \n",
    "                                         shuffle=False, \n",
    "                                         pin_memory=True) \n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "trainer.params.prune_threshold = PRUNE\n",
    "test_result = trainer.eval(model, test_loader)\n",
    "acc = test_result.custom_losses['val_accuracy']\n",
    "print(f'Loss:{test_result.val_loss}, KL Loss: {test_result.dist_loss}, FitLoss: {test_result.fit_loss}, Accuracy {acc}, Prune parameters: {test_result.cnt_prune_parameters}/{test_result.cnt_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device=device)\n",
    "model.prune({'threshold': 1.0})\n",
    "model.set_map_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 4.2992e-03, -5.4342e-01, -0.0000e+00],\n",
      "          [ 3.9089e-01, -0.0000e+00, -0.0000e+00],\n",
      "          [ 8.2518e-01,  3.0815e-01, -2.3478e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8153e-02,  0.0000e+00, -0.0000e+00],\n",
      "          [ 4.4879e-01,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.4131e+00, -7.5729e-01, -0.0000e+00],\n",
      "          [ 2.0788e-01,  4.6619e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  2.6288e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  9.8380e-01,  3.4592e-01],\n",
      "          [-0.0000e+00,  4.0430e-01,  0.0000e+00],\n",
      "          [-8.4115e-01, -3.8792e-01, -1.5979e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0565e-01,  0.0000e+00,  2.3229e-01],\n",
      "          [ 0.0000e+00,  6.6020e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -3.2411e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00,  3.8068e-01,  0.0000e+00],\n",
      "          [-1.7023e-03,  7.2274e-01,  1.6451e-01],\n",
      "          [-2.6313e-01,  0.0000e+00, -8.0280e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  7.1311e-01, -0.0000e+00],\n",
      "          [ 7.3480e-01,  0.0000e+00, -6.3528e-01],\n",
      "          [ 1.7638e-02, -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8662e-01,  4.1352e-01,  7.5745e-01],\n",
      "          [ 3.4204e-03, -2.4012e-03,  1.9629e-01],\n",
      "          [-0.0000e+00, -1.8996e+00, -5.4733e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7047e-01, -0.0000e+00, -4.2426e-02],\n",
      "          [-0.0000e+00,  8.9670e-01,  8.5076e-01],\n",
      "          [-4.0429e-01,  5.5609e-01, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  1.1400e-01],\n",
      "          [ 0.0000e+00,  4.4838e-01, -0.0000e+00],\n",
      "          [ 4.5566e-02, -0.0000e+00, -1.9310e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.7405e-02,  2.3569e-01, -0.0000e+00],\n",
      "          [ 4.6704e-01,  8.9131e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -1.1183e-02, -6.1903e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 5.3916e-02,  1.3328e-02, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4441e-01,  0.0000e+00, -2.3364e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  7.9347e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6268e-01,  0.0000e+00, -0.0000e+00],\n",
      "          [ 6.3382e-01,  3.4143e-01, -0.0000e+00],\n",
      "          [-0.0000e+00, -3.0772e-01, -8.3751e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0354e-01,  0.0000e+00, -0.0000e+00],\n",
      "          [ 4.2287e-01,  0.0000e+00,  3.6846e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.1328e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0544e-01, -1.0880e+00, -1.3626e+00],\n",
      "          [ 0.0000e+00,  4.4564e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  6.4581e-01,  3.5768e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  3.1633e-01, -6.6071e-01],\n",
      "          [ 0.0000e+00,  2.3753e-01, -0.0000e+00],\n",
      "          [ 3.6975e-01, -5.6517e-03, -6.6312e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.1901e-01,  6.4522e-02,  2.1885e-01],\n",
      "          [-0.0000e+00,  6.1452e-01,  4.0866e-01],\n",
      "          [-1.2748e-01,  5.6207e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.3363e-01, -0.0000e+00, -0.0000e+00],\n",
      "          [ 2.1696e-01,  0.0000e+00,  6.1144e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.8670e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  6.6921e-01,  3.2235e-01],\n",
      "          [-0.0000e+00,  4.6664e-01,  1.8888e-01],\n",
      "          [-5.4447e-01, -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.0248e-01, -0.0000e+00,  1.2330e-01],\n",
      "          [-0.0000e+00,  0.0000e+00,  6.1526e-01],\n",
      "          [-1.3471e-01,  3.3910e-01,  2.8420e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  2.2249e-01,  0.0000e+00],\n",
      "          [ 1.4262e-01,  8.8915e-01,  0.0000e+00],\n",
      "          [-0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1939e+00, -4.6484e-01, -0.0000e+00],\n",
      "          [-8.6274e-01,  1.4272e-01,  0.0000e+00],\n",
      "          [ 1.0309e-01,  4.9730e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1762e-01, -1.4468e-01, -0.0000e+00],\n",
      "          [ 3.6268e-01,  5.3481e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  5.2241e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00,  0.0000e+00,  1.2648e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.5915e-01],\n",
      "          [-0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3550e-02,  0.0000e+00,  6.7948e-02],\n",
      "          [ 5.6981e-01,  0.0000e+00,  4.5842e-01],\n",
      "          [ 2.9938e-02,  1.7861e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  3.6278e-01, -2.5424e-01],\n",
      "          [ 9.4070e-01,  0.0000e+00, -2.1502e-02],\n",
      "          [ 9.6985e-03,  6.5121e-02, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  9.1819e-02],\n",
      "          [ 0.0000e+00, -0.0000e+00, -3.3740e-01],\n",
      "          [-0.0000e+00, -0.0000e+00, -2.1633e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3137e-02, -0.0000e+00, -0.0000e+00],\n",
      "          [ 5.4615e-01,  2.9908e-01, -0.0000e+00],\n",
      "          [ 9.4902e-01,  2.2312e-01, -3.2910e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6456e-02, -3.2759e-01, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.7491e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -1.7607e-01, -7.8085e-02],\n",
      "          [-0.0000e+00,  1.0843e+00,  0.0000e+00],\n",
      "          [-7.0030e-02,  0.0000e+00,  1.0573e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  9.0907e-01],\n",
      "          [-1.3929e-01, -2.4492e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00]]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.base_module.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = test_dataset[100]\n",
    "plt.imshow(image.permute(1, 2, 0), cmap = 'gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2.1405], device='cuda:0'),\n",
       "indices=tensor([5], device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(model(image.cuda()).data, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
