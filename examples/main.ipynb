{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sasha/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../src', '/home/sasha/BMM/bayes_deep_compression/examples', '/home/sasha/anaconda3/lib/python311.zip', '/home/sasha/anaconda3/lib/python3.11', '/home/sasha/anaconda3/lib/python3.11/lib-dynload', '', '/home/sasha/anaconda3/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier(nn.Module): \n",
    "    def __init__(self, classes: int = 10): \n",
    "        super().__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) \n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        #self.dropout1 = nn.Dropout2d(0.25) \n",
    "        #self.dropout2 = nn.Dropout2d(0.5) \n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128) \n",
    "        self.fc2 = nn.Linear(128, classes) \n",
    "  \n",
    "    def forward(self, x): \n",
    "        x = self.pool(F.relu(self.conv1(x))) \n",
    "        #x = self.dropout1(x) \n",
    "        x = self.pool(F.relu(self.conv2(x))) \n",
    "        #x = self.dropout2(x) \n",
    "        x = x.view(-1, 64 * 7 * 7) \n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.fc2(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayescomp.bayes.variational.distribution import LogUniformVarDist\n",
    "from bayescomp.bayes.variational.net_distribution import VarBayesModuleNetDistribution\n",
    "from bayescomp.bayes.base.net_distribution import BaseNetDistributionPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogUniformVarDist(param_mus: torch.Size([2]), param_std_log: torch.Size([2]), scale_mus: torch.Size([2]), scale_alphas_log: torch.Size([2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = nn.Parameter(torch.tensor([0.0, 1.0]))\n",
    "LogUniformVarDist.from_parameter(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayescomp.bayes.variational.net import LogUniformVarBayesModule, VarBayesModuleNet\n",
    "from bayescomp.bayes.variational.optimization import LogUniformVarKLLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 6592148.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 192913.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 1796107.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4114585.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayes_model = BayesModule(module)\n",
    "var_module = LogUniformVarBayesModule(module)\n",
    "bayes_model = VarBayesModuleNet(module, nn.ModuleList([var_module]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VarBayesModuleNet(\n",
      "  (module_list): ModuleList(\n",
      "    (0): LogUniformVarBayesModule(\n",
      "      (posterior_params): ParameterList(\n",
      "          (0): Object of type: ParameterDict\n",
      "          (1): Object of type: ParameterDict\n",
      "          (2): Object of type: ParameterDict\n",
      "          (3): Object of type: ParameterDict\n",
      "          (4): Object of type: ParameterDict\n",
      "          (5): Object of type: ParameterDict\n",
      "          (6): Object of type: ParameterDict\n",
      "          (7): Object of type: ParameterDict\n",
      "        (0): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 32x1x3x3]\n",
      "        )\n",
      "        (1): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 32]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        )\n",
      "        (2): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 64x32x3x3]\n",
      "        )\n",
      "        (3): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 64]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        )\n",
      "        (4): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 128x3136]\n",
      "        )\n",
      "        (5): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 128]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 128]\n",
      "        )\n",
      "        (6): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 10x128]\n",
      "        )\n",
      "        (7): ParameterDict(\n",
      "            (param_mus): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (param_std_log): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (scale_alphas_log): Parameter containing: [torch.FloatTensor of size 10]\n",
      "            (scale_mus): Parameter containing: [torch.FloatTensor of size 10]\n",
      "        )\n",
      "      )\n",
      "      (prior_params): ParameterList()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(bayes_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i, p in enumerate(bayes_model.parameters()):\n",
    "    cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0, 2.], [3, 0]])\n",
    "b =  torch.tensor([1., 1.])\n",
    "a_s = a.to_sparse()\n",
    "print(a_s @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(bayes_model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1.weight': None,\n",
       " 'conv1.bias': None,\n",
       " 'conv2.weight': None,\n",
       " 'conv2.bias': None,\n",
       " 'fc1.weight': None,\n",
       " 'fc1.bias': None,\n",
       " 'fc2.weight': None,\n",
       " 'fc2.bias': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_model.prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = test_dataset[10]\n",
    "y = bayes_model(torch.ones_like(image))\n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "bayes_model.prior\n",
    "out = y.sum() + kl_loss(bayes_model.weights, bayes_model.posterior, bayes_model.prior)\n",
    "optimizer.zero_grad() \n",
    "out.backward() \n",
    "optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_distributon = VarBayesModuleNetDistribution(bayes_model.base_module, bayes_model.posterior)\n",
    "net_distributon_pruner = BaseNetDistributionPruner(net_distributon)\n",
    "net_distributon.set_map_params()\n",
    "net_distributon_pruner.prune(-2.2)\n",
    "#get basic model for evaluation\n",
    "eval_model = net_distributon.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-1.7739e-01,  4.8183e-02, -7.3418e-02],\n",
      "          [ 1.2302e-01,  1.6080e-01, -2.2654e-03],\n",
      "          [-2.0022e-02, -2.0802e-01,  8.2771e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2365e-01, -4.5209e-02, -6.6389e-02],\n",
      "          [ 4.6611e-02,  3.8977e-02, -2.1094e-01],\n",
      "          [ 4.0353e-02, -1.8961e-01, -6.4226e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.1916e-02,  7.5624e-02,  7.2735e-02],\n",
      "          [ 6.4230e-02,  9.6525e-02, -1.5932e-01],\n",
      "          [ 8.0029e-02, -1.9937e-01, -1.0564e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.5881e-03, -6.3533e-03, -1.6173e-01],\n",
      "          [ 7.2034e-02,  2.1627e-01, -1.4444e-01],\n",
      "          [-1.1444e-01, -2.3313e-01, -8.8791e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6789e-02,  3.4321e-02,  1.6554e-01],\n",
      "          [-8.0557e-02, -1.0476e-01,  1.4158e-01],\n",
      "          [ 6.8749e-02,  1.2548e-01,  2.5378e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3215e-02,  6.9166e-02, -1.7316e-01],\n",
      "          [ 1.7167e-02, -1.6875e-01, -7.5956e-02],\n",
      "          [ 3.1626e-02, -3.1497e-02,  6.2589e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6173e-02,  1.3643e-01,  1.0016e-01],\n",
      "          [ 4.3877e-02,  8.2547e-02, -1.0138e-01],\n",
      "          [ 3.1965e-02,  8.5215e-02,  1.4769e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1623e-06,  3.7669e-02,  1.9328e-01],\n",
      "          [ 1.5213e-01,  2.5446e-02,  2.3217e-01],\n",
      "          [ 1.6749e-01, -1.2354e-01, -1.5832e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7491e-01, -7.4801e-02,  1.8945e-01],\n",
      "          [ 4.4983e-02,  6.9799e-02, -5.8427e-02],\n",
      "          [-7.2602e-02, -2.2298e-01,  2.0435e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.7723e-02, -7.0888e-02, -4.5855e-02],\n",
      "          [-1.1058e-01,  6.9804e-03, -5.0156e-02],\n",
      "          [-1.9062e-01,  5.8854e-02, -2.9709e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3459e-01,  2.3276e-01, -2.1904e-01],\n",
      "          [-4.3692e-02, -8.0149e-02,  1.3329e-01],\n",
      "          [ 1.8218e-01,  6.3240e-03, -2.1208e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8660e-01, -2.7688e-02,  1.4019e-02],\n",
      "          [-5.1908e-02, -1.9486e-01,  9.8252e-02],\n",
      "          [ 2.9512e-02, -5.8996e-02, -2.9908e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.8244e-02, -7.0845e-02,  1.6836e-01],\n",
      "          [ 1.2452e-01, -8.6652e-02,  8.8540e-03],\n",
      "          [-1.0239e-01,  7.8269e-02, -3.5127e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.2290e-02,  1.9347e-01,  9.6616e-02],\n",
      "          [ 3.4048e-03, -7.9681e-03,  8.2397e-02],\n",
      "          [-1.0360e-01,  2.1662e-01, -2.0306e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8591e-02, -1.0444e-01, -1.5528e-01],\n",
      "          [ 7.9637e-02,  1.8183e-01, -1.5766e-01],\n",
      "          [ 1.8604e-01, -1.8331e-01,  3.4698e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.9590e-02, -1.2329e-01, -5.5089e-02],\n",
      "          [ 1.7556e-01,  1.5864e-01, -2.2543e-01],\n",
      "          [-1.4236e-01, -1.1258e-01,  6.0847e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9323e-01,  1.1925e-01, -1.7147e-02],\n",
      "          [-6.2334e-02, -3.2212e-02,  1.7893e-01],\n",
      "          [-3.9204e-02, -4.8635e-02,  2.4092e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1452e-01, -8.1882e-02, -2.4362e-02],\n",
      "          [ 1.2819e-01, -2.0138e-01, -4.9377e-02],\n",
      "          [ 2.2147e-01,  7.7812e-02,  1.8022e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1135e-02,  9.5859e-02,  6.2445e-02],\n",
      "          [-1.7136e-01, -1.1247e-02, -2.9087e-02],\n",
      "          [-5.4996e-02,  4.4153e-02, -1.7160e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.6058e-02, -2.3696e-02, -1.6544e-01],\n",
      "          [ 4.3972e-02,  1.3498e-02, -4.4945e-02],\n",
      "          [-6.6369e-02, -2.1737e-02, -9.0653e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3667e-02,  5.8797e-02, -8.9404e-02],\n",
      "          [ 1.8302e-01,  1.0182e-01,  5.5840e-02],\n",
      "          [ 2.3031e-02, -1.3167e-01, -2.0909e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5883e-01, -1.2181e-01,  1.4254e-01],\n",
      "          [ 2.0590e-01, -2.1660e-01, -1.7590e-01],\n",
      "          [ 1.9925e-01, -1.1216e-01,  2.1881e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4872e-02,  1.8082e-01,  4.3790e-02],\n",
      "          [ 5.4441e-02, -8.7037e-02,  3.1896e-02],\n",
      "          [-1.6122e-01,  6.9328e-03,  3.9606e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6585e-01, -1.9689e-01, -1.7195e-01],\n",
      "          [ 1.1572e-01,  6.2457e-02,  2.8566e-02],\n",
      "          [ 1.3417e-02,  8.4631e-02,  9.1358e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.3857e-02, -5.1108e-02, -1.9860e-01],\n",
      "          [ 3.7587e-02, -1.6833e-01,  8.7599e-02],\n",
      "          [-2.1228e-01,  2.9166e-02,  2.7162e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4410e-02, -1.9439e-01, -2.0151e-01],\n",
      "          [-7.5428e-02, -7.9624e-02, -3.8616e-03],\n",
      "          [-8.3894e-02,  1.4152e-01,  1.8559e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.8756e-02, -1.4618e-01, -2.4759e-02],\n",
      "          [-1.0453e-01, -1.1094e-01,  1.7698e-01],\n",
      "          [ 1.9624e-01, -4.1806e-02, -7.1082e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1268e-03,  1.7590e-01,  2.3129e-01],\n",
      "          [ 1.6045e-02,  5.4744e-02, -1.7411e-01],\n",
      "          [ 1.3573e-01,  2.2484e-01, -3.6621e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5568e-01, -2.2964e-02,  1.3215e-01],\n",
      "          [ 8.7660e-02,  1.3352e-02, -1.2037e-01],\n",
      "          [-2.3053e-01,  8.3443e-02, -2.1319e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1151e-01, -4.4025e-02,  3.4868e-02],\n",
      "          [ 2.2575e-01,  1.2624e-01,  2.5062e-02],\n",
      "          [ 1.5654e-01,  1.5959e-01, -1.1695e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1717e-02, -4.3689e-02, -1.3914e-01],\n",
      "          [-2.0823e-01, -5.5472e-02,  1.4015e-01],\n",
      "          [-3.2663e-02, -2.0320e-01, -3.2553e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0998e-01, -2.6108e-02,  7.4646e-02],\n",
      "          [ 2.0123e-01, -8.4403e-02, -1.3372e-02],\n",
      "          [-1.2092e-03,  1.9688e-02,  2.4854e-02]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(eval_model.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('module_list.0.posterior_params.0.param_mus',\n",
       "              tensor([[[[-1.7739e-01,  4.8183e-02, -7.3418e-02],\n",
       "                        [ 1.2302e-01,  1.6080e-01, -2.2654e-03],\n",
       "                        [-2.0022e-02, -2.0802e-01,  8.2771e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2365e-01, -4.5209e-02, -6.6389e-02],\n",
       "                        [ 4.6611e-02,  3.8977e-02, -2.1094e-01],\n",
       "                        [ 4.0353e-02, -1.8961e-01, -6.4226e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1916e-02,  7.5624e-02,  7.2735e-02],\n",
       "                        [ 6.4230e-02,  9.6525e-02, -1.5932e-01],\n",
       "                        [ 8.0029e-02, -1.9937e-01, -1.0564e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.5881e-03, -6.3533e-03, -1.6173e-01],\n",
       "                        [ 7.2034e-02,  2.1627e-01, -1.4444e-01],\n",
       "                        [-1.1444e-01, -2.3313e-01, -8.8791e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.6789e-02,  3.4321e-02,  1.6554e-01],\n",
       "                        [-8.0557e-02, -1.0476e-01,  1.4158e-01],\n",
       "                        [ 6.8749e-02,  1.2548e-01,  2.5378e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3215e-02,  6.9166e-02, -1.7316e-01],\n",
       "                        [ 1.7167e-02, -1.6875e-01, -7.5956e-02],\n",
       "                        [ 3.1626e-02, -3.1497e-02,  6.2589e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6173e-02,  1.3643e-01,  1.0016e-01],\n",
       "                        [ 4.3877e-02,  8.2547e-02, -1.0138e-01],\n",
       "                        [ 3.1965e-02,  8.5215e-02,  1.4769e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1623e-06,  3.7669e-02,  1.9328e-01],\n",
       "                        [ 1.5213e-01,  2.5446e-02,  2.3217e-01],\n",
       "                        [ 1.6749e-01, -1.2354e-01, -1.5832e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7491e-01, -7.4801e-02,  1.8945e-01],\n",
       "                        [ 4.4983e-02,  6.9799e-02, -5.8427e-02],\n",
       "                        [-7.2602e-02, -2.2298e-01,  2.0435e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.7723e-02, -7.0888e-02, -4.5855e-02],\n",
       "                        [-1.1058e-01,  6.9804e-03, -5.0156e-02],\n",
       "                        [-1.9062e-01,  5.8854e-02, -2.9709e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3459e-01,  2.3276e-01, -2.1904e-01],\n",
       "                        [-4.3692e-02, -8.0149e-02,  1.3329e-01],\n",
       "                        [ 1.8218e-01,  6.3240e-03, -2.1208e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.8660e-01, -2.7688e-02,  1.4019e-02],\n",
       "                        [-5.1908e-02, -1.9486e-01,  9.8252e-02],\n",
       "                        [ 2.9512e-02, -5.8996e-02, -2.9908e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.8244e-02, -7.0845e-02,  1.6836e-01],\n",
       "                        [ 1.2452e-01, -8.6652e-02,  8.8540e-03],\n",
       "                        [-1.0239e-01,  7.8269e-02, -3.5127e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.2290e-02,  1.9347e-01,  9.6616e-02],\n",
       "                        [ 3.4048e-03, -7.9681e-03,  8.2397e-02],\n",
       "                        [-1.0360e-01,  2.1662e-01, -2.0306e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.8591e-02, -1.0444e-01, -1.5528e-01],\n",
       "                        [ 7.9637e-02,  1.8183e-01, -1.5766e-01],\n",
       "                        [ 1.8604e-01, -1.8331e-01,  3.4698e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.9590e-02, -1.2329e-01, -5.5089e-02],\n",
       "                        [ 1.7556e-01,  1.5864e-01, -2.2543e-01],\n",
       "                        [-1.4236e-01, -1.1258e-01,  6.0847e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9323e-01,  1.1925e-01, -1.7147e-02],\n",
       "                        [-6.2334e-02, -3.2212e-02,  1.7893e-01],\n",
       "                        [-3.9204e-02, -4.8635e-02,  2.4092e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1452e-01, -8.1882e-02, -2.4362e-02],\n",
       "                        [ 1.2819e-01, -2.0138e-01, -4.9377e-02],\n",
       "                        [ 2.2147e-01,  7.7812e-02,  1.8022e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.1135e-02,  9.5859e-02,  6.2445e-02],\n",
       "                        [-1.7136e-01, -1.1247e-02, -2.9087e-02],\n",
       "                        [-5.4996e-02,  4.4153e-02, -1.7160e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.6058e-02, -2.3696e-02, -1.6544e-01],\n",
       "                        [ 4.3972e-02,  1.3498e-02, -4.4945e-02],\n",
       "                        [-6.6369e-02, -2.1737e-02, -9.0653e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3667e-02,  5.8797e-02, -8.9404e-02],\n",
       "                        [ 1.8302e-01,  1.0182e-01,  5.5840e-02],\n",
       "                        [ 2.3031e-02, -1.3167e-01, -2.0909e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5883e-01, -1.2181e-01,  1.4254e-01],\n",
       "                        [ 2.0590e-01, -2.1660e-01, -1.7590e-01],\n",
       "                        [ 1.9925e-01, -1.1216e-01,  2.1881e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.4872e-02,  1.8082e-01,  4.3790e-02],\n",
       "                        [ 5.4441e-02, -8.7037e-02,  3.1896e-02],\n",
       "                        [-1.6122e-01,  6.9328e-03,  3.9606e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6585e-01, -1.9689e-01, -1.7195e-01],\n",
       "                        [ 1.1572e-01,  6.2457e-02,  2.8566e-02],\n",
       "                        [ 1.3417e-02,  8.4631e-02,  9.1358e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3857e-02, -5.1108e-02, -1.9860e-01],\n",
       "                        [ 3.7587e-02, -1.6833e-01,  8.7599e-02],\n",
       "                        [-2.1228e-01,  2.9166e-02,  2.7162e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.4410e-02, -1.9439e-01, -2.0151e-01],\n",
       "                        [-7.5428e-02, -7.9624e-02, -3.8616e-03],\n",
       "                        [-8.3894e-02,  1.4152e-01,  1.8559e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.8756e-02, -1.4618e-01, -2.4759e-02],\n",
       "                        [-1.0453e-01, -1.1094e-01,  1.7698e-01],\n",
       "                        [ 1.9624e-01, -4.1806e-02, -7.1082e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.1268e-03,  1.7590e-01,  2.3129e-01],\n",
       "                        [ 1.6045e-02,  5.4744e-02, -1.7411e-01],\n",
       "                        [ 1.3573e-01,  2.2484e-01, -3.6621e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5568e-01, -2.2964e-02,  1.3215e-01],\n",
       "                        [ 8.7660e-02,  1.3352e-02, -1.2037e-01],\n",
       "                        [-2.3053e-01,  8.3443e-02, -2.1319e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1151e-01, -4.4025e-02,  3.4868e-02],\n",
       "                        [ 2.2575e-01,  1.2624e-01,  2.5062e-02],\n",
       "                        [ 1.5654e-01,  1.5959e-01, -1.1695e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.1717e-02, -4.3689e-02, -1.3914e-01],\n",
       "                        [-2.0823e-01, -5.5472e-02,  1.4015e-01],\n",
       "                        [-3.2663e-02, -2.0320e-01, -3.2553e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0998e-01, -2.6108e-02,  7.4646e-02],\n",
       "                        [ 2.0123e-01, -8.4403e-02, -1.3372e-02],\n",
       "                        [-1.2092e-03,  1.9688e-02,  2.4854e-02]]]])),\n",
       "             ('module_list.0.posterior_params.0.param_std_log',\n",
       "              tensor([[[[ -4.6058,  -5.3209,  -4.5138],\n",
       "                        [ -6.2662,  -5.6594,  -5.9341],\n",
       "                        [ -4.5563,  -5.7041,  -4.6615]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.0556,  -4.8308,  -6.5638],\n",
       "                        [ -6.3392,  -5.2813,  -6.4494],\n",
       "                        [ -6.4732,  -5.6824,  -4.8561]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.8805,  -5.7132,  -6.2418],\n",
       "                        [ -5.0569,  -6.3155,  -4.9901],\n",
       "                        [ -4.6823,  -4.6568,  -5.4332]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -7.0614,  -5.6802,  -6.1873],\n",
       "                        [ -7.0016,  -5.3152,  -5.1711],\n",
       "                        [ -5.7341,  -6.5063,  -5.0791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.1656,  -4.5974,  -5.5052],\n",
       "                        [ -4.7815,  -5.9665,  -4.7458],\n",
       "                        [ -5.5232,  -4.5176,  -4.9227]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3276,  -5.1535,  -5.9732],\n",
       "                        [ -6.3002,  -5.3347,  -4.6114],\n",
       "                        [ -5.1356,  -4.5804,  -7.2468]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.4888,  -5.3157,  -4.5599],\n",
       "                        [ -5.7381,  -6.1987,  -5.0411],\n",
       "                        [ -6.3498,  -6.0347,  -5.3610]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9081,  -6.1947,  -7.1894],\n",
       "                        [ -4.5504,  -5.1767,  -5.0740],\n",
       "                        [ -5.3953,  -5.9159,  -4.6070]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.7924,  -5.3843,  -4.9934],\n",
       "                        [-12.7951,  -4.9122,  -4.5252],\n",
       "                        [ -5.1474,  -5.4827,  -5.8940]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.3846,  -4.6900,  -6.3992],\n",
       "                        [ -4.7517,  -4.6551,  -5.6789],\n",
       "                        [ -5.4284,  -4.7093,  -4.7557]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9902,  -5.9904,  -4.6757],\n",
       "                        [ -6.9545,  -5.3209,  -5.1379],\n",
       "                        [ -5.2402,  -5.5240,  -6.2707]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.8428,  -4.6956,  -4.6114],\n",
       "                        [ -6.3143,  -6.1582,  -5.1634],\n",
       "                        [ -6.2568,  -5.9608,  -5.7134]]],\n",
       "              \n",
       "              \n",
       "                      [[[-10.6031,  -4.8723,  -4.5719],\n",
       "                        [ -4.6654,  -7.8930,  -4.8332],\n",
       "                        [ -4.6352,  -5.0519,  -4.7558]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.5169,  -5.2821,  -6.2428],\n",
       "                        [ -5.7896,  -9.5623,  -4.5706],\n",
       "                        [ -5.0535,  -5.5939,  -6.3808]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9463,  -5.8373,  -5.0490],\n",
       "                        [ -6.3861,  -7.7445,  -5.6533],\n",
       "                        [ -5.2304,  -6.7135,  -4.6980]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7980,  -5.1809,  -6.1487],\n",
       "                        [ -5.4368,  -8.0620,  -4.7516],\n",
       "                        [ -6.5438,  -4.5631,  -4.5599]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6520,  -4.6787,  -4.9025],\n",
       "                        [ -4.6765,  -4.9948,  -4.9914],\n",
       "                        [ -6.2878,  -6.3012,  -7.5825]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -7.9637,  -6.5192,  -5.0577],\n",
       "                        [ -5.9058,  -7.8054,  -4.9731],\n",
       "                        [ -6.4734,  -6.5317,  -7.4408]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.7755,  -4.7402,  -5.8580],\n",
       "                        [ -5.5001,  -4.5069,  -4.7511],\n",
       "                        [ -4.5177,  -4.5669,  -4.6210]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.0948,  -5.3652,  -6.3472],\n",
       "                        [ -5.3806,  -7.4284,  -5.1186],\n",
       "                        [ -5.3879,  -4.9641,  -4.5426]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7486,  -8.8424,  -4.8388],\n",
       "                        [ -6.5388,  -6.1006,  -4.6993],\n",
       "                        [ -4.8332,  -4.5228,  -6.0624]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.0854,  -4.5144,  -6.6309],\n",
       "                        [ -4.9309,  -5.1723,  -6.4383],\n",
       "                        [ -7.0027,  -5.7064,  -5.0992]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.6405,  -4.6859,  -5.1442],\n",
       "                        [ -5.9903,  -6.9882,  -5.8776],\n",
       "                        [ -4.5571,  -5.0242,  -5.0602]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.1351,  -4.5642,  -5.1013],\n",
       "                        [ -4.5998,  -5.7592,  -6.0570],\n",
       "                        [ -5.9127,  -5.9299,  -5.6241]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.9614,  -5.2592,  -7.9743],\n",
       "                        [ -5.0119,  -6.1092,  -4.6778],\n",
       "                        [ -5.2184,  -5.7889,  -4.5648]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9604,  -5.0924,  -4.5732],\n",
       "                        [ -6.6183,  -7.0417,  -4.6593],\n",
       "                        [ -4.6146,  -4.5750,  -4.8962]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.1342,  -6.2884,  -4.5960],\n",
       "                        [ -5.2539,  -6.8203,  -5.4319],\n",
       "                        [ -5.1699,  -5.0613,  -6.8007]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.8421,  -6.0571,  -5.2796],\n",
       "                        [ -4.5208,  -5.4540,  -5.4261],\n",
       "                        [ -5.1576,  -5.7070,  -4.5772]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3317,  -4.7990,  -6.4892],\n",
       "                        [ -5.1108,  -5.0824,  -6.5498],\n",
       "                        [ -4.5920,  -4.6593,  -5.1644]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7625,  -4.5272,  -5.2809],\n",
       "                        [ -4.5924,  -5.7443,  -7.1819],\n",
       "                        [ -5.6780,  -5.2674,  -5.6467]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.7220,  -5.9429,  -5.3177],\n",
       "                        [ -5.0692,  -4.8140,  -9.1113],\n",
       "                        [ -5.3592,  -6.2776,  -4.7629]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.4234,  -4.5205,  -4.6749],\n",
       "                        [ -4.5108,  -4.7498,  -4.8773],\n",
       "                        [ -4.7852,  -6.4310,  -5.6618]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_alphas_log',\n",
       "              tensor([[[[-3.1920, -2.5869, -3.2926],\n",
       "                        [-3.1651, -3.8543, -2.5660],\n",
       "                        [-3.1259, -3.3117, -2.2173]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9872, -2.3479, -2.0675],\n",
       "                        [-2.2878, -3.2627, -2.8418],\n",
       "                        [-2.0872, -3.3657, -2.1452]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9443, -3.1112, -1.9228],\n",
       "                        [-3.4322, -2.7905, -2.0444],\n",
       "                        [-2.6203, -2.0347, -2.1531]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9374, -3.7856, -3.1908],\n",
       "                        [-3.8248, -3.1816, -2.6375],\n",
       "                        [-3.8558, -2.4405, -3.1619]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6105, -3.7010, -2.3709],\n",
       "                        [-3.8244, -2.6583, -2.0316],\n",
       "                        [-3.4999, -2.1819, -2.8750]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4114, -1.9347, -2.4311],\n",
       "                        [-2.8143, -2.1177, -3.7953],\n",
       "                        [-2.8611, -2.6434, -2.7285]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2609, -2.7416, -2.0812],\n",
       "                        [-3.3901, -3.1662, -2.6168],\n",
       "                        [-3.3924, -3.2707, -2.6739]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6611, -2.4868, -2.0456],\n",
       "                        [-3.5299, -2.2565, -2.6414],\n",
       "                        [-3.7009, -3.8145, -3.4018]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9375, -2.2125, -2.5208],\n",
       "                        [-3.0432, -3.8703, -1.9044],\n",
       "                        [-2.6349, -3.6590, -2.7619]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8983, -2.9796, -3.3058],\n",
       "                        [-2.4793, -3.7394, -2.1750],\n",
       "                        [-3.6986, -3.7019, -2.8390]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0212, -2.7231, -2.4197],\n",
       "                        [-2.5241, -3.7490, -3.2857],\n",
       "                        [-2.4692, -2.1428, -3.5634]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6382, -2.6128, -3.4210],\n",
       "                        [-3.1407, -2.1809, -3.3288],\n",
       "                        [-2.0238, -2.5696, -2.2689]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6197, -2.8286, -3.6648],\n",
       "                        [-3.0917, -2.7945, -3.1443],\n",
       "                        [-3.5416, -2.0358, -1.9987]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3317, -2.7884, -3.0386],\n",
       "                        [-2.7785, -2.6014, -1.9129],\n",
       "                        [-3.7468, -2.3556, -3.3200]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3484, -1.9336, -3.8341],\n",
       "                        [-2.6361, -2.4892, -3.6211],\n",
       "                        [-2.4784, -2.2950, -3.2272]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2927, -3.5501, -3.5777],\n",
       "                        [-3.8743, -2.4152, -3.0605],\n",
       "                        [-2.9672, -3.6662, -1.9394]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0178, -2.6658, -3.0780],\n",
       "                        [-3.8559, -2.9749, -2.8471],\n",
       "                        [-2.1938, -1.9077, -3.1088]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4419, -2.1780, -2.3505],\n",
       "                        [-2.2807, -3.0480, -2.8418],\n",
       "                        [-3.0377, -1.9075, -3.5114]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8485, -2.5628, -3.5313],\n",
       "                        [-3.4825, -2.6678, -3.3196],\n",
       "                        [-3.1095, -2.7215, -3.1049]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4744, -3.0050, -3.8297],\n",
       "                        [-2.2416, -3.3054, -3.5208],\n",
       "                        [-2.1013, -3.2770, -2.7185]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8042, -2.5847, -2.9780],\n",
       "                        [-2.8062, -2.7034, -2.4162],\n",
       "                        [-3.4467, -2.3322, -3.8041]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0378, -2.1461, -2.0394],\n",
       "                        [-3.3426, -1.9921, -2.7989],\n",
       "                        [-2.9398, -3.3173, -3.2817]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3756, -2.5850, -2.1502],\n",
       "                        [-3.5525, -2.2404, -2.8406],\n",
       "                        [-2.8031, -2.7780, -3.4554]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9447, -3.2900, -2.3650],\n",
       "                        [-2.5029, -2.7094, -3.3249],\n",
       "                        [-3.1576, -3.5282, -2.5150]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6101, -2.4383, -3.3858],\n",
       "                        [-3.1335, -3.0011, -2.3984],\n",
       "                        [-2.0539, -1.9175, -3.1577]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9662, -3.8034, -3.5803],\n",
       "                        [-2.1050, -3.5189, -2.8176],\n",
       "                        [-3.3374, -3.1554, -2.2855]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4723, -1.9649, -2.7834],\n",
       "                        [-3.4692, -3.4608, -3.8788],\n",
       "                        [-2.9081, -2.8703, -3.5376]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9102, -3.0814, -3.4471],\n",
       "                        [-2.2830, -3.2011, -2.7516],\n",
       "                        [-3.6616, -2.1410, -3.6493]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9489, -2.6719, -2.0767],\n",
       "                        [-2.3073, -3.2962, -2.5403],\n",
       "                        [-2.6757, -2.2915, -3.7987]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2555, -3.7559, -3.5348],\n",
       "                        [-2.0026, -2.6404, -3.2861],\n",
       "                        [-2.6224, -2.1487, -3.6010]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7224, -3.7808, -2.1233],\n",
       "                        [-3.1090, -3.3552, -2.1302],\n",
       "                        [-2.9215, -2.5467, -3.1806]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9251, -3.5789, -3.8646],\n",
       "                        [-2.1911, -3.0281, -1.9942],\n",
       "                        [-3.8705, -2.3769, -2.1363]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.1.param_mus',\n",
       "              tensor([ 0.0921, -0.0969,  0.0401, -0.0062, -0.2203, -0.2199, -0.1611,  0.1856,\n",
       "                      -0.0417,  0.1512,  0.1246,  0.1956, -0.0995,  0.0909, -0.2239,  0.2183,\n",
       "                      -0.0724,  0.2330,  0.0717, -0.1062,  0.0233, -0.2014,  0.0278,  0.0318,\n",
       "                       0.1496, -0.0137,  0.0072,  0.0760,  0.0890, -0.1732,  0.0152,  0.2157])),\n",
       "             ('module_list.0.posterior_params.1.param_std_log',\n",
       "              tensor([-5.7512, -4.5444, -5.4927, -5.7675, -5.7627, -9.2058, -4.6879, -5.4641,\n",
       "                      -5.4263, -6.0323, -5.1306, -4.8645, -7.6498, -6.7577, -5.3409, -4.6794,\n",
       "                      -4.5463, -5.5416, -4.6299, -6.0808, -5.1188, -7.6445, -4.5443, -7.1751,\n",
       "                      -6.2179, -4.8470, -5.8433, -4.5566, -5.0035, -7.2985, -5.8879, -5.9582])),\n",
       "             ('module_list.0.posterior_params.1.scale_alphas_log',\n",
       "              tensor([-2.8779, -3.0882, -2.2745, -3.1111, -2.9619, -3.7916, -3.2610, -3.6799,\n",
       "                      -2.8195, -1.9358, -3.2361, -2.0745, -3.1138, -3.5156, -2.2925, -2.6367,\n",
       "                      -2.2899, -2.1035, -2.3715, -3.6565, -3.5442, -3.8690, -2.8758, -2.2246,\n",
       "                      -2.4389, -2.4422, -3.0973, -2.2500, -3.3087, -2.1978, -3.5588, -3.2859])),\n",
       "             ('module_list.0.posterior_params.1.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.2.param_mus',\n",
       "              tensor([[[[-0.0428, -0.0954,  0.0781],\n",
       "                        [-0.0594,  0.0834, -0.0726],\n",
       "                        [ 0.0994, -0.0813, -0.0798]],\n",
       "              \n",
       "                       [[ 0.0450, -0.0433,  0.0731],\n",
       "                        [ 0.0959,  0.0415,  0.0579],\n",
       "                        [-0.0915,  0.0752,  0.0888]],\n",
       "              \n",
       "                       [[-0.0890, -0.0711, -0.0708],\n",
       "                        [-0.0965, -0.0644,  0.0537],\n",
       "                        [-0.0747,  0.0749, -0.0450]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0914, -0.0948, -0.0612],\n",
       "                        [ 0.0730, -0.0797,  0.0747],\n",
       "                        [ 0.0818,  0.0846, -0.0676]],\n",
       "              \n",
       "                       [[ 0.0556, -0.0764,  0.0888],\n",
       "                        [-0.0780, -0.0982,  0.0998],\n",
       "                        [ 0.0664,  0.0922,  0.0881]],\n",
       "              \n",
       "                       [[-0.0699, -0.0415, -0.0924],\n",
       "                        [-0.0520, -0.0989,  0.0745],\n",
       "                        [ 0.0887,  0.0763,  0.0752]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0435,  0.0667, -0.0716],\n",
       "                        [-0.0501,  0.0779, -0.0630],\n",
       "                        [ 0.0660,  0.0474, -0.0742]],\n",
       "              \n",
       "                       [[-0.0469, -0.0808, -0.0717],\n",
       "                        [ 0.0480, -0.0698, -0.0802],\n",
       "                        [-0.0810, -0.0587, -0.0758]],\n",
       "              \n",
       "                       [[ 0.0423,  0.0945, -0.0810],\n",
       "                        [ 0.0744, -0.0799,  0.0911],\n",
       "                        [-0.0672,  0.0500,  0.0888]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0966, -0.0745, -0.0878],\n",
       "                        [-0.0690,  0.0797, -0.0672],\n",
       "                        [ 0.0778,  0.0888,  0.0899]],\n",
       "              \n",
       "                       [[-0.0801, -0.0431,  0.0901],\n",
       "                        [ 0.0634,  0.0666,  0.0429],\n",
       "                        [ 0.0433, -0.0529,  0.0956]],\n",
       "              \n",
       "                       [[-0.0952, -0.0955, -0.0735],\n",
       "                        [-0.0902,  0.0524,  0.0786],\n",
       "                        [ 0.0657, -0.0969,  0.0426]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0495, -0.0974,  0.0896],\n",
       "                        [ 0.0544,  0.0888, -0.0997],\n",
       "                        [ 0.0913,  0.0652, -0.0779]],\n",
       "              \n",
       "                       [[-0.0882,  0.0662, -0.0646],\n",
       "                        [ 0.0825,  0.0945, -0.0738],\n",
       "                        [-0.0671, -0.0622,  0.0984]],\n",
       "              \n",
       "                       [[-0.0766, -0.0684, -0.0808],\n",
       "                        [-0.0482, -0.0527, -0.0954],\n",
       "                        [ 0.0777,  0.0866,  0.0496]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0817, -0.0878,  0.0783],\n",
       "                        [ 0.0694,  0.0875, -0.0973],\n",
       "                        [-0.0470,  0.0988,  0.0937]],\n",
       "              \n",
       "                       [[-0.0494,  0.0515, -0.0965],\n",
       "                        [-0.0994,  0.0483, -0.0489],\n",
       "                        [-0.0652, -0.0950, -0.0842]],\n",
       "              \n",
       "                       [[ 0.0749,  0.0892, -0.0696],\n",
       "                        [ 0.0548,  0.0515,  0.0520],\n",
       "                        [-0.0433,  0.0500, -0.0569]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0842, -0.0999,  0.0877],\n",
       "                        [-0.0993,  0.0583, -0.0968],\n",
       "                        [ 0.0901, -0.0615,  0.0904]],\n",
       "              \n",
       "                       [[-0.0711,  0.0455,  0.0828],\n",
       "                        [ 0.0426, -0.0757, -0.0983],\n",
       "                        [-0.0908,  0.0644, -0.0869]],\n",
       "              \n",
       "                       [[ 0.0418, -0.0943,  0.0705],\n",
       "                        [ 0.0415,  0.0511, -0.0586],\n",
       "                        [ 0.0660,  0.0930,  0.0650]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0890, -0.0745,  0.0854],\n",
       "                        [-0.0996,  0.0543, -0.0678],\n",
       "                        [-0.0932, -0.0418,  0.0507]],\n",
       "              \n",
       "                       [[ 0.0574, -0.0987, -0.0924],\n",
       "                        [ 0.0985, -0.0712,  0.0414],\n",
       "                        [-0.0419,  0.0594,  0.0522]],\n",
       "              \n",
       "                       [[ 0.0784, -0.0737, -0.0835],\n",
       "                        [ 0.0810, -0.0630,  0.0699],\n",
       "                        [-0.0734,  0.0698,  0.0669]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0652,  0.0653,  0.0773],\n",
       "                        [ 0.0752,  0.0756, -0.0751],\n",
       "                        [-0.0916,  0.0854, -0.0647]],\n",
       "              \n",
       "                       [[-0.0896, -0.0828, -0.0457],\n",
       "                        [ 0.0834, -0.0628,  0.0454],\n",
       "                        [-0.0682,  0.0414,  0.0715]],\n",
       "              \n",
       "                       [[-0.0883, -0.0433, -0.0655],\n",
       "                        [-0.0438, -0.0775,  0.0726],\n",
       "                        [ 0.0571, -0.0998, -0.0874]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0748,  0.0445,  0.0530],\n",
       "                        [ 0.0606,  0.0945,  0.0880],\n",
       "                        [-0.0447,  0.0463,  0.0799]],\n",
       "              \n",
       "                       [[ 0.0660,  0.0444, -0.0418],\n",
       "                        [-0.0419, -0.0776, -0.0705],\n",
       "                        [ 0.0737,  0.0944,  0.0792]],\n",
       "              \n",
       "                       [[ 0.0993,  0.0574, -0.0779],\n",
       "                        [-0.0658, -0.0484, -0.0919],\n",
       "                        [-0.0880, -0.0855, -0.0501]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0468, -0.0627, -0.0493],\n",
       "                        [ 0.0491, -0.0922, -0.0593],\n",
       "                        [-0.0703,  0.0682,  0.0670]],\n",
       "              \n",
       "                       [[ 0.0839,  0.0609, -0.0800],\n",
       "                        [-0.0984, -0.0653, -0.0562],\n",
       "                        [ 0.0881,  0.0766, -0.0574]],\n",
       "              \n",
       "                       [[-0.0937,  0.0573, -0.0660],\n",
       "                        [-0.0916,  0.0915,  0.0648],\n",
       "                        [ 0.0626, -0.0821, -0.0466]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0777,  0.0704, -0.0971],\n",
       "                        [ 0.0609,  0.0490,  0.0637],\n",
       "                        [ 0.0482,  0.0581,  0.0768]],\n",
       "              \n",
       "                       [[-0.0459,  0.0868, -0.0862],\n",
       "                        [-0.0432,  0.0474, -0.0847],\n",
       "                        [ 0.0807,  0.0747,  0.0444]],\n",
       "              \n",
       "                       [[-0.0479,  0.0507,  0.0991],\n",
       "                        [-0.0813,  0.0516,  0.0570],\n",
       "                        [ 0.0920,  0.0663,  0.0583]]]])),\n",
       "             ('module_list.0.posterior_params.2.param_std_log',\n",
       "              tensor([[[[ -5.0862,  -5.0565,  -4.6608],\n",
       "                        [ -5.9751,  -4.7067,  -5.4262],\n",
       "                        [ -4.8310,  -5.0940,  -5.7469]],\n",
       "              \n",
       "                       [[ -4.7527,  -4.7550,  -6.5533],\n",
       "                        [ -4.6758,  -4.8779,  -5.4712],\n",
       "                        [ -7.1801,  -5.5659,  -5.0518]],\n",
       "              \n",
       "                       [[ -5.3380,  -4.9144,  -5.7932],\n",
       "                        [ -5.4022,  -6.2082,  -6.7250],\n",
       "                        [ -4.5800,  -5.1314,  -5.0587]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -6.3693,  -5.0496,  -5.0541],\n",
       "                        [ -4.6451,  -7.8148,  -4.9493],\n",
       "                        [ -5.2838,  -4.8858,  -4.7454]],\n",
       "              \n",
       "                       [[ -6.5905,  -4.9188,  -6.2962],\n",
       "                        [ -6.2456,  -4.8339,  -4.7861],\n",
       "                        [ -4.7367,  -5.4559,  -5.2482]],\n",
       "              \n",
       "                       [[ -4.8401,  -6.9287,  -4.7537],\n",
       "                        [ -4.9588,  -5.0482,  -4.8873],\n",
       "                        [ -5.1511,  -5.5141,  -5.1181]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.9826,  -5.0771,  -6.8098],\n",
       "                        [ -4.5179,  -4.9237,  -6.0686],\n",
       "                        [ -5.3690,  -5.3602,  -5.1648]],\n",
       "              \n",
       "                       [[ -4.5570,  -7.1526,  -6.2675],\n",
       "                        [ -4.9696,  -5.5183,  -4.9887],\n",
       "                        [ -6.4455,  -5.9845,  -4.5948]],\n",
       "              \n",
       "                       [[ -5.0068,  -4.8799,  -4.7612],\n",
       "                        [ -5.5975,  -6.0096,  -6.8184],\n",
       "                        [ -4.7178,  -6.0242,  -4.6879]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -6.8080,  -4.6866,  -4.6265],\n",
       "                        [ -4.6616,  -4.8789,  -4.5696],\n",
       "                        [ -5.0916,  -5.7546,  -4.7685]],\n",
       "              \n",
       "                       [[ -4.8635,  -7.1533,  -5.4547],\n",
       "                        [ -6.0452,  -9.9963,  -5.4458],\n",
       "                        [ -6.6059,  -7.1471,  -5.2880]],\n",
       "              \n",
       "                       [[ -5.0497,  -5.6706,  -6.2600],\n",
       "                        [ -4.5264,  -6.6195,  -5.0061],\n",
       "                        [ -5.7778,  -4.8092,  -6.0471]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.5489,  -4.5284,  -5.7712],\n",
       "                        [ -6.2811,  -5.5423,  -6.6874],\n",
       "                        [ -4.5953,  -5.1846,  -4.9048]],\n",
       "              \n",
       "                       [[ -4.9287,  -5.0025,  -5.5228],\n",
       "                        [ -6.3249,  -4.7485,  -5.8001],\n",
       "                        [ -6.4116,  -4.6579,  -4.8115]],\n",
       "              \n",
       "                       [[ -4.5195,  -5.1911,  -4.9415],\n",
       "                        [ -4.5427,  -6.5104,  -4.5441],\n",
       "                        [ -6.0396,  -6.0713,  -6.1527]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.7968,  -4.8711,  -4.8630],\n",
       "                        [ -5.8317,  -4.9644,  -4.5565],\n",
       "                        [ -5.4734,  -4.7410,  -4.6342]],\n",
       "              \n",
       "                       [[ -6.7053,  -6.8632,  -5.6666],\n",
       "                        [ -4.8592,  -4.6962,  -4.8054],\n",
       "                        [ -6.0775,  -4.8141,  -6.6616]],\n",
       "              \n",
       "                       [[ -4.7754,  -4.6495,  -6.3014],\n",
       "                        [ -4.6082,  -4.9710,  -4.5853],\n",
       "                        [ -4.5616,  -4.5154,  -5.2515]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7116,  -6.5736,  -4.9954],\n",
       "                        [ -5.2253,  -4.6311,  -6.0895],\n",
       "                        [ -6.0313,  -5.6685,  -4.9352]],\n",
       "              \n",
       "                       [[ -5.5182,  -6.2365,  -5.0919],\n",
       "                        [ -5.0063,  -5.3562,  -7.8269],\n",
       "                        [ -6.5046,  -7.3077,  -4.9361]],\n",
       "              \n",
       "                       [[ -5.1926,  -4.6092,  -5.1617],\n",
       "                        [ -4.9137,  -6.1951,  -4.6026],\n",
       "                        [ -4.5992,  -5.9202,  -4.7768]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.8987,  -4.9861,  -6.2089],\n",
       "                        [ -4.6246,  -5.2676,  -5.9061],\n",
       "                        [ -5.4958,  -5.8082,  -5.1999]],\n",
       "              \n",
       "                       [[ -4.7323,  -4.6123,  -4.9902],\n",
       "                        [ -5.0240,  -4.8827,  -7.2079],\n",
       "                        [ -5.6198,  -5.7301,  -4.5663]],\n",
       "              \n",
       "                       [[ -5.2203,  -9.1526,  -5.6727],\n",
       "                        [ -6.4038,  -4.8917,  -5.6272],\n",
       "                        [ -4.5061,  -5.4744,  -5.6070]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.2589,  -4.5642,  -6.5819],\n",
       "                        [ -6.6631,  -6.7389,  -4.8875],\n",
       "                        [ -4.5405,  -4.5420,  -4.6523]],\n",
       "              \n",
       "                       [[ -4.9827,  -6.3385,  -5.0701],\n",
       "                        [ -4.5912,  -5.7179,  -4.9743],\n",
       "                        [ -4.8584,  -5.5102,  -4.7920]],\n",
       "              \n",
       "                       [[ -5.8147,  -5.0496,  -6.1315],\n",
       "                        [ -5.4580,  -4.5755,  -5.5540],\n",
       "                        [ -5.9968,  -7.4450,  -4.5239]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.1644,  -5.1790,  -4.8386],\n",
       "                        [ -4.7932,  -4.9150,  -5.1933],\n",
       "                        [ -4.9876,  -5.5344,  -6.2126]],\n",
       "              \n",
       "                       [[-10.6290,  -4.8313,  -5.5725],\n",
       "                        [ -5.2133,  -5.7557,  -5.4072],\n",
       "                        [ -4.5593,  -4.6326,  -7.1015]],\n",
       "              \n",
       "                       [[ -5.3096,  -6.7203,  -6.2413],\n",
       "                        [ -5.2456,  -5.6014,  -4.5069],\n",
       "                        [ -5.8489,  -5.5483,  -5.5036]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.5335,  -4.5529,  -5.9066],\n",
       "                        [ -5.6882,  -6.0680,  -4.5359],\n",
       "                        [ -5.2296,  -4.6500,  -5.0016]],\n",
       "              \n",
       "                       [[ -4.9612,  -5.6962,  -6.0795],\n",
       "                        [ -7.1345,  -4.9137,  -4.7902],\n",
       "                        [ -5.9072,  -5.8029,  -6.3461]],\n",
       "              \n",
       "                       [[-10.9198,  -4.7059,  -4.8781],\n",
       "                        [ -5.3645,  -4.8372,  -5.9112],\n",
       "                        [ -4.7185,  -5.7238,  -4.9717]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.7964,  -7.1462,  -5.7325],\n",
       "                        [ -5.3192,  -5.3209,  -4.6719],\n",
       "                        [ -5.7349,  -6.8587,  -4.6100]],\n",
       "              \n",
       "                       [[ -4.5303,  -5.2787,  -4.9182],\n",
       "                        [ -4.5615,  -4.5951,  -6.1200],\n",
       "                        [ -5.2413,  -4.7409,  -5.8566]],\n",
       "              \n",
       "                       [[ -4.5800,  -4.5665,  -5.1088],\n",
       "                        [ -5.6263,  -6.2710,  -6.3216],\n",
       "                        [ -5.8122,  -5.4928,  -4.7813]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_alphas_log',\n",
       "              tensor([[[[-2.1714, -2.5018, -3.2376],\n",
       "                        [-3.6147, -3.5560, -2.9808],\n",
       "                        [-3.6410, -3.3287, -2.7962]],\n",
       "              \n",
       "                       [[-2.8116, -2.2751, -2.8066],\n",
       "                        [-3.0042, -2.0591, -3.6281],\n",
       "                        [-2.4349, -2.1489, -3.1496]],\n",
       "              \n",
       "                       [[-2.6300, -3.4544, -3.7583],\n",
       "                        [-3.7785, -2.2394, -3.8795],\n",
       "                        [-2.5209, -3.2277, -2.3423]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.7409, -3.5833, -3.7699],\n",
       "                        [-3.8998, -2.2986, -3.6510],\n",
       "                        [-3.6158, -2.9517, -2.8980]],\n",
       "              \n",
       "                       [[-3.0286, -3.7296, -2.2987],\n",
       "                        [-2.8595, -3.2675, -3.6974],\n",
       "                        [-2.5293, -2.7017, -3.3662]],\n",
       "              \n",
       "                       [[-3.7082, -2.8900, -3.5210],\n",
       "                        [-3.7368, -2.5365, -2.3124],\n",
       "                        [-3.2852, -3.0583, -3.3459]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2550, -3.7550, -2.2804],\n",
       "                        [-2.9400, -2.9591, -3.8589],\n",
       "                        [-3.4077, -1.9433, -2.2719]],\n",
       "              \n",
       "                       [[-2.0799, -2.8500, -3.3655],\n",
       "                        [-3.4963, -3.5103, -3.3506],\n",
       "                        [-3.8172, -3.3089, -2.6921]],\n",
       "              \n",
       "                       [[-2.5958, -2.7386, -2.9020],\n",
       "                        [-3.0489, -3.6072, -2.6025],\n",
       "                        [-3.4839, -2.4529, -2.7342]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2001, -3.1986, -3.0340],\n",
       "                        [-2.1361, -2.3702, -2.9715],\n",
       "                        [-2.5126, -3.1047, -2.0137]],\n",
       "              \n",
       "                       [[-3.0712, -3.5322, -2.4635],\n",
       "                        [-3.8410, -2.5569, -3.8545],\n",
       "                        [-3.0920, -2.9572, -2.7203]],\n",
       "              \n",
       "                       [[-3.0062, -2.0083, -3.1930],\n",
       "                        [-3.8325, -2.5448, -2.8338],\n",
       "                        [-2.6107, -2.2392, -3.6289]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.7022, -3.2702, -3.3478],\n",
       "                        [-3.6723, -3.7347, -2.5838],\n",
       "                        [-2.1031, -3.4475, -2.2600]],\n",
       "              \n",
       "                       [[-3.7770, -2.8728, -3.5366],\n",
       "                        [-2.2219, -2.9040, -3.1547],\n",
       "                        [-1.9172, -3.1287, -3.1267]],\n",
       "              \n",
       "                       [[-2.6311, -2.7378, -3.7439],\n",
       "                        [-1.9539, -2.4549, -3.3723],\n",
       "                        [-2.5093, -3.7191, -2.1353]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.7691, -3.6683, -1.9416],\n",
       "                        [-3.3770, -3.6060, -2.1127],\n",
       "                        [-1.9634, -3.0039, -3.5560]],\n",
       "              \n",
       "                       [[-2.7999, -3.0471, -2.9933],\n",
       "                        [-2.6317, -3.5093, -2.1226],\n",
       "                        [-2.5993, -3.0745, -2.3115]],\n",
       "              \n",
       "                       [[-2.4257, -3.4422, -2.4385],\n",
       "                        [-2.7543, -3.2529, -3.3327],\n",
       "                        [-2.8849, -3.4368, -2.5881]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.0098, -3.6559, -3.1862],\n",
       "                        [-2.3024, -3.5395, -2.9183],\n",
       "                        [-3.7015, -3.5528, -2.8299]],\n",
       "              \n",
       "                       [[-3.5413, -2.2841, -2.0702],\n",
       "                        [-2.6760, -2.5713, -2.2997],\n",
       "                        [-2.4173, -2.3488, -1.9438]],\n",
       "              \n",
       "                       [[-3.1860, -3.7976, -2.6618],\n",
       "                        [-2.1206, -3.0095, -3.4690],\n",
       "                        [-3.7956, -2.1895, -3.5360]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.9797, -3.4075, -2.4752],\n",
       "                        [-2.0500, -2.6482, -3.7642],\n",
       "                        [-2.3718, -2.5525, -2.0180]],\n",
       "              \n",
       "                       [[-3.6831, -3.4211, -3.5397],\n",
       "                        [-1.9879, -2.4954, -3.5872],\n",
       "                        [-2.9857, -2.2502, -3.0767]],\n",
       "              \n",
       "                       [[-2.5348, -3.2499, -3.8828],\n",
       "                        [-2.4922, -2.1782, -3.3535],\n",
       "                        [-2.5307, -2.3992, -3.1127]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9594, -1.9705, -3.8721],\n",
       "                        [-2.5496, -2.8562, -2.9407],\n",
       "                        [-1.9743, -2.1033, -3.1048]],\n",
       "              \n",
       "                       [[-2.7083, -2.9908, -2.3064],\n",
       "                        [-3.8971, -2.3260, -3.4796],\n",
       "                        [-1.9824, -3.4970, -2.8828]],\n",
       "              \n",
       "                       [[-2.5418, -2.9945, -3.7180],\n",
       "                        [-3.5479, -2.3773, -3.5902],\n",
       "                        [-2.0878, -3.4225, -3.2930]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.8055, -2.2557, -3.1745],\n",
       "                        [-2.4875, -2.5113, -2.7966],\n",
       "                        [-3.4032, -2.2730, -2.9235]],\n",
       "              \n",
       "                       [[-3.7427, -3.5359, -3.2444],\n",
       "                        [-3.3377, -2.0842, -3.4182],\n",
       "                        [-3.4182, -3.7707, -3.0749]],\n",
       "              \n",
       "                       [[-2.9630, -3.7752, -1.9224],\n",
       "                        [-1.9600, -3.4112, -3.1031],\n",
       "                        [-3.4583, -2.1108, -3.7307]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4176, -3.0341, -1.9470],\n",
       "                        [-2.9779, -3.4656, -2.2124],\n",
       "                        [-3.5014, -2.4725, -3.6521]],\n",
       "              \n",
       "                       [[-2.6161, -3.0985, -2.8761],\n",
       "                        [-3.8039, -3.8712, -1.9910],\n",
       "                        [-2.2627, -2.2122, -2.2468]],\n",
       "              \n",
       "                       [[-2.8443, -3.6581, -2.2795],\n",
       "                        [-3.1146, -2.4488, -2.6752],\n",
       "                        [-2.0181, -3.4120, -2.5837]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.9297, -3.3067, -2.1707],\n",
       "                        [-3.4821, -3.6863, -2.8029],\n",
       "                        [-2.2683, -3.2436, -2.8759]],\n",
       "              \n",
       "                       [[-3.0446, -2.4530, -2.5820],\n",
       "                        [-3.1957, -2.3468, -1.9046],\n",
       "                        [-3.3361, -3.3559, -2.6559]],\n",
       "              \n",
       "                       [[-3.0107, -2.2780, -3.2185],\n",
       "                        [-2.6648, -3.7163, -3.0063],\n",
       "                        [-3.8761, -1.9185, -2.8743]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.3.param_mus',\n",
       "              tensor([ 0.0750,  0.0467, -0.0571, -0.0871,  0.0660, -0.0546,  0.0640, -0.0991,\n",
       "                       0.0565,  0.0501, -0.0694,  0.0644,  0.0635, -0.0526, -0.0667,  0.0414,\n",
       "                       0.0437, -0.0801, -0.0760, -0.0441,  0.0883, -0.0829,  0.0646,  0.0599,\n",
       "                      -0.0865, -0.0833, -0.0592,  0.0840, -0.0805, -0.0669, -0.0686,  0.0820,\n",
       "                       0.0754,  0.0593,  0.0770, -0.0853, -0.0716, -0.0967,  0.0800, -0.0708,\n",
       "                       0.0779, -0.0508,  0.0834, -0.0761,  0.0465, -0.0746,  0.0707, -0.0570,\n",
       "                      -0.0489, -0.0849,  0.0719, -0.0686,  0.0928,  0.0455, -0.0832, -0.0437,\n",
       "                       0.0951,  0.0589,  0.0819,  0.0844, -0.0457, -0.0600, -0.0825, -0.0908])),\n",
       "             ('module_list.0.posterior_params.3.param_std_log',\n",
       "              tensor([-4.9792, -7.0863, -4.6312, -5.0462, -5.1243, -4.5889, -5.8878, -4.6843,\n",
       "                      -4.5665, -4.9542, -5.3295, -5.7663, -5.3527, -5.1087, -4.5234, -4.6242,\n",
       "                      -5.9020, -4.5429, -4.8736, -7.0775, -6.2837, -5.0368, -6.3454, -4.5849,\n",
       "                      -4.9635, -6.5224, -4.7879, -6.1058, -6.1020, -5.2793, -4.5626, -4.8635,\n",
       "                      -5.7222, -5.7158, -5.5625, -5.5997, -4.7639, -5.3140, -6.4825, -5.3622,\n",
       "                      -5.1614, -4.6049, -6.1469, -4.6329, -7.5214, -7.3658, -6.1176, -4.9962,\n",
       "                      -5.4985, -4.9225, -5.5893, -5.9871, -5.5881, -4.5136, -6.7475, -5.0191,\n",
       "                      -4.6571, -4.6600, -4.7997, -9.3072, -5.3994, -4.8254, -5.6128, -5.5328])),\n",
       "             ('module_list.0.posterior_params.3.scale_alphas_log',\n",
       "              tensor([-3.3338, -2.3058, -2.7044, -3.4066, -2.2615, -2.6613, -2.0806, -2.5960,\n",
       "                      -2.4914, -1.9068, -2.8343, -3.5351, -2.9773, -3.6777, -2.3381, -3.3923,\n",
       "                      -3.4214, -3.4744, -3.7091, -3.0408, -3.4107, -3.0543, -3.4342, -2.2540,\n",
       "                      -3.6110, -3.6060, -3.6822, -3.2690, -2.6526, -2.0743, -3.4957, -2.2283,\n",
       "                      -3.0100, -2.1385, -3.5580, -2.9726, -3.1560, -2.7370, -2.6906, -2.6309,\n",
       "                      -2.7383, -3.8092, -3.6927, -2.0086, -3.2940, -3.7876, -3.1608, -3.7410,\n",
       "                      -1.9031, -3.8654, -2.6362, -2.7575, -2.2171, -2.0424, -2.9357, -3.5660,\n",
       "                      -3.0409, -2.9524, -3.6795, -2.9103, -2.1524, -3.8797, -3.0298, -3.3821])),\n",
       "             ('module_list.0.posterior_params.3.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.4.param_mus',\n",
       "              tensor([[ 0.0860,  0.0992,  0.0898,  ..., -0.0837,  0.0962, -0.0974],\n",
       "                      [ 0.0828, -0.0950,  0.0942,  ..., -0.0846, -0.0935,  0.0858],\n",
       "                      [-0.0892,  0.0915,  0.0916,  ...,  0.0965,  0.0834, -0.0936],\n",
       "                      ...,\n",
       "                      [-0.0955, -0.0912, -0.0928,  ...,  0.0896,  0.0849, -0.0836],\n",
       "                      [ 0.0883, -0.0960, -0.0912,  ...,  0.0896, -0.0921,  0.0988],\n",
       "                      [-0.0904,  0.0977,  0.0826,  ...,  0.0922, -0.0900,  0.0828]])),\n",
       "             ('module_list.0.posterior_params.4.param_std_log',\n",
       "              tensor([[-4.7150, -4.6476, -6.4415,  ..., -5.7122, -7.1345, -4.5776],\n",
       "                      [-5.4241, -5.6931, -5.2670,  ..., -4.5776, -6.2073, -4.6651],\n",
       "                      [-5.8958, -5.2775, -4.6845,  ..., -4.9588, -5.3249, -5.1524],\n",
       "                      ...,\n",
       "                      [-5.0503, -6.2035, -5.0383,  ..., -9.1553, -5.3104, -4.7109],\n",
       "                      [-7.8387, -5.6284, -4.5466,  ..., -5.0527, -5.0765, -4.8553],\n",
       "                      [-5.5694, -5.2547, -5.9677,  ..., -6.0411, -6.3424, -5.5881]])),\n",
       "             ('module_list.0.posterior_params.4.scale_alphas_log',\n",
       "              tensor([[-2.6613, -3.7336, -3.7339,  ..., -2.2275, -2.6285, -3.6052],\n",
       "                      [-3.2578, -2.7042, -2.2629,  ..., -3.1826, -2.5889, -2.8004],\n",
       "                      [-3.7699, -3.6400, -2.8782,  ..., -2.3241, -3.2197, -3.4767],\n",
       "                      ...,\n",
       "                      [-2.8885, -2.8872, -3.6607,  ..., -2.7561, -3.6821, -2.7116],\n",
       "                      [-3.7904, -3.4909, -3.1144,  ..., -2.1126, -3.1984, -3.5116],\n",
       "                      [-2.3988, -3.8449, -3.7693,  ..., -2.0337, -2.1942, -3.1682]])),\n",
       "             ('module_list.0.posterior_params.4.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.5.param_mus',\n",
       "              tensor([-0.0881, -0.0944,  0.0919, -0.0835,  0.0869, -0.0935, -0.0963, -0.0843,\n",
       "                      -0.0867,  0.0840,  0.0834, -0.0827,  0.0988,  0.0827,  0.0838, -0.0885,\n",
       "                      -0.0871, -0.0998,  0.0962, -0.0967, -0.0846,  0.0957, -0.0845,  0.0833,\n",
       "                       0.0875,  0.0975, -0.0978,  0.0923, -0.0907, -0.0877,  0.0883,  0.0970,\n",
       "                      -0.0929, -0.0977,  0.0855, -0.0939, -0.0921, -0.0890, -0.0870, -0.0962,\n",
       "                      -0.0937,  0.0908,  0.0822,  0.0994, -0.0864,  0.0945,  0.0878, -0.0834,\n",
       "                       0.0915,  0.0831, -0.0907, -0.0945, -0.0875, -0.0836,  0.0979, -0.0847,\n",
       "                      -0.0919,  0.0944, -0.0974,  0.0881, -0.0966,  0.0939, -0.0839,  0.0947,\n",
       "                       0.0987, -0.0903,  0.0858, -0.0979, -0.0964, -0.0923,  0.0870,  0.0963,\n",
       "                      -0.0966,  0.0927, -0.0945, -0.0909,  0.0830, -0.0969,  0.0938, -0.0901,\n",
       "                       0.0997, -0.0858, -0.0981,  0.0875, -0.0916, -0.0882, -0.0939,  0.0937,\n",
       "                      -0.0829,  0.0985,  0.0843, -0.0988,  0.0876,  0.0938, -0.0944,  0.0887,\n",
       "                       0.0857,  0.0980, -0.0830,  0.0861, -0.0979, -0.0838,  0.0923,  0.0830,\n",
       "                      -0.0939, -0.0832, -0.0968,  0.0885, -0.0921,  0.0905,  0.0968, -0.0980,\n",
       "                      -0.0861,  0.0885, -0.0881, -0.0856,  0.0914, -0.0891, -0.0931, -0.0837,\n",
       "                       0.0940, -0.0995,  0.0980, -0.0873,  0.0857,  0.0863, -0.0969,  0.0881])),\n",
       "             ('module_list.0.posterior_params.5.param_std_log',\n",
       "              tensor([-4.6723, -5.0398, -5.1953, -5.0998, -5.6914, -4.9399, -4.9645, -4.5663,\n",
       "                      -5.2343, -5.4034, -8.9621, -4.5160, -4.7030, -5.4203, -4.5072, -4.7571,\n",
       "                      -5.6281, -4.6500, -5.9424, -6.9428, -4.8226, -7.2173, -4.7530, -5.4223,\n",
       "                      -4.7904, -5.0569, -4.7254, -6.5923, -6.2232, -6.3474, -5.5257, -4.8037,\n",
       "                      -4.8268, -4.7379, -5.0500, -5.2554, -4.5769, -4.7746, -5.2214, -5.9704,\n",
       "                      -5.8778, -5.6734, -4.9649, -5.1937, -5.0364, -4.8869, -7.9520, -4.7732,\n",
       "                      -4.8364, -5.9053, -4.8955, -8.2808, -4.8569, -4.6049, -4.5495, -5.0159,\n",
       "                      -4.6397, -5.3617, -6.6299, -6.0283, -5.8414, -4.7470, -5.7174, -4.7996,\n",
       "                      -5.7394, -5.1101, -5.1602, -5.4704, -6.7547, -4.8971, -5.4559, -7.6821,\n",
       "                      -5.3958, -4.5061, -5.0098, -4.5614, -4.8308, -5.1740, -4.8726, -4.7357,\n",
       "                      -5.1067, -5.0961, -7.5481, -4.6566, -5.5433, -5.3020, -5.4187, -4.7594,\n",
       "                      -8.0083, -5.4983, -6.6646, -4.7921, -5.5838, -6.8553, -4.9550, -7.7311,\n",
       "                      -4.5097, -5.0979, -4.5239, -4.9897, -4.6573, -5.7406, -6.9062, -5.7380,\n",
       "                      -7.2292, -5.4211, -5.6339, -7.6132, -4.6333, -5.7036, -4.6150, -4.8322,\n",
       "                      -4.8853, -5.0858, -5.3856, -4.8027, -4.9459, -6.4170, -5.3185, -7.0971,\n",
       "                      -5.6594, -4.8675, -5.4766, -9.6729, -4.6988, -5.0575, -4.5937, -4.6761])),\n",
       "             ('module_list.0.posterior_params.5.scale_alphas_log',\n",
       "              tensor([-2.5769, -3.7612, -1.9163, -3.1754, -1.9153, -3.8029, -2.6125, -2.5561,\n",
       "                      -3.3700, -2.0130, -2.7109, -3.6588, -2.2628, -3.1343, -3.2668, -3.6790,\n",
       "                      -2.9894, -3.2231, -2.7817, -3.7441, -3.5497, -3.3379, -3.7182, -3.5812,\n",
       "                      -2.5209, -2.1643, -1.9775, -2.4984, -2.0017, -3.3826, -2.0952, -3.1960,\n",
       "                      -2.4687, -2.2370, -2.4349, -2.5971, -3.0572, -3.1977, -3.8692, -2.1600,\n",
       "                      -2.7240, -2.5722, -3.5886, -2.2042, -3.5262, -3.6083, -2.5410, -3.1766,\n",
       "                      -2.5499, -3.2009, -2.5658, -3.6664, -2.4411, -2.2158, -2.8517, -2.2366,\n",
       "                      -2.2998, -2.6301, -3.3267, -2.4017, -3.7308, -3.1828, -2.7808, -2.3140,\n",
       "                      -2.8430, -3.5802, -3.6343, -3.8148, -3.8892, -2.7990, -2.0746, -2.7659,\n",
       "                      -3.1547, -2.0220, -2.5094, -2.6501, -2.6447, -3.7424, -3.5362, -3.6678,\n",
       "                      -2.9170, -1.9560, -2.9436, -3.4126, -2.8960, -2.8651, -2.8893, -2.2778,\n",
       "                      -3.0391, -3.5036, -2.2732, -3.1252, -2.9115, -1.9566, -2.1967, -3.0880,\n",
       "                      -2.0762, -3.7056, -3.4154, -3.5561, -2.4595, -2.1710, -2.1597, -2.0297,\n",
       "                      -2.3629, -2.3563, -3.1926, -2.9363, -3.6852, -3.4217, -2.3646, -2.6624,\n",
       "                      -2.4641, -2.6420, -2.9654, -3.2412, -2.1051, -2.0210, -2.6688, -2.5840,\n",
       "                      -2.7543, -2.2878, -2.4847, -3.0013, -2.2058, -2.8738, -2.1517, -3.1688])),\n",
       "             ('module_list.0.posterior_params.5.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('module_list.0.posterior_params.6.param_mus',\n",
       "              tensor([[-0.0889, -0.0129, -0.0757,  ..., -0.0197, -0.0683,  0.0293],\n",
       "                      [-0.0261, -0.0716,  0.0988,  ..., -0.0780, -0.0434, -0.0801],\n",
       "                      [ 0.0984,  0.0282, -0.0520,  ..., -0.0483, -0.0572, -0.0557],\n",
       "                      ...,\n",
       "                      [ 0.0607,  0.0978, -0.0156,  ..., -0.0227, -0.0708, -0.0133],\n",
       "                      [-0.0449,  0.0646,  0.0919,  ...,  0.0918, -0.0655,  0.0206],\n",
       "                      [-0.0476,  0.0986, -0.0987,  ...,  0.0208,  0.0550,  0.0433]])),\n",
       "             ('module_list.0.posterior_params.6.param_std_log',\n",
       "              tensor([[-5.8885, -4.7813, -4.5557,  ..., -4.6321, -4.9114, -5.4092],\n",
       "                      [-8.2078, -6.7939, -4.6667,  ..., -8.8423, -4.6748, -4.8086],\n",
       "                      [-5.3251, -6.0053, -4.7842,  ..., -5.7170, -5.3099, -4.7693],\n",
       "                      ...,\n",
       "                      [-6.3173, -5.5967, -5.4578,  ..., -4.8698, -4.5182, -4.8063],\n",
       "                      [-5.4984, -4.8667, -4.6134,  ..., -8.5712, -5.1324, -4.9273],\n",
       "                      [-4.8687, -5.8434, -5.2042,  ..., -4.9430, -5.1664, -4.8054]])),\n",
       "             ('module_list.0.posterior_params.6.scale_alphas_log',\n",
       "              tensor([[-3.0451, -3.4883, -1.9244,  ..., -3.1747, -2.3017, -1.9677],\n",
       "                      [-2.1353, -3.2108, -3.3882,  ..., -2.8542, -1.9713, -3.3933],\n",
       "                      [-3.7841, -3.0529, -3.7248,  ..., -3.2358, -2.6023, -3.5003],\n",
       "                      ...,\n",
       "                      [-2.6320, -2.5855, -3.1778,  ..., -3.1528, -3.3036, -3.0799],\n",
       "                      [-2.5576, -3.3180, -2.8055,  ..., -3.6584, -2.3423, -2.4460],\n",
       "                      [-3.4748, -3.6757, -3.1052,  ..., -3.7449, -2.7519, -2.5389]])),\n",
       "             ('module_list.0.posterior_params.6.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.7.param_mus',\n",
       "              tensor([-0.0611, -0.0430,  0.0125, -0.0953,  0.0317, -0.0694,  0.0289,  0.0475,\n",
       "                      -0.0228,  0.0602])),\n",
       "             ('module_list.0.posterior_params.7.param_std_log',\n",
       "              tensor([-5.6091, -5.8308, -5.2220, -5.1715, -4.6179, -4.6855, -4.5114, -6.0461,\n",
       "                      -4.9495, -4.9905])),\n",
       "             ('module_list.0.posterior_params.7.scale_alphas_log',\n",
       "              tensor([-3.1071, -3.5517, -3.3400, -3.1957, -3.3199, -2.1332, -3.3192, -2.4961,\n",
       "                      -2.5239, -2.1192])),\n",
       "             ('module_list.0.posterior_params.7.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2574,  0.0943, -0.2167, -0.3983,  0.0213,  0.2146, -0.0947,  0.1659,\n",
      "          0.1276,  0.3128]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.2574,  0.0943, -0.2167, -0.3983,  0.0213,  0.2146, -0.0947,  0.1659,\n",
      "          0.1276,  0.3128]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(bayes_model(torch.zeros_like(image)))\n",
    "#print(bayes_model(torch.zeros_like(image), sample = False))\n",
    "print(module(torch.zeros_like(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayescomp.bayes.variational.trainer import VarBayesTrainer, VarTrainerParams, Beta_Scheduler_Plato, CallbackLossAccuracy\n",
    "from bayescomp.report.base import ReportChain\n",
    "from bayescomp.report.variational import VarBaseReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = Beta_Scheduler_Plato()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.], requires_grad=True)\n",
      "tensor([1., 4.], grad_fn=<PowBackward0>)\n",
      "Parameter containing:\n",
      "tensor([1., 4.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 4.], requires_grad=True)\n",
      "tensor([1., 2.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2.], requires_grad=True)\n",
    "print(x)\n",
    "y = x ** 2\n",
    "print(y)\n",
    "z = nn.Parameter(y)\n",
    "loss = z.sum()\n",
    "print(z)\n",
    "loss .backward()\n",
    "print(z)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2ec8f9aa964c29a5f60c1074836a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4000],Loss:3039518.0, KL Loss: 3039515.75. FitLoss: 2.2958476543426514,Accuracy:0.13374999999999992,Validation Loss:3038043.0,Validation Accuracy:0.265, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [2/4000],Loss:3036897.0, KL Loss: 3036894.75. FitLoss: 2.2877578735351562,Accuracy:0.16235000000000002,Validation Loss:3035425.0,Validation Accuracy:0.239, Prune parameters: 0.0/421642,Beta: 0.01\n",
      "Epoch [3/4000],Loss:3034280.5, KL Loss: 3034278.25. FitLoss: 2.285029888153076,Accuracy:0.1886625,Validation Loss:3032810.0,Validation Accuracy:0.226, Prune parameters: 0.0/421642,Beta: 0.000625\n",
      "Epoch [4/4000],Loss:3031666.75, KL Loss: 3031664.5. FitLoss: 2.2839386463165283,Accuracy:0.18256249999999996,Validation Loss:3030196.5,Validation Accuracy:0.187, Prune parameters: 0.0/421642,Beta: 2.44140625e-06\n",
      "Epoch [5/4000],Loss:3029053.25, KL Loss: 3029051.0. FitLoss: 2.284726619720459,Accuracy:0.18298750000000005,Validation Loss:3027583.0,Validation Accuracy:0.207, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [6/4000],Loss:3026440.5, KL Loss: 3026438.0. FitLoss: 2.2872841358184814,Accuracy:0.18932500000000002,Validation Loss:3024970.25,Validation Accuracy:0.185, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [7/4000],Loss:3023826.75, KL Loss: 3023824.75. FitLoss: 2.2910521030426025,Accuracy:0.17302499999999998,Validation Loss:3022356.5,Validation Accuracy:0.195, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [8/4000],Loss:3021213.0, KL Loss: 3021211.0. FitLoss: 2.2944979667663574,Accuracy:0.17467499999999989,Validation Loss:3019742.75,Validation Accuracy:0.209, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [9/4000],Loss:3018599.25, KL Loss: 3018597.0. FitLoss: 2.2974698543548584,Accuracy:0.1540499999999999,Validation Loss:3017128.75,Validation Accuracy:0.161, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [10/4000],Loss:3015984.75, KL Loss: 3015982.75. FitLoss: 2.299926519393921,Accuracy:0.1341125,Validation Loss:3014513.75,Validation Accuracy:0.111, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [11/4000],Loss:3013369.75, KL Loss: 3013367.0. FitLoss: 2.3014118671417236,Accuracy:0.11296250000000004,Validation Loss:3011898.25,Validation Accuracy:0.087, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [12/4000],Loss:3010754.25, KL Loss: 3010751.75. FitLoss: 2.302149534225464,Accuracy:0.10094999999999994,Validation Loss:3009283.0,Validation Accuracy:0.087, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [13/4000],Loss:3008138.25, KL Loss: 3008136.0. FitLoss: 2.3024652004241943,Accuracy:0.09798750000000005,Validation Loss:3006666.25,Validation Accuracy:0.087, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [14/4000],Loss:3005521.5, KL Loss: 3005519.5. FitLoss: 2.302489995956421,Accuracy:0.10181249999999997,Validation Loss:3004049.75,Validation Accuracy:0.087, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [15/4000],Loss:3002904.5, KL Loss: 3002902.5. FitLoss: 2.30257511138916,Accuracy:0.09956249999999997,Validation Loss:3001432.75,Validation Accuracy:0.087, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [16/4000],Loss:3000287.0, KL Loss: 3000284.75. FitLoss: 2.302581787109375,Accuracy:0.09980000000000003,Validation Loss:2998814.25,Validation Accuracy:0.087, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [17/4000],Loss:2997668.75, KL Loss: 2997666.5. FitLoss: 2.3025598526000977,Accuracy:0.09834999999999998,Validation Loss:2996196.0,Validation Accuracy:0.087, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [18/4000],Loss:2995050.0, KL Loss: 2995048.0. FitLoss: 2.302522659301758,Accuracy:0.10003750000000004,Validation Loss:2993577.0,Validation Accuracy:0.087, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [19/4000],Loss:2992430.5, KL Loss: 2992428.5. FitLoss: 2.3025386333465576,Accuracy:0.09687499999999999,Validation Loss:2990957.5,Validation Accuracy:0.092, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [20/4000],Loss:2989811.0, KL Loss: 2989809.0. FitLoss: 2.3024709224700928,Accuracy:0.10142499999999999,Validation Loss:2988337.25,Validation Accuracy:0.092, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [21/4000],Loss:2987190.75, KL Loss: 2987188.5. FitLoss: 2.302476406097412,Accuracy:0.10089999999999999,Validation Loss:2985716.75,Validation Accuracy:0.092, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [22/4000],Loss:2984569.75, KL Loss: 2984567.5. FitLoss: 2.3024649620056152,Accuracy:0.10245000000000001,Validation Loss:2983095.5,Validation Accuracy:0.092, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [23/4000],Loss:2981948.0, KL Loss: 2981945.75. FitLoss: 2.3024508953094482,Accuracy:0.099525,Validation Loss:2980473.25,Validation Accuracy:0.092, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [24/4000],Loss:2979325.75, KL Loss: 2979323.5. FitLoss: 2.302405834197998,Accuracy:0.1008125,Validation Loss:2977851.0,Validation Accuracy:0.092, Prune parameters: 0.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [25/4000],Loss:2976703.5, KL Loss: 2976701.25. FitLoss: 2.302395820617676,Accuracy:0.10428750000000005,Validation Loss:2975227.75,Validation Accuracy:0.107, Prune parameters: 45.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [26/4000],Loss:2974080.0, KL Loss: 2974078.0. FitLoss: 2.30237078666687,Accuracy:0.10441250000000005,Validation Loss:2972604.0,Validation Accuracy:0.107, Prune parameters: 875.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [27/4000],Loss:2971456.0, KL Loss: 2971454.0. FitLoss: 2.3023641109466553,Accuracy:0.10750000000000004,Validation Loss:2969980.0,Validation Accuracy:0.107, Prune parameters: 1716.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [28/4000],Loss:2968832.0, KL Loss: 2968830.0. FitLoss: 2.302316427230835,Accuracy:0.10587500000000002,Validation Loss:2967355.25,Validation Accuracy:0.107, Prune parameters: 2540.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [29/4000],Loss:2966206.75, KL Loss: 2966204.5. FitLoss: 2.3023645877838135,Accuracy:0.10254999999999999,Validation Loss:2964730.0,Validation Accuracy:0.107, Prune parameters: 3396.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [30/4000],Loss:2963581.0, KL Loss: 2963578.75. FitLoss: 2.302363157272339,Accuracy:0.1044,Validation Loss:2962103.75,Validation Accuracy:0.107, Prune parameters: 4205.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [31/4000],Loss:2960954.75, KL Loss: 2960952.75. FitLoss: 2.3023786544799805,Accuracy:0.10350000000000008,Validation Loss:2959477.25,Validation Accuracy:0.107, Prune parameters: 5083.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [32/4000],Loss:2958328.0, KL Loss: 2958325.5. FitLoss: 2.302273988723755,Accuracy:0.1057875,Validation Loss:2956850.25,Validation Accuracy:0.107, Prune parameters: 5876.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [33/4000],Loss:2955701.0, KL Loss: 2955698.75. FitLoss: 2.3023245334625244,Accuracy:0.10631249999999999,Validation Loss:2954222.5,Validation Accuracy:0.107, Prune parameters: 6720.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [34/4000],Loss:2953073.0, KL Loss: 2953070.5. FitLoss: 2.302295207977295,Accuracy:0.10478750000000003,Validation Loss:2951594.25,Validation Accuracy:0.107, Prune parameters: 7562.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [35/4000],Loss:2950444.25, KL Loss: 2950442.0. FitLoss: 2.3022940158843994,Accuracy:0.10598750000000001,Validation Loss:2948965.75,Validation Accuracy:0.107, Prune parameters: 8430.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [36/4000],Loss:2947815.25, KL Loss: 2947813.0. FitLoss: 2.3022806644439697,Accuracy:0.10472500000000004,Validation Loss:2946336.0,Validation Accuracy:0.107, Prune parameters: 9352.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [37/4000],Loss:2945185.5, KL Loss: 2945183.25. FitLoss: 2.302351713180542,Accuracy:0.10687500000000003,Validation Loss:2943705.75,Validation Accuracy:0.107, Prune parameters: 10219.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [38/4000],Loss:2942555.0, KL Loss: 2942552.75. FitLoss: 2.3022589683532715,Accuracy:0.10719999999999996,Validation Loss:2941075.25,Validation Accuracy:0.107, Prune parameters: 11044.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [39/4000],Loss:2939924.0, KL Loss: 2939921.75. FitLoss: 2.3022661209106445,Accuracy:0.1090875,Validation Loss:2938444.25,Validation Accuracy:0.107, Prune parameters: 11878.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [40/4000],Loss:2937292.75, KL Loss: 2937290.5. FitLoss: 2.30230450630188,Accuracy:0.10643750000000007,Validation Loss:2935812.25,Validation Accuracy:0.107, Prune parameters: 12780.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [41/4000],Loss:2934660.5, KL Loss: 2934658.25. FitLoss: 2.3022749423980713,Accuracy:0.10656250000000003,Validation Loss:2933179.75,Validation Accuracy:0.107, Prune parameters: 13606.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [42/4000],Loss:2932027.5, KL Loss: 2932025.5. FitLoss: 2.3023133277893066,Accuracy:0.10502500000000001,Validation Loss:2930546.75,Validation Accuracy:0.107, Prune parameters: 14452.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [43/4000],Loss:2929394.5, KL Loss: 2929392.25. FitLoss: 2.302234411239624,Accuracy:0.10687500000000003,Validation Loss:2927913.0,Validation Accuracy:0.107, Prune parameters: 15313.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [44/4000],Loss:2926760.75, KL Loss: 2926758.25. FitLoss: 2.302265167236328,Accuracy:0.10672500000000007,Validation Loss:2925278.75,Validation Accuracy:0.107, Prune parameters: 16221.0/421642,Beta: 1.9073486328125e-08\n",
      "Epoch [45/4000],Loss:2924126.25, KL Loss: 2924124.0. FitLoss: 2.3023464679718018,Accuracy:0.10632500000000009,Validation Loss:2922644.25,Validation Accuracy:0.107, Prune parameters: 17045.0/421642,Beta: 1.9073486328125e-08\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=1000\n",
    "EPOCHS=4000\n",
    "LR = 5e-4 #5e-4\n",
    "# Split the training set into training and validation sets \n",
    "VAL_PERCENT = 0.2 # percentage of the data used for validation \n",
    "SAMPLES = 10\n",
    "BETA = 0.01 #5e-5\n",
    "BETA_FAC = 5e-1\n",
    "PRUNE = 1.9#1.99, 2.1\n",
    "PLATO_TOL = 20\n",
    "\n",
    "base_module = Classifier()\n",
    "var_module = LogUniformVarBayesModule(base_module)\n",
    "model = VarBayesModuleNet(base_module, nn.ModuleList([var_module]))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "fit_loss = nn.CrossEntropyLoss() \n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "\n",
    "beta = Beta_Scheduler_Plato(BETA, BETA_FAC, PLATO_TOL)\n",
    "beta_KL = Beta_Scheduler_Plato(beta.beta, 1 / BETA_FAC, PLATO_TOL, ref = beta, threshold=1e-4)\n",
    "def post_train_step(trainer: VarTrainerParams, train_result: VarBayesTrainer.TrainResult):\n",
    "    beta.step(train_result.fit_loss)\n",
    "    beta_KL.step(train_result.dist_loss)\n",
    "    trainer.params.beta = float(beta)\n",
    "    \n",
    "#print(model.base_module.state_dict().keys())\n",
    "val_size    = int(VAL_PERCENT * len(train_dataset)) \n",
    "train_size  = len(train_dataset) - val_size \n",
    "#ВЫНЕСТИ В ПАРАМЕТРЫ ТРЕЙНЕРА\n",
    "t_dataset, v_dataset = torch.utils.data.random_split(train_dataset,  \n",
    "                                                        [train_size,  \n",
    "                                                            val_size]) \n",
    "\n",
    "# Create DataLoaders for the training and validation sets \n",
    "train_loader = torch.utils.data.DataLoader(t_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=True, \n",
    "                                        pin_memory=True) \n",
    "eval_loader = torch.utils.data.DataLoader(v_dataset,  \n",
    "                                        batch_size=BATCH_SIZE,  \n",
    "                                        shuffle=False, \n",
    "                                        pin_memory=True) \n",
    "\n",
    "model.to(device) \n",
    "train_params = VarTrainerParams(EPOCHS, optimizer,fit_loss, kl_loss, SAMPLES, PRUNE, BETA, {'accuracy': CallbackLossAccuracy()})\n",
    "trainer = VarBayesTrainer(train_params, ReportChain([VarBaseReport()]), train_loader, eval_loader, [post_train_step])\n",
    "trainer.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_module.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_bayes.pt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(409356., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.prune({'threshold': 1.9})\n",
    "print(model.prune_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47343., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.prune([{'threshold': -2.2}])\n",
    "print(model.prune_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = Classifier()\n",
    "var_module = LogUniformVarBayesModule(module)\n",
    "model = VarBayesModuleNet(module, nn.ModuleList([var_module]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('module_list.0.posterior_params.0.param_mus',\n",
       "              tensor([[[[-0.2737, -0.0213, -0.1784],\n",
       "                        [-0.0449,  0.1339,  0.2884],\n",
       "                        [ 0.1757,  0.2454,  0.0318]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2829,  0.1125,  0.2672],\n",
       "                        [-0.0329,  0.1954,  0.2326],\n",
       "                        [-0.0857, -0.2534,  0.0893]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1525,  0.0669, -0.2533],\n",
       "                        [-0.1758,  0.1672,  0.1206],\n",
       "                        [ 0.0153,  0.1936, -0.3305]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0107,  0.3182,  0.2102],\n",
       "                        [-0.1029,  0.3132, -0.2125],\n",
       "                        [-0.2650,  0.0061,  0.2422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1922,  0.1445, -0.1445],\n",
       "                        [-0.1862, -0.1703,  0.1814],\n",
       "                        [-0.3061, -0.1629,  0.1818]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2469, -0.2962, -0.1922],\n",
       "                        [-0.1502, -0.0190, -0.1009],\n",
       "                        [ 0.1418,  0.0435, -0.2017]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2999,  0.2396,  0.0861],\n",
       "                        [-0.1399,  0.0275, -0.3024],\n",
       "                        [-0.1098, -0.1394, -0.2101]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0273,  0.2970, -0.2747],\n",
       "                        [ 0.1127,  0.2224,  0.0496],\n",
       "                        [-0.2127,  0.1349, -0.2917]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0222,  0.2411,  0.0425],\n",
       "                        [ 0.0817,  0.1037,  0.2716],\n",
       "                        [ 0.0878, -0.2382, -0.0517]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0719,  0.1895,  0.1076],\n",
       "                        [-0.1426, -0.1827,  0.3090],\n",
       "                        [-0.1734,  0.0608, -0.1394]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2088,  0.1865,  0.1586],\n",
       "                        [-0.1817, -0.1410, -0.1049],\n",
       "                        [-0.1832, -0.3061, -0.3109]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2269,  0.1814, -0.3188],\n",
       "                        [ 0.2725, -0.0902, -0.2374],\n",
       "                        [-0.1628, -0.2985, -0.0739]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2382, -0.0886,  0.2284],\n",
       "                        [ 0.0932, -0.0300,  0.1199],\n",
       "                        [-0.3036,  0.0679,  0.3242]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2995, -0.0269,  0.2335],\n",
       "                        [-0.2868,  0.1297,  0.2263],\n",
       "                        [-0.1365,  0.0827, -0.1368]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2408, -0.1476,  0.1649],\n",
       "                        [ 0.1636, -0.0114, -0.1543],\n",
       "                        [ 0.1516,  0.2401, -0.3093]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0533,  0.1382,  0.0024],\n",
       "                        [-0.1546,  0.2536, -0.2555],\n",
       "                        [-0.1677, -0.0555,  0.0449]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2179,  0.0416,  0.1664],\n",
       "                        [ 0.1895,  0.1240, -0.2714],\n",
       "                        [-0.0561, -0.2904,  0.1815]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0931, -0.2447, -0.1122],\n",
       "                        [ 0.2836, -0.3144,  0.2693],\n",
       "                        [ 0.0475,  0.0702,  0.2088]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2935, -0.0657,  0.2059],\n",
       "                        [-0.2644,  0.2140,  0.0178],\n",
       "                        [-0.0679, -0.2655, -0.0174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1912, -0.0838, -0.1078],\n",
       "                        [ 0.2290,  0.2124, -0.2783],\n",
       "                        [-0.0186,  0.2010, -0.1156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2628, -0.2447,  0.0938],\n",
       "                        [-0.1858, -0.2919, -0.2134],\n",
       "                        [ 0.2410, -0.0449,  0.1174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3145, -0.2647,  0.2348],\n",
       "                        [ 0.1423, -0.1619, -0.1704],\n",
       "                        [ 0.3221, -0.1983, -0.0801]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0133, -0.3084,  0.1228],\n",
       "                        [ 0.1514,  0.0796, -0.1055],\n",
       "                        [ 0.2269,  0.1001, -0.2295]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1243,  0.1812,  0.0307],\n",
       "                        [ 0.2902,  0.2480, -0.0722],\n",
       "                        [-0.1125,  0.2348,  0.0912]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2855,  0.0356,  0.2712],\n",
       "                        [ 0.3197, -0.0580,  0.0020],\n",
       "                        [-0.2933, -0.1005,  0.2072]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1050, -0.2946,  0.0811],\n",
       "                        [-0.0863,  0.2160, -0.2627],\n",
       "                        [-0.1286,  0.0596, -0.1345]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0546, -0.0362,  0.0594],\n",
       "                        [ 0.0646,  0.1745, -0.0352],\n",
       "                        [-0.1120, -0.0474,  0.0383]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1332, -0.2500, -0.1542],\n",
       "                        [-0.2412, -0.3166, -0.0210],\n",
       "                        [ 0.1060,  0.1158,  0.0057]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2678, -0.2166,  0.0712],\n",
       "                        [-0.0535,  0.1413,  0.2406],\n",
       "                        [-0.2855, -0.3059, -0.2075]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2055, -0.2482,  0.1404],\n",
       "                        [-0.2513, -0.1904,  0.1103],\n",
       "                        [-0.2845,  0.0184,  0.2082]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0582,  0.2715,  0.1728],\n",
       "                        [-0.1080,  0.1155,  0.1371],\n",
       "                        [ 0.2162, -0.0247, -0.2244]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1486,  0.0659,  0.1559],\n",
       "                        [-0.2081,  0.0449,  0.3216],\n",
       "                        [ 0.2564,  0.2344, -0.0866]]]])),\n",
       "             ('module_list.0.posterior_params.0.param_std_log',\n",
       "              tensor([[[[-7.6443, -6.8122, -6.2178],\n",
       "                        [-4.6537, -8.1042, -5.0853],\n",
       "                        [-6.9559, -4.9253, -4.6574]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.9750, -6.1978, -5.7079],\n",
       "                        [-5.8540, -7.7156, -6.2078],\n",
       "                        [-4.9556, -5.0383, -6.1048]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7616, -5.4980, -4.7636],\n",
       "                        [-4.9685, -8.0552, -6.3784],\n",
       "                        [-4.9320, -6.9730, -6.1062]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8593, -5.2212, -4.8359],\n",
       "                        [-4.9786, -7.6505, -5.0176],\n",
       "                        [-5.6760, -5.2133, -5.7229]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.5549, -5.6953, -7.5045],\n",
       "                        [-4.8243, -5.2325, -8.2682],\n",
       "                        [-4.7497, -5.2409, -6.0584]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.2319, -5.1681, -5.0143],\n",
       "                        [-4.6465, -4.7084, -6.2273],\n",
       "                        [-4.7883, -5.2719, -4.9517]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0582, -5.2466, -5.4416],\n",
       "                        [-5.1359, -5.2855, -5.4410],\n",
       "                        [-5.7903, -4.6311, -5.1965]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9802, -4.6867, -5.9103],\n",
       "                        [-4.9393, -7.2178, -5.2489],\n",
       "                        [-4.6243, -5.9567, -5.4351]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6969, -5.5580, -5.1405],\n",
       "                        [-4.7906, -5.6145, -7.0589],\n",
       "                        [-5.0275, -4.7744, -5.2552]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.2480, -6.9430, -4.8825],\n",
       "                        [-5.6597, -6.6762, -4.9689],\n",
       "                        [-5.1752, -4.9931, -5.0197]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6701, -4.8942, -5.5445],\n",
       "                        [-5.9894, -5.5842, -4.8125],\n",
       "                        [-5.2390, -4.8248, -6.3544]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0899, -6.3075, -5.0728],\n",
       "                        [-4.7244, -4.7276, -5.5322],\n",
       "                        [-6.5785, -5.2176, -8.2081]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.8461, -6.0238, -5.0947],\n",
       "                        [-4.7004, -4.7245, -4.9359],\n",
       "                        [-5.4876, -4.8804, -5.2382]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7568, -4.7962, -4.8076],\n",
       "                        [-4.8334, -4.6812, -4.8790],\n",
       "                        [-5.2112, -4.6500, -5.2285]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1571, -5.5234, -5.3730],\n",
       "                        [-6.3554, -4.7353, -5.0411],\n",
       "                        [-4.7423, -5.0554, -5.8877]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.4057, -5.4768, -5.8319],\n",
       "                        [-4.8379, -4.8591, -7.9367],\n",
       "                        [-6.0085, -4.6697, -5.8908]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7667, -5.2830, -4.8108],\n",
       "                        [-4.7277, -5.0035, -4.8743],\n",
       "                        [-4.7109, -7.0394, -4.8987]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5578, -5.4441, -4.7811],\n",
       "                        [-4.6132, -5.0880, -4.7208],\n",
       "                        [-5.2930, -4.7753, -5.3517]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0392, -6.9003, -6.4838],\n",
       "                        [-6.2912, -4.9652, -6.3513],\n",
       "                        [-5.4759, -4.9867, -5.3265]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.6965, -5.1672, -4.6054],\n",
       "                        [-5.8090, -4.9806, -5.4375],\n",
       "                        [-5.2273, -5.3135, -5.2484]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8862, -4.9312, -5.9119],\n",
       "                        [-5.3062, -5.0569, -4.6850],\n",
       "                        [-5.4883, -6.1027, -5.0738]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.3343, -6.1922, -6.2508],\n",
       "                        [-5.0133, -4.8441, -6.0976],\n",
       "                        [-7.5900, -5.7515, -4.6156]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5193, -6.1760, -5.7592],\n",
       "                        [-5.5590, -4.8624, -5.6229],\n",
       "                        [-4.9285, -4.8645, -5.8739]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6902, -5.6837, -4.9300],\n",
       "                        [-5.4640, -6.1872, -5.1738],\n",
       "                        [-4.6249, -4.7705, -4.9058]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1386, -4.6787, -4.8687],\n",
       "                        [-4.7995, -6.2731, -5.5295],\n",
       "                        [-7.9139, -5.6268, -4.8398]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4830, -5.1139, -5.3729],\n",
       "                        [-4.6113, -5.2906, -5.0130],\n",
       "                        [-5.5503, -4.9968, -4.6078]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.3845, -6.3526, -5.5192],\n",
       "                        [-6.8718, -5.3505, -5.9623],\n",
       "                        [-5.2600, -5.0851, -5.2559]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.5084, -6.8383, -6.7434],\n",
       "                        [-5.1087, -5.0522, -5.0362],\n",
       "                        [-4.8434, -4.6105, -5.9471]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.0541, -6.8497, -5.4263],\n",
       "                        [-5.1009, -4.6458, -5.4793],\n",
       "                        [-5.4213, -4.9003, -4.8682]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4279, -8.2878, -5.5914],\n",
       "                        [-5.8017, -5.5931, -4.8151],\n",
       "                        [-4.7875, -5.1253, -4.8293]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.6792, -5.2176, -6.3633],\n",
       "                        [-6.5483, -4.7496, -5.1030],\n",
       "                        [-4.7008, -4.6548, -4.8405]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.9131, -5.5380, -5.7411],\n",
       "                        [-8.2987, -4.6276, -5.5294],\n",
       "                        [-5.5955, -4.9558, -8.0978]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_alphas_log',\n",
       "              tensor([[[[-3.9730, -3.8184, -2.7370],\n",
       "                        [-2.8423, -3.3155, -3.7674],\n",
       "                        [-2.8688, -3.4832, -3.3337]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4496, -3.1676, -2.3279],\n",
       "                        [-2.5704, -2.6994, -2.5631],\n",
       "                        [-2.3078, -3.7059, -3.1989]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3379, -3.3761, -2.0345],\n",
       "                        [-3.8821, -2.3943, -3.7338],\n",
       "                        [-3.1945, -2.8338, -3.7807]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3331, -3.7250, -3.6263],\n",
       "                        [-3.3903, -2.8828, -3.6775],\n",
       "                        [-3.0060, -2.4066, -2.8119]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3633, -2.0377, -2.0332],\n",
       "                        [-3.5051, -3.9339, -3.9972],\n",
       "                        [-2.8213, -2.7204, -2.4167]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4371, -3.7661, -2.8416],\n",
       "                        [-2.1897, -2.4125, -2.5461],\n",
       "                        [-3.4732, -3.3259, -2.3366]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2825, -3.0099, -2.5968],\n",
       "                        [-3.0321, -3.8588, -3.2249],\n",
       "                        [-3.7188, -3.9843, -3.5802]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8530, -3.9986, -3.0276],\n",
       "                        [-2.0767, -3.6595, -2.9175],\n",
       "                        [-3.2203, -2.1420, -3.6336]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5784, -2.8119, -2.3119],\n",
       "                        [-3.2846, -3.0844, -2.5892],\n",
       "                        [-3.3545, -2.3341, -3.3552]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5695, -2.5832, -2.3026],\n",
       "                        [-3.3705, -3.8097, -3.8492],\n",
       "                        [-2.4600, -2.2967, -3.7054]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3626, -3.4220, -3.9690],\n",
       "                        [-2.0460, -2.1348, -3.8663],\n",
       "                        [-2.3202, -3.0671, -2.3580]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1191, -3.4663, -3.9155],\n",
       "                        [-2.9626, -2.6909, -2.0241],\n",
       "                        [-3.6772, -2.0887, -2.8112]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5335, -2.2046, -3.8070],\n",
       "                        [-2.0733, -3.4714, -3.3680],\n",
       "                        [-2.0920, -3.3321, -3.0712]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9456, -3.9397, -2.3680],\n",
       "                        [-2.0659, -3.5653, -2.3071],\n",
       "                        [-3.2517, -3.4542, -2.0715]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2097, -3.9403, -2.1460],\n",
       "                        [-3.0559, -3.4030, -2.5687],\n",
       "                        [-3.4692, -2.5501, -3.5228]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8775, -3.4609, -3.5841],\n",
       "                        [-3.2468, -3.9733, -3.9215],\n",
       "                        [-3.4708, -3.8749, -3.1619]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4536, -3.0306, -3.1692],\n",
       "                        [-2.9309, -2.0621, -2.1662],\n",
       "                        [-2.1606, -2.5014, -2.8317]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8540, -3.1003, -2.3888],\n",
       "                        [-2.9370, -2.7015, -3.5162],\n",
       "                        [-2.7293, -2.3345, -3.2506]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4800, -3.4780, -2.7654],\n",
       "                        [-2.0434, -2.3557, -2.0213],\n",
       "                        [-2.2703, -2.0352, -3.7971]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9834, -3.0913, -2.8502],\n",
       "                        [-2.8904, -2.8264, -3.4881],\n",
       "                        [-3.3516, -3.2357, -2.9829]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1380, -3.2730, -3.5269],\n",
       "                        [-2.6177, -3.5875, -3.6728],\n",
       "                        [-2.7636, -3.6273, -3.2167]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4872, -3.5043, -2.3076],\n",
       "                        [-2.8557, -3.3450, -2.6795],\n",
       "                        [-2.7737, -2.7499, -3.3472]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2195, -2.7689, -2.0130],\n",
       "                        [-3.5297, -3.6577, -2.2098],\n",
       "                        [-2.0077, -3.4508, -3.4853]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1046, -3.8315, -3.3988],\n",
       "                        [-2.0476, -3.0053, -3.8965],\n",
       "                        [-2.1855, -2.1632, -2.1847]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9850, -2.6428, -2.9310],\n",
       "                        [-2.1326, -3.2657, -2.4740],\n",
       "                        [-3.1584, -2.4350, -3.3533]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9450, -2.5128, -3.1556],\n",
       "                        [-3.2801, -3.5410, -2.8983],\n",
       "                        [-2.5519, -3.2341, -2.8721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8494, -3.8954, -3.0426],\n",
       "                        [-3.2585, -3.2226, -3.6094],\n",
       "                        [-3.2983, -3.4633, -3.9118]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4175, -2.1018, -2.3832],\n",
       "                        [-2.6769, -2.5597, -3.1847],\n",
       "                        [-3.8278, -2.5293, -3.5093]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6108, -3.0801, -2.6812],\n",
       "                        [-2.7818, -3.4267, -3.2687],\n",
       "                        [-2.1624, -2.1442, -2.5664]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5382, -2.5531, -3.3821],\n",
       "                        [-2.7202, -3.1200, -3.5994],\n",
       "                        [-3.7090, -3.5544, -3.7490]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.9206, -2.9339, -2.6854],\n",
       "                        [-2.8685, -3.9728, -2.4037],\n",
       "                        [-3.7632, -2.0636, -2.3169]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5363, -2.2065, -3.9187],\n",
       "                        [-2.5296, -2.8139, -2.1778],\n",
       "                        [-3.0076, -2.6238, -3.4175]]]])),\n",
       "             ('module_list.0.posterior_params.0.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.1.param_mus',\n",
       "              tensor([-0.0917,  0.2394,  0.0686, -0.2604, -0.0798,  0.2396, -0.0338,  0.2310,\n",
       "                       0.0511, -0.0118,  0.1305,  0.2870,  0.1377,  0.0071, -0.0213, -0.0859,\n",
       "                       0.1393, -0.0984, -0.1080,  0.1917,  0.1436, -0.2344,  0.0637, -0.2897,\n",
       "                      -0.2618, -0.2384, -0.1295,  0.1794, -0.0685, -0.0023, -0.2036, -0.0473])),\n",
       "             ('module_list.0.posterior_params.1.param_std_log',\n",
       "              tensor([-5.6001, -5.0561, -7.3938, -4.6664, -5.3911, -4.6895, -5.8183, -4.6080,\n",
       "                      -4.9778, -5.0134, -5.1747, -6.2682, -5.6235, -4.6147, -4.6179, -5.5958,\n",
       "                      -7.3049, -5.8125, -5.3669, -6.1171, -5.4824, -4.6084, -4.8485, -5.1090,\n",
       "                      -4.6260, -4.8618, -4.6064, -5.7304, -4.9281, -6.2759, -6.1592, -4.6723])),\n",
       "             ('module_list.0.posterior_params.1.scale_alphas_log',\n",
       "              tensor([-3.8439, -3.2271, -3.3951, -2.1596, -3.5587, -3.3096, -3.8678, -3.2271,\n",
       "                      -3.7286, -2.2776, -3.4039, -2.1131, -3.8562, -2.1256, -2.6956, -2.0418,\n",
       "                      -3.5359, -3.6205, -3.8657, -2.2383, -2.6532, -2.0978, -2.3008, -3.0798,\n",
       "                      -3.8545, -2.1004, -2.2579, -3.7659, -2.8519, -2.2167, -2.4384, -3.4444])),\n",
       "             ('module_list.0.posterior_params.1.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.2.param_mus',\n",
       "              tensor([[[[-0.0196,  0.0454,  0.0391],\n",
       "                        [ 0.0089,  0.0444,  0.0319],\n",
       "                        [ 0.0151, -0.0048, -0.0067]],\n",
       "              \n",
       "                       [[ 0.0389,  0.0052, -0.0038],\n",
       "                        [ 0.0210, -0.0377,  0.0379],\n",
       "                        [-0.0082, -0.0270,  0.0123]],\n",
       "              \n",
       "                       [[-0.0195, -0.0450, -0.0348],\n",
       "                        [-0.0266,  0.0158,  0.0558],\n",
       "                        [ 0.0572, -0.0150, -0.0562]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0117, -0.0527,  0.0530],\n",
       "                        [-0.0441, -0.0011,  0.0099],\n",
       "                        [ 0.0460, -0.0206,  0.0311]],\n",
       "              \n",
       "                       [[ 0.0086, -0.0104,  0.0082],\n",
       "                        [-0.0060,  0.0010,  0.0508],\n",
       "                        [ 0.0234, -0.0204, -0.0198]],\n",
       "              \n",
       "                       [[ 0.0014,  0.0375, -0.0589],\n",
       "                        [-0.0500, -0.0523, -0.0287],\n",
       "                        [-0.0491,  0.0049,  0.0422]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0086, -0.0462,  0.0437],\n",
       "                        [-0.0584, -0.0168, -0.0261],\n",
       "                        [-0.0548, -0.0186, -0.0516]],\n",
       "              \n",
       "                       [[ 0.0359, -0.0341,  0.0119],\n",
       "                        [-0.0516, -0.0310, -0.0073],\n",
       "                        [-0.0050,  0.0106,  0.0388]],\n",
       "              \n",
       "                       [[ 0.0335,  0.0242, -0.0266],\n",
       "                        [-0.0136,  0.0261,  0.0277],\n",
       "                        [-0.0235, -0.0340, -0.0570]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0397, -0.0346,  0.0134],\n",
       "                        [-0.0087,  0.0414,  0.0012],\n",
       "                        [-0.0219,  0.0087,  0.0025]],\n",
       "              \n",
       "                       [[-0.0426,  0.0360, -0.0347],\n",
       "                        [-0.0527, -0.0319,  0.0490],\n",
       "                        [ 0.0425,  0.0571,  0.0575]],\n",
       "              \n",
       "                       [[ 0.0446,  0.0385,  0.0485],\n",
       "                        [ 0.0124,  0.0016, -0.0074],\n",
       "                        [ 0.0091, -0.0570, -0.0402]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0326, -0.0093, -0.0427],\n",
       "                        [-0.0027, -0.0183,  0.0407],\n",
       "                        [ 0.0067,  0.0192, -0.0295]],\n",
       "              \n",
       "                       [[ 0.0398, -0.0258, -0.0529],\n",
       "                        [ 0.0533, -0.0561,  0.0226],\n",
       "                        [-0.0508, -0.0089, -0.0217]],\n",
       "              \n",
       "                       [[-0.0574,  0.0053,  0.0086],\n",
       "                        [ 0.0176, -0.0122,  0.0389],\n",
       "                        [ 0.0315, -0.0262,  0.0497]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0496,  0.0429, -0.0389],\n",
       "                        [ 0.0564,  0.0134, -0.0487],\n",
       "                        [ 0.0151, -0.0558, -0.0526]],\n",
       "              \n",
       "                       [[ 0.0041,  0.0085,  0.0242],\n",
       "                        [-0.0357,  0.0532, -0.0053],\n",
       "                        [ 0.0320,  0.0389, -0.0084]],\n",
       "              \n",
       "                       [[-0.0232, -0.0328, -0.0265],\n",
       "                        [ 0.0073,  0.0322,  0.0154],\n",
       "                        [ 0.0334, -0.0364, -0.0399]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0362, -0.0152, -0.0356],\n",
       "                        [-0.0227,  0.0356,  0.0551],\n",
       "                        [ 0.0449,  0.0479,  0.0460]],\n",
       "              \n",
       "                       [[ 0.0109, -0.0216,  0.0328],\n",
       "                        [ 0.0278,  0.0500, -0.0082],\n",
       "                        [ 0.0543, -0.0203,  0.0153]],\n",
       "              \n",
       "                       [[ 0.0102,  0.0585, -0.0482],\n",
       "                        [ 0.0470,  0.0210,  0.0068],\n",
       "                        [ 0.0122,  0.0472, -0.0473]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0350,  0.0331,  0.0211],\n",
       "                        [ 0.0469,  0.0194, -0.0124],\n",
       "                        [ 0.0085,  0.0097,  0.0335]],\n",
       "              \n",
       "                       [[-0.0213, -0.0421,  0.0169],\n",
       "                        [ 0.0271,  0.0084, -0.0281],\n",
       "                        [-0.0009,  0.0395,  0.0552]],\n",
       "              \n",
       "                       [[-0.0405,  0.0506,  0.0431],\n",
       "                        [ 0.0378,  0.0429,  0.0452],\n",
       "                        [ 0.0226,  0.0213, -0.0085]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0589, -0.0413,  0.0375],\n",
       "                        [-0.0113,  0.0128, -0.0504],\n",
       "                        [ 0.0348,  0.0297, -0.0023]],\n",
       "              \n",
       "                       [[ 0.0142, -0.0146,  0.0395],\n",
       "                        [-0.0279,  0.0025, -0.0369],\n",
       "                        [-0.0193,  0.0065,  0.0184]],\n",
       "              \n",
       "                       [[ 0.0535, -0.0271,  0.0205],\n",
       "                        [ 0.0521,  0.0121,  0.0178],\n",
       "                        [-0.0015, -0.0246,  0.0102]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0374,  0.0082,  0.0361],\n",
       "                        [-0.0384, -0.0128,  0.0242],\n",
       "                        [ 0.0210,  0.0459, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0085,  0.0549, -0.0122],\n",
       "                        [ 0.0470, -0.0425,  0.0118],\n",
       "                        [-0.0259, -0.0331,  0.0163]],\n",
       "              \n",
       "                       [[-0.0175,  0.0018,  0.0136],\n",
       "                        [ 0.0412, -0.0085, -0.0292],\n",
       "                        [ 0.0508, -0.0501,  0.0192]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0055, -0.0442, -0.0088],\n",
       "                        [-0.0253, -0.0387, -0.0068],\n",
       "                        [-0.0327,  0.0401,  0.0176]],\n",
       "              \n",
       "                       [[-0.0053, -0.0276,  0.0089],\n",
       "                        [ 0.0546,  0.0484, -0.0486],\n",
       "                        [ 0.0030,  0.0041, -0.0256]],\n",
       "              \n",
       "                       [[ 0.0418,  0.0024, -0.0539],\n",
       "                        [ 0.0261, -0.0357, -0.0540],\n",
       "                        [ 0.0082, -0.0161,  0.0249]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0420, -0.0219, -0.0447],\n",
       "                        [-0.0553, -0.0467, -0.0041],\n",
       "                        [-0.0133, -0.0239,  0.0284]],\n",
       "              \n",
       "                       [[-0.0090,  0.0331,  0.0218],\n",
       "                        [-0.0550, -0.0575, -0.0531],\n",
       "                        [ 0.0528, -0.0313,  0.0230]],\n",
       "              \n",
       "                       [[-0.0138,  0.0412, -0.0435],\n",
       "                        [ 0.0420, -0.0355,  0.0162],\n",
       "                        [ 0.0510,  0.0107,  0.0575]]]])),\n",
       "             ('module_list.0.posterior_params.2.param_std_log',\n",
       "              tensor([[[[ -4.8953,  -5.0285,  -6.2216],\n",
       "                        [ -4.9035,  -8.6040,  -6.4262],\n",
       "                        [ -5.3935,  -6.4831,  -5.3591]],\n",
       "              \n",
       "                       [[ -5.5549,  -5.1110,  -4.7856],\n",
       "                        [ -5.0981,  -4.8755,  -5.7412],\n",
       "                        [ -5.6913,  -5.1175,  -5.4186]],\n",
       "              \n",
       "                       [[ -7.5934,  -4.9929,  -4.8682],\n",
       "                        [ -6.5329,  -6.7392,  -5.7023],\n",
       "                        [ -4.6655,  -6.5716,  -5.0604]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.6578,  -4.9114,  -5.8949],\n",
       "                        [ -5.4794,  -5.1367,  -5.2141],\n",
       "                        [ -7.1503,  -5.0723,  -6.8911]],\n",
       "              \n",
       "                       [[ -7.7260,  -4.7098,  -4.7194],\n",
       "                        [ -4.8400,  -5.9135,  -5.9438],\n",
       "                        [ -4.6816,  -5.5583,  -4.6564]],\n",
       "              \n",
       "                       [[ -5.4169,  -4.8717,  -4.7754],\n",
       "                        [ -5.1123,  -4.8388,  -5.6561],\n",
       "                        [ -5.6101,  -5.9402,  -5.5524]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.3646,  -6.1044,  -4.8309],\n",
       "                        [ -4.9290,  -6.4702,  -4.7857],\n",
       "                        [ -4.7454,  -6.7668,  -4.7657]],\n",
       "              \n",
       "                       [[ -5.3774,  -6.1290,  -5.3385],\n",
       "                        [ -8.1817,  -5.3416,  -4.6654],\n",
       "                        [ -6.9278,  -5.2007,  -5.8790]],\n",
       "              \n",
       "                       [[ -6.2015,  -4.7918,  -7.0114],\n",
       "                        [ -6.6029,  -4.9880,  -5.1994],\n",
       "                        [ -4.7158,  -4.6187,  -4.7050]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -7.0537,  -5.3076,  -5.5863],\n",
       "                        [ -5.8178,  -5.1174,  -5.0456],\n",
       "                        [ -5.3676,  -5.2478,  -5.6625]],\n",
       "              \n",
       "                       [[ -5.3646,  -6.0331,  -4.8292],\n",
       "                        [ -5.1204,  -5.0109,  -5.4891],\n",
       "                        [ -6.4985,  -4.7923,  -4.8494]],\n",
       "              \n",
       "                       [[ -5.2417,  -5.3264,  -4.9075],\n",
       "                        [ -4.6669,  -5.7886,  -5.0299],\n",
       "                        [ -4.8249,  -4.7134,  -5.8615]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -6.3013,  -5.6837,  -6.1340],\n",
       "                        [ -4.8347,  -6.8893,  -6.6270],\n",
       "                        [ -5.4885,  -6.7957,  -4.8725]],\n",
       "              \n",
       "                       [[ -4.7680,  -7.2965,  -6.8039],\n",
       "                        [ -7.3785,  -4.9002,  -5.0066],\n",
       "                        [ -4.6913,  -5.5690,  -4.6084]],\n",
       "              \n",
       "                       [[ -4.8951,  -7.2483,  -4.8205],\n",
       "                        [ -5.4375,  -5.4348,  -5.8624],\n",
       "                        [ -5.6269,  -4.8600,  -8.1621]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -4.9090,  -5.1043,  -6.6300],\n",
       "                        [ -4.9572,  -5.2812,  -4.9467],\n",
       "                        [ -6.9966,  -5.9345,  -5.1252]],\n",
       "              \n",
       "                       [[ -4.6989,  -4.8439,  -5.2943],\n",
       "                        [ -5.1051,  -5.7968,  -5.8932],\n",
       "                        [-10.1077,  -4.7491,  -8.4951]],\n",
       "              \n",
       "                       [[ -5.6271,  -5.8009,  -5.6112],\n",
       "                        [ -5.6509,  -4.7704,  -6.9457],\n",
       "                        [ -6.5300,  -5.8772,  -6.3974]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ -6.2656,  -6.2033,  -4.9923],\n",
       "                        [ -4.8826,  -8.2525,  -5.1309],\n",
       "                        [ -4.8151,  -5.6355,  -5.0209]],\n",
       "              \n",
       "                       [[ -6.3848,  -6.0805,  -7.8335],\n",
       "                        [ -4.8021,  -5.2011,  -4.9359],\n",
       "                        [ -5.2328,  -6.5811,  -4.6836]],\n",
       "              \n",
       "                       [[ -4.6560,  -4.6885, -11.7446],\n",
       "                        [ -6.5880,  -4.7699,  -5.2749],\n",
       "                        [ -5.6483,  -4.7934,  -6.8433]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.2342,  -5.2849,  -6.0316],\n",
       "                        [ -5.3714,  -4.7595,  -5.4207],\n",
       "                        [ -6.7571,  -9.9357,  -7.0918]],\n",
       "              \n",
       "                       [[ -7.8484,  -7.9049,  -4.8852],\n",
       "                        [ -8.5928,  -6.9321,  -4.7064],\n",
       "                        [ -4.6875,  -4.8348,  -5.5023]],\n",
       "              \n",
       "                       [[ -4.7033,  -4.6839,  -5.3626],\n",
       "                        [ -5.8149,  -4.6163,  -4.7024],\n",
       "                        [ -5.2816,  -5.4297,  -4.8385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -4.7027,  -4.6516,  -5.3516],\n",
       "                        [ -5.2600,  -4.8881,  -5.0138],\n",
       "                        [ -5.9239,  -5.4689,  -4.6260]],\n",
       "              \n",
       "                       [[ -4.9607,  -5.8558,  -5.9619],\n",
       "                        [ -5.1053,  -7.0853,  -5.5569],\n",
       "                        [ -4.6085,  -6.3642,  -4.8830]],\n",
       "              \n",
       "                       [[ -5.5688,  -4.9501,  -6.1348],\n",
       "                        [ -6.3153,  -5.5237,  -4.7659],\n",
       "                        [ -4.6286,  -5.5474,  -6.4980]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.5645,  -4.6941,  -5.2743],\n",
       "                        [ -5.4054,  -4.9133,  -6.4651],\n",
       "                        [ -7.0040,  -4.9656,  -7.0266]],\n",
       "              \n",
       "                       [[ -5.2028,  -5.1697,  -4.7442],\n",
       "                        [ -4.8667,  -5.2562,  -6.2058],\n",
       "                        [ -7.5951,  -4.6418,  -4.9033]],\n",
       "              \n",
       "                       [[ -4.6518,  -5.0600,  -5.0147],\n",
       "                        [ -6.5606,  -5.0663,  -5.1944],\n",
       "                        [ -7.4739,  -4.6704,  -4.6449]]],\n",
       "              \n",
       "              \n",
       "                      [[[ -5.6330,  -6.6073,  -5.0135],\n",
       "                        [ -4.9958,  -4.8325,  -4.6252],\n",
       "                        [ -4.9012,  -6.2909,  -6.0797]],\n",
       "              \n",
       "                       [[ -4.8079,  -7.8986,  -5.3821],\n",
       "                        [ -5.9537,  -7.2645,  -5.7079],\n",
       "                        [ -4.7860,  -5.0177,  -5.3445]],\n",
       "              \n",
       "                       [[ -4.9210,  -5.5095,  -4.9153],\n",
       "                        [ -9.2945,  -5.2109,  -5.0991],\n",
       "                        [ -4.6786,  -4.8999,  -4.7837]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ -5.0940,  -6.4246,  -6.0016],\n",
       "                        [ -5.9106,  -4.6236,  -9.3768],\n",
       "                        [ -4.8565,  -4.6549,  -4.8105]],\n",
       "              \n",
       "                       [[ -5.0449,  -5.1650,  -4.6892],\n",
       "                        [ -5.7240,  -5.5601,  -4.7530],\n",
       "                        [ -4.6144,  -5.6058,  -7.4718]],\n",
       "              \n",
       "                       [[ -6.1598,  -4.6782,  -5.3052],\n",
       "                        [ -5.1732,  -5.6023,  -5.3645],\n",
       "                        [ -5.2507,  -5.4567,  -4.8220]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_alphas_log',\n",
       "              tensor([[[[-2.9031, -3.5752, -3.1913],\n",
       "                        [-2.2432, -3.7676, -3.9219],\n",
       "                        [-2.2315, -3.3817, -3.0104]],\n",
       "              \n",
       "                       [[-3.4620, -2.1322, -2.3796],\n",
       "                        [-3.2906, -3.9242, -2.4920],\n",
       "                        [-2.6064, -2.2625, -3.8039]],\n",
       "              \n",
       "                       [[-3.0305, -3.3771, -3.4199],\n",
       "                        [-2.7889, -2.9304, -3.7615],\n",
       "                        [-2.1174, -2.1470, -3.9918]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2688, -2.4659, -3.1240],\n",
       "                        [-3.7692, -3.6450, -3.6797],\n",
       "                        [-3.3195, -2.8639, -2.6135]],\n",
       "              \n",
       "                       [[-2.1157, -2.3645, -3.2899],\n",
       "                        [-3.4988, -3.0115, -2.7938],\n",
       "                        [-3.8293, -3.2961, -2.8436]],\n",
       "              \n",
       "                       [[-3.9779, -2.0617, -3.1237],\n",
       "                        [-3.9790, -2.6218, -2.4551],\n",
       "                        [-3.5406, -3.1608, -3.2890]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6755, -2.0339, -3.6471],\n",
       "                        [-3.1715, -3.2779, -2.7492],\n",
       "                        [-2.6883, -3.9882, -3.6644]],\n",
       "              \n",
       "                       [[-2.4057, -2.0133, -2.1821],\n",
       "                        [-2.7596, -2.0538, -2.6359],\n",
       "                        [-3.5137, -3.3185, -3.5885]],\n",
       "              \n",
       "                       [[-3.0351, -2.9763, -2.0979],\n",
       "                        [-3.3766, -3.9956, -2.0556],\n",
       "                        [-2.8010, -3.5787, -3.6768]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.9227, -3.6770, -3.7636],\n",
       "                        [-3.2002, -2.1039, -2.2279],\n",
       "                        [-3.7049, -2.7865, -2.1264]],\n",
       "              \n",
       "                       [[-3.0326, -2.2067, -2.2916],\n",
       "                        [-2.1105, -3.7049, -2.5112],\n",
       "                        [-3.1940, -2.1001, -3.4853]],\n",
       "              \n",
       "                       [[-2.8792, -3.0937, -2.7589],\n",
       "                        [-2.6047, -2.2957, -3.1234],\n",
       "                        [-3.8853, -2.5147, -2.4693]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4313, -3.4454, -2.5228],\n",
       "                        [-2.2018, -3.2355, -2.3762],\n",
       "                        [-3.8663, -3.0295, -3.5700]],\n",
       "              \n",
       "                       [[-3.5861, -2.0395, -2.0020],\n",
       "                        [-2.1038, -3.2346, -2.7971],\n",
       "                        [-2.3657, -2.5616, -3.5310]],\n",
       "              \n",
       "                       [[-3.3006, -3.3535, -3.3189],\n",
       "                        [-3.1244, -3.3003, -3.5692],\n",
       "                        [-2.7795, -2.1361, -2.3262]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.1123, -3.5558, -2.4190],\n",
       "                        [-2.8286, -2.1191, -2.5490],\n",
       "                        [-2.3278, -2.8362, -3.7079]],\n",
       "              \n",
       "                       [[-2.0250, -2.0361, -2.2242],\n",
       "                        [-3.5920, -2.1569, -3.2739],\n",
       "                        [-2.3617, -3.3745, -2.4369]],\n",
       "              \n",
       "                       [[-3.4996, -2.8253, -2.5848],\n",
       "                        [-3.4868, -3.3970, -3.3454],\n",
       "                        [-3.3596, -3.8827, -3.4139]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.1325, -2.0101, -2.3009],\n",
       "                        [-3.3946, -3.7420, -2.2947],\n",
       "                        [-2.8810, -3.1959, -2.4976]],\n",
       "              \n",
       "                       [[-3.0886, -3.6569, -2.8172],\n",
       "                        [-3.7599, -3.9197, -2.1939],\n",
       "                        [-3.7000, -2.5793, -3.5384]],\n",
       "              \n",
       "                       [[-2.8714, -2.3903, -2.9222],\n",
       "                        [-2.1279, -3.4309, -2.6593],\n",
       "                        [-3.9820, -2.9647, -3.0653]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4074, -3.5453, -2.9808],\n",
       "                        [-2.2863, -3.9489, -2.0954],\n",
       "                        [-3.8373, -3.9608, -3.8983]],\n",
       "              \n",
       "                       [[-3.3889, -2.3294, -3.8718],\n",
       "                        [-2.4368, -2.1073, -2.8512],\n",
       "                        [-3.6483, -3.7381, -3.0208]],\n",
       "              \n",
       "                       [[-2.0715, -3.7128, -2.4285],\n",
       "                        [-3.7453, -2.5793, -3.9045],\n",
       "                        [-2.2144, -2.8838, -3.2419]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8225, -2.4760, -2.3612],\n",
       "                        [-3.4040, -2.1312, -3.9279],\n",
       "                        [-3.2219, -3.0139, -2.9078]],\n",
       "              \n",
       "                       [[-3.9570, -3.6798, -3.8169],\n",
       "                        [-2.9281, -3.5607, -2.0121],\n",
       "                        [-2.0334, -3.3228, -3.2737]],\n",
       "              \n",
       "                       [[-3.0264, -2.6413, -2.7952],\n",
       "                        [-2.6720, -2.2991, -3.6808],\n",
       "                        [-2.9856, -3.2928, -3.7279]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.2259, -2.7306, -3.2844],\n",
       "                        [-3.2082, -2.3142, -3.7642],\n",
       "                        [-2.4837, -2.9002, -2.0545]],\n",
       "              \n",
       "                       [[-3.8918, -3.5356, -2.0444],\n",
       "                        [-2.3271, -2.4968, -3.9083],\n",
       "                        [-2.4074, -2.6570, -2.4153]],\n",
       "              \n",
       "                       [[-2.0498, -3.5175, -2.1168],\n",
       "                        [-3.9951, -2.7050, -2.6350],\n",
       "                        [-2.7071, -2.6911, -3.2756]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4691, -2.6418, -3.3070],\n",
       "                        [-2.0403, -3.3388, -3.3410],\n",
       "                        [-3.4311, -2.3567, -2.7274]],\n",
       "              \n",
       "                       [[-2.9643, -3.1868, -2.6083],\n",
       "                        [-3.9008, -2.3488, -2.8015],\n",
       "                        [-3.6829, -3.6533, -3.1903]],\n",
       "              \n",
       "                       [[-3.1084, -2.5719, -3.7105],\n",
       "                        [-2.5479, -3.8481, -2.2664],\n",
       "                        [-2.6867, -2.7838, -3.6353]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0250, -2.3754, -2.1942],\n",
       "                        [-2.2754, -2.2488, -2.5304],\n",
       "                        [-3.6430, -2.9638, -3.1415]],\n",
       "              \n",
       "                       [[-3.1872, -2.3818, -3.4090],\n",
       "                        [-3.5182, -3.5750, -3.3125],\n",
       "                        [-2.8591, -2.2255, -3.4907]],\n",
       "              \n",
       "                       [[-2.1073, -3.1520, -3.7595],\n",
       "                        [-2.5730, -2.0243, -3.1251],\n",
       "                        [-3.6950, -3.2891, -3.7837]]]])),\n",
       "             ('module_list.0.posterior_params.2.scale_mus',\n",
       "              tensor([[[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]],\n",
       "              \n",
       "              \n",
       "                      [[[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]],\n",
       "              \n",
       "                       [[1., 1., 1.],\n",
       "                        [1., 1., 1.],\n",
       "                        [1., 1., 1.]]]])),\n",
       "             ('module_list.0.posterior_params.3.param_mus',\n",
       "              tensor([-0.0347, -0.0540, -0.0008,  0.0293, -0.0292,  0.0349, -0.0176,  0.0116,\n",
       "                       0.0173,  0.0239,  0.0535,  0.0285,  0.0451, -0.0420,  0.0108, -0.0409,\n",
       "                       0.0453, -0.0289, -0.0493, -0.0556, -0.0361, -0.0034, -0.0584,  0.0529,\n",
       "                       0.0162, -0.0444,  0.0243,  0.0210, -0.0163,  0.0040,  0.0075, -0.0225,\n",
       "                      -0.0476,  0.0339,  0.0409, -0.0459,  0.0447,  0.0547,  0.0345, -0.0486,\n",
       "                       0.0053, -0.0136,  0.0179, -0.0266,  0.0421, -0.0030, -0.0182, -0.0482,\n",
       "                      -0.0340, -0.0338,  0.0125, -0.0354,  0.0531, -0.0226, -0.0371, -0.0432,\n",
       "                       0.0315,  0.0339, -0.0145,  0.0430,  0.0406,  0.0375, -0.0415, -0.0373])),\n",
       "             ('module_list.0.posterior_params.3.param_std_log',\n",
       "              tensor([-5.4569, -4.6801, -4.7204, -5.3099, -5.5642, -7.9669, -5.1158, -5.7351,\n",
       "                      -4.8519, -5.2321, -6.6220, -5.4749, -5.7233, -5.7436, -4.8307, -5.3099,\n",
       "                      -5.5596, -6.0521, -5.2583, -4.7860, -4.8898, -5.6637, -4.7467, -4.6643,\n",
       "                      -5.3782, -6.6473, -4.6510, -5.2890, -4.7336, -4.6367, -4.8326, -7.7491,\n",
       "                      -5.7414, -5.3058, -5.7958, -4.8864, -4.6670, -5.3566, -6.6464, -6.9234,\n",
       "                      -6.2836, -4.6365, -7.2882, -6.8838, -4.6835, -5.1239, -7.1621, -5.2982,\n",
       "                      -5.1323, -6.3269, -5.4452, -6.2584, -6.0409, -5.0412, -4.7253, -4.7920,\n",
       "                      -4.8736, -4.7333, -4.9122, -4.8091, -6.4931, -5.7098, -8.9380, -4.7787])),\n",
       "             ('module_list.0.posterior_params.3.scale_alphas_log',\n",
       "              tensor([-2.0096, -3.1070, -2.4744, -2.8249, -2.1330, -2.1949, -3.7866, -3.2097,\n",
       "                      -3.8550, -3.1583, -3.0586, -2.9922, -2.6323, -2.1886, -2.5555, -2.2712,\n",
       "                      -2.9222, -2.3903, -2.9189, -2.6913, -2.1877, -2.3527, -2.1297, -3.1475,\n",
       "                      -2.6098, -2.0891, -3.4339, -2.4926, -3.6903, -2.8732, -2.1957, -3.5118,\n",
       "                      -2.2983, -3.3832, -3.4829, -2.7464, -3.3553, -3.5355, -2.4428, -3.0015,\n",
       "                      -2.7173, -2.5134, -3.9719, -2.8202, -2.6662, -3.1703, -2.6489, -2.1131,\n",
       "                      -2.0383, -3.8398, -2.6632, -2.2751, -2.4046, -2.9891, -2.8446, -3.0018,\n",
       "                      -2.0600, -3.5996, -3.0579, -2.5789, -3.7129, -2.4109, -2.5351, -3.2553])),\n",
       "             ('module_list.0.posterior_params.3.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('module_list.0.posterior_params.4.param_mus',\n",
       "              tensor([[ 0.0009,  0.0158,  0.0126,  ..., -0.0105, -0.0025, -0.0128],\n",
       "                      [ 0.0080, -0.0029, -0.0087,  ...,  0.0028, -0.0101,  0.0126],\n",
       "                      [ 0.0150, -0.0064, -0.0075,  ..., -0.0084, -0.0034, -0.0038],\n",
       "                      ...,\n",
       "                      [-0.0002, -0.0109,  0.0178,  ..., -0.0034, -0.0082, -0.0020],\n",
       "                      [-0.0095,  0.0160, -0.0090,  ..., -0.0084,  0.0039,  0.0121],\n",
       "                      [-0.0176, -0.0070,  0.0146,  ..., -0.0085,  0.0145, -0.0063]])),\n",
       "             ('module_list.0.posterior_params.4.param_std_log',\n",
       "              tensor([[-5.0882, -5.6143, -5.0647,  ..., -5.6104, -4.6591, -4.9445],\n",
       "                      [-4.6745, -5.9688, -5.0048,  ..., -6.3473, -4.6243, -6.2210],\n",
       "                      [-4.7615, -7.7854, -5.7147,  ..., -7.3079, -5.9162, -5.9307],\n",
       "                      ...,\n",
       "                      [-6.7976, -5.2108, -5.6782,  ..., -5.2774, -5.6684, -6.0092],\n",
       "                      [-6.6351, -4.8296, -5.0264,  ..., -7.7251, -5.2107, -4.8150],\n",
       "                      [-7.3702, -8.7021, -4.7729,  ..., -4.8881, -4.7526, -5.0925]])),\n",
       "             ('module_list.0.posterior_params.4.scale_alphas_log',\n",
       "              tensor([[-2.3414, -2.7704, -3.4864,  ..., -2.1757, -3.9189, -2.2035],\n",
       "                      [-2.3410, -2.2061, -3.1260,  ..., -3.4673, -2.0878, -3.4667],\n",
       "                      [-3.9802, -2.7468, -2.0136,  ..., -2.2748, -3.8034, -2.2377],\n",
       "                      ...,\n",
       "                      [-2.4080, -2.7311, -2.1504,  ..., -3.6135, -2.4462, -2.0026],\n",
       "                      [-3.4683, -2.5169, -2.6618,  ..., -2.9077, -2.7889, -2.0861],\n",
       "                      [-2.1884, -3.1091, -3.6772,  ..., -2.2174, -2.0252, -2.5327]])),\n",
       "             ('module_list.0.posterior_params.4.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.5.param_mus',\n",
       "              tensor([-0.0112,  0.0141,  0.0014,  0.0127, -0.0057, -0.0123, -0.0136,  0.0164,\n",
       "                       0.0140,  0.0152,  0.0077,  0.0159, -0.0018, -0.0005,  0.0025,  0.0036,\n",
       "                       0.0174, -0.0110,  0.0078, -0.0102,  0.0028,  0.0009,  0.0105,  0.0106,\n",
       "                       0.0002, -0.0018,  0.0092, -0.0014, -0.0002,  0.0019,  0.0001,  0.0019,\n",
       "                      -0.0122,  0.0073, -0.0102, -0.0153, -0.0162,  0.0075,  0.0051,  0.0153,\n",
       "                       0.0129, -0.0160, -0.0173, -0.0098, -0.0150,  0.0157, -0.0045,  0.0022,\n",
       "                      -0.0135,  0.0099,  0.0101,  0.0171,  0.0014, -0.0172,  0.0025, -0.0021,\n",
       "                       0.0169,  0.0017,  0.0117, -0.0016,  0.0121, -0.0066, -0.0090, -0.0044,\n",
       "                      -0.0091,  0.0011, -0.0143,  0.0033, -0.0132, -0.0091, -0.0091, -0.0157,\n",
       "                       0.0127,  0.0111, -0.0166,  0.0143,  0.0017, -0.0061, -0.0174,  0.0098,\n",
       "                       0.0034, -0.0063,  0.0041, -0.0007, -0.0088, -0.0068, -0.0123, -0.0048,\n",
       "                       0.0054, -0.0105, -0.0157,  0.0175, -0.0124,  0.0101,  0.0101,  0.0164,\n",
       "                       0.0117, -0.0088, -0.0032,  0.0164,  0.0047,  0.0089, -0.0158, -0.0005,\n",
       "                       0.0097, -0.0070,  0.0082,  0.0131, -0.0131, -0.0050,  0.0024, -0.0050,\n",
       "                       0.0152,  0.0010, -0.0035, -0.0169,  0.0012, -0.0119, -0.0085, -0.0127,\n",
       "                       0.0139,  0.0060,  0.0050, -0.0074, -0.0137,  0.0144,  0.0127, -0.0140])),\n",
       "             ('module_list.0.posterior_params.5.param_std_log',\n",
       "              tensor([ -8.5058,  -4.9983,  -4.7748,  -6.4515,  -8.2332, -10.5456,  -5.4021,\n",
       "                       -8.7938,  -6.3761,  -5.5005,  -7.5101,  -5.7537,  -4.8349,  -6.5463,\n",
       "                       -4.9158,  -6.0935,  -7.2662,  -5.4875,  -5.6636,  -4.8700,  -4.7151,\n",
       "                       -4.7584,  -4.8736,  -5.3312,  -4.9649,  -4.9046,  -4.9326,  -7.3845,\n",
       "                       -6.0946,  -5.0042,  -4.9009,  -4.6594,  -5.4126,  -4.7578,  -5.2708,\n",
       "                       -7.4743,  -5.6484,  -5.0898,  -5.7023,  -5.2178,  -6.5615,  -7.9420,\n",
       "                       -5.2271,  -5.7446,  -5.1716,  -5.5231,  -5.2031,  -6.4824,  -4.7606,\n",
       "                       -5.7502,  -5.2827,  -6.0781,  -5.8726,  -5.0141,  -4.9438,  -8.0827,\n",
       "                       -5.3131,  -5.7115,  -4.7213,  -4.6253,  -4.7276,  -4.6258,  -5.1091,\n",
       "                       -5.2092,  -5.5085,  -5.6953,  -4.6783,  -4.9021,  -4.7901,  -4.9724,\n",
       "                       -5.9262,  -6.1041,  -5.0713,  -4.6735,  -6.4833,  -5.2216,  -5.1605,\n",
       "                       -4.9854,  -5.7718,  -6.8357,  -4.9983,  -6.0955,  -5.8611,  -5.9829,\n",
       "                       -4.8589,  -5.1603,  -6.4991,  -5.6061,  -5.8304,  -5.4435,  -4.6777,\n",
       "                       -4.7764,  -5.0857,  -4.9599,  -4.7925,  -4.8101,  -4.6988,  -4.6460,\n",
       "                       -5.2655,  -6.4285,  -5.7866,  -5.3847,  -5.1084,  -5.3568,  -5.4592,\n",
       "                       -5.4557,  -7.1196,  -4.6417,  -6.3491,  -4.9110,  -5.1545,  -4.8412,\n",
       "                       -5.2638,  -6.0338,  -4.9269,  -7.4436,  -5.8754,  -4.9944,  -5.3159,\n",
       "                       -5.9607,  -6.5675,  -6.2111,  -5.1559,  -7.5439,  -4.7024,  -5.7944,\n",
       "                       -4.7159,  -5.0060])),\n",
       "             ('module_list.0.posterior_params.5.scale_alphas_log',\n",
       "              tensor([-2.9711, -2.3029, -3.2661, -3.8841, -3.9730, -2.9972, -3.0801, -2.8908,\n",
       "                      -3.2214, -2.5367, -3.7855, -3.5761, -3.2829, -2.4807, -3.7627, -3.3901,\n",
       "                      -3.2457, -2.9323, -3.2918, -3.2453, -3.4675, -2.9678, -3.9310, -2.9987,\n",
       "                      -2.2035, -2.3976, -3.5818, -3.1568, -2.2656, -3.4460, -3.9424, -3.2561,\n",
       "                      -2.0742, -3.8532, -3.1280, -2.8851, -2.0143, -2.0730, -2.5920, -3.7779,\n",
       "                      -2.5698, -3.7920, -3.6548, -2.3358, -3.9477, -3.6476, -3.8149, -2.5764,\n",
       "                      -2.8168, -3.6043, -3.2515, -3.9662, -3.3422, -2.4601, -2.8934, -2.9427,\n",
       "                      -3.4763, -2.3204, -2.2301, -2.4737, -3.8858, -3.7568, -3.4567, -3.1788,\n",
       "                      -2.4339, -2.0268, -2.8586, -3.4026, -2.9261, -2.2214, -3.0145, -3.9870,\n",
       "                      -2.0210, -3.2889, -2.6818, -2.6525, -2.6215, -2.5191, -3.3091, -2.5133,\n",
       "                      -2.1772, -2.7749, -3.2064, -2.7597, -2.0681, -2.4307, -2.3182, -3.3219,\n",
       "                      -3.7947, -3.7979, -2.5180, -2.9864, -2.1951, -3.9902, -2.8577, -3.3741,\n",
       "                      -3.5462, -3.3496, -2.4838, -2.2125, -3.5979, -2.9471, -3.3925, -3.8978,\n",
       "                      -3.0267, -2.5021, -2.3832, -3.2529, -2.6711, -3.8071, -3.5777, -3.3519,\n",
       "                      -2.8422, -2.2266, -2.3704, -2.8740, -2.7499, -2.9441, -2.7132, -3.9846,\n",
       "                      -2.8880, -3.0201, -3.8964, -2.4971, -3.7383, -2.5198, -2.3017, -3.7625])),\n",
       "             ('module_list.0.posterior_params.5.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.])),\n",
       "             ('module_list.0.posterior_params.6.param_mus',\n",
       "              tensor([[ 0.0861,  0.0572,  0.0623,  ...,  0.0349, -0.0029,  0.0783],\n",
       "                      [ 0.0663, -0.0496, -0.0471,  ...,  0.0246, -0.0090,  0.0290],\n",
       "                      [ 0.0787, -0.0569, -0.0074,  ...,  0.0223,  0.0753,  0.0849],\n",
       "                      ...,\n",
       "                      [-0.0752, -0.0523,  0.0439,  ..., -0.0768, -0.0083, -0.0679],\n",
       "                      [-0.0070, -0.0547, -0.0404,  ...,  0.0185, -0.0464, -0.0533],\n",
       "                      [-0.0087, -0.0757, -0.0331,  ...,  0.0254, -0.0312,  0.0815]])),\n",
       "             ('module_list.0.posterior_params.6.param_std_log',\n",
       "              tensor([[-5.2017, -7.5709, -4.9455,  ..., -5.7424, -5.2740, -7.6515],\n",
       "                      [-5.7487, -5.2041, -5.0962,  ..., -6.7837, -5.8445, -6.4197],\n",
       "                      [-5.0128, -4.9754, -5.1209,  ..., -5.3098, -6.3397, -8.8992],\n",
       "                      ...,\n",
       "                      [-6.1798, -5.0020, -5.8882,  ..., -4.7352, -8.7045, -4.7601],\n",
       "                      [-6.9533, -5.3401, -4.6249,  ..., -4.6350, -4.9398, -4.7976],\n",
       "                      [-5.3153, -4.6354, -5.0823,  ..., -5.2240, -5.2665, -4.6325]])),\n",
       "             ('module_list.0.posterior_params.6.scale_alphas_log',\n",
       "              tensor([[-3.4896, -2.3144, -3.2581,  ..., -2.1586, -3.0065, -2.2661],\n",
       "                      [-2.4441, -2.0589, -2.5914,  ..., -3.1640, -3.8862, -2.6127],\n",
       "                      [-2.4363, -2.7432, -2.3645,  ..., -2.4624, -2.6623, -2.2037],\n",
       "                      ...,\n",
       "                      [-3.5581, -3.5343, -3.9614,  ..., -3.5155, -3.0719, -3.5733],\n",
       "                      [-3.6154, -3.6500, -2.4728,  ..., -2.0083, -3.4753, -2.4960],\n",
       "                      [-3.1972, -3.5865, -2.2273,  ..., -3.9335, -3.2613, -3.5673]])),\n",
       "             ('module_list.0.posterior_params.6.scale_mus',\n",
       "              tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      ...,\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "                      [1., 1., 1.,  ..., 1., 1., 1.]])),\n",
       "             ('module_list.0.posterior_params.7.param_mus',\n",
       "              tensor([ 0.0045,  0.0808, -0.0811,  0.0353,  0.0298, -0.0510, -0.0097,  0.0499,\n",
       "                       0.0105, -0.0429])),\n",
       "             ('module_list.0.posterior_params.7.param_std_log',\n",
       "              tensor([-5.2095, -5.1445, -5.7701, -4.7362, -6.1606, -5.0685, -5.4482, -5.0233,\n",
       "                      -5.1172, -4.9747])),\n",
       "             ('module_list.0.posterior_params.7.scale_alphas_log',\n",
       "              tensor([-2.7219, -3.5050, -3.6166, -2.6818, -2.5404, -2.2111, -2.9576, -3.6258,\n",
       "                      -2.4424, -2.8427])),\n",
       "             ('module_list.0.posterior_params.7.scale_mus',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_bayes.pt'))\n",
    "image1, label1 = test_dataset[10]\n",
    "image2, label2 = test_dataset[11]\n",
    "model(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:16906.90234375, KL Loss: 1690681.375, FitLoss: 0.09073139727115631, Accuracy 0.98, Prune parameters: 221821.0/421642\n"
     ]
    }
   ],
   "source": [
    "val_loss = 0.0\n",
    "val_acc = 0.0\n",
    "PRUNE = 1.0\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,  \n",
    "                                         batch_size=BATCH_SIZE,  \n",
    "                                         shuffle=False, \n",
    "                                         pin_memory=True) \n",
    "kl_loss = LogUniformVarKLLoss()\n",
    "trainer.params.prune_threshold = PRUNE\n",
    "test_result = trainer.eval(model, test_loader)\n",
    "acc = test_result.custom_losses['val_accuracy']\n",
    "print(f'Loss:{test_result.val_loss}, KL Loss: {test_result.dist_loss}, FitLoss: {test_result.fit_loss}, Accuracy {acc}, Prune parameters: {test_result.cnt_prune_parameters}/{test_result.cnt_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device=device)\n",
    "model.prune({'threshold': 1.0})\n",
    "model.set_map_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 4.2992e-03, -5.4342e-01, -0.0000e+00],\n",
      "          [ 3.9089e-01, -0.0000e+00, -0.0000e+00],\n",
      "          [ 8.2518e-01,  3.0815e-01, -2.3478e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8153e-02,  0.0000e+00, -0.0000e+00],\n",
      "          [ 4.4879e-01,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.4131e+00, -7.5729e-01, -0.0000e+00],\n",
      "          [ 2.0788e-01,  4.6619e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  2.6288e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  9.8380e-01,  3.4592e-01],\n",
      "          [-0.0000e+00,  4.0430e-01,  0.0000e+00],\n",
      "          [-8.4115e-01, -3.8792e-01, -1.5979e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0565e-01,  0.0000e+00,  2.3229e-01],\n",
      "          [ 0.0000e+00,  6.6020e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -3.2411e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00,  3.8068e-01,  0.0000e+00],\n",
      "          [-1.7023e-03,  7.2274e-01,  1.6451e-01],\n",
      "          [-2.6313e-01,  0.0000e+00, -8.0280e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  7.1311e-01, -0.0000e+00],\n",
      "          [ 7.3480e-01,  0.0000e+00, -6.3528e-01],\n",
      "          [ 1.7638e-02, -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8662e-01,  4.1352e-01,  7.5745e-01],\n",
      "          [ 3.4204e-03, -2.4012e-03,  1.9629e-01],\n",
      "          [-0.0000e+00, -1.8996e+00, -5.4733e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7047e-01, -0.0000e+00, -4.2426e-02],\n",
      "          [-0.0000e+00,  8.9670e-01,  8.5076e-01],\n",
      "          [-4.0429e-01,  5.5609e-01, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  1.1400e-01],\n",
      "          [ 0.0000e+00,  4.4838e-01, -0.0000e+00],\n",
      "          [ 4.5566e-02, -0.0000e+00, -1.9310e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.7405e-02,  2.3569e-01, -0.0000e+00],\n",
      "          [ 4.6704e-01,  8.9131e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -1.1183e-02, -6.1903e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 5.3916e-02,  1.3328e-02, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4441e-01,  0.0000e+00, -2.3364e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  7.9347e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6268e-01,  0.0000e+00, -0.0000e+00],\n",
      "          [ 6.3382e-01,  3.4143e-01, -0.0000e+00],\n",
      "          [-0.0000e+00, -3.0772e-01, -8.3751e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0354e-01,  0.0000e+00, -0.0000e+00],\n",
      "          [ 4.2287e-01,  0.0000e+00,  3.6846e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.1328e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0544e-01, -1.0880e+00, -1.3626e+00],\n",
      "          [ 0.0000e+00,  4.4564e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  6.4581e-01,  3.5768e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  3.1633e-01, -6.6071e-01],\n",
      "          [ 0.0000e+00,  2.3753e-01, -0.0000e+00],\n",
      "          [ 3.6975e-01, -5.6517e-03, -6.6312e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.1901e-01,  6.4522e-02,  2.1885e-01],\n",
      "          [-0.0000e+00,  6.1452e-01,  4.0866e-01],\n",
      "          [-1.2748e-01,  5.6207e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.3363e-01, -0.0000e+00, -0.0000e+00],\n",
      "          [ 2.1696e-01,  0.0000e+00,  6.1144e-02],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.8670e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  6.6921e-01,  3.2235e-01],\n",
      "          [-0.0000e+00,  4.6664e-01,  1.8888e-01],\n",
      "          [-5.4447e-01, -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.0248e-01, -0.0000e+00,  1.2330e-01],\n",
      "          [-0.0000e+00,  0.0000e+00,  6.1526e-01],\n",
      "          [-1.3471e-01,  3.3910e-01,  2.8420e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  2.2249e-01,  0.0000e+00],\n",
      "          [ 1.4262e-01,  8.8915e-01,  0.0000e+00],\n",
      "          [-0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1939e+00, -4.6484e-01, -0.0000e+00],\n",
      "          [-8.6274e-01,  1.4272e-01,  0.0000e+00],\n",
      "          [ 1.0309e-01,  4.9730e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.1762e-01, -1.4468e-01, -0.0000e+00],\n",
      "          [ 3.6268e-01,  5.3481e-01,  0.0000e+00],\n",
      "          [ 0.0000e+00,  5.2241e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00,  0.0000e+00,  1.2648e-01],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.5915e-01],\n",
      "          [-0.0000e+00,  0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3550e-02,  0.0000e+00,  6.7948e-02],\n",
      "          [ 5.6981e-01,  0.0000e+00,  4.5842e-01],\n",
      "          [ 2.9938e-02,  1.7861e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  3.6278e-01, -2.5424e-01],\n",
      "          [ 9.4070e-01,  0.0000e+00, -2.1502e-02],\n",
      "          [ 9.6985e-03,  6.5121e-02, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  9.1819e-02],\n",
      "          [ 0.0000e+00, -0.0000e+00, -3.3740e-01],\n",
      "          [-0.0000e+00, -0.0000e+00, -2.1633e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3137e-02, -0.0000e+00, -0.0000e+00],\n",
      "          [ 5.4615e-01,  2.9908e-01, -0.0000e+00],\n",
      "          [ 9.4902e-01,  2.2312e-01, -3.2910e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6456e-02, -3.2759e-01, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  3.7491e-01]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -1.7607e-01, -7.8085e-02],\n",
      "          [-0.0000e+00,  1.0843e+00,  0.0000e+00],\n",
      "          [-7.0030e-02,  0.0000e+00,  1.0573e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  9.0907e-01],\n",
      "          [-1.3929e-01, -2.4492e-01,  0.0000e+00],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00]]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.base_module.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = test_dataset[100]\n",
    "plt.imshow(image.permute(1, 2, 0), cmap = 'gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2.1405], device='cuda:0'),\n",
       "indices=tensor([5], device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(model(image.cuda()).data, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
